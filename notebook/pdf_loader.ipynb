{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8fa813f",
   "metadata": {},
   "source": [
    "RAG Pipelines- Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f26d7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89b7f2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini API configured successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "print(\"✅ Gemini API configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "868f1262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 PDF files to process\n",
      "\n",
      "Processing: 12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf\n",
      "  âœ“ Loaded 19 pages\n",
      "\n",
      "Processing: 12037624.pdf\n",
      "  âœ“ Loaded 30 pages\n",
      "\n",
      "Processing: RAG_Research_Paper_arkiv.pdf\n",
      "  âœ“ Loaded 21 pages\n",
      "\n",
      "Processing: Resume_Latest.pdf\n",
      "  âœ“ Loaded 1 pages\n",
      "\n",
      "Processing: __The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf\n",
      "  âœ“ Loaded 11 pages\n",
      "\n",
      "Total documents loaded: 82\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  âœ“ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ee25c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='12-Month Roadmap to Become a Production-Ready\\nAI Engineer (Agentic AI Specialization)\\nOverview: This roadmap is tailored for Yash – a 4th-year ECE student with basic Python, math, and ML\\nknowledge – to transform into a production-ready AI Engineer specialized in Agentic AI over 12 months.\\nYash  will  dedicate  ~8  hours  daily.  The  plan  is  divided  into  monthly  phases  with  clear  goals,  hands-on\\nprojects,  and  curated  resources.  To  minimize  dropout  risk,  we  emphasize  project-based  learning and\\nspaced repetition (regularly revisiting past concepts) to reinforce knowledge. By the end, Yash will have a\\nstrong portfolio (GitHub projects and YouTube content on his channel “Engimemer”) demonstrating skills in\\nbuilding agent-based AI applications (AutoGPT-like systems) and the confidence to pursue FAANG-level\\nroles or AI freelancing.\\nMonth 1: Foundations – Python Mastery & Math Refresher\\nFocus: Build a strong foundation in programming and mathematics for AI.\\nKey Learning Goals: Solidify intermediate Python skills and refresh essential math for ML.\\nSpecifically, master Python language constructs (functions, OOP) and data handling libraries, and\\nreview linear algebra (vectors, matrices, eigenvalues), basic calculus (derivatives, gradients), and\\nprobability/statistics (mean, variance, Bayes’ theorem). \\nCore Concepts & Tools: Python best practices (writing clean, efficient code); using Jupyter/VS Code\\nand Google Colab for experiments; NumPy for matrix operations, Pandas for data manipulation,\\nMatplotlib/Seaborn for plotting. Math concepts like matrix multiplication, differentiation (for\\ngradient descent), and statistical thinking for data analysis. \\nBest Resources:\\nPython: “Automate the Boring Stuff” (for practice scripts) and Real Python tutorials on OOP . \\nMath: Khan Academy or Mathematics for Machine Learning (online book) for linear algebra &\\ncalculus refresh. \\nStatQuest (YouTube) – excellent simple videos on stats and linear algebra concepts (e.g. StatQuest’s\\nlinear regression, PCA videos). \\nfast.ai’s optional math review sections or Gilbert Strang’s MIT lectures for linear algebra (if deeper\\ndive needed). \\nProjects & Portfolio:\\nCode a simple linear regression from scratch (no ML libraries) to predict a small dataset (e.g.\\nhouse prices). This solidifies math-programming synergy. Visualize the fit line and error\\nconvergence. Publish this on GitHub. \\nYouTube Opportunity: Create a vlog-style video explaining how linear regression works and walking\\nthrough your implementation. This helps cement your understanding and kicks off your Engimemer\\nchannel content. \\nSpaced Repetition: Start making flashcards or notes for key formulas (e.g. matrix operations,\\nderivative rules). Review these weekly to build long-term retention.\\n• \\n1\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n1'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Month 2: Machine Learning Basics – Models & Pipeline\\nFocus: Grasp classic ML algorithms and the end-to-end ML workflow by building your first ML projects.\\nKey Learning Goals: Understand the ML pipeline: data preprocessing, feature engineering, model\\ntraining, evaluation, and iteration. Learn core algorithms in supervised learning (regression,\\nclassification) and unsupervised learning. Key topics include train/test splits, overfitting vs.\\ngeneralization, and performance metrics. \\nCore Concepts & Tools: Supervised vs. unsupervised learning; algorithms like linear & logistic\\nregression, decision trees, k-NN, SVMs for basics; clustering (k-means, DBSCAN) for\\nunsupervised. Tools: scikit-learn (implementing algorithms and pipeline), pandas for data cleaning,\\nand matplotlib for result visualization. Also introduce version control (Git/GitHub) to manage code. \\nBest Resources:\\nAndrew Ng’s Machine Learning Specialization (Coursera) – covers regression, classification,\\nclustering, etc., providing a solid theoretical grounding. \\nHands-On Machine Learning with Scikit-Learn & TensorFlow (Aurélien Géron) – a practical book\\nto reference implementations and tips. \\nStatQuest – continue using videos for intuitions on algorithms (e.g. StatQuest’s decision tree and\\nPCA videos). \\nscikit-learn docs & tutorials – to learn API usage for training models and evaluating them. \\nProjects & Portfolio:\\nEnd-to-End ML Project: Pick a simple dataset (e.g. Titanic survival or California housing prices).\\nPerform data cleaning, exploratory analysis (visualize key patterns), then train a model (e.g. logistic\\nregression or decision tree). Evaluate with appropriate metrics (accuracy for classification or RMSE\\nfor regression). Finally, deploy this as a simple app – e.g., a Streamlit or Gradio web app where a\\nuser can input features and get a prediction. This exposes you to the full lifecycle. \\nOptionally, tackle a second project focusing on unsupervised learning (e.g. use k-means to cluster a\\ndataset and visualize results) to appreciate different ML paradigms. \\nYouTube Opportunity: Create a tutorial video “How I built my first ML model to predict Titanic\\nsurvivors” – show data exploration, model intuition, and a live demo of your app. This not only builds\\nyour portfolio but also reinforces your understanding by teaching it. \\nSpaced Repetition: Continue weekly reviews of last month’s math (e.g., quiz yourself on what\\noverfitting means or the formula for linear regression). Also begin a habit of summarizing each\\ncompleted project’s learning points and revisiting them later .\\nMonth 3: Deep Learning Fundamentals – Neural Networks from\\nScratch\\nFocus: Dive into deep learning basics, learning how neural networks work and training simple networks.\\nKey Learning Goals: Build intuition for neural networks (why and how they learn). Key concepts\\ninclude the perceptron, activation functions (ReLU, sigmoid), forward and backward propagation,\\nloss functions (e.g. cross-entropy), and optimizers like SGD/Adam. By month’s end, you should be\\nable to implement and train a basic neural network and understand the math of backpropagation. \\nCore Concepts & Tools: Neural network architecture (layers, weights, biases), gradient descent and\\nhow gradients are used to update weights, problems like vanishing gradients. Frameworks: PyTorch\\n• \\n2\\n• \\n3\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n2\\n• \\n• \\n• \\n• \\n4\\n• \\n2'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='or TensorFlow – choose one (PyTorch is popular in research/startups, so you might start there). Also\\nfamiliarize with Keras (which can be used via TensorFlow) for quick prototyping. Tools: Google\\nColab for GPU access (since training even simple networks will be faster with a GPU – start utilizing\\nfree Colab GPUs). \\nBest Resources:\\nDeepLearning.AI’s Deep Neural Networks (Andrew Ng) – part of the Deep Learning Specialization,\\nit covers forward/backprop in detail and is math-friendly. \\nfast.ai – Practical Deep Learning for Coders (Part 1) – a top-down approach: you start training\\nstate-of-the-art models (with less math), which can be motivating. Fast.ai’s course is very hands-on\\nand emphasizes experimentation first, aligning well with our project-based philosophy (Hugging\\nFace even recommends doing an intro DL course like fast.ai or DeepLearning.AI before advanced\\ntopics). \\nAndrej Karpathy’s “Neural Networks: Zero to Hero” (YouTube) – Karpathy builds neural nets and\\na mini-GPT from scratch in code. The early videos (micrograd, makemore series) are excellent to see\\nbackpropagation and training loop coded line-by-line. This can deeply solidify your\\nunderstanding of how everything works under the hood. \\nPyTorch official tutorials – to learn the basics of tensor operations and autograd, once you grasp\\nthe manual concepts. \\nProjects & Portfolio:\\nNeural Net from Scratch: Implement a simple multilayer perceptron using only NumPy (no high-\\nlevel library) to classify a small dataset (e.g. classify handwritten digits 0–9 from the MNIST dataset).\\nThis means coding the forward pass and backpropagation manually. It’s challenging, but doing this\\nfor even a small network (e.g. one hidden layer) will cement your understanding of how gradients\\nflow. \\nDeep Learning Project: Using a framework (PyTorch/Keras), train a feed-forward neural network on\\nMNIST or a similar dataset. Aim for good accuracy on validation data. This lets you focus on\\nusing library components (layers, loss functions, optimizers) now that you understand what they do.\\nSave this project to GitHub, including instructions to run it on Colab (since you may not have a local\\nGPU). \\nYouTube Opportunity: Create a video titled “I built a neural network from scratch in Python” –\\nexplain the concept of backpropagation in simple terms and demo your NumPy network learning to\\nrecognize digits. This not only advertises your skill but also helps you review the concept by teaching\\nit. \\nSpaced Repetition: This month introduces many new concepts – make flashcards for definitions\\n(e.g. “What is an activation function? Give examples.” or “What does the derivative of ReLU look\\nlike?”). Revisit your math cards from prior months to keep the fundamentals fresh, since deep\\nlearning heavily uses them (e.g., understanding gradients).\\nMonth 4: Deep Learning Expanded – Computer Vision and/or NLP\\nBasics\\nFocus: Broaden your deep learning skills to new data types. You can split this month between Computer\\nVision (CNNs)  and  Natural  Language  Processing (RNNs/transformers  basics),  or  focus  more  on  one\\n5\\n• \\n• \\n• \\n6\\n• \\n7 8\\n• \\n• \\n• \\n• \\n9\\n• \\n• \\n3'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='domain based on interest. Given the end-goal of agentic AI (which leans toward NLP/LLMs), prioritize NLP if\\nneeded, but a taste of CV will make you well-rounded.\\nKey Learning Goals (CV): Understand Convolutional Neural Networks (CNNs) for image data –\\nconvolution/pooling operations, architectures like LeNet/ResNet, and why CNNs excel in vision tasks\\n. Learn about using pretrained models and transfer learning (e.g. using a pretrained ResNet on a\\nnew small image dataset). \\nKey Learning Goals (NLP): Understand basics of text representation – text preprocessing\\n(tokenization, embeddings like word2vec), and how sequence models work. Recurrent Neural\\nNetworks (RNNs) and LSTMs were traditional approaches; understand their role and limitations (e.g.\\nvanishing gradients in long sequences). Introduce the concept of the Transformer architecture,\\nwhich overcomes those limitations and forms the backbone of modern LLMs. By the end, you\\nshould grasp why transformers replaced RNNs for NLP , even if you don’t deeply train an RNN. \\nCore Concepts & Tools:\\nCV: Convolutions, filters/kernels, feature maps, common CNN layers. Tools: PyTorch/TensorFlow\\nwith CNN modules (e.g. torchvision for datasets and pretrained models). Possibly experiment\\nwith OpenCV for basic image processing to augment understanding. \\nNLP: Text cleaning (stopwords, stemming – though less needed with modern models), word\\nembeddings (learn what they are conceptually), sequence modeling. Tools: experiment with a simple\\nRNN using Keras or PyTorch’s nn.LSTM. Also introduce Hugging Face Transformers library at a\\nhigh level – for example, try using a pre-trained BERT or GPT-2 model for a simple task to see the\\ntransformer in action (more on this next month). \\nBest Resources:\\nDeepLearning.AI’s courses on CNNs and Sequence Models (Andrew Ng) – these provide a solid\\nbase in each domain (CNN course covers ConvNet architectures, Sequence course covers RNN,\\nLSTM, and an intro to attention mechanism). If pressed for time, focus on sequence models because\\nLLMs/Agentic AI will build on that. \\nfast.ai Course (if following) – fast.ai’s early lessons cover CNNs for image classification in a very\\nhands-on way (you build an image classifier in Lesson 1 itself with transfer learning). This is\\nmotivating and teaches practical tips. They also cover an NLP segment where you fine-tune an AWD-\\nLSTM on text – insightful even if LSTMs are now older , because it teaches how to handle text data. \\nStanford CS231n (for CV) – lecture videos or notes (if you want deeper theoretical knowledge of\\nCNNs and vision tasks). \\nStanford CS224n (for NLP) – lectures on NLP and transformers by leading researchers (good to\\ndeepen theory behind attention and transformers). \\nYouTube: 3Blue1Brown’s video “But what is a convolution?” (for an intuitive visualization), and\\nStatQuest’s “RNNs and LSTMs” for simple explanations of these concepts. \\nProjects & Portfolio:\\nComputer Vision Project: Build and deploy a simple image classifier. For example, collect or use a\\ndataset of, say, plant diseases or traffic signs (something small). Train a CNN to categorize images. If\\nusing a small dataset, apply transfer learning with a pretrained model (e.g., fine-tune ResNet on your\\ndataset) – a valuable real-world skill. Aim to achieve decent accuracy, and deploy this model as a web\\ndemo (perhaps on Hugging Face Spaces or a simple Flask app). This demonstrates the ability to\\napply deep learning to real data. \\nNLP Project: Build a text classifier or chatbot. For instance, create a sentiment analysis model for\\nmovie reviews. You could fine-tune a pre-trained transformer (like DistilBERT) on a movie reviews\\ndataset to classify sentiment. This will expose you to the Hugging Face ecosystem and transformer\\n• \\n10\\n• \\n11\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n4'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='fine-tuning in practice. (If computing resources are an issue, use Google Colab with free GPU for\\ntraining, or choose a smaller model and smaller dataset to fine-tune.) By now, you may start\\nChapter 1–4 of Hugging Face’s free Transformers course, which walks through using pre-trained\\nmodels and fine-tuning – it’s a great guided project that will result in a model you can share on\\nHugging Face Hub. \\nYouTube Opportunity: For the CV project, make a video like “Building an AI that recognizes plant\\ndiseases” – show how you collected data and how the CNN performs (people love visual demos). For\\nthe NLP project, consider a video titled “Fine-tuning my first Transformer model” – explain in simple\\nterms what BERT is doing and show your model in action. These not only market your skills but also\\nforce you to articulate complex concepts clearly. \\nSpaced Repetition: This is a content-heavy month. Leverage spaced repetition by frequently\\nrevisiting earlier lessons – e.g., when learning transformers, recall how an RNN works and how a\\nCNN works; this comparative thinking reinforces memory. Quiz yourself: “Why might an LSTM be\\ninsufficient for long text?” or “What does a convolution filter do?”. Also keep using your Anki/flashcards\\nfor math and DL basics (the cumulative knowledge will soon be applied in building LLM-based\\nagents).\\nMonth 5: Mastering Transformers – Hugging Face and LLMs\\nFocus: Deep dive into transformers and large language models (LLMs), and become proficient with the\\nHugging  Face  ecosystem  for  NLP .  This  month  transitions  from  traditional  ML/DL  into  the  realm  of\\ngenerative AI and LLMs, which is core for agentic AI. \\nKey Learning Goals: Gain a solid understanding of how Transformer architectures work (self-\\nattention mechanism, encoder-decoder vs decoder-only models), and how modern LLMs (GPT, BERT,\\netc.) are built on these principles. Learn to use pre-trained LLMs from Hugging Face for various tasks\\nand fine-tune them on custom data. By the end of the month, you should comfortably load a model\\nfrom Hugging Face Hub, use it for inference (text generation, classification, etc.), and know the\\nworkflow for fine-tuning a model on a new dataset. \\nCore Concepts & Tools: Transformers theory (multi-head attention, positional embeddings, etc.),\\ndifferences between model types (e.g. BERT is an encoder-only transformer good for understanding\\ntasks, GPT-3 is decoder-only, etc.), the concept of transfer learning in NLP (pretrain on large corpus,\\nfine-tune on task). Tools: Hugging Face Transformers library (APIs like AutoModel, \\nAutoTokenizer), Hugging Face Datasets (to load common NLP datasets easily), and using \\nHugging Face Hub to find and use community models. If resources allow, familiarize with Google\\nColab Pro or Kaggle Kernels for longer training jobs. Also, practice using Git and GitHub more as\\nyou handle larger code/projects – this is part of being production-ready. \\nBest Resources:\\nThe Hugging Face Course (Transformers) – complete this course this month. It’s free and covers\\nusing Transformers, fine-tuning, and even deploying models. Chapters 1-8 will teach you how to\\nload models, tokenize data, fine-tune on a dataset, and share your model. (Chapters 9+ go into\\nbuilding demos and advanced topics – which you will find useful for sharing your work and for next\\nmonth’s advanced LLM techniques.) This course is highly recommended as it’s hands-on and up-to-\\ndate with the latest Hugging Face tools, which are industry-standard. \\nAnnotated Transformer (blog or video by Harvard NLP) – for an in-depth look at the original\\nTransformer model “Attention is All You Need”. This can solidify your theoretical understanding. \\n12\\n• \\n• \\n• \\n• \\n• \\n• \\n12\\n• \\n5'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content=\"Andrej Karpathy’s “Let's build GPT” video – if you haven’t already, watch Karpathy’s video where he\\nlive-codes a GPT-like mini model. It’s a fantastic way to see how pieces of a transformer\\n(tokenization, self-attention, etc.) come together in code. This can be dense, but it connects theory to\\nimplementation. \\nYouTube & Blogs: Look up “Transformers from scratch” by Jay Alammar (famous visual illustrations\\nof how transformer attention works) and Simplilearn or StatQuest summaries on transformers for\\nintuitive explanations. Also consider the Hugging Face YouTube channel – they often have videos\\nfor beginners on using their library. \\nProjects & Portfolio:\\nFine-tune an LLM: Choose a task and fine-tune a pre-trained transformer on it. For example, create\\na Question-Answering system on a niche dataset: use Hugging Face to fine-tune a smaller model\\n(like DistilBERT or RoBERTa) on a QA dataset (SQuAD or a custom set of Q&A pairs you prepare). This\\nteaches you the end-to-end of customizing an LLM. After fine-tuning, evaluate it and upload your\\nmodel to Hugging Face Hub (so others can see/use it, and you can reference it on your resume). \\nHugging Face’s course actually guides you through such a project, so follow that closely. \\nBuild a Language Generation Demo: Using an open-source language model (like GPT-2 or\\nEleutherAI’s GPT-Neo), build a fun demo – e.g., a text generator that completes a sentence or writes\\nshort stories on prompts. You can do this without fine-tuning (just use the pre-trained model with a\\nprompt) or fine-tune it on a specific style (say Shakespearean text) if resources permit. Host this as a\\nHugging Face Space (they support Gradio apps for free) so you have a live demo in your portfolio\\n. \\nYouTube Opportunity: Publish a video titled “Fine-tuning a Transformer model (Hugging Face\\nCourse Review)” – share your screen as you walk through the fine-tuning process you did, explaining\\neach step (loading data, training, evaluating). For the generation demo, you could do a creative piece\\nlike “I taught a GPT-2 to write Shakespeare – here’s how!”. These make for engaging content and\\ndemonstrate your practical skills with LLMs. \\nSpaced Repetition: Now that you’re dealing with a lot of new info, use spaced repetition for\\nterminology (e.g., “What is self-attention?”, “What does CLS token mean in BERT?”). Revisit your older\\nflashcards on ML basics – bridging old and new (e.g. compare how a transformer vs a simple neural\\nnet handles inputs). Also, consider writing a weekly summary of what you learned in a short blog or\\njournal – rephrasing concepts in your own words is a great review technique and can be content for\\nLinkedIn or Medium.\\nMonth 6: Projects & Portfolio Expansion – Applying What You’ve\\nLearned\\nFocus: Consolidate your knowledge by building multiple  portfolio-worthy projects. This month is about\\nlearning by doing – picking projects that integrate the skills from the first half of the year and pushing\\nthem a bit further . By now, you have a range of skills: classical ML, deep learning, and basic LLM usage. It’s\\ntime to showcase them and fill any small gaps in knowledge through practice. \\nKey Learning Goals: Gain confidence in independently scoping and executing AI projects end-to-\\nend. Solidify understanding of the entire workflow: problem formulation, data collection, model\\nselection, training, testing, and deployment. Also, learn how to present your projects (readme\\ndocumentation, clean code, brief reports) because employers and freelance clients value clarity. In\\naddition, start exploring Kaggle competitions or AI hackathons to experience real-world problem\\nsolving under constraints, which builds both skill and resume. \\n• \\n13\\n• \\n• \\n• \\n12\\n• \\n14\\n• \\n• \\n• \\n6\"),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Core Concepts & Tools: End-to-end project development, using mix of techniques (e.g., combining a\\npre-trained model with a custom algorithm). If any tool is still unfamiliar (say you focused on\\nPyTorch, you might try a small TensorFlow/Keras project to be versatile; or if you haven’t touched \\nSQL or data engineering basics, do so now as data handling is crucial in production). Additionally,\\nfamiliarize with basic software engineering practices: writing modular code, using git branches,\\nwriting tests for critical functions – these will elevate your code quality towards production-ready. \\nBest Resources:\\nReddit & Community insights: Browse r/learnmachinelearning and r/MachineLearning for “project\\nideas” threads. The community often shares what’s impactful. Also, review how top Kaggle kernels\\nare written – you’ll learn a lot about clean coding and analysis from them. \\nFull-Stack Deep Learning (fullstackdeeplearning.com) – a course/material that covers the practical\\naspects of ML projects (like setting up proper experiments, managing data, etc.). Skim relevant\\nsections to get ideas on best practices. \\nCoursera: “AI for Everyone” or “Data Engineering” – not mandatory, but if you feel weak on the\\n“data” side, a quick course or YouTube series on data pipelines, or one on software engineering for\\nML (Google has a free course on ML engineering professionalism) could be beneficial. \\nKaggle’s micro-courses (free) on topics like data cleaning, ML explainability, etc., to fill minor skill\\ngaps while doing projects. \\nProjects & Portfolio:(Aim to complete 2 projects this month, which can be smaller in scope since you’ll\\njuggle multiple.)\\nProject 1 – NLP or CV Application: Build a practical tool, for example an “AI Resume Reviewer.”\\nThis could use NLP to parse a resume and give feedback. Concretely: use a spaCy or transformer\\nmodel to extract entities (skills, experience), then some rules/ML model to score or suggest\\nimprovements. This project ties NLP with a real-world use-case and is appealing in a portfolio.\\nAlternatively, build a vision-based tool, e.g., an app that can take a picture of a circuit board and\\nidentify components (leveraging your ECE background) using a trained CNN. Focus on deployability:\\npackage it with a simple UI. \\nProject 2 – Open-Ended Creative Project*: Pick something that excites you – maybe a *generative\\nart or music project using AI, or a chatbot that uses multiple skills (sentiment analysis + response\\ngeneration). The goal is to have fun and be creative, which keeps motivation high. For instance,\\ncreate a chatbot for a specific domain (like a math tutor bot): it might use an LLM for the\\nconversation, but also incorporate a Python-based calculator tool for solving equations (this idea\\nforeshadows agentic AI with tool use). \\nProject 3 (Optional, Hackathon/Kaggle): Participate in a Kaggle competition or an online AI\\nhackathon this month. This will force you to apply your skills under time pressure and teamwork if\\nit’s a team hackathon. Websites like Lablab.ai regularly host GenAI hackathons – joining one\\nfocused on LLMs or agents can give you a taste of building agentic AI in a sprint. Even if you don’t\\nwin, the experience is invaluable and can be mentioned on your resume (“Participated in XYZ\\nHackathon, built a prototype that does …”). \\nPolish & Presentation: For each project, invest time in making it public-ready: a clean GitHub repo\\nwith a good README (describe the problem, solution, and how to run the code). If possible, deploy\\nthe project (web demo or at least screenshots) and include those in the repo or your portfolio\\nwebsite (if you have one). This will strengthen your profile significantly. \\nYouTube Opportunity: Each project can yield content. For Project 1, you could do a walkthrough\\ntitled “I built an AI Resume Reviewer – Here’s how it works”. For the creative project, maybe a more\\nfun video, “Tour of my AI chatbot that can do math homework!”. Also, consider making a vlog about\\nyour hackathon or Kaggle experience – sharing the approach you took, the mistakes, and lessons\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n15\\n• \\n16\\n• \\n7'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='learned (this humanizes your journey and might resonate with others learning). Regular uploads will\\nsteadily grow your Engimemer channel and also keep you reflecting on your learning. \\nSpaced Repetition: At this midpoint, review everything learned so far in a structured way. Spend a\\nday each week summarizing earlier material: re-derive the formula for backprop, sketch the\\ntransformer architecture from memory, etc. You might even create a “cheat sheet” of key AI concepts\\nlearned in 6 months. This not only helps retention but will be useful in interviews later . Continue\\nusing Anki or your flashcards for any new terms or formulas encountered in projects.\\n(By the end of Month 6, you should have 3-4 solid projects in your portfolio, showcasing different skills – exactly\\nwhat many AI recruiters look for. You’ve also built consistency in learning and doing, which will serve you\\nwell in the next, more specialized phase.)\\nMonth 7: Specialization – Introduction to Agentic AI (LangChain &\\nPrompt Engineering)\\nFocus: Enter the world of Agentic AI by learning how LLMs can be used as agents (software programs that\\nperceive, reason, and act). This month, you will learn prompt engineering in depth and start working with\\nframeworks like LangChain that simplify building AI agents. The goal is to understand how to make LLMs\\ndo things – e.g. perform a series of tasks or use external tools – which is the essence of AutoGPT-like\\nsystems.\\nKey Learning Goals: Develop prompt engineering expertise – crafting effective prompts to get\\nreliable outputs from LLMs, and using techniques like few-shot prompting. Understand the concept\\nof an AI agent: an LLM that can take actions (like calling tools or APIs) autonomously based on\\ninstructions. Learn what architectures like AutoGPT or BabyAGI are doing under the hood\\n(planning, tool use, memory) so you can build simpler versions. By end of month, you should be able\\nto create a basic agent that, given a goal, decides on steps and uses some tools to execute them. \\nCore Concepts & Tools: Prompt design principles (clarity, context, constraints). Advanced prompting\\nmethods: e.g., chain-of-thought prompting (getting the LLM to reason step by step) and few-shot\\nexamples to guide style/format. Understand prompt tokens and costs (to be cost-efficient). Tools: \\nOpenAI API (or another LLM API) – practice sending prompts and parsing outputs in code. \\nLangChain – a powerful framework for chaining LLM calls and integrating tools and memory. Learn\\nLangChain’s basics: what are “chains”, what are “agents”, how to use its components (it provides\\nabstractions for doing retrieval, using tools, maintaining conversation memory, etc.). Also introduce \\nvector databases conceptually here if you haven’t already (LangChain uses vector DBs for long-term\\nmemory and retrieval of facts). We will dive deeper into vector DB next month, but start thinking in\\nthat direction. \\nBest Resources:\\n“ChatGPT Prompt Engineering for Developers” (DeepLearning.AI short course) – this is a free 1.5-\\nhour course by OpenAI’s Isa Fulford and Andrew Ng that teaches prompt engineering best practices\\nand how to use LLM APIs. It’s concise and extremely relevant, covering how to structure\\nprompts, use temperature, etc., and even how to build a custom chatbot using an API. Go through\\nthis course early in the month – it will level up your prompting skills quickly with real examples. \\nLangChain for LLM Application Development (DeepLearning.AI short course) – another short\\ncourse, taught by LangChain’s creator Harrison Chase. In ~1.5 hours it covers LangChain’s core\\nconcepts: models, prompts, parsers, memory, chains, and agents. This is a perfect quickstart to\\n• \\n17 18\\n• \\n19\\n• \\n• \\n• \\n20\\n• \\n21\\n22\\n8'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='using LangChain effectively. Take this after the prompt engineering course; it will tie together\\nprompt skills with a framework to build things. \\nLangChain Documentation & Tutorials – LangChain’s official docs have a tutorial “Build an Agent”\\nthat shows how to create an agent that can use a search tool. Follow this step-by-step to build\\nyour first agent. They also explain various types of agents and tools integration – extremely useful\\nreading. \\nOpenAI Cookbook & Examples – OpenAI’s cookbook (on GitHub) has a section on using models\\nwith function calling (letting GPT-4 use tools) and other prompt tactics. Skim these recipes to learn\\npractical tips (e.g. how to format a prompt for a JSON output, etc.). \\nAnthropic’s “Building Effective Agents” guide – a blog post by Anthropic that discusses best\\npractices for AI agents (like when to use agents vs simple chains, how to handle tool use). It’s a great\\nread to develop an intuition for agent design choices, and many working AI engineers refer to it\\n. \\nCommunities: Join the r/AI_Agents subreddit and the LangChain community (Discord or forums).\\nSince agentic AI is so new, a lot of knowledge is shared in real-time on forums. Seeing others’\\nexperiments or issues will teach you a lot and keep you updated. \\nProjects & Portfolio:\\nPrompt Engineering Mini-Project: Design a complex prompt that turns GPT-4 (or another LLM) into\\nsomething useful, without coding an agent. For example, a prompt that makes the LLM a helpful \\ntravel planner (“You are a travel agent AI...”). Refine it to handle tricky inputs. This exercise in\\niterative prompt crafting will teach you how small wording changes impact outputs. Document your\\nfinal prompt and some chat transcripts as a portfolio piece (it shows your ability to coax functionality\\nfrom an API, which is a valuable skill on its own). \\nBuild Your First AI Agent: Using LangChain, create a simple agent that can perform a task using\\ntools. For instance, “Research Assistant Agent”: it takes a query, uses a web search tool (LangChain\\nhas search integrations) and then summarizes an answer . This involves the agent deciding to call the\\nsearch tool, then perhaps a calculator or wiki API, etc. Another idea: an “Email Assistant Agent”\\nthat reads your emails (you can feed it sample emails), and drafts replies using an LLM, possibly\\nusing a calendar API as a tool to check your availability when scheduling meetings. Keep the scope\\nnarrow so it’s achievable – e.g. one that uses 2 tools maximum. The goal is to get hands-on\\nexperience with the agent loop (LLM observes -> decides action -> tool -> new input -> LLM\\ncontinues...). You will encounter challenges like ensuring the agent doesn’t get stuck or making\\noutput formatted, which are great learning opportunities. \\nVectorstore Experiment (mini): Set up a simple vector database (could be as easy as using FAISS in\\nmemory) with a small custom text dataset (maybe a compilation of your own notes or a few articles).\\nHook it up with LangChain’s retrieval API to create a knowledge base. This isn’t a full project by\\nitself, but a tech demo: e.g., ask questions and have the system retrieve relevant info and feed it to\\nthe LLM (classic RAG pipeline). This will prepare you for next month where we do this more fully. \\nYouTube Opportunity: Share what you learn about prompt engineering – e.g., “5 Prompt Engineering\\nTricks I Learned” with examples (this can attract a lot of viewers given interest in ChatGPT tips). For\\nthe agent, do a live demo video: “Building my first AI agent with LangChain!” – show the agent in action\\n(maybe split-screen with code and it executing tasks). Even if it’s a simple research bot, viewers find\\nthe concept exciting, and it demonstrates cutting-edge skills. You could also reflect on failures or\\niterations, which shows your problem-solving process. \\nSpaced Repetition: As you venture into new territory, relate back to fundamentals. For example,\\nrecall how transformers and embeddings work (important for vector databases and prompt\\nembeddings), or how the ML pipeline works (when thinking about feeding info to LLMs). Revise\\nprevious notes on evaluation metrics – now you should think: How do I evaluate if my agent is “working\\n• \\n19\\n• \\n• \\n23\\n24\\n• \\n• \\n• \\n• \\n25\\n• \\n• \\n• \\n9'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='well”? Maybe by accuracy of retrieved info or user feedback. This meta-thinking will reinforce old\\nknowledge in a new context. Also, maintain your Anki deck for new LangChain terms or best\\npractices (“What is a LangChain agent?”, “Name 3 best practices for prompt design”). \\nMonth 8: Advanced Applications – Building with LLMs, Memory &\\nRetrieval (RAG)\\nFocus: Develop deep expertise in  Retrieval-Augmented Generation (RAG) and  long-term memory for\\nagents using vector databases, and build a substantial project that utilizes these. Also, get comfortable with\\nvarious LLM APIs/platforms (not just one) to increase your versatility. By the end of this month, you will\\nhave built an AI application that  combines an LLM with external knowledge, a critical capability for\\nagentic systems.\\nKey Learning Goals: Understand how to handle large knowledge with LLMs – since LLMs have\\ncontext length limits, we use embeddings + vector stores to give them relevant info on the fly.\\nMaster the workflow of creating embeddings for data, storing and querying a vector database. Learn\\nabout popular vector DB solutions (FAISS, Pinecone, Weaviate, etc.) and trade-offs (memory vs\\nspeed, local vs cloud service). Additionally, explore memory management in agent frameworks\\n(keeping conversation history, summarizing to compress memory, etc.). By now, you should also\\ndeepen your knowledge of various LLM providers – experiment with a new model or API (e.g.,\\nCohere, Anthropic Claude, open-source LLaMA2) to broaden your toolset. \\nCore Concepts & Tools: Embeddings (how text is converted to high-dimensional vectors, e.g. using\\nOpenAI’s text-embedding-ada model or Sentence Transformers). Vector database operations: insert,\\nsimilarity search. LangChain’s RetrievalQA chain or similar: feeding retrieved docs to LLM. Memory\\nin LangChain: short-term (conversation buffers) vs long-term (using a vector store as memory)\\n. Tools: Pick a vector DB – for learning, FAISS (an open-source library) is straightforward to use\\nlocally. You might also try Pinecone or ChromaDB for a managed solution (they have free tiers).\\nContinue with LangChain to integrate these pieces seamlessly. Also consider using Hugging Face\\nHub for embeddings/models if you want to try non-OpenAI models. If you haven’t yet, using a local\\nLLM (like Llama-2 13B on a Colab or smaller model on CPU) could be educational to see how to\\ndeploy models without an API – though this is optional if resources are limited. \\nBest Resources:\\nHugging Face Course, Chapter on “Build Reasoning Agents” – the later chapters of the HF course\\n(Ch. 11-12) cover fine-tuning LLMs and building reasoning models. These might touch on retrieval\\nand advanced use-cases – worth reading for a structured insight. \\nBlogs on RAG: “How to build a QA system with RAG” – many blog posts or Medium articles exist (e.g.\\nby AWS, Cohere, or independent bloggers) that walk through building a document Q&A bot with\\nLangChain + vector DB. Follow one of these tutorials to reinforce your understanding. \\nDeepLearning.AI short course: “Building and Evaluating Advanced RAG Applications” – (as\\nhinted in their site) if available, this could be very relevant. If not, seek out conference talks or\\nwebinars on RAG. For instance, Pinecone’s blog has articles on designing good RAG systems\\n(covering chunking strategies, etc.). \\nDocumentation: Read Pinecone’s docs or FAISS wiki to understand how vector search works under\\nthe hood (helps if you need to optimize or debug retrieval issues). Also, the LangChain docs on\\nMemory and on VectorStores are crucial – they provide code snippets and explain different types of\\nmemory (short-term vs long-term). \\n• \\n• \\n26\\n27\\n• \\n• \\n• \\n• \\n• \\n28 29\\n10'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Research papers (optional): If curious, skim the Retrieval-Augmented Generation paper by\\nFacebook (if available) or related literature to see the formal approach. And Anthropic’s work on\\n“Claude’s long documents” or OpenAI’s on “Retrieval for GPT” to know the state-of-art thinking\\n(optional but inspiring). \\nProjects & Portfolio:\\nCapstone Project Part 1 – “AI Research Assistant” (RAG System): Begin a major project that will\\nspan this month and next. Build an Agentic AI system that can ingest and use a knowledge base.\\nFor example, an agent that a user can ask questions, and if it doesn’t know the answer it will search a\\ncustom document repository to find relevant info and then answer (akin to an enterprise Q&A bot).\\nThis involves: \\nGathering a knowledge corpus (could be a set of PDFs or markdown notes – perhaps your\\nuniversity lecture notes or a collection of articles in a domain you like). \\nIndexing them: split into chunks, embed each chunk, store in a vector DB. \\nImplementing retrieval: given a query, get top relevant chunks. \\nFeeding them to an LLM with a proper prompt (prompt engineering to incorporate retrieved\\ninfo and cite sources perhaps). \\n(Optional advanced agent behavior) If the question requires multi-step reasoning, the agent\\nmight break it down. But even a single-step QA with retrieval is a huge accomplishment. \\nTest the system on various queries, refine chunk sizes or prompt as needed for better\\nanswers.\\nThis project solidifies many skills and is highly relevant to real-world applications (companies\\nlove this use-case). Make sure to log how well it answers questions (you can demonstrate it\\nanswering things that vanilla ChatGPT cannot because it has your custom data). \\nExperiment with Multi-LLM or Tools: As part of above or separate small experiment, try using a\\ndifferent model for embedding vs answering. For instance, use OpenAI’s API for answers but a local\\nmodel for embeddings, or vice versa. Or incorporate a new tool into your agent: e.g., a calculator or\\nPython REPL for math problems. This will teach you how to mix and match components for efficiency\\n(an important production consideration is cost and latency – e.g., using a smaller model when\\nappropriate). \\nIntermediate Deliverable: By end of this month, have a working Q&A system (even if not fully an\\nautonomous “agent”), which accepts user queries about your documents and returns answers with\\nreferences. This sets the stage for next month, where you can extend it into more of an “agent” with\\nplanning abilities. \\nYouTube Opportunity: Document this capstone’s development. For instance, “Building a GPT-4\\nPowered Research Assistant – Part 1” where you show how you set up the vector database and got the\\nQA working. This could be a series (audience loves following along a build). Explain concepts like\\nembeddings and RAG in simple terms while demoing. Not only does this educate your viewers, it\\nreinforces your own learning and demonstrates mastery to potential employers who might see it. \\nSpaced Repetition: At this advanced stage, spaced repetition might involve integrating knowledge.\\nFor example, explain to yourself (or in notes) how a concept from Month 2 (say, evaluation metrics)\\napplies when evaluating your QA system (you might think of precision/recall of relevant info). Revisit\\nyour flashcards on prompt engineering and see if your understanding has evolved – update them\\nwith new insights (e.g., you might add notes like “When doing retrieval+LLM, remember to prompt\\nthe model to only use provided info.”). Regularly revisit fundamentals like big-O complexity or\\nsystem design basics, since soon you’ll be interviewing and those may come up too.\\n• \\n• \\n• \\n◦ \\n◦ \\n◦ \\n◦ \\n◦ \\n◦ \\n• \\n30\\n• \\n• \\n• \\n11'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Month 9: Capstone – Building an Autonomous AI Agent (AutoGPT-\\nLite)\\nFocus: This month, you will integrate everything to build a showcase Agentic AI application – essentially\\nyour own simplified version of AutoGPT catered to a specific use-case. This is the culmination of your\\nspecialization, demonstrating you can orchestrate LLMs, tools, and knowledge bases to perform complex\\ntasks autonomously. Also, you’ll solidify production-level considerations while building this capstone.\\nKey Learning Goals: Learn to design an agent system architecture: breaking a problem into sub-\\ntasks that an AI agent can handle (planning). Implementing a loop where the agent can decide\\nactions (tool use or asking for more info) and stopping criteria. Handling errors or unexpected\\noutputs gracefully (robustness). Additionally, deepen understanding of production concerns: rate\\nlimits of APIs, error handling, logging agent decisions, and cost management. By the end, you’ll have\\na functioning multi-step agent and know how to evaluate and improve it. \\nCore Concepts & Tools: Planning algorithms for agents (e.g., the ReAct framework – reasoning and\\nacting iteratively). Tool integration in LangChain: ensure you know how to add custom tools. If not\\nalready, explore LangChain’s AgentExecutor and how it manages the loop. Memory\\nmanagement – possibly use a summary of past interactions to keep context short. Evaluation: learn\\nhow to test agent performance (maybe create specific scenarios to see if it succeeds, and log\\nresults). Continue using your chosen LLM API (perhaps GPT-4 if available for complex reasoning, due\\nto its strength in reasoning) along with cheaper models for simpler tasks (as a production-minded\\nstrategy). Possibly introduce guardrails (like OpenAI’s function calling or the Guardrails AI library) to\\nconstrain outputs – this is a cutting-edge practice to improve reliability. \\nBest Resources:\\nAuto-GPT and BabyAGI GitHub repos – review their README and maybe part of the code to\\nunderstand how those projects structure the agent loop and memory. You don’t need to replicate\\nthem fully, but it’s insightful to see how others implemented autonomous agents. \\nSoftware Engineering Daily podcast episode “LangChain and Agentic AI” – an interview with\\nHarrison Chase (LangChain creator) or similar talks on YouTube where developers discuss building\\nwith agents. These often reveal pitfalls and best practices (like how to avoid agents going in circles,\\netc.). \\nReddit - r/AI_Agents and r/LangChain threads – look for posts like “Lessons learned building an\\nagent” or “Why AutoGPT fails at X”. Community wisdom will teach you what not to do. In fact, one AI\\nengineer on Reddit shared tips: e.g., keep agents’ scope narrow, have each LLM call do one specific\\ntask, and show the agent’s reasoning steps for transparency. Such insights can guide your\\ndesign. \\nLangChain documentation (advanced): Specifically, read about custom Agents and agent policies.\\nLangChain now has features like Multi-Action Agents or using LangSmith for tracing – these are\\nmore advanced, but skimming these can give you ideas on improving your agent. \\nOpenAI/Anthropic docs on usage limits – ensure you know how to set API call limits or monitor\\nusage (OpenAI lets you set a quota) so that during development your agent doesn’t accidentally\\nrack up huge costs. This is an important production skill (cost management). \\nPossibly revisit Chip Huyen’s blog on LLM applications – especially sections on agents and tool use\\n, and the challenges of making them reliable. It will remind you to think about edge cases\\nand user expectations in production. \\nProjects & Portfolio:\\n• \\n• \\n19\\n• \\n• \\n• \\n• \\n25 31\\n• \\n• \\n32\\n• \\n33 34\\n• \\n12'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Capstone Project Part 2 – Autonomous Agent: Continue and complete the capstone started last\\nmonth by adding autonomous capabilities. Building on the “AI Research Assistant” (or whichever\\nRAG system you made), add a planning and tool-use layer. For example, enable the agent to\\nhandle a complex query like: “Summarize the key differences between these two research papers\\nand email the summary to my colleague.” This would require the agent to break it down: (a) search\\nor retrieve info on paper 1 and 2, (b) summarize differences, (c) formulate an email, (d) possibly\\nactually send an email via an email API (if you choose to integrate that tool). This is just an example –\\ndefine a scenario relevant to your interests. The agent should use multiple steps autonomously:\\nretrieving data, using a writing tool, maybe a calculation or API call, etc., without you intervening in\\neach step. Document the chain of thought: have the agent output or log its reasoning at each step\\n(this is great for demo and debugging). \\nTesting and Refinement: Once built, test your agent on a variety of tasks within its scope. Observe\\nfailure modes (does it get stuck in a loop? Does it ever hallucinate wrong info from outside the\\ndocs?). Refine by adjusting prompts or adding constraints. For instance, if it tends to hallucinate, you\\nmight enforce that it must quote sources for factual info, or if it loops, add a rule to break after N steps\\nwith a graceful response. This process teaches MLOps mindset – iterate to improve reliability. \\nFinalize Deployment: Deploy your capstone if possible. For instance, create a small web interface\\nfor it (a simple frontend where you input a query and see the agent’s plan and answer). If deploying\\nfully is hard, at least record a compelling demo of it working. Also, prepare a technical write-up in\\nyour GitHub repo or a Medium article about how you built this agent. This can be gold for your\\nportfolio – it demonstrates end-to-end project execution and thought leadership (few people have\\nwritten detailed guides on building agents – you could!). \\nYouTube Opportunity: This is the big one – create a showcase video: “I built my own Auto-GPT in 30\\ndays” or “Autonomous AI Agent demo – [Your Agent’s Name]”. In this video, present the problem it\\nsolves, show it performing a multi-step task live (with its thinking printed out), and explain how you\\nmade it. This is likely to attract attention given the hype around AI agents, and it serves as a\\ncapstone presentation of your skills. Share this video on LinkedIn, Reddit, etc. for feedback and\\nperhaps it catches the eye of recruiters or potential collaborators. \\nSpaced Repetition: At this point, spaced repetition is about interview prep and knowledge\\nsynthesis. Start reviewing topics you may not have touched recently: e.g., revisit how SVMs work or\\nhow backprop works – interviews might dig into fundamentals even if your focus was on LLMs. Use\\nflashcards for data structures and algorithms (you’ll need some for coding interviews at FAANG). Also\\nconsider doing a high-level review of all projects: can you summarize each project’s key idea and\\nlearning in a few sentences from memory? If not, review it. This prepares you to talk about them\\nfluently in interviews. Continue using spaced repetition for new things too (e.g., key lessons you\\nlearned about agent design – write those down and revisit).\\nMonth 10: Production Readiness – MLOps, Deployment, and\\nScalability\\nFocus: Shift gears to learn MLOps and deployment best practices. This month is about making sure you can\\ntake an AI model/agent and deploy it in a production environment reliably. You’ll also prepare for the job\\nhunt by aligning your skills with what industry expects (scalability, reliability, collaboration).\\nKey Learning Goals: Learn how to package and deploy models and AI systems as services.\\nUnderstand the concepts of containerization (Docker), CI/CD, and cloud deployment (AWS/GCP/\\nAzure) as applicable to AI apps. Learn to monitor a live AI system (logging, detecting failures or drift).\\n• \\n• \\n• \\n• \\n• \\n• \\n13'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Also, familiarize with ML experiment tracking (tools like MLflow or Weights & Biases) – in\\nproduction roles, being able to track model versions and experiments is valuable. Additionally, gain\\nknowledge of data pipelines: how to regularly update a model or feed it new data, and basics of\\nscheduling jobs. Essentially, aim to bridge the gap between a prototype (which you have built many\\nof) and a production-grade application that can handle real users and data. \\nCore Concepts & Tools: Containerization with Docker (create a Dockerfile for one of your apps,\\ncontainerize it with all dependencies). Serving models: using FastAPI or Flask to create an API\\nendpoint for your model/agent. Possibly look into streaming data and real-time considerations if\\nrelevant (for example, if your agent were to run continuously). CI/CD: using GitHub Actions to\\nautomate tests and deployments when you push updates. Cloud: pick one (say AWS) and learn basics\\n(AWS has free tier – try deploying your FastAPI app on AWS EC2 or using AWS Lambda for a simple\\nfunction, or use Heroku for simplicity). Learn about scaling: how would you scale an API that gets\\nheavy usage? (e.g., using load balancers, multi-instance). Also consider cost optimization: e.g. using\\nsmaller models or batching calls in a production setting to save cost. Security: understand basic\\nmeasures (storing API keys securely, not exposing secrets, etc.). \\nBest Resources:\\nFull Stack Deep Learning – their material on deployment and monitoring is very relevant (they talk\\nabout packaging models and setting up inference endpoints). \\nCoursera or Udacity MLOps courses – if available, doing a crash course on MLOps will systematize\\nthis knowledge. Andrew Ng’s MLOps specialization or Google Cloud’s ML Engineering courses\\ncould be useful. \\nAWS/GCP free tutorials – both AWS and Google have free training for deploying ML models (e.g.,\\nAWS SageMaker tutorials, GCP Vertex AI samples). Even if you don’t use the managed services now,\\nknowing they exist and how they work is good for interviews. \\nDocker Official Docs & DockerCaptain YouTube – to learn writing Dockerfiles and container basics.\\nFastAPI docs – FastAPI is a great tool to wrap your models into web services quickly. Their docs are\\nbeginner-friendly and you can have a simple “Hello World” model API running in minutes. \\n“Building LLM applications for production” by Chip Huyen – this blog (if you haven’t fully read it\\nyet) covers practical challenges in deploying LLM apps (like handling ambiguity in prompts,\\nversioning, evaluation). It’s basically a checklist of things to keep in mind so that your fancy LLM\\ndemo doesn’t break in the real world. Read it and reflect on how you can apply those principles to\\nyour capstone agent if you deployed it. \\nProjects & Portfolio:\\nDeploy Your Capstone Agent: Take the autonomous agent from last month and deploy it as a\\nservice. For example, wrap it in a FastAPI server where one endpoint /ask triggers the agent with\\na user query and returns the answer . Containerize this with Docker . Then try deploying it to a cloud\\nservice or at least run it on a cloud VM to simulate production. This exercise will expose issues\\n(memory usage, need for loading models efficiently, etc.). Ensure you include logging – have the\\nservice log each step of the agent’s reasoning to a file or console for monitoring. If possible, simulate\\na few concurrent users to see how it handles (you might realize the agent is stateful and needs\\nunique sessions or it’s slow – which is normal; note those findings). \\nCI/CD Pipeline: Set up a simple CI pipeline for one of your projects. For instance, use GitHub Actions\\nsuch that when you push to main on your capstone’s repo, it automatically runs tests (if you add any)\\nand maybe deploys to your server . This shows you understand DevOps culture. Document this in\\nyour project readme (“Using GitHub Actions to auto-deploy on update”). It’s a nice touch that many\\ncandidates lack. \\n• \\n30\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n35\\n• \\n• \\n• \\n14'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Freelance Simulation Project: Since one of your goals is freelancing, try a project that simulates a\\nfreelance task. For example, find a real problem on Reddit or Freelance boards – e.g., “I need a\\nscript to categorize a bunch of customer feedback using AI.” Then build a quick solution for it: maybe\\nfine-tune a model or use an off-the-shelf model via API, and deliver it as a script or small app. Do it\\nend-to-end in say 3-4 days as if it were a paid gig. This will teach working under requirements and\\nalso give you a template for similar future freelance tasks. You can write about this experience as\\nwell. \\nYouTube/Blog Opportunity: Create content focusing on the production aspect this time – e.g., \\n“How to deploy an AI model as an API (step-by-step)”. This could be a tutorial where you containerize\\nand deploy a smaller ML model (maybe your Month 2 model or a simple Hugging Face model) to a\\nfree service. Many find this educational, and it forces you to articulate the process. Additionally,\\nconsider writing a Medium blog post summarizing your capstone project with a focus on its\\nproduction design (“Building an AutoGPT-style agent and deploying it on AWS”). Writing an article\\ncan increase your visibility in the field (and you can add it to your resume). \\nSpaced Repetition: Now shift some focus to interview preparation content for spaced repetition.\\nFor example, use flashcards to remember key points that you might mention in interviews: big-O\\ncomplexities, definitions of overfitting vs underfitting, the trade-offs of different model types, etc.\\nRevisit any theoretical gaps you feel – e.g., if you skipped some math, review it now. Continue to\\nrevisit high-level summaries of each project and each major concept (by now you have a web of\\nknowledge – solidify the connections: how does an embedding from Month 8 relate to the cosine\\nsimilarity you learned in Month 1 math? How does Docker compare to a virtualenv from earlier\\nprojects? Connecting dots is a great memory tool).\\nMonth 11: Job Hunt Preparation – Polishing Skills and Portfolio\\nFocus: This month is about getting ready to land a job or freelance clients. We will polish your resume,\\nportfolio, and online presence, and prepare for technical interviews (both coding and ML system design).\\nWe’ll also ensure you leverage your YouTube channel and network for opportunities.\\nKey Tasks – Resume & Portfolio: Craft a strong resume that highlights your AI projects and skills.\\nEmphasize outcomes: e.g., “Built an autonomous research assistant agent using LangChain and\\nGPT-4, integrating vector database for 20k documents (GitHub, demo link)”. Quantify where possible\\n(even if just “achieved 90% accuracy on X” or “improved inference speed by Y% with optimization”).\\nInclude keywords like the tools and frameworks you know (TensorFlow, PyTorch, Hugging Face,\\nLangChain, Docker , etc.) so it passes automated scans. Also update your LinkedIn to reflect your\\nyear of projects – write a summary that you’re an AI engineer specializing in LLMs/agents, open to\\nopportunities. On GitHub, pin your best projects to showcase them. Ensure your project READMEs\\nare clear because recruiters will look at them. If you have a personal portfolio website, update it with\\nlinks to your YouTube videos and project write-ups – make it a one-stop-shop of your expertise. \\nKey Tasks – Networking: Start actively networking. Announce on LinkedIn the completion of your\\nyear-long learning journey, perhaps with a post sharing your Medium article or YouTube capstone\\ndemo. Engage with communities: e.g., on Twitter (X) share insights or small threads about\\nsomething cool you learned about agents (tagging relevant hashtags like #LangChain, #LLM). This\\ncan get you noticed. Also consider reaching out to people in companies you’re interested in – not\\nasking for a job outright, but commenting on their work or asking for advice given your newly\\nminted experience. Join hackathons or meetups (if available locally or virtually) to meet like-minded\\nfolks. Often job leads come from these connections. \\n• \\n• \\n• \\n• \\n16\\n• \\n15'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Interview Prep – Coding: Dedicate daily time to coding interview prep. Even for AI roles, many top\\ncompanies will have a coding round (FAANG especially). Use platforms like LeetCode or HackerRank.\\nFocus on problems around arrays, strings, hash maps, graphs, etc. Aim to solve at least one\\nmedium-difficulty problem each day, and periodically do timed mock interviews. Use spaced\\nrepetition to remember common patterns (two-pointer , BFS, DP etc.). Since you can code in Python,\\nleverage that, but be familiar with complexity analysis. \\nInterview Prep – ML & System Design: Prepare to answer questions on ML concepts: e.g., explain\\nhow logistic regression works, what is bias vs variance, how do you handle missing data, etc. Review\\nyour flashcards on all fundamental definitions. Practice explaining your projects out loud – you\\nshould be able to crisply discuss the goal, approach, and results of each. Also practice ML system\\ndesign questions (common in ML engineer interviews): e.g., “How would you design a system to\\nrecommend products?” or “How would you deploy a model that handles 1 million requests/day?” –\\nhere you draw from your Month 10 knowledge (talk about load balancing, caching, monitoring). If\\napplying to specifically LLM-related roles, prepare for questions like “How do you fine-tune an LLM?\\nWhat are the challenges?” or “How would you improve inference latency for an LLM in production?”.\\nDraw on what you learned about quantization or using smaller models for speed. \\nFreelance Prep: In parallel, if freelancing is a goal, create profiles on platforms like Upwork or\\nFreelancer . Showcase your projects there (many clients will be impressed by an AutoGPT-like project).\\nPerhaps start by bidding on a small project that matches your skills to get a feel for the freelance\\nworkflow. Even if you plan to take a full-time job, a little freelancing can provide experience and a\\nside income. Also, your YouTube channel is now a portfolio piece – mention it in your bio (“I also run\\na YouTube channel with tutorials on AI, with X subscribers”). Having an audience can set you apart. \\nBest Resources:\\nCracking the Coding Interview (book) – for coding questions patterns. \\nInterview Query or Machine Learning Interview guides – there are blogs and books that list\\ncommon ML engineer interview Qs. Go through those.\\nLeetCode’s database and system design sections – sometimes AI roles ask SQL or basic system\\ndesign; ensure you can write simple SQL queries and outline system architecture. \\nMock interviews: Try Pramp (free mock interview platform) or interview with a friend/mentor . This\\ncan greatly boost confidence. \\nResume review communities: r/EngineeringResumes on Reddit or others – you can get feedback\\non your resume from peers. \\nProjects (Polish & Present): This month you likely won’t start new technical projects, but you might \\nrevisit an old project to polish it. For example, if one of your earlier projects lacked tests or had\\nsome bugs, fixing those shows growth. You can even do a “v2” of a project using new skills (e.g.,\\nrefactor your Month 2 ML project with proper pipelines or deploy your Month 4 CNN as an API).\\nMinor improvements can be content on your blog (“I revisited my old project with new eyes and\\nhere’s what I improved”). It demonstrates continuous improvement. \\nYouTube Opportunity: Share your journey now that you have nearly completed it. A video like “How\\nI became an AI Engineer in 12 months” where you candidly discuss the roadmap, challenges, and\\nshow snippets of projects could inspire others and also serve as a self-reflection. Additionally, you\\ncould do live streams solving LeetCode problems or talking about interview prep – this shows you’re\\nserious about the job transition and might even attract leads (somebody could refer you after seeing\\nyour depth). \\nSpaced Repetition: This is where your spaced repetition habit pays off – keep cycling through all\\nthose flashcards on theory and math regularly so everything is fresh. Also, simulate Q&A: have a list\\nof likely interview questions (technical and behavioral) and practice responding out loud or in\\nwriting. Use Anki for tricky algorithm tips or specific facts (like “What’s the equation for a neuron\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n16'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='output? What’s cross-entropy?”). By now, you should also revisit any ECE core knowledge if relevant\\n– sometimes, roles value that background, so don’t neglect what you learned in your degree; be\\nready to mention how it complements your AI skills (e.g., knowledge of hardware could help\\noptimize models, etc.). Keep your mind fresh but also get enough rest – don’t burn out right before\\ninterviews.\\nMonth 12: Transition – Interviews, Contributions, and Next Steps\\nFocus: This final month, you will be actively interviewing (if things go to plan) or at least aggressively\\napplying. Meanwhile, continue sharpening skills by contributing to open-source and staying up-to-date with\\nthe latest in AI (to discuss in interviews). Also, lay the groundwork for lifelong learning, since this year is just\\nthe beginning of a career .\\nJob Applications: By now, you should apply to a range of companies – FAANG (stretch goals, but\\nyour strong portfolio gives you a shot!) as well as top startups especially in the AI tooling/LLM space.\\nMany startups would value your experience with LangChain, vector DBs, etc., as those are hot skills.\\nTailor each application – mention your specific experience relevant to their work. Leverage referrals if\\npossible: use LinkedIn to see if you have connections at these companies; a referral plus your project\\nlinks can get you interviews. For freelance, step up outreach: send proposals highlighting similar\\nwork you’ve done. \\nInterview Rounds: Hopefully, you land interviews. In technical rounds, draw confidently on your\\npreparation. For coding, keep practicing problems daily up to the interview day. In ML design\\nrounds, use a structured approach (clarify requirements, explain your approach clearly – you’ve\\npracticed by explaining on YouTube, so use those skills). In behavioral rounds, tell the story of this\\nself-driven journey – it demonstrates passion, perseverance, and ability to learn fast, all highly\\nvalued. Be ready with examples of projects: e.g., “Tell me about a challenging problem you solved” –\\nyou can cite debugging your agent’s hallucinations or managing without a GPU by optimizing code,\\netc. Emphasize how you independently initiated and completed a complex roadmap – that’s akin to\\nbeing a self-driven employee. \\nOpen-Source Contribution: This is a good time to contribute to an open-source project related to\\nyour specialization (if you haven’t yet). For example, contribute a small fix or documentation update\\nto LangChain or Hugging Face Transformers. It signals to employers that you engage with the\\ncommunity and understand collaborative workflows. It could be as simple as improving an example\\nin LangChain’s docs or fixing a minor bug you encountered. Mention this in interviews (“I even\\ncontributed a bugfix to LangChain that got merged”) – it’s impressive. \\nContinued Learning: The field of AI moves rapidly. Identify a few key sources to stay updated: e.g., \\nDeepLearning.AI’s “The Batch” newsletter for weekly AI news, the r/MachineLearning subreddit\\nfor latest research highlights, and YouTube channels like Yannic Kilcher or Two Minute Papers for\\nresearch summaries. This habit will help you in interviews if asked about recent developments (“Have\\nyou heard about GPT-4’s new vision capabilities?” – you can give an informed opinion). It will also\\nserve you well on the job. \\nFreelance/SaaS angle: If by end of the year you decide to build an AI SaaS product (another stated\\ngoal), you now have the skills. This month, you could draft a business plan for a tool you built. For\\nexample, maybe your capstone agent can be turned into a SaaS for researchers or students.\\nConsider if you want to pursue that: even if you take a job, this could be a side project or a startup\\nattempt. Evaluate the market, get feedback from potential users (this itself could be a learning\\nproject – building the product mindset). \\n• \\n• \\n• \\n• \\n• \\n17'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Reflect and Plan Ahead: Take time to reflect on how far you’ve come. Identify what you loved most –\\nwas it building end-to-end projects, was it the research aspect of trying new techniques, or making\\ncontent? This can guide your next steps. If working at a big company, you’ll continue learning on the\\njob. If freelancing, you might pick a niche (LLM apps for finance, for example). If doing a startup,\\nyour learning shifts to business. In any case, set aside a little time to update your knowledge: maybe\\nplan to tackle a new advanced topic next (like reinforcement learning or AI for robotics) as a\\ncontinued growth goal. \\nCelebrate: Don’t forget to acknowledge your achievements. Completing such an intensive roadmap\\nis rare and employers will recognize the caliber of effort. Perhaps make a final YouTube video or blog\\npost wrapping up the journey and announcing your next step (whether you got a job or launching\\nsomething). It not only gives closure to your audience but also to you. It can mark the transition\\nfrom “learner” to professional AI Engineer. \\nYouTube/Community: In this month, your YouTube channel might start paying off: with a body of\\ncontent, you could see increased engagement. Engage with your commenters, maybe do a Q&A\\nabout “How I would learn AI in 2026” or similar – this reinforces your own knowledge and establishes\\nyou as part of the community. Being active in the community can lead to job offers or freelance gigs\\nunexpectedly (people might reach out seeing your content). \\nSpaced Repetition: Keep your flashcards routine alive lightly to stay sharp, but also realize that by\\nnow repetition is happening via real-life usage (interviews, projects). Use your spaced repetition\\nmore for maintaining interview readiness until you land an offer . Also, use it for any new on-the-job\\nlearning that might occur if you started working. Essentially, the habit you built will continue to serve\\nyou in your career for continuous learning.\\nConclusion: By following this 12-month roadmap, Yash will have transformed from a student with basic\\nknowledge into a well-rounded AI Engineer capable of building production-grade AI systems. He will have\\na rich portfolio of projects (from simple models to an AutoGPT-like agent), hands-on experience with\\nstate-of-the-art tools (Hugging Face, LangChain, vector DBs, etc.), and a personal brand via his YouTube\\nchannel.  This  journey  emphasizes  active  learning  through  projects  and  consistent  review,  which  keeps\\nmotivation high and knowledge retained. \\nBy focusing on Agentic AI in the latter half, Yash is entering one of the most cutting-edge areas of AI in\\n2025,  positioning  himself  strongly  for  roles  in  AI  startups  or  innovative  teams  at  big  tech.  The\\ncombination  of  foundational  understanding  and  practical  building  experience  means  he  can  not  only\\ndesign solutions but also implement and deploy them – exactly what companies seek in a “production-\\nready” AI engineer. \\nFinally,  the  roadmap’s  emphasis  on  sharing  (GitHub,  YouTube,  blog)  ensures  Yash  gets  feedback  and\\nrecognition for his work, minimizing the risk of losing momentum. Each project built is not an end, but a\\nstepping stone to the next, creating a virtuous cycle of learning. With this approach, by the end of the year\\nYash will be well-prepared to land a top-tier job or freelance contracts and even have the foundation to\\nlaunch his own AI-powered tools, fulfilling all the goals set out at the start.\\nSources: The roadmap recommendations are informed by industry-aligned curricula and expert insights.\\nFor example, the breakdown of foundational topics and portfolio building follows suggestions from an AI\\nDeveloper  roadmap .  Emphasis  on  LangChain,  LLMs,  and  vector  databases  reflects  current  best\\npractices for building AI agents. The strategy to “learn then build” iteratively is echoed by practitioners\\n• \\n• \\n• \\n• \\n36\\n36\\n35\\n37 38\\n36\\n18'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='on Reddit , who advise swiftly applying new skills to projects (like using LangChain with a dataset).\\nHugging Face’s course is highlighted as a best-in-class resource for mastering transformers, and short\\ncourses by DeepLearning.AI are recommended to quickly pick up prompt engineering and LangChain from\\nthe  experts .  Additionally,  tips  for  agent  design  (e.g.,  limiting  each  LLM  call  to  a  single  task,\\noptimizing  for  cost)  are  drawn  from  experienced  AI  engineers’  lessons.  By  following  this  guided\\napproach,  Yash  can  be  confident  that  he’s  learning  the  most  relevant  skills with  the  most  effective\\nmethods, as validated by the AI community and industry leaders. Good luck, and happy learning!\\nAI Developer Roadmap (2025 Edition) | by CodePicker\\n| Medium\\nhttps://medium.com/@codepicker57/ai-developer-roadmap-2025-edition-e04dddd2ed3a\\nIntroduction - Hugging Face LLM Course\\nhttps://huggingface.co/learn/llm-course/en/chapter1/1\\nNeural Networks: Zero To Hero\\nhttps://karpathy.ai/zero-to-hero.html\\nRoadmap to Becoming an AI Engineer in 8 to 12 Months (From Scratch). : r/learnmachinelearning\\nhttps://www.reddit.com/r/learnmachinelearning/comments/1g6d4cz/roadmap_to_becoming_an_ai_engineer_in_8_to_12/\\nBuild an Agent |  LangChain\\nhttps://python.langchain.com/docs/tutorials/agents/\\nChatGPT Prompt Engineering for Developers - DeepLearning.AI\\nhttps://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\\nLangChain for LLM Application Development - DeepLearning.AI\\nhttps://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/\\nAI Agent best practices from one year as AI Engineer : r/AI_Agents\\nhttps://www.reddit.com/r/AI_Agents/comments/1lpj771/ai_agent_best_practices_from_one_year_as_ai/\\nBuilding LLM applications for production\\nhttps://huyenchip.com/2023/04/11/llm-engineering.html\\n39\\n12\\n20 21\\n25\\n1 2 3 4 5 9 10 11 14 16 17 18 36 37 38\\n6 12\\n7 8 13\\n15 39\\n19 28 29\\n20\\n21 22\\n23 24 25 26 27 30 31 32\\n33 34 35\\n19'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 0, 'page_label': '1', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='1 \\n \\nNews Values - Revised \\nTheodora Ivancheva \\n \\n \\n \\nIntroduction. The notion of what makes events become news has been an object of \\nconsiderable research among academics and practitioners of various backgrounds: \\nsociologists, linguists, psychologists, practicing journalists and anthropologists. The theory of \\nnews values was initially pioneered by the Norwegian scholars Johan Galtung and Mari \\nHomboe Ruge. It comprises twelve criteria that the authors claim serve as definition of \\nnewsworthiness. Since its emergence, the news values set of criteria has given rise to many a \\nhot discussions among academics and professionals. \\nThe present artice presents a succinct overview of the existing theory of news values. Apart \\nfrom the seminal work of Galtung and Juge, the conclusions of authors auch as Hardcup and \\nO’Neill, MacShane and Brighton and Foy are discussed. \\n \\nWhat is news?  In the times of globalization we are constantly exposed to messages that claim \\nto present us with news of any kind, source and topic. Apart from the traditional news \\nprogrammes streaming through diversified television channels and the countless number of \\nnewspapers on news stalls, our mail boxes are periodically, if not daily, filled with \\nnewsletters, updates, the latest news concerning a topic of our interest/subscription or simply \\na wayward message that promises to contain news, purely as spam.  In other words, the \\nlexical item “news” has numerous connotations depending on the context in which it appears. \\nFor instance, the utterance “Have you heard the latest news?” is open to multiple \\ninterpretations: \\n1.  two people discussing the latest breaking news on TV, national or local \\nnewspapers, or; \\n2.  the development of a news story that hit news reports some time ago; \\n3.  the latest findings concerning some scientific research;   \\n4.  two colleagues talking about the latest changes in their working place or a \\ncorporate gossip; \\n5.  spouses chatting about family issues; \\nbrought to you by COREView metadata, citation and similar papers at core.ac.uk\\nprovided by New Bulgarian University Scholar Electronic Repository'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 1, 'page_label': '2', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='2 \\n \\n6.  teenagers gossiping about a friend’s new relationship; \\n7.  elderly ladies commenting the development of the main characters’ life stories of \\ntheir favourite soap opera; \\n8.  the key question of a TV commercial where friends are sharing information about \\nthe irresistibly low interest rates of a bank. \\nThese are just a few possible interpretations and they invariably depend on the writer’s \\nawareness and experience of various contexts as well as cultural identity.  \\nIn further words, the answer to the question “What is news?” may seem more that obvious. \\nNews is everything that is new that is happening. The dictionary of Merriam Webster offers \\nthe following definitions: \\n1.  a : a report of recent events \\nb : previously unknown information  \\nc : something having a specified influence or effect  \\n2.  a : material reported in a newspaper or news periodical or on a newscast \\nb : matter that is newsworthy (see: http://www.merriam-webster.com/dictionary/news ) \\nThe British National Corpus (BNC) http://www.natcorp.ox.ac.uk/  enables a quick check \\nof the different contexts in which the word item “news” appears. The contexts are a collection \\nof over 100 million, wide-range written and spoken language sources, designed to represent \\nthe later part of the 20 th  century, referring both to written and spoken British English, which is \\nof paramount importance for the purposes of the present research as the examples are entirely \\nexcerpted from British online or printed newspapers.  It is also worth noting that each \\nindividual search offers 50 random solutions, i.e the solutions quoted below may differ from \\nany consecutive trial. Furthermore, the initials at the beginning of each item indicate the \\nsource reference, given here in parenthesis right after the excerpted item to ascertain the \\nreader-friendly nature of the example (see Appendix). \\nThe tables below are a summarized version of the number of general occurrances of \\nthe word “news” in different written and oral contexts. It is worth noting that these are not the \\ntotal number of utterances, which by far outnumber the number of contextual occurrences. A \\nmore detailed study of the use of the item “news” would benefit tremendously of the overall \\nfigure of utterances to exapmlify its broad usage and various semantic fields.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 2, 'page_label': '3', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='3 \\n \\nsource  \\n          \\nOnline \\nnewspaper \\nPrinted \\nnewspaper \\nFiction \\nBook \\nSpecialized \\nliterature \\nother \\noccurrances  6 6 8 7 8 \\nTable 1.  \\nTable 1  illustrates the usage of the word “news” in written corpora. The ratio between newspapers and \\nother written materials is in favour of newspapers – 12 occurrences in printed and online newspapers \\nversus 8 in fiction literature, 7 in specialized literature, and 8 in other types of printed materials like \\nnewsletters or catalogues (see Table 1).  \\nsource \\n  \\n          \\nTV Programme Radio Programme Business Meeting  \\noccurrences  1 2 2 \\nTable 2.  \\nTable 2  shows the appearance of the lexical item “news” in corpora of oral performance. The \\nratio is almost equal - two times in radio programmes and business meetings each compared \\nto just one occurrence in a television programme (see Table 2).  \\nOn balance, the lexical item news has broad applications in terms of language contexts both \\nwritten and oral. Its polysemy requires plausible limitations for the purposes of the present \\nwork. What we assume as news here is closer to what Merriam Webster’s Dictionary \\nsuggests, i.e a report of recent events and material reported in a newspaper or news periodical \\nor on a newscast  (see: http://www.merriam-webster.com/dictionary/news ). \\nAs the influx of news in our lives is uncontrollable and, thus hard to observe, we will focus \\nour attention on what is reported in media, that is to say what makes events or happenings \\nbecome news items, bearing in mind that new things happen all the time everywhere in the \\nworld and they never find their way into newspapers or onto the air in a newscast. \\nFurthermore, as the number of printed and electronic media is vast, the encuing examples \\nhave been excerpted from the printed or electronic versions of newspapers.  \\nWhat makes a story newsworthy enough to be published or broadcast? It is news values that \\ngive journalists and editors a set of rules by which to work, plan and execute the content of a \\npublication or a broadcast. The types of media are varied. A newspaper is a publication that is \\nissued daily, weekly, bidaily, or bimonthly, and includes local and international news stories, \\nadvertisements, announcements, opinions, cartoons, sports news, television listings,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 3, 'page_label': '4', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='4 \\n \\nclassifieds and other sections. It is an important method of letting the public knows everything \\nthat is happening around the world and in their local area. Even with the advancements in \\ncomputer technology, newspapers continue to be an important aspect of everyday life.  \\nNot only are there a vast number of media types available but there are various types \\nof printed newspaper on offer as well. Newspapers generally are divided into three categories: \\nbroadsheets, the Berliner format, and tabloids. Broadsheets are believed to present high-\\nquality journalism; however, they are unsuited to reading in public transport that is why \\nseveral years ago a more manageable format was adopted, as people have no other time to \\nread newspapers but on their way to work. Thus, the newspaper format can hardly serve as a \\ncritical quality factor of the printed media of today.  The Berliner format is a blending \\nbetween broadsheets and tabloids. Some broadsheet newspapers in Britain have looked to the \\nBerliner format as a portable-size format, without the typically applied negative connotations \\nto tabloids. For example, the Guardian adopted the Berliner format in 2005 right after \\ncompeting broadsheet newspapers had switched to the tabloid format. Tabloids are the \\nsmallest newspapers in terms of format as well as the least reputed ones due to their tendency \\nto present rumors, gossips, and sensational news about celebrities. The Times  was printed in \\nbroadsheet format for 219 years but since 2004 it has switched to a tabloid format, both to \\nease its readers with its user-friendly size and to appeal to a much younger audience. Almost \\nall Bulgarian dailies share the tabloid format and have never had a broadsheet one but the \\ndaily Dnevnik which, when initially published, was the only broadsheet daily on the market. \\nThe other broadsheet in the country is the weekly – Kapital  that carters for the public’s need \\nof political, economic and cultural analyses as well as the demand to offer and search for job \\nvacancies in the high, more sophisticated job market niche. Kapital  still shares the broadsheet \\nformat, which is inkeeping with its content and target audience. The weekly is dedicated \\nprimarily to business analyses and its audience comprises highly educated economists, CEOs \\nand the business community in Bulgaria in general.  \\nTechnological advances have allowed printed newspapers to address audiences of \\ndifferent reading habits, those who traditionally prefer to buy and read the printed copy of \\ntheir preffered paper, as well as those who are keener on making use of technologies and, \\nrespectively visit the online version of the paper(s), or users of e-book readers who can simply \\ndownload their favoured newspaper, magazine or e-book.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 4, 'page_label': '5', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='5 \\n \\nWhat is the role of the journalist?  For a layperson, the answer to this question may reach as \\nfar as to simply saying “to report or present news” or “to write articles.” However, the reality \\nis much more complex and is worth reviewing. Strange as it may seem, the features of printed \\nand electronic media are so strikingly diversified that they result in many “journalisms.” That \\ndiversity naturally differs from country to country; however, there are numerous similarities \\nthat unify journalism as a whole. With the rapid development and improvement of \\ntechnologies, every personal computer owner is enabled to disseminate information, \\nsometimes, even much wider than the official news organizations. However well organized a \\nwebsite may seem it may not necessarily offer reliable, trustworthy news. Additionally, news \\nis not a scarce commodity any more and, thus the role of the journalist has become more \\nimportant that it has ever been before. News items, whether breaking news, features or even \\nanalyses have to be accurate. For the purpose journalist, unlike gossipers and proponents, \\ncollect the information they need to present a story and verify its validity. Objectivity is \\nanother concern with the profession. Journalists are reasoning, thinking human beings and it \\nwould be naïve to think that what is published does not contain personal opinion. Potter states \\nthat ” By using an objective, scientific method for verifying information, journalists can report \\nstories that do not reflect their own personal views. The story itself, in other words, should be \\nimpartial and fair.” (Potter 2006:11). While opinion reflects on personal thoughts, \\nunderstanding and believes, fairness refers to the different angles a story is presented. At the \\ntime of which the present work is being written the British jazz and soul singer Amy \\nWinehouse has been found dead in her apartment in Camden, North Lonon. Let us take, for \\ninstance, the news presentation of this news account in the Telegraph online \\n(http://www.telegraph.co.uk/ ). Five days after the news hit the headlines, the Telegraph \\ncontains an influx of items on the topic. The event is presented from several different angles. \\nFirst, it is explicable that the newspaper does not contain breking-news headlines. i.e large \\ntexts in huge fonts, as that is the fifth day after the dead of the celebrity; the event is not \\ntreated as hard news any more, still it forms prolific follow-ups. However, the Telegraph \\nacknowledges the event in the Obituary section with a detailed bibliographical article, \\npresenting the chronological events and artistical achievements of the life of the renowned, \\nand at the same time notorious, singer. Confiremed fans are offered to watch and listen to \\nsummarized famous videos of the most popular hit tracks together with the official \\nannouncement of the discovery of the deceased read in public by a superintendant. The tone \\nof the announcemet is neutral at the start; however, it finishes with the police, as institution, \\nexpressing deep regrets and sorrow following the tragic news. The section Culture presents a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 5, 'page_label': '6', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"6 \\n \\nfull-length interview with Amy Winehouse that is claimed to be the last ever, conducted by \\nNeil McCormick, who has been the most prominent music critic for the The Telegraph since \\n1996. Concomitant events are featured, albeit short in time and span, related to the funeral \\nceremony of the singer. Here are the headlines directly copied and pasted from the online \\nTelegraph; the size of font and typeface are the original ones. If the selection of typeface and \\nfont size bring about the level of importance of news stories and events being projected on a \\nnewspapers page then the full story of the death of the British jazz and soul singer are given \\nequal prominence (see Hodson 1984:100; Ivancheva 2005:261).  \\n1.Amy Winehouse: police continue investigation into \\nmusician's death \\n2.Amy Winehouse: the final interview by Neil McCormick  \\n 3.Amy Winehouse's last public appearance \\n4. Amy Winehouse 'drunk' on stage in Belgrade \\n5. Amy Winehouse's parents visit singer's Camden home \\n6. Amy Winehouse 'looked fine' day before death \\n7. Former collaborator Mark Ronson arrives for Amy \\nWinehouse memorial \\nThe representation of the story of Winehouse is an illustrative example of what fair \\njournalism should be, i.e “…to report all significant viewpoints in a way that is fair to those \\ninvolved and that also presents a complete and honest picture to the audience.”(  Potter  \\n2006:16).  \\nTo sum up, contemporary journalists are to perform challanging, complicated multitasking. In \\ntheir pursuit for independence from the people or organizations they write about, journalists \\nstruggle to strike a balance between an objective, fair representation deprived of explicit \\npersonal opinion. They search contrasting views and report them without taking one side or \\nanother. Journalists do original reporting being able to differentiate between fact, opinion, and \\nrumour.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 6, 'page_label': '7', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='7 \\n \\nWhat is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \\nsociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \\nstudies. Stuart Hall states that:  \\nThe media do not simply and transparently  report events which are \\nnaturally newsworthy in themselves. News is the end product of a \\ncomplex process, which begins with systematic sorting and selecting \\nof events and topics according to a socially constructed set of \\ncategories.  \\n       Stuart Hall ( in Fowler1991:12) \\n  Philo goes on even further to maintain that news is not found or even gathered. It is a \\ncreation of a journalistic process, an artefact, and a commodity ( in Fowler 1991). The last \\nstatement, as discussed above, is hardly applicable in the contemporary era of mass \\ncommunication, where, with the existence of the internet, everybody can have access to \\npractically any nugget of information. Brighton and Foy are of the opinion that: \\nIt is news values that give journalists and editors a set of rules – often \\nintangible, informal, almost unconscious elements – by which to work, \\nfrom which to plan and execute the content of a publication or a broadcast. \\nIn its purest sense everything that happens in the world is a new event, and \\nsomebody, somewhere, will have some level of interest in that occurrence. \\nBut what takes it from being new to being news? The set of values applied \\nby different media – local, regional, national and international, print, \\ntelevision, radio, internet, bulleting board – are as varied as the media \\nthemselves.  \\n    Brighton and Foy (2007:1) \\n A classical definition of what constitutes news values was developed by two Norwegian \\nsocial scientists Johan Galtung and Mari Homboe Ruge and officially published back in \\n1965.  \\n  The list of criteria is as follows (in Fowler 1991:13): \\n/head2right Frequency.  An event is more likely to be reported if its duration is close to the \\npublication frequency of the news medium. Because newspapers are published once a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 7, 'page_label': '8', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='8 \\n \\nday, a single event is more likely to be reported rather than a long process one. For \\ninstance, the publication of unemployment figures on a certain day is more \\nnewsworthy than the long-term phenomenon of unemployment itself. \\n/head2right Threshold.  Refers to the ‘size’ needed for an event to become newsworthy. For \\nexample, an accident involving  a hundred people is more likely to be published than \\none involving two or three people. \\n/head2right Unambiguity .  Mysterious events as well as clear ones are newsworthy if they can be \\nrelated to cultural stereotypes, where a stereotype is a socially-constructed mental \\npigeon-hole into which events and individuals can be sorted, thereby making such \\nevents and individuals comprehensible. \\n/head2right Meaningfulness  (with its two subcategories Cultural proximity and Relevance).  \\nRefers to a preoccupation with countries, societies and individuals perceived to be \\nlike oneself.  \\n/square4 Cultural proximity.  Relates to geographical closeness of a country. \\nCultural proximity is founded on an ideology of ethnocentrism: a \\npreoccupation with countries, societies and individuals perceived to \\nbe like oneself  (Fowler 1991). \\n/square4 Relevance. If Culture1 and Culture2 i1 are geographically far away but \\nin Culture1 it is likely to happen the same type of event, so Culture1 is \\naffected in the same way as Culture2. \\n/head2right Consonance  with its two sub criteria predictability  and demand  refer to categories of \\nevents which people either expect to happen or want to happen, e.g. Royal weddings \\nand births. \\n/head2right Unexpectedness .  An event is even more newsworthy if it happens without warning or \\nis unusual. \\n/head2right Continuity.  Once an event is defined as news, it will continue to be news even though \\nits amplitude may be less. Moreover, even ‘non-events’ which are part of the story will \\nbe covered. \\n/head2right  Composition . Refers to the balance of a paper bulletin, that is, an item will be more or \\nless newsworthy depending on what else is available for inclusion. \\n/head2right Reference to elite nations. Encodes a ‘superpowers’ ideology of the dominating status \\nof North America, Japan, Europe and Russia in world political and cultural affairs. \\n                                                             \\n1 Where Culture1 is the culture of the recipient of the information and Culture2 is the culture of the target \\ncountry.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 8, 'page_label': '9', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"9 \\n \\n/head2right Reference to elite people. Refers to media's infatuation of celebrities, e.g. Bill Clinton, \\nUS President between 1993 – 2001 more popular among ordinary people with the \\nLewinski Scandal. \\n/head2right Reference to persons (Personalisation). Whenever possible events are seen as the \\nactions of people as individuals. Personalisation varies from paper to paper being most \\nstriking in the popular press. \\n/head2right Reference to something negative.   It suggests that news take the normal for granted, \\nand so is driven to make stories out of deviant: crime, dissidence, disaster. As Fowler \\n(1991) points out, negativity is a value rather than anything more natural: there is no \\nnatural reason why disasters should be more newsworthy than triumphs.  \\nThe set of criteria can also be summarized under the following unifying headings: \\n1.  Impact : frequency, unambiguity, threshold, negativity, unexpectedness \\n2.  Audience identification : personalization, meaningfulness, reference to elite nation, \\nreference to elite persons. \\n3.  Pragmatics of media coverage : consonance, continuity, composition \\n \\nJohan Galtung and Mari Ruge’s seminal work on the taxonomy of news values that make an \\nevent become news, or that serves as criteria for selection prior to publication, has been the \\ncore of a great amount of encuing scientific research elaborating on the issue of \\nnewsworthiness.  Several attempts to revise the list of criteria have been made since the \\noriginal publication appeared in the 1965 edition of the Journal of International Peace \\nStudies , entitled Structuring and Selecting News . For example, Denis MacShane 2 (quoted in \\nBrighton and Foy 2007: 8) suggested later in 1979 a new subdivision of newsworthy events \\ninto several categoris such as: \\n/head2right Conflict \\n/head2right Hardship and danger to the community \\n/head2right Unusualness (oddity, novelty) \\n/head2right Scandal \\n/head2right Individualism \\n                                                             \\n2 Denis MacShane  is a British politician, who has been theMember of Parliament (MP) for Rotherham since \\nthe 1994 by-election and served as the Minister for Europe from 2002 until 2005. From 1969 to 1977 he worked \\nas a newsreader and reported for  BBC Radio Birmingham. (http://en.wikipedia.org/wiki/Denis_MacShane )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 9, 'page_label': '10', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='10 \\n \\nMost of the above have more to do with impact like conflict, scandal unusualness, hardship \\nand danger to community; individualism falls into the category of audience identification. \\nWhat MacShane fails to isolate as a criterion is the pragmatic news value of stories in a news \\norganization diary that bring about the balance of any meadia in question.  \\nHardcup and O’Neill argue that Galtung and Ruge’s taxonomy possesses certain problematic \\nareas and, thus the authors pose the following questions: \\n/head2right Frequency . How does this relate to stories that are not about events at all, but about \\ntrends, speculation, or even the absence of events? \\n/head2right Threshold. Isn’t this still open to subjective interpretation? Which is bigger – 20 \\ndeaths in ten road accidents or five deaths in one rail crash? \\n/head2right Unambiguity.  Is the ambiguity in the subject or the journalist’s interpretation? \\n/head2right Meaningfulness.  This is a slippery concept that changes over time and relies on \\nsubjective interpretation. \\n/head2right Unexpectedness.  How can we tell if the journalist is simply taking an unexpected \\nangle on a predictable event? \\n/head2right Consonance . How useful is this category if it is possible only to guess if and when it \\nhas applied? \\n/head2right Composition . How is it possible to know what was in the selector’s mind when \\nmaking a particular decision? \\n/head2right Elite Nations . The dearth of foreign news in UK tabloids newspapers renders this \\nrelatively infrequently identified factors; does that mean it does not apply? \\n/head2right Elite People . How useful is a category that does not distinguish between the Spice \\nGirls and the President of the USA? \\n/head2right Reference to persons . Is this intrinsic to the subject or the journalist’s technique? \\n/head2right Reference to something negative . Negative for whom? Bad news for some might be \\ngood news for others.  \\n   Hardcup and O’Neill, 2001 (in Othman and Tiung 2009 )\\n     \\nAs a result of their study Hardcup and O’Neill (in Brighton and Foy  2007: 8) present their list \\nof criteria.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 10, 'page_label': '11', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='11 \\n \\n/head2right Power elite - powerful individuals, polititians, tycoons, organisations or institutions \\n(e.g Boiko Borisov PM of Bulgaria, Donald Trump, Robert Kiyosaki, etc.); \\n/head2right Celebrity  - people who are already famous or notorious; \\n/head2right Entertainment -  sex, gay couples,  music, theatre, stories of human interest, romantic \\ndrama, intriguing photographs, etc.;   \\n/head2right Surprise  – surprising events, both positive or negative in content; \\n/head2right Bad news – conflicts, tragedies – events with overall negative connotations; \\n/head2right Good news  – rescues, cures, survivals – events with overall positive connotations; \\n/head2right Magnitude  – events whose number of people involved is of paramount importance ,or \\nwhose impact concerns a grat number of people; \\n/head2right Relevance  - events that concern specific groups of people and/or whole nations \\nrelevant to the readership; \\n/head2right Follow-ups  – news items that have already been in the news and continue to develop; \\n/head2right Media agenda  - stories that set or fit the news organisation’s own agenda. \\nHardcup and O’Neill’s classification of news values fall in three major summarized areas. \\nThe first is related to the protagonists within a strory, i.e powr elite, celebrities; the second has \\na conceptual essence, for instance – relevance. The third comprises the notion of media \\npractices – follow-ups, media agenda. \\nJohan Galtung and Mari Homboe Ruge Hardcup and O’Neill \\nFrequency  \\nThreshold Magnitude \\nUnambiguity  \\nMeaningfulness Relevance \\nConsonance  predictability demand  Entertainment \\nUnexpectedness Surprise \\nContinuity Follow-ups \\nComposition Media agenda \\nReference to elite nations  \\nReference to elite people Celebrity \\nPersonalisation  \\n Power elite \\nReference to something negative  Bad news, Good news  \\nTable 3'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 11, 'page_label': '12', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='12 \\n \\nMoreover, a brief comparison of the two pairs of scholars’ research reveals a predominant \\noverlap of the news values criteria (see Table 3). Hardcup and O’Neill’s idea of “size” of an \\nevent, termed magnitude, is nothing different from Galtun and Ruge’s threshold. \\nMeaningfulness and relevance both refer to the notion of the acceptance and self-\\nidentification of a culture “preoccupied with countries, societies and individuals perceived to \\nbe like oneself,” as Fowler words it (Fowler 1991). Some might argue that a culture can be a \\nconstruct of many subcultures, which virtually is true, and one event may not be equally \\nrelevant to the whole multitude of cultures; however, that argument, to my mind, reflects on \\nthe type of media and its readership profile’s interest. Consonance and entertainment also \\nhave similar connotations. If consonance refers to peoples’ expectations or need something to \\nhappen, then all types of events like, gay weddings, personal drama, organized events \\n(theathre, music concerts, etc) cater for peoples’ demand to satisfy their curiosity, need for \\nrelaxation and quench their thirst for human-interest information. Continuity and follow-ups \\nreflect the tendency for some event to fail to drop news bulletins, having already been in the \\nnews. These events are predominantly of negative nature, such as murders, natural disasters, \\nepidemics; rarely are there follow-ups of good news unless the protagonists are of royal origin \\nor non-royal one, which is the case of the marriage between the British Prince William and \\nCatherine Middelton on 29 th  April, 2011 at Westminster Abbey. As Fowler rightly defines \\nsuch negative occurrences in the media as “hysteria in the Press,” especially in the printed (as \\nwell as online, it must be noted) press, giving an illustrative example of a roughly three-month \\ncontinuity of salmonella panic among the British (between late November, 1988 and early \\nMarch, 1989) (Fowler 1991: 148). Composition and media agenda imply technical media \\npractices referring to the choice of media what else is available to include on a specific day. \\nSuch choices could be also dependent on hard news as prominence is heavily dependent on \\njuxtaposed news items, especially in the printed press (see Ivancheva 2005). Reference to elite \\npeople compares to Hardcup and O’Neill’s celebrity where both teams of researchers refer to \\nthe notoriety of already popular people whose public behavior frequently makes newspaper \\nheadlines. Last but not least, most of the concepts of both lists totally coincide or repeat each \\nother; their difference is only a matter of synonymy. \\nStuart Hall (ibid) distinguishes between formal and ideological news values. The \\nformer are: \\n/head2right Linkage  – Has the story got any connection with previous events and \\noccurrences, or does it allow journalists to link it to any of the above?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 12, 'page_label': '13', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='13 \\n \\n/head2right  Recency  – Has the event happened lately and how much worthy is it from the \\npoin of view of the present moment? \\n/head2right Newsworthiness of event/person \\nIn their book, News Values  published in 2007 the two practitioner-academics Paul Brighton \\nand Dennis Foy attempt to present a revisited and more contemporary version of the news \\nvalues theory. The authors discuss newspaper, radio and television practices, as well as the \\ninternet news channels. They suggest seven criteria, which are: \\n/head2right Relevance  – the significance of an item to the viewer, listener, or reader.  \\n/head2right Topicality  – Is it new, current, immediately relevant?  \\n/head2right Composition  – How a news item fits with the other items that surround it. \\n/head2right Expectation  – Does the consumer expect to be told about this?  \\n/head2right Unusualness  – What sets it apart from other events, which are not reported?  \\n/head2right Worth  – Does it justify its appearance in the news?  \\n/head2right External influences – Is the content of a news item pure, or has it been \\ncorrupted by pressure from outside, such as a proprietor, an advertiser or \\npolitician?          \\n      (Brighton and Foy  2007:26) \\nThe criterion relevance corresponds to Galtung and Ruge’s term of consonance. Relevance is \\na broad notion and, as the writers claim ‘”…it is this aspect of the news values system that is \\ninstinctively deployed by professional news-gatherers, who will often claim to ‘know the \\naudience’.”(Brighton and Foy 2007). A car crash, let us say, in Durhum, UK, with one \\ncasualty will be of direct interest only to those who reside in Durhum. However, if the \\ncasualty happens to be a Bulgarian, then the car- crash accident will, most probably, become a \\nleading news item for most dailies and electronic newscasts in Bulgaria.  \\nTopicality has to do with events like anniversaries of historical events as 1 9th  February in \\nBulgaria, which commemorates either the birth or the death of the prominent Bulgarian hero – \\nVassil Levski, who idelogised a revolutionary movement to liberate Bulgaria from Ottoman \\nrule. In such cases, there are planned media agendas at work.  \\nComposition is as old criterion as that of Galtung and Ruge’s publication in 1965, \\ncorresponding to the common market law of demand and supply. A news editor will provide \\ntheir readership with what is felt to be the demand and, will respectively strive to achieve a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 13, 'page_label': '14', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='14 \\n \\nbalanced presentation of various news items – the supply, also taking into consideration the \\nmarket competition with other media available in the respective country. \\n Anything that is likely to have an impact on the public falls in the category of expectation. A \\ndrug dealer, caught red handed selling dope to the schoolchildren in the local school; a singer \\nthat is alledgedly thought to have had a love affair with a country’s president (e.g. the \\nBulgarian singer Mariana Popova and the President of the Republic of Bulgaria - Georgi \\nParvanov); a local hospital medicals that ridiculously confirm only two final diagnosis of their  \\npatients as the hospital management has just two clinical pathways contracted with the \\nNational Health Insurance Fund; pediatritians that charge underaged patients a consumer tax; \\na bomb scare in the subway of London. All of the above examples are of information that the \\npublic expects to be told about, locally, nationally, or internationally.  \\nAs far as unusualness is concerned, it is clearly exemplified by the popular journalistic quote -\\nwhen a dog bites a man that is not news, because it happens so often. But if a man bites a dog, \\nthat is news. 3 The quote self-sufficiently identifies the nature if such unexpected, sensational, \\nunplanned events and happenings that inevitably become hard news, forming large-point fonts \\nand specially typefaced headlines in the printed media, as well as the breaking news items of \\nnewscasts. It would not be an exaggeration to state that unusual events turn into hard news – \\nthe staple diet of media.  \\nThe criterion worth, to my mind, is similar to Galtung and Ruge’s ideas of threshold with the \\nsubtle difference that Brighton and Foy attribute not only to the “size” of the event, but to the \\ntype of protagonists involved as well; rather its assimilation with the formers’ reference to \\nelite nations or people.  The authors discuss the newsworthy nature of the subjects whether \\nthey are popular at all to have any impact on the public’s interest and lives of people. The \\nscholars, rightly though, go on to discuss the contemporary implication of the lexical item \\n“celebrity,” which refers not only to politically involved persons but also musicians, actors, \\nactresses, and even soap opera stars.  \\nLast but not least, the writers discuss external influences as a criterion with regard to human-\\ninterest factors that might prevent an event from becoming a news item like, for example the \\n                                                             \\n3 The origin of the popular quote is yet controversial. Several hypotheses exist: 1.It is said to have been coined \\nby Alfred Harmsworth, a British newspaper magnate. 2. It is attributed to Charles Anderson Dana (1819 – 1897) \\nan American journalist, author, and government official; or to 3. John B. Bogart (1848–1921),  New York \\nSun  editor. (see http://en.wikipedia.org/wiki/Man_bites_dog_(journalism))'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 14, 'page_label': '15', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='15 \\n \\nowner of a news corporation’s control over what is published/ aired or not ( see Brighton and \\nFoy 2007:164). \\n \\nConclusion.\\n  The theory of what makes events become potential news has been, as \\nsuccincltly discussed, the focus of attention to scholars of different scientific background. \\nJohan Galtung and Mari Homboe Ruge unarguably set the beginning of a critical approach to \\nmedia practices not only of high relevance to those professionally involved, but also to those \\nwho consume media products. The encuing revisions of the original taxonomy have added \\nnew shades of what news values could be at the dawn of the 21 st  centrury. The widespread \\napplication of technology and all available means of mass communication give rise to the \\napplicability of some of the original criteria. When the Norwegian scholars conducted their \\nresearch in 1965 (or, logically prior to the date of the publication of their results), the internet \\nwas non-existent. Hence, a criterion as frequency, in their terminology, has taken new \\nconnotations, especially with new practices of printed media to sell yesterday today’s news \\n(most newspapers are on the stalls the night before the date of their publication in Bulgartia). \\nWhat is more, the online versions of printed newspapers, being advantageous of the \\ncapabilities of technological advances, update hard news as frequently as it is felt to be \\nnecessary; and change the so called news in brief (NIB), which is said to be space fillers. \\nGiven that, composition as criterion calls for further research, albeit some authors (Hardcup \\nand O’Neill; Brighton and Foy 2007) attribute it to media agenda. In contrast, MacShane’s \\nfailure to discuss such pragmatic practicalities of media coverage and focus of attention to \\nimpact and audience identification (see above) could be ascribed to his having been a \\npractitioner, rather than a scholar, thus considering such criterion as a taken-for-granted one \\namong professionals. Moreover, it is worth noting that journalists are critical-thinking \\nmembers of a sociocultural environment and, despite their professional ethics to objectively \\npresent news, they still have an opinion on events and happenings. Personal opinion can be \\nencoded in any utterance by means of special usage of the verb system of the target language \\n(e.g Active vs Passive Voice; positive vs negative connotation; modality);syntax (e.g elliptical \\nsentences; metaphors); nominal syntagms (choice of adjectives); phonostylistical devices, etc. \\nThese phenomena possess their peculiarities as far as languages are concerned and they would \\nbe worth investigating from sociolinguistic/sociocultural point of view in futher research \\npaper work.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 15, 'page_label': '16', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"16 \\n \\nExternal influences in Brighton and Foy’terminology set another aspect of news gathering. \\nMedia ownership self-sufficiently establishes what and, more importantly, whose ideas a \\nmedium voices. Downie and Schudson, 2002 suggest a new perspective of what influences \\nmeadia choices of news presentation: \\n“…the economic foundation of the nation’s newspapers, long supported by advertising, is \\ncollapsing, and newspapers themselves, which have been the country’s (the USA here) chief \\nsource of independent reporting, are shrinking literally. Fewer journalists are reporting less \\nnews in fewer pages. ” \\n      Downie and Schudson 2002( Fenton 2011:3) \\nThe picture is almost identical in Central and Eastern Europe and the Commonwealth of \\nIndependent States: Albania, Armenia, Bosnia and Herzegovina, Bulgaria, Czech Republic, \\nEstonia, Hungary, Kyrguzstan, Latvia, Lithuania, Macedonia, Modlova, Montenegro, Poland, \\nRomania, Serbia, Slovakia, and Ukraine, according to an investigation conducted by the Open \\nSociety Institute Media Program (OSI 2010) (ibid).  \\nOn balance, the process of newsgathering is a complex phenomenon. The theoretical \\ntaxonomies in academic literature, on the one hand, present one possible aspect of what types \\nof events are prone to turn into news items. The human interference as a journalistic choice, \\npersonal values, stereotypes, and cultural belonging add to the picture of news selection and \\npresentation. Media ownership together with political and economic factors are other criteria \\nthat influence media contents. Audiences and readership profiles are to be taken into \\nconsideration as well. Finally yet importantly, news values are then to be viewed as qualities \\nof potential reports and they are not simply features of selection but features of representation. \\nNews events, being systematically sorted and selected, are to be carefully worded, designed, \\nprojected and given prominence to on the newspaper's pages, computer and television screens.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 16, 'page_label': '17', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"17 \\n \\nBibliography \\n \\nBell, Garret 1998: Bell, Allan, Garrett, Peter. Approaches to Media Discourse. //Oxford: \\nBlackwell Publishers, 1998 \\nBranston, Stafford  1999:  Branston,Gill, Stafford, Roy. The Media Student's Book. London: \\nRoutledge,1999 \\nDijk 1985:   Dijk, Teun, Adrianus, van. Handbook of Discourse Analysis vol.2 Dimensions of \\nDiscourse, Florida: Academic Press, 1985 \\nFedler, Bender,Davenport,Drager 1999: Fedler, Fred, Bender, Jhon, Davenport, Lucinda, \\nDrager, Michalel. Reporting for the Media. Haracourt Brace & Company,1999 \\nFenton 2011:  Fenton, Natelie. Deregulation of democracy? New media, news, neoliberalism and \\nthe public interest.// Continuum: \\n 25: 1, 63 — 72, Routledge \\nFiske 1990: Fiske, John. Introduction to Communication Studies (2 nd ed). London and New York: \\nRoutledge, 1990 \\nFowler 1991: Fowler, Roger. Language in the News: Discourse and Ideology in the Press. \\nLondon: Routledge, 1991 \\nGaltung, Ruge 1965:  Galtung, Johan, Ruge, Marie, Holmboe. Structure of Foreign News. Sage \\n<\\nhttp://www.blisty.cz/files/2010/07/20/galtung-structure-foreign-news-1965.pdf > (27.08.2011)  \\nHodgson 1984:  Hodgson, F. W. Modern Newspaper Practice. Oxford: Focal Press, 1984 \\nKeeble 1994:  Keeble, Richard.  The Newspapers Handbook. London and New York: Routledge, \\n1994 \\nO'Sullivan, Dutton, Rayner  1994:  O'Sullivan, Tim, Dutton, Brian, Rayner, Philip.  Studying the \\nMedia: An Introduction. London: Arnold, 1994 \\nOthman, Tiung 2009:  Othman, Siti, Suriani, Tiung.Lee,Kuok. The News Types of Two \\nCountries: A Comparative Study of News Values Quality Newspapers and Popular Newspapers in \\nMalaysia and Britain.//Sosiohumanica \\n<\\nhttp://www.sosiohumanikajpssk.com/sh_files/File/siti.lee.usim.ums.pdf > (27.08.2011) \\nPotter 2006: Potter, Deborah., (2006) Handbook of Independent Journalism , Bureau of \\nInternational Information Programmes: U.S Department of State \\n< http://www.america.gov/media/pdf/books/journalism.pdf#popup > (27.08.2011)  \\nReah 1998:  Reah, Danuta. The Language of Newspapers. London: Routledge,1998 \\nSimpson 1993:  Simpson, Paul.  Language Ideology and Point of View. London: Routledge, 1993 \\nIvancheva 2005:   Ivancheva, Theodora. Comparative Analysis of Linguistic and Non-linguistic \\nMethods of Projecting News Values in the Dailies Trud and The Times.// New Bulgarian \\nUniversity, vol. 6. Sofia, 2005\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 17, 'page_label': '18', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='18 \\n \\n \\nWebsites: \\n \\nhttp://en.wikipedia.org/wiki/Denis_MacShane  \\nhttp://en.wikipedia.org/wiki/Man_bites_dog_(journalism) \\nhttp://www.natcorp.ox.ac.uk/  \\nhttp://www.telegraph.co.uk/'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 18, 'page_label': '19', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"19 \\n \\nAPPENDIX \\n(Here is a random selection of 50 solutions from the 14684 found). \\nA1R  3 THE STORY was that Breakfast News (BBC 1), the third relaunch of the cereal \\ntelevision which began in 1983 as Breakfast Time with Frank Bough and Selina Scott \\nchummy in jumpers, was going serious. (A1R  [Independent, electronic edition of 19891003].  \\nLondon: Newspaper Publishing plc, 1989, Arts material, pp. ??. 61 s-units, 1545 words. ) \\nA29  54  The People's Daily, the Communist party organ, published news of his death nearly \\ntwo weeks late but avoided any harsh commentary.( A29  [Independent, electronic edition of \\n19891004].  London: Newspaper Publishing plc, 1989, Gazette material, pp. ??. 133 s-units, \\n3354 words. ) \\nA2F  17  News of the Prague embassy's open door seems likely to provoke a greatly increased \\nflow of new emigrants from East Germany. (A2F  [Independent, electronic edition of \\n19891004].  London: Newspaper Publishing plc, 1989, Title material, pp. ??. 138 s-units, 3149 \\nwords. ) \\nA3D  13  Foreign News Page 10 (A3D  [Independent, electronic edition of 19891007].  London: \\nNewspaper Publishing plc, 1989, Foreign material, pp. ??. 439 s-units, 9297 words. ) \\nA8F  406  No wonder he can't bring himself to show much emotion at the news of his family's \\ndemise.( A8F  [Guardian, electronic edition of 19891123].  London: Guardian Newspapers \\nLtd, 1989, Arts material, pp. ??. 888 s-units, 18531 words. ) \\nABH  1649  The prime minister warned MPs that the Gulf war would not be ‘an easy or \\npainless business’ and readied them for ‘difficult news’to come. (ABH  The Economist.  \\nLondon: The Economist Newspaper Ltd, 1991, pp. ??. 3341 s-units, 60150 words. ) \\nAC2  1057  That afternoon the convener communicated his version of the story to the shop \\nsteward's committee and within an hour every department was buzzing with the news. (AC2  \\nMan at the sharp end.  Kilby, M. Lewes, East Sussex: The Book Guild Ltd, 1991, pp. ??. 2565 \\ns-units, 36227 words. ) \\nACG  1865  Though he sits by the gate of Shiloh, in his blindness watching the road, he is \\nnearly the last in the town to hear the news. (ACG  Lo and behold!  Dennis, Trevor. London: \\nSPCK, 1991, pp. ??. 1987 s-units, 36214 words. ) \\nAKG  none  Daily Telegraph, electronic edition of 1992-04-13: News and features. (AKG  \\n[Daily Telegraph, electronic edition of 19920413].  London: The Daily Telegraph plc, 1992, \\nSocial material, pp. ??. 34 s-units, 677 words. ) \\nAKH  919  In 1970 Hall joined the News of the World, where she was woman's editor until \\n1988. (AKH  [Daily Telegraph, electronic edition of 19920413].  London: The Daily \\nTelegraph plc, 1992, World affairs material, pp. ??. 963 s-units, 20012 words. (AKH  [Daily \\nTelegraph, electronic edition of 19920413].  London: The Daily Telegraph plc, 1992, World \\naffairs material, pp. ??. 963 s-units, 20012 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 19, 'page_label': '20', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"20 \\n \\nAPW  879  I did not hear the sailor's words, but Lachlan forbade me to waken Hector, he said \\nthe morning would do for the news. (APW  Quest for a babe.  Hendry, Frances Mary. \\nEdinburgh: Canongate Publishing Ltd, 1990, pp. 43-141. 3543 s-units, 37837 words. ) \\nB1R  1566  This remedy may be needed after a fright, rage, vexation, jealousy or hearing bad \\nnews. (B1R  How to use homeopathy.  Hammond, Christopher. Shaftesbury, Dorset: Element \\nBooks Ltd, 1991, pp. 1-134. 2739 s-units, 35304 words. ) \\nB2E  1373  We began to get worse and worse news from the Continent about Concentration \\nCamps, for Jews and others, that were almost unbelievably brutal. (B2E  Oh! sister I saw the \\nbells go down.  Saunders-Veness, Frances. Lewes, East Sussex: The Book Guild Ltd, 1989, \\npp. 7-73. 1596 s-units, 25384 words. ) \\nC86  1607  When Creed called, Jed was watching a news report about a vulture who'd just \\nbeen arrested on a murder charge. (C86  The five gates of hell.  Thomson, Rupert. London: \\nBloomsbury Publishing Ltd, 1991, pp. 123-226. 4332 s-units, 41866 words. ) \\nCBU  603  The news of the near fatal stabbing of WPC Harrison in Liverpool has focused \\nattention again on the vulnerability of women to physical violence, particularly during their \\nworking lives. (CBU  Accountancy.  London: Institute of Chartered Accountants, 1993, pp. ??. \\n5049 s-units, 102586 words. ) \\nCGD  997  Resistance to uncomfortable news, for example a recommendation to give up one's \\nown home, is as strongly present as in earlier life.( CGD  Family work with elderly people.  \\nFroggatt, Alison. Basingstoke: Macmillan Publishers Ltd, 1990, pp. 1-107. 1936 s-units, \\n37812 words. ) \\nCGL  288  This quarterly publication, available to members of CWH is full of news updates on \\nthe aircraft of the CWH Museum along with articles of an historical nature. (CGL  FlyPast.  \\nStamford, Lincs: Key Publishing, 1992, pp. ??. 1934 s-units, 39395 words. ) \\nCH6  9210  ‘I've got some great news,’ she told her mother Barbara Cooper. (CH6  The Daily \\nMirror.  London: Mirror Group Newspapers, 1992, pp. ??. 9610 s-units, 127906 words.) \\nCH7  2499  The former Kent all-rounder was ‘disgusted’ that news of his sacking — along \\nwith batsman Andrew Brown — was announced before the club had told them.( CH7  The \\nDaily Mirror.  London: Mirror Group Newspapers, 1992, pp. ??. 5437 s-units, 84868 words. ) \\nCKB  3038  ‘Have you heard the news?’ (CKB  The raven on the water.  Taylor, Andrew. \\nLondon: Fontana Press, 1992, pp. 7-136. 3819 s-units, 39288 words.) \\nCR8  776  They were more reassured by the news that the prince was about to give a lunch, \\nwhich would be attended by his son, Prince Ranariddh, who leads FUNCINPEC, and by Chea \\nSim, the general secretary of the CPP.( CR8  The Economist.  London: The Economist \\nNewspaper Ltd, 1993, pp. ??. 3139 s-units, 57460 words. ) \\nCRA  469  FOR a writer who was put in the ‘Garbage School of Literature’ along with \\nTennessee Williams and William Faulkner by the editor of the Jackson Daily News, Eudora \\nWelty has done well for herself. (CRA  The Economist.  London: The Economist Newspaper \\nLtd, 1993, pp. ??. 3317 s-units, 58734 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 20, 'page_label': '21', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"21 \\n \\nCRC  2650  It owns 40% of Nikkei Quick, a Japanese-language on-line financial news service \\nwhose cubby-hole is the first in which company announcements are placed. (CRC  The \\nEconomist.  London: The Economist Newspaper Ltd, 1993, pp. ??. 4039 s-units, 71921 \\nwords.) \\nCRU  540  The Gay News Defence Committee organised many forms of protest, including a \\nmarch and meeting in Trafalgar Square which attracted 5,000 people. (CRU  Permission and \\nRegulation.  Newburn, T. London: Routledge & Kegan Paul plc, 1992, pp. 1-70. 1152 s-units, \\n31189 words. ) \\nCTD  49  Not such good news from one of the original players in this arena though, Mac-on-\\nRISC house Quorum Software Systems Inc, Menlo Park, California, has filed suit against \\nApple seeking to counter allegations of patent and copyright infringement made by Apple. \\n(CTD  Unigram x.  APT Data Services Ltd., 1993, pp. ??. 418 s-units, 10171 words. ) \\nCTE  264  Another piece of what sounds like good news is that the entire Coherent 4.0 consists \\nof six floppy disks and ‘installs in less than an hour’. (CTE  Unigram x.  APT Data Services \\nLtd., 1993, pp. ??. 331 s-units, 8060 words. ) \\nEC2  100  ’(News at Ten, 4.6.91). (EC2  ASH Supporters' News Issue No. 29.  London: Action \\non Smoking & Health, 1991, pp. ??. 375 s-units, 7001 words. ) \\nFM2  855  So that's good news. (FM2  Missprint planning meeting (Business). Recorded on 28 \\nMarch 1993 with 5 participants, totalling 15029 words, 1941 utterances (duration not \\nrecorded).  \\nPS000  17 words, 48 utterances.  \\nPS1S1  (`Wendy', female, 25, lexicographer): 8022 words, 782 utterances.  \\nPS1S2  (`Clare', female, 21, transcriber): 1937 words, 353 utterances.  \\nPS1S3  (`Derek', male, 24, transcriber): 3430 words, 480 utterances.  \\nPS1S4  (`David', male, 24, transcriber): 1623 words, 278 utterances. ) \\nFS0  710  Auque's news appeared to point to the fact that John was being held by an Iranian-\\nbacked group, and in March Hashemi Rafsanjani called a news conference in Tehran during \\nwhich he repeated his request that Britain should help locate the missing Iranians in Beirut if \\nit wanted Iran to help with the British hostages. (FS0  Some other rainbow.  Morrell, J and \\nMcCarthy, J. London: Transworld Publishers Ltd, 1993, pp. ??. 1974 s-units, 35288 words. ) \\nGUK  955  The news of Soeur Dosithée's holy and resigned death came on a black-edged card \\nin a black-edged envelope. (GUK  Daughters of the house.  Roberts, Michele. London: Virago \\nPress Ltd, 1993, pp. 30-153. 3950 s-units, 41259 words. ) \\nGUU  1404  ‘Any news of Ivor?’ she asked gently. (GUU  Freelance death.  Taylor, Andrew. \\nLondon: Victor Gollancz Ltd, 1993, pp. 52-175. 4337 s-units, 40867 words. ) \\nH0M  543  the fucking news… (H0M  Money.  Amis, Martin. London: Penguin Group, 1985, \\npp. ??. 4072 s-units, 41518 words. ) \\nH46  277  NEWS ( H46  Bookseller.  London: J Whitaker & sons, 1993, pp. ??. 1326 s-units, \\n25503 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 21, 'page_label': '22', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"22 \\n \\nHAF  419  NEWS DIGEST ( HAF  The Sunday People.  pp. ??. 1337 s-units, 19285 words. ) \\nHAK  41  After joining Courage, he used his editing experience on in-house newspapers and \\nmagazines and branched out into video news and promotional programmes. (HAK  BAIE \\nNews for communicators in business.  Dorking: Hardman Press, 1993, pp. ??. 399 s-units, \\n8457 words. ) \\nHP4  616  Wimpey News has teamed up with Kuoni, one of the world's leading travel \\ncompanies, to offer readers the chance of visiting one of three exotic holiday destinations for \\nlittle more than the cost of a European holiday. (HP4  [Misc unpublished -- Wimpey \\nnewsletter].  u.p., n.d., pp. ??. 1680 s-units, 33791 words. ) \\nHS2  616  GOLF NEWS ( HS2  Glenpatrick News.  u.p., n.d., pp. ??. 627 s-units, 11375 words. ) \\nHSY  10  More news? (HSY  CompuAdd. The catalogue.  u.p., n.d., pp. ??. 172 s-units, 2733 \\nwords. ) \\nHU1  797  We await further news of quantitative surveys with interest. (HU1  The Embalmer.  \\nKnebworth: British Institute of Embalmers, 1993, pp. 3-35. 960 s-units, 18716 words. ) \\nHY5  259  When Charles Emmanuel II died, in 1675, special envoys bringing news of his \\ndeath were treated in both Paris and London as the representatives of a king: both Charles II \\nand Louis XIV wore violet mourning, the colour appropriate for a royal death. (HY5  The rise \\nof modern diplomacy 1450–1919.  Anderson, M S. Harlow: Longman Group UK Ltd, 1993, \\npp. 41-148. 1543 s-units, 44759 words. ) \\nJ1C  2344  Subject: Youth Team News (J1C  [Leeds United e-mail list].  u.p., n.d., pp. ??. 3437 \\ns-units, 40333 words. ) \\nJ1H  2665  Team news for Saturday eagerly awaited. (J1H  [Leeds United e-mail list].  u.p., \\nn.d., pp. ??. 4079 s-units, 46681 words. ) \\nJ27  25  During his lifetime Jesus challenged the people of his time to accept the message of \\nthe ‘Good News’, or Gospel (Mark 1:15). (J27  Short courses in religious and moral \\neducation.  u.p., n.d., pp. ??. 881 s-units, 14566 words. ) \\nJ54  21  I shall definitely be at the airport to meet you and I hope to have some startling and \\nimportant news to give you in person. (J54  The divided house.  Raymond, Mary. UK: F A \\nThorpe (Publishing) Ltd, 1985, pp. 1-236. 2757 s-units, 35534 words. ) \\nK5M  10539  Meanwhile, Colin and Wendy Parry, of Great Sankey, Warrington, saw hopes \\nfor their son Tim snatched away with the news that his condition has deteriorated in the \\nintensive care unit of Liverpool's Walton neurosurgical centre. (K5M  [Scotsman].  u.p., n.d., \\nWorld affairs material, pp. ??. 12622 s-units, 261981 words. ) \\nKAC  8 We, the Editors of the Medau News, would like to know your views and suggestions \\non this subject and look forward to printing them in the January issue. (KAC  Medau News. \\nUK: The Medau Society, 1979, pp. ??. 207 s-units, 3505 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 22, 'page_label': '23', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"23 \\n \\nKCJ  1256  well it's, it's it's on at one o'clock, one o'clock and er it's on erm half past six \\ntonight, well I've taped it at half past six tonight and after everybody's watched the news I've, \\nI watched it after, er, you know, so, I watch it then an hour (KCJ  2 conversations recorded by \\n`James' (PS1C7) between 3 and 6 April 1992 with 2 interlocutors, totalling 13482 words, \\n1486 utterances, and 1 hour 23 minutes 47 seconds of recordings.  \\nPS1C7  (`James', male, 63, retired, DE, north-east England): 7486 words, 735 utterances.  \\nPS1C8  (`Patricia', female, 72, housewife, DE, north-east England): 2953 words, 429 \\nutterances.  \\nPS1C9  (`Margaret', female, 30, housewife, north-east England): 3043 words, 322 utterances. \\n) \\nKGH  1434  To the news we go with with Wipe Out by the Safaris. (KGH  BBC Radio \\nNottingham: radio broadcast (Leisure). Recorded on 10 November 1993 with 9 participants, \\ntotalling 16523 words, 1149 utterances, and lasting 1 hour 30 minutes.  \\nPS388  (`Geoff', male, radio presenter): 1667 words, 146 utterances.  \\nPS389  (`Sue', female): 605 words, 31 utterances.  \\nPS38A  (`Teresa', female, radio weather forecaster): 530 words, 35 utterances.  \\nPS38B  (male, 10+, schoolchild): 280 words, 24 utterances.  \\nPS38C  (male, 10+, schoolchild): 1021 words, 88 utterances.  \\nPS38D  (male, 10+, schoolchild): 99 words, 15 utterances.  \\nPS38E  (male, 10+, schoolchild): 208 words, 25 utterances.  \\nPS38F  (male, 10+, schoolchild): 6740 words, 508 utterances.  \\nPS38G  (`Trudy', female): 1094 words, 176 utterances. ) \\nKLV  534  So there's some good news there. (KLV  General Portfolio management meeting \\n(Business). Recorded on 7 April 1993 with 9 participants, totalling 16821 words, 834 \\nutterances (duration not recorded).  \\nPS000  4813 words, 478 utterances.  \\nPS3SF  (`Mike', male, 40+, group manager, London): 9438 words, 189 utterances.  \\nPS3SG  (`Robert', male, 45+, team manager, Home Counties): 609 words, 31 utterances.  \\nPS3SH  (`Jackie', female, 35+, team manager, Home Counties): 622 words, 35 utterances.  \\nPS3SJ  (`Steve', male, 50+, team manager, Home Counties): 93 words, 9 utterances.  \\nPS3SK  (`Sheila', female, 45+, team manager, Home Counties): 293 words, 46 utterances.  \\nPS3SL  (`Phil', male, 45+, team manager, Home Counties): 846 words, 33 utterances.  \\nPS3SM  (`Ian', male, 45+, team manager, Home Counties): 36 words, 4 utterances.  \\nPS3SN  (female, 45+, personal assistant, Home Counties): 71 words, 9 utterances. ) \\nKRT  1876  Well, we, we as you correctly say er with the whole industry had a, had a difficult \\nAugust, I think the good news for Rover is that we fell less in volume terms than most of the \\ncompetition, and indeed we marginally increased our market share (KRT  Fox FM News: \\nradio programme. Recorded on [date unknown] with 292 participants, totalling 158242 words, \\n2687 utterances (duration not recorded).  \\nPS63J  (`A', male): 609 words, 18 utterances.  \\nPS63K  (`JM', female): 38152 words, 799 utterances.  \\nPS63L  (`AW', female): 2227 words, 30 utterances.  \\nPS63M  (`PC', male): 543 words, 9 utterances.  \\nPS63N  (`BC', male): 497 words, 8 utterances.  \\nPS63P  (`MT', female): 179 words, 6 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 23, 'page_label': '24', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"24 \\n \\nPS63R  (`NW', male): 372 words, 4 utterances.  \\nPS63S  (`VH', female): 97 words, 1 utterance.  \\nPS63T  (`JG', male): 415 words, 4 utterances.  \\nPS63U  (`DB', male): 615 words, 10 utterances.  \\nPS63V  (`B', male): 777 words, 27 utterances.  \\nPS63W  (`TB', male): 1029 words, 10 utterances.  \\nPS63X  (`NT', male): 576 words, 6 utterances.  \\nPS63Y  (`MN', male): 723 words, 6 utterances.  \\nPS640  (`LB', female): 3539 words, 64 utterances.  \\nPS641  (`TR', male): 199 words, 2 utterances.  \\nPS642  (`MM', female): 57 words, 1 utterance.  \\nPS643  (`PM', male): 2713 words, 48 utterances.  \\nPS644  (`SI', male): 679 words, 13 utterances.  \\nPS645  (`MP', male): 404 words, 9 utterances.  \\nPS646  (`TS', male): 77 words, 2 utterances.  \\nPS647  (`C', male): 440 words, 22 utterances.  \\nPS648  (`JP', male): 1705 words, 14 utterances.  \\nPS649  (`CS', male): 267 words, 3 utterances.  \\nPS64A  (`D', male): 348 words, 21 utterances.  \\nPS64B  (`CM', male): 310 words, 6 utterances.  \\nPS64C  (`MG', female): 92 words, 1 utterance.  \\nPS64D  (`E', female): 241 words, 9 utterances.  \\nPS64E  (`F', female): 208 words, 9 utterances.  \\nPS64F  (`G', female): 42 words, 2 utterances.  \\nPS64G  (`H', female): 129 words, 8 utterances.  \\nPS64H  (`AS', male): 1243 words, 10 utterances.  \\nPS64J  (`TD', male): 66 words, 1 utterance.  \\nPS64K  (`I', female): 338 words, 5 utterances.  \\nPS64L  (`J', male): 645 words, 33 utterances.  \\nPS64M  (`MB', male): 505 words, 8 utterances.  \\nPS64N  (`BW', male): 83 words, 4 utterances.  \\nPS64P  (`CR', female): 508 words, 4 utterances.  \\nPS64R  (`BF', male): 374 words, 3 utterances.  \\nPS64S  (`K', male): 629 words, 10 utterances.  \\nPS64T  (`TM', male): 327 words, 8 utterances.  \\nPS64U  (`AR', male): 538 words, 10 utterances.  \\nPS64V  (`PR', male): 534 words, 10 utterances.  \\nPS64W  (`L', male): 665 words, 11 utterances.  \\nPS64X  (`CP', male): 593 words, 7 utterances.  \\nPS64Y  (`HH', male): 1528 words, 22 utterances.  \\nPS650  (`IP', male): 48 words, 1 utterance.  \\nPS651  (`PP', male): 350 words, 8 utterances.  \\nPS652  (`AD', female): 368 words, 17 utterances.  \\nPS653  (`TC', male): 193 words, 3 utterances.  \\nPS654  (`TA', male): 117 words, 1 utterance.  \\nPS655  (`IW', male): 505 words, 9 utterances.  \\nPS656  (`DO', male): 784 words, 5 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 24, 'page_label': '25', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"25 \\n \\nPS657  (`RP', male): 2475 words, 43 utterances.  \\nPS658  (`DG', male): 438 words, 8 utterances.  \\nPS659  (`CF', female): 74 words, 1 utterance.  \\nPS65A  (`CJ', female): 310 words, 2 utterances.  \\nPS65B  (`GM', male): 913 words, 15 utterances.  \\nPS65C  (`NS', male): 54 words, 1 utterance.  \\nPS65D  (`DM', male): 585 words, 4 utterances.  \\nPS65E  (`RG', female): 826 words, 6 utterances.  \\nPS65F  (`GO', male): 232 words, 2 utterances.  \\nPS65G  (`F', male): 372 words, 17 utterances.  \\nPS65H  (`RJ', male): 526 words, 7 utterances.  \\nPS65J  (`JB', female): 423 words, 9 utterances.  \\nPS65K  (`G', male): 907 words, 26 utterances.  \\nPS65L  (`JM', male): 1503 words, 18 utterances.  \\nPS65M  (`H', male): 583 words, 21 utterances.  \\nPS65N  (`LR', male): 130 words, 3 utterances.  \\nPS65P  (`MU', male): 14 words, 1 utterance.  \\nPS65R  (`HN', male): 368 words, 4 utterances.  \\nPS65S  (`I', male): 344 words, 19 utterances.  \\nPS65T  (`DW', female): 452 words, 3 utterances.  \\nPS65U  (`RH', male): 653 words, 6 utterances.  \\nPS65V  (`EA', male): 348 words, 9 utterances.  \\nPS65W  (`JH', male): 561 words, 4 utterances.  \\nPS65X  (`MM', male): 218 words, 3 utterances.  \\nPS65Y  (`DF', male): 349 words, 6 utterances.  \\nPS660  (`NH', male): 237 words, 3 utterances.  \\nPS661  (`IG', male): 216 words, 4 utterances.  \\nPS662  (`NC', male): 686 words, 9 utterances.  \\nPS663  (`MH', male): 342 words, 4 utterances.  \\nPS664  (`TN', male): 457 words, 8 utterances.  \\nPS665  (`CG', male): 1006 words, 16 utterances.  \\nPS666  (`LS', male): 487 words, 8 utterances.  \\nPS667  (`DH', male): 816 words, 11 utterances.  \\nPS668  (`Zippy', male): 17 words, 1 utterance.  \\nPS669  (`SJ', female): 699 words, 5 utterances.  \\nPS66A  (`A', female): 631 words, 16 utterances.  \\nPS66B  (`RR', male): 66 words, 2 utterances.  \\nPS66C  (`ML', male): 3676 words, 30 utterances.  \\nPS66D  (`AC', male): 575 words, 7 utterances.  \\nPS66E  (`JZ', female): 641 words, 3 utterances.  \\nPS66F  (`D', female): 256 words, 9 utterances.  \\nPS66G  (`RB', male): 386 words, 6 utterances.  \\nPS66H  (`DS', male): 1486 words, 15 utterances.  \\nPS66J  (`KG', male): 52 words, 1 utterance.  \\nPS66K  (`AH', female): 61 words, 1 utterance.  \\nPS66L  (`SW', male): 256 words, 5 utterances.  \\nPS66M  (`LM', male): 37 words, 1 utterance.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 25, 'page_label': '26', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"26 \\n \\nPS66N  (`RM', male): 1230 words, 11 utterances.  \\nPS66P  (`BG', female): 24 words, 1 utterance.  \\nPS66R  (`E', male): 591 words, 23 utterances.  \\nPS66S  (`CB', female): 576 words, 5 utterances.  \\nPS66T  (`AH', male): 259 words, 1 utterance.  \\nPS66U  (`BH', male): 1512 words, 10 utterances.  \\nPS66V  (`P', male): 74 words, 2 utterances.  \\nPS66W  (`AK', female): 174 words, 7 utterances.  \\nPS66X  (`Q', male): 317 words, 8 utterances.  \\nPS66Y  (`Bungle', male): 158 words, 14 utterances.  \\nPS670  (`Jeffrey', male): 5 words, 1 utterance.  \\nPS671  (`JB', male): 1436 words, 22 utterances.  \\nPS672  (`SH', male): 666 words, 6 utterances.  \\nPS673  (`SK', male): 266 words, 6 utterances.  \\nPS674  (`MS', male): 104 words, 2 utterances.  \\nPS675  (`PS', male): 925 words, 16 utterances.  \\nPS676  (`RV', female): 67 words, 3 utterances.  \\nPS677  (`AA', male): 474 words, 4 utterances.  \\nPS678  (`MH', male): 42 words, 1 utterance.  \\nPS679  (`JE', male): 307 words, 3 utterances.  \\nPS67A  (`EL', female): 469 words, 4 utterances.  \\nPS67B  (`NY', female): 256 words, 3 utterances.  \\nPS67C  (`LJ', male): 393 words, 6 utterances.  \\nPS67D  (`IC', male): 472 words, 10 utterances.  \\nPS67E  (`JW', male): 845 words, 14 utterances.  \\nPS67F  (`NA', male): 223 words, 1 utterance.  \\nPS67G  (`PT', male): 601 words, 7 utterances.  \\nPS67H  (`MI', male): 4138 words, 53 utterances.  \\nPS67J  (`PG', male): 91 words, 1 utterance.  \\nPS67K  (`FD', male): 47 words, 1 utterance.  \\nPS67L  (`TK', male): 595 words, 8 utterances.  \\nPS67M  (`TP', male): 87 words, 1 utterance.  \\nPS67N  (`NM', male): 43 words, 1 utterance.  \\nPS67P  (`JS', male): 2060 words, 17 utterances.  \\nPS67R  (`GD', male): 418 words, 7 utterances.  \\nPS67S  (`MR', male): 1035 words, 5 utterances.  \\nPS67T  (`PJ', male): 557 words, 5 utterances.  \\nPS67U  (`AT', male): 194 words, 2 utterances.  \\nPS67V  (`GW', male): 518 words, 4 utterances.  \\nPS67W  (`RG', male): 199 words, 4 utterances.  \\nPS67X  (`MJ', male): 393 words, 5 utterances.  \\nPS67Y  (`AP', male): 151 words, 3 utterances.  \\nPS680  (`PA', male): 186 words, 4 utterances.  \\nPS681  (`FJ', male): 407 words, 2 utterances.  \\nPS682  (`VB', female): 419 words, 4 utterances.  \\nPS683  (`RK', male): 366 words, 10 utterances.  \\nPS684  (`B', female): 127 words, 6 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 26, 'page_label': '27', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"27 \\n \\nPS685  (`GB', male): 181 words, 3 utterances.  \\nPS686  (`JT', female): 35 words, 1 utterance.  \\nPS687  (`JK', female): 11 words, 1 utterance.  \\nPS688  (`HC', female): 82 words, 2 utterances.  \\nPS689  (`RA', male): 213 words, 4 utterances.  \\nPS68A  (`AB', female): 89 words, 1 utterance.  \\nPS68B  (`PK', male): 3131 words, 43 utterances.  \\nPS68C  (`AG', female): 325 words, 5 utterances.  \\nPS68D  (`MW', male): 686 words, 7 utterances.  \\nPS68E  (`MH', female): 971 words, 11 utterances.  \\nPS68F  (`SP', female): 22 words, 1 utterance.  \\nPS68G  (`BJ', male): 61 words, 1 utterance.  \\nPS68H  (`BW', female): 51 words, 1 utterance.  \\nPS68J  (`PH', male): 488 words, 4 utterances.  \\nPS68K  (`WT', male): 299 words, 6 utterances.  \\nPS68L  (`KP', male): 33 words, 1 utterance.  \\nPS68M  (`PL', male): 53 words, 1 utterance.  \\nPS68N  (`CW', male): 91 words, 1 utterance.  \\nPS68P  (`MB', female): 279 words, 4 utterances.  \\nPS68R  (`KM', male): 236 words, 5 utterances.  \\nPS68S  (`K', female): 116 words, 4 utterances.  \\nPS68T  (`SS', female): 241 words, 4 utterances.  \\nPS68U  (`AJ', male): 149 words, 8 utterances.  \\nPS68V  (`BG', male): 89 words, 2 utterances.  \\nPS68W  (`GF', male): 106 words, 4 utterances.  \\nPS68X  (`RS', male): 1256 words, 13 utterances.  \\nPS68Y  (`NH', female): 69 words, 1 utterance.  \\nPS690  (`CL', female): 455 words, 7 utterances.  \\nPS691  (`DP', male): 719 words, 7 utterances.  \\nPS692  (`JN', female): 987 words, 13 utterances.  \\nPS693  (`PB', male): 215 words, 4 utterances.  \\nPS694  (`MF', male): 74 words, 2 utterances.  \\nPS695  (`IJ', male): 142 words, 1 utterance.  \\nPS696  (`WH', male): 55 words, 1 utterance.  \\nPS697  (`AK', male): 536 words, 12 utterances.  \\nPS698  (`C', female): 134 words, 7 utterances.  \\nPS699  (`JC', male): 110 words, 2 utterances.  \\nPS69A  (`HK', male): 74 words, 1 utterance.  \\nPS69B  (`HM', male): 65 words, 1 utterance.  \\nPS69C  (`EP', female): 649 words, 4 utterances.  \\nPS69D  (`SP', male): 217 words, 2 utterances.  \\nPS69E  (`RL', male): 272 words, 3 utterances.  \\nPS69F  (`TI', male): 47 words, 1 utterance.  \\nPS69G  (`LH', female): 522 words, 12 utterances.  \\nPS69H  (`FW', male): 365 words, 5 utterances.  \\nPS69J  (`LM', female): 132 words, 7 utterances.  \\nPS69K  (`NR', female): 360 words, 5 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 27, 'page_label': '28', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"28 \\n \\nPS69L  (`TF', female): 26 words, 2 utterances.  \\nPS69M  (`GP', female): 356 words, 3 utterances.  \\nPS69N  (`SM', female): 637 words, 10 utterances.  \\nPS69P  (`NK', male): 285 words, 6 utterances.  \\nPS69R  (`WE', male): 97 words, 1 utterance.  \\nPS69S  (`NP', female): 382 words, 3 utterances.  \\nPS69T  (`DC', male): 104 words, 1 utterance.  \\nPS69U  (`CH', female): 77 words, 1 utterance.  \\nPS69V  (`EF', male): 405 words, 4 utterances.  \\nPS69W  (`BS', male): 218 words, 3 utterances.  \\nPS69X  (`MC', female): 45 words, 1 utterance.  \\nPS69Y  (`BH', female): 807 words, 19 utterances.  \\nPS6A0  (`BY', female): 24 words, 1 utterance.  \\nPS6A1  (`CH', male): 362 words, 3 utterances.  \\nPS6A2  (`KS', male): 219 words, 2 utterances.  \\nPS6A3  (`RM', female): 51 words, 1 utterance.  \\nPS6A4  (`JJ', male): 169 words, 1 utterance.  \\nPS6A5  (`CA', female): 107 words, 4 utterances.  \\nPS6A6  (`CC', male): 207 words, 4 utterances.  \\nPS6A7  (`KC', male): 123 words, 2 utterances.  \\nPS6A8  (`JW', female): 231 words, 5 utterances.  \\nPS6A9  (`JMC', female): 500 words, 12 utterances.  \\nPS6AA  (`FJM', female): 117 words, 3 utterances.  \\nPS6AB  (`KK', female): 397 words, 5 utterances.  \\nPS6AC  (`BO', male): 63 words, 2 utterances.  \\nPS6AD  (`NP', male): 447 words, 5 utterances.  \\nPS6AE  (`HA', male): 40 words, 1 utterance.  \\nPS6AF  (`DW', male): 910 words, 11 utterances.  \\nPS6AG  (`JV', male): 720 words, 4 utterances.  \\nPS6AH  (`RD', female): 30 words, 1 utterance.  \\nPS6AJ  (`EC', male): 69 words, 1 utterance.  \\nPS6AK  (`WR', male): 526 words, 3 utterances.  \\nPS6AL  (`PD', male): 176 words, 2 utterances.  \\nPS6AM  (`HE', female): 129 words, 5 utterances.  \\nPS6AN  (`DV', male): 725 words, 5 utterances.  \\nPS6AP  (`PE', male): 180 words, 3 utterances.  \\nPS6AR  (`AF', male): 555 words, 4 utterances.  \\nPS6AS  (`LH', male): 19 words, 1 utterance.  \\nPS6AT  (`LC', male): 22 words, 1 utterance.  \\nPS6AU  (`BN', male): 447 words, 4 utterances.  \\nPS6AV  (`TJ', male): 217 words, 1 utterance.  \\nPS6AW  (`WW', female): 218 words, 2 utterances.  \\nPS6AX  (`SR', male): 531 words, 11 utterances.  \\nPS6AY  (`PW', male): 271 words, 6 utterances.  \\nPS6B0  (`YO', female): 17 words, 1 utterance.  \\nPS6B1  (`FM', male): 212 words, 4 utterances.  \\nPS6B2  (`SA', female): 380 words, 11 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 28, 'page_label': '29', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"29 \\n \\nPS6B3  (`KB', male): 47 words, 1 utterance.  \\nPS6B4 (`WA', male): 32 words, 1 utterance.  \\nPS6B5  (`VB', male): 86 words, 1 utterance.  \\nPS6B6  (`AM', male): 56 words, 1 utterance.  \\nPS6B7  (`HA', female): 92 words, 1 utterance.  \\nPS6B8  (`RJ', female): 364 words, 3 utterances.  \\nPS6B9  (`TF', male): 80 words, 1 utterance.  \\nPS6BA  (`FH', female): 512 words, 4 utterances.  \\nPS6BB  (`AL', male): 171 words, 2 utterances.  \\nPS6BC  (`JL', male): 416 words, 5 utterances.  \\nPS6BD  (`BV', male): 367 words, 3 utterances.  \\nPS6BE  (`CK', female): 402 words, 5 utterances.  \\nPS6BF  (`ZW', female): 136 words, 2 utterances.  \\nPS6BG  (`AC', female): 35 words, 3 utterances.  \\nPS6BH  (`EH', female): 106 words, 1 utterance.  \\nPS6BJ  (`HT', female): 105 words, 2 utterances.  \\nPS6BK  (`JR', male): 293 words, 5 utterances.  \\nPS6BL  (`PK', female): 92 words, 2 utterances.  \\nPS6BM  (`MA', female): 320 words, 10 utterances.  \\nPS6BN  (`JG', female): 147 words, 3 utterances.  \\nPS6BP  (`M', male): 24 words, 1 utterance.  \\nPS6BS  (`JO', male): 58 words, 2 utterances.  \\nPS6BT  (`LB', male): 282 words, 6 utterances.  \\nPS6BU  (`DD', female): 65 words, 1 utterance.  \\nPS6BV  (`AM', female): 123 words, 3 utterances.  \\nPS6BW  (`NO', male): 239 words, 3 utterances.  \\nPS6BX  (`DJ', male): 440 words, 6 utterances.  \\nPS6BY  (`N', male): 136 words, 5 utterances.  \\nPS6C0  (`EH', male): 252 words, 3 utterances.  \\nPS6C1  (`BM', male): 221 words, 5 utterances.  \\nPS6C2  (`O', male): 51 words, 5 utterances.  \\nPS6C3  (`JH', female): 194 words, 3 utterances.  \\nPS6C4  (`R', male): 176 words, 9 utterances.  \\nPS6C5  (`JS', female): 118 words, 3 utterances.  \\nPS6C6  (`AT', female): 294 words, 3 utterances.  \\nPS6C7  (`DL', male): 56 words, 1 utterance.  \\nPS6C8  (`KH', male): 67 words, 1 utterance.  \\nPS6C9  (`BS', female): 63 words, 1 utterance.  \\nPS6CA  (`SC', female): 275 words, 3 utterances.  \\nPS6CB  (`LT', male): 236 words, 5 utterances.  \\nPS6CC  (`DM', female): 253 words, 10 utterances.  \\nPS6CD  (`NA', female): 232 words, 3 utterances.  \\nPS6CE  (`J', female): 60 words, 4 utterances.  \\nPS6CF  (`ID', female): 355 words, 3 utterances.  \\nPS6CG  (`CB', male): 255 words, 4 utterances.  \\nPS6CH  (`RD', male): 72 words, 1 utterance.  \\nPS6CJ  (`RO', male): 109 words, 1 utterance.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 29, 'page_label': '30', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"30 \\n \\nPS6CK  (`GH', male): 30 words, 1 utterance.  \\nPS6CL  (`CM', female): 305 words, 6 utterances.  \\nPS6CM  (`LT'): 332 words, 7 utterances.  \\nKRTPS000  95 words, 1 utterance. )” \\n (see it also online for resource details: http://www.natcorp.ox.ac.uk/using/index.xml?ID=simple )\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='1\\nRetrieval-Augmented Generation for Large\\nLanguage Models: A Survey\\nYunfan Gaoa, Yun Xiongb, Xinyu Gao b, Kangxiang Jia b, Jinliu Pan b, Yuxi Bic, Yi Dai a, Jiawei Sun a, Meng\\nWangc, and Haofen Wang a,c\\naShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\\nbShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\\ncCollege of Design and Innovation, Tongji University\\nAbstract—Large Language Models (LLMs) showcase impres-\\nsive capabilities but encounter challenges like hallucination,\\noutdated knowledge, and non-transparent, untraceable reasoning\\nprocesses. Retrieval-Augmented Generation (RAG) has emerged\\nas a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the\\ngeneration, particularly for knowledge-intensive tasks, and allows\\nfor continuous knowledge updates and integration of domain-\\nspecific information. RAG synergistically merges LLMs’ intrin-\\nsic knowledge with the vast, dynamic repositories of external\\ndatabases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing\\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\\nIt meticulously scrutinizes the tripartite foundation of RAG\\nframeworks, which includes the retrieval, the generation and the\\naugmentation techniques. The paper highlights the state-of-the-\\nart technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG\\nsystems. Furthermore, this paper introduces up-to-date evalua-\\ntion framework and benchmark. At the end, this article delineates\\nthe challenges currently faced and points out prospective avenues\\nfor research and development 1.\\nIndex Terms—Large language model, retrieval-augmented gen-\\neration, natural language processing, information retrieval\\nI. I NTRODUCTION\\nL\\nARGE language models (LLMs) have achieved remark-\\nable success, though they still face significant limitations,\\nespecially in domain-specific or knowledge-intensive tasks [1],\\nnotably producing “hallucinations” [2] when handling queries\\nbeyond their training data or requiring current information. To\\novercome challenges, Retrieval-Augmented Generation (RAG)\\nenhances LLMs by retrieving relevant document chunks from\\nexternal knowledge base through semantic similarity calcu-\\nlation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,\\nestablishing RAG as a key technology in advancing chatbots\\nand enhancing the suitability of LLMs for real-world applica-\\ntions.\\nRAG technology has rapidly developed in recent years, and\\nthe technology tree summarizing related research is shown\\nCorresponding Author.Email:haofen.wang@tongji.edu.cn\\n1Resources are available at https://github.com/Tongji-KGLLM/\\nRAG-Survey\\nin Figure 1. The development trajectory of RAG in the era\\nof large models exhibits several distinct stage characteristics.\\nInitially, RAG’s inception coincided with the rise of the\\nTransformer architecture, focusing on enhancing language\\nmodels by incorporating additional knowledge through Pre-\\nTraining Models (PTM). This early stage was characterized\\nby foundational work aimed at refining pre-training techniques\\n[3]–[5].The subsequent arrival of ChatGPT [6] marked a\\npivotal moment, with LLM demonstrating powerful in context\\nlearning (ICL) capabilities. RAG research shifted towards\\nproviding better information for LLMs to answer more com-\\nplex and knowledge-intensive tasks during the inference stage,\\nleading to rapid development in RAG studies. As research\\nprogressed, the enhancement of RAG was no longer limited\\nto the inference stage but began to incorporate more with LLM\\nfine-tuning techniques.\\nThe burgeoning field of RAG has experienced swift growth,\\nyet it has not been accompanied by a systematic synthesis that\\ncould clarify its broader trajectory. This survey endeavors to\\nfill this gap by mapping out the RAG process and charting\\nits evolution and anticipated future paths, with a focus on the\\nintegration of RAG within LLMs. This paper considers both\\ntechnical paradigms and research methods, summarizing three\\nmain research paradigms from over 100 RAG studies, and\\nanalyzing key technologies in the core stages of “Retrieval,”\\n“Generation,” and “Augmentation.” On the other hand, current\\nresearch tends to focus more on methods, lacking analysis and\\nsummarization of how to evaluate RAG. This paper compre-\\nhensively reviews the downstream tasks, datasets, benchmarks,\\nand evaluation methods applicable to RAG. Overall, this\\npaper sets out to meticulously compile and categorize the\\nfoundational technical concepts, historical progression, and\\nthe spectrum of RAG methodologies and applications that\\nhave emerged post-LLMs. It is designed to equip readers and\\nprofessionals with a detailed and structured understanding of\\nboth large models and RAG. It aims to illuminate the evolution\\nof retrieval augmentation techniques, assess the strengths and\\nweaknesses of various approaches in their respective contexts,\\nand speculate on upcoming trends and innovations.\\nOur contributions are as follows:\\n• In this survey, we present a thorough and systematic\\nreview of the state-of-the-art RAG methods, delineating\\nits evolution through paradigms including naive RAG,\\narXiv:2312.10997v5  [cs.CL]  27 Mar 2024'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2\\nFig. 1. Technology tree of RAG research. The stages of involving RAG mainly include pre-training, fine-tuning, and inference. With the emergence of LLMs,\\nresearch on RAG initially focused on leveraging the powerful in context learning abilities of LLMs, primarily concentrating on the inference stage. Subsequent\\nresearch has delved deeper, gradually integrating more with the fine-tuning of LLMs. Researchers have also been exploring ways to enhance language models\\nin the pre-training stage through retrieval-augmented techniques.\\nadvanced RAG, and modular RAG. This review contex-\\ntualizes the broader scope of RAG research within the\\nlandscape of LLMs.\\n• We identify and discuss the central technologies integral\\nto the RAG process, specifically focusing on the aspects\\nof “Retrieval”, “Generation” and “Augmentation”, and\\ndelve into their synergies, elucidating how these com-\\nponents intricately collaborate to form a cohesive and\\neffective RAG framework.\\n• We have summarized the current assessment methods of\\nRAG, covering 26 tasks, nearly 50 datasets, outlining\\nthe evaluation objectives and metrics, as well as the\\ncurrent evaluation benchmarks and tools. Additionally,\\nwe anticipate future directions for RAG, emphasizing\\npotential enhancements to tackle current challenges.\\nThe paper unfolds as follows: Section II introduces the\\nmain concept and current paradigms of RAG. The following\\nthree sections explore core components—“Retrieval”, “Gen-\\neration” and “Augmentation”, respectively. Section III focuses\\non optimization methods in retrieval,including indexing, query\\nand embedding optimization. Section IV concentrates on post-\\nretrieval process and LLM fine-tuning in generation. Section V\\nanalyzes the three augmentation processes. Section VI focuses\\non RAG’s downstream tasks and evaluation system. Sec-\\ntion VII mainly discusses the challenges that RAG currently\\nfaces and its future development directions. At last, the paper\\nconcludes in Section VIII.\\nII. O VERVIEW OF RAG\\nA typical application of RAG is illustrated in Figure 2.\\nHere, a user poses a question to ChatGPT about a recent,\\nwidely discussed news. Given ChatGPT’s reliance on pre-\\ntraining data, it initially lacks the capacity to provide up-\\ndates on recent developments. RAG bridges this information\\ngap by sourcing and incorporating knowledge from external\\ndatabases. In this case, it gathers relevant news articles related\\nto the user’s query. These articles, combined with the original\\nquestion, form a comprehensive prompt that empowers LLMs\\nto generate a well-informed answer.\\nThe RAG research paradigm is continuously evolving, and\\nwe categorize it into three stages: Naive RAG, Advanced\\nRAG, and Modular RAG, as showed in Figure 3. Despite\\nRAG method are cost-effective and surpass the performance\\nof the native LLM, they also exhibit several limitations.\\nThe development of Advanced RAG and Modular RAG is\\na response to these specific shortcomings in Naive RAG.\\nA. Naive RAG\\nThe Naive RAG research paradigm represents the earli-\\nest methodology, which gained prominence shortly after the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='3\\nFig. 2. A representative instance of the RAG process applied to question answering. It mainly consists of 3 steps. 1) Indexing. Documents are split into chunks,\\nencoded into vectors, and stored in a vector database. 2) Retrieval. Retrieve the Top k chunks most relevant to the question based on semantic similarity. 3)\\nGeneration. Input the original question and the retrieved chunks together into LLM to generate the final answer.\\nwidespread adoption of ChatGPT. The Naive RAG follows\\na traditional process that includes indexing, retrieval, and\\ngeneration, which is also characterized as a “Retrieve-Read”\\nframework [7].\\nIndexing starts with the cleaning and extraction of raw data\\nin diverse formats like PDF, HTML, Word, and Markdown,\\nwhich is then converted into a uniform plain text format. To\\naccommodate the context limitations of language models, text\\nis segmented into smaller, digestible chunks. Chunks are then\\nencoded into vector representations using an embedding model\\nand stored in vector database. This step is crucial for enabling\\nefficient similarity searches in the subsequent retrieval phase.\\nRetrieval. Upon receipt of a user query, the RAG system\\nemploys the same encoding model utilized during the indexing\\nphase to transform the query into a vector representation.\\nIt then computes the similarity scores between the query\\nvector and the vector of chunks within the indexed corpus.\\nThe system prioritizes and retrieves the top K chunks that\\ndemonstrate the greatest similarity to the query. These chunks\\nare subsequently used as the expanded context in prompt.\\nGeneration. The posed query and selected documents are\\nsynthesized into a coherent prompt to which a large language\\nmodel is tasked with formulating a response. The model’s\\napproach to answering may vary depending on task-specific\\ncriteria, allowing it to either draw upon its inherent parametric\\nknowledge or restrict its responses to the information con-\\ntained within the provided documents. In cases of ongoing\\ndialogues, any existing conversational history can be integrated\\ninto the prompt, enabling the model to engage in multi-turn\\ndialogue interactions effectively.\\nHowever, Naive RAG encounters notable drawbacks:\\nRetrieval Challenges . The retrieval phase often struggles\\nwith precision and recall, leading to the selection of misaligned\\nor irrelevant chunks, and the missing of crucial information.\\nGeneration Difficulties. In generating responses, the model\\nmay face the issue of hallucination, where it produces con-\\ntent not supported by the retrieved context. This phase can\\nalso suffer from irrelevance, toxicity, or bias in the outputs,\\ndetracting from the quality and reliability of the responses.\\nAugmentation Hurdles . Integrating retrieved information\\nwith the different task can be challenging, sometimes resulting\\nin disjointed or incoherent outputs. The process may also\\nencounter redundancy when similar information is retrieved\\nfrom multiple sources, leading to repetitive responses. Deter-\\nmining the significance and relevance of various passages and\\nensuring stylistic and tonal consistency add further complexity.\\nFacing complex issues, a single retrieval based on the original\\nquery may not suffice to acquire adequate context information.\\nMoreover, there’s a concern that generation models might\\noverly rely on augmented information, leading to outputs that\\nsimply echo retrieved content without adding insightful or\\nsynthesized information.\\nB. Advanced RAG\\nAdvanced RAG introduces specific improvements to over-\\ncome the limitations of Naive RAG. Focusing on enhancing re-\\ntrieval quality, it employs pre-retrieval and post-retrieval strate-\\ngies. To tackle the indexing issues, Advanced RAG refines\\nits indexing techniques through the use of a sliding window\\napproach, fine-grained segmentation, and the incorporation of\\nmetadata. Additionally, it incorporates several optimization\\nmethods to streamline the retrieval process [8].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='4\\nFig. 3. Comparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\\nchain-like structure. (Right) Modular RAG inherits and develops from the previous paradigm, showcasing greater flexibility overall. This is evident in the\\nintroduction of multiple specific functional modules and the replacement of existing modules. The overall process is not limited to sequential retrieval and\\ngeneration; it includes methods such as iterative and adaptive retrieval.\\nPre-retrieval process. In this stage, the primary focus is\\non optimizing the indexing structure and the original query.\\nThe goal of optimizing indexing is to enhance the quality of\\nthe content being indexed. This involves strategies: enhancing\\ndata granularity, optimizing index structures, adding metadata,\\nalignment optimization, and mixed retrieval. While the goal\\nof query optimization is to make the user’s original question\\nclearer and more suitable for the retrieval task. Common\\nmethods include query rewriting query transformation, query\\nexpansion and other techniques [7], [9]–[11].\\nPost-Retrieval Process. Once relevant context is retrieved,\\nit’s crucial to integrate it effectively with the query. The main\\nmethods in post-retrieval process include rerank chunks and\\ncontext compressing. Re-ranking the retrieved information to\\nrelocate the most relevant content to the edges of the prompt is\\na key strategy. This concept has been implemented in frame-\\nworks such as LlamaIndex 2, LangChain3, and HayStack [12].\\nFeeding all relevant documents directly into LLMs can lead\\nto information overload, diluting the focus on key details with\\nirrelevant content.To mitigate this, post-retrieval efforts con-\\ncentrate on selecting the essential information, emphasizing\\ncritical sections, and shortening the context to be processed.\\n2https://www.llamaindex.ai\\n3https://www.langchain.com/\\nC. Modular RAG\\nThe modular RAG architecture advances beyond the for-\\nmer two RAG paradigms, offering enhanced adaptability and\\nversatility. It incorporates diverse strategies for improving its\\ncomponents, such as adding a search module for similarity\\nsearches and refining the retriever through fine-tuning. Inno-\\nvations like restructured RAG modules [13] and rearranged\\nRAG pipelines [14] have been introduced to tackle specific\\nchallenges. The shift towards a modular RAG approach is\\nbecoming prevalent, supporting both sequential processing and\\nintegrated end-to-end training across its components. Despite\\nits distinctiveness, Modular RAG builds upon the foundational\\nprinciples of Advanced and Naive RAG, illustrating a progres-\\nsion and refinement within the RAG family.\\n1) New Modules: The Modular RAG framework introduces\\nadditional specialized components to enhance retrieval and\\nprocessing capabilities. The Search module adapts to spe-\\ncific scenarios, enabling direct searches across various data\\nsources like search engines, databases, and knowledge graphs,\\nusing LLM-generated code and query languages [15]. RAG-\\nFusion addresses traditional search limitations by employing\\na multi-query strategy that expands user queries into diverse\\nperspectives, utilizing parallel vector searches and intelligent\\nre-ranking to uncover both explicit and transformative knowl-\\nedge [16]. The Memory module leverages the LLM’s memory\\nto guide retrieval, creating an unbounded memory pool that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='5\\naligns the text more closely with data distribution through iter-\\native self-enhancement [17], [18]. Routing in the RAG system\\nnavigates through diverse data sources, selecting the optimal\\npathway for a query, whether it involves summarization,\\nspecific database searches, or merging different information\\nstreams [19]. The Predict module aims to reduce redundancy\\nand noise by generating context directly through the LLM,\\nensuring relevance and accuracy [13]. Lastly, the Task Adapter\\nmodule tailors RAG to various downstream tasks, automating\\nprompt retrieval for zero-shot inputs and creating task-specific\\nretrievers through few-shot query generation [20], [21] .This\\ncomprehensive approach not only streamlines the retrieval pro-\\ncess but also significantly improves the quality and relevance\\nof the information retrieved, catering to a wide array of tasks\\nand queries with enhanced precision and flexibility.\\n2) New Patterns: Modular RAG offers remarkable adapt-\\nability by allowing module substitution or reconfiguration\\nto address specific challenges. This goes beyond the fixed\\nstructures of Naive and Advanced RAG, characterized by a\\nsimple “Retrieve” and “Read” mechanism. Moreover, Modular\\nRAG expands this flexibility by integrating new modules or\\nadjusting interaction flow among existing ones, enhancing its\\napplicability across different tasks.\\nInnovations such as the Rewrite-Retrieve-Read [7]model\\nleverage the LLM’s capabilities to refine retrieval queries\\nthrough a rewriting module and a LM-feedback mechanism\\nto update rewriting model., improving task performance.\\nSimilarly, approaches like Generate-Read [13] replace tradi-\\ntional retrieval with LLM-generated content, while Recite-\\nRead [22] emphasizes retrieval from model weights, enhanc-\\ning the model’s ability to handle knowledge-intensive tasks.\\nHybrid retrieval strategies integrate keyword, semantic, and\\nvector searches to cater to diverse queries. Additionally, em-\\nploying sub-queries and hypothetical document embeddings\\n(HyDE) [11] seeks to improve retrieval relevance by focusing\\non embedding similarities between generated answers and real\\ndocuments.\\nAdjustments in module arrangement and interaction, such\\nas the Demonstrate-Search-Predict (DSP) [23] framework\\nand the iterative Retrieve-Read-Retrieve-Read flow of ITER-\\nRETGEN [14], showcase the dynamic use of module out-\\nputs to bolster another module’s functionality, illustrating a\\nsophisticated understanding of enhancing module synergy.\\nThe flexible orchestration of Modular RAG Flow showcases\\nthe benefits of adaptive retrieval through techniques such as\\nFLARE [24] and Self-RAG [25]. This approach transcends\\nthe fixed RAG retrieval process by evaluating the necessity\\nof retrieval based on different scenarios. Another benefit of\\na flexible architecture is that the RAG system can more\\neasily integrate with other technologies (such as fine-tuning\\nor reinforcement learning) [26]. For example, this can involve\\nfine-tuning the retriever for better retrieval results, fine-tuning\\nthe generator for more personalized outputs, or engaging in\\ncollaborative fine-tuning [27].\\nD. RAG vs Fine-tuning\\nThe augmentation of LLMs has attracted considerable atten-\\ntion due to their growing prevalence. Among the optimization\\nmethods for LLMs, RAG is often compared with Fine-tuning\\n(FT) and prompt engineering. Each method has distinct charac-\\nteristics as illustrated in Figure 4. We used a quadrant chart to\\nillustrate the differences among three methods in two dimen-\\nsions: external knowledge requirements and model adaption\\nrequirements. Prompt engineering leverages a model’s inherent\\ncapabilities with minimum necessity for external knowledge\\nand model adaption. RAG can be likened to providing a model\\nwith a tailored textbook for information retrieval, ideal for pre-\\ncise information retrieval tasks. In contrast, FT is comparable\\nto a student internalizing knowledge over time, suitable for\\nscenarios requiring replication of specific structures, styles, or\\nformats.\\nRAG excels in dynamic environments by offering real-\\ntime knowledge updates and effective utilization of external\\nknowledge sources with high interpretability. However, it\\ncomes with higher latency and ethical considerations regarding\\ndata retrieval. On the other hand, FT is more static, requiring\\nretraining for updates but enabling deep customization of the\\nmodel’s behavior and style. It demands significant compu-\\ntational resources for dataset preparation and training, and\\nwhile it can reduce hallucinations, it may face challenges with\\nunfamiliar data.\\nIn multiple evaluations of their performance on various\\nknowledge-intensive tasks across different topics, [28] re-\\nvealed that while unsupervised fine-tuning shows some im-\\nprovement, RAG consistently outperforms it, for both exist-\\ning knowledge encountered during training and entirely new\\nknowledge. Additionally, it was found that LLMs struggle\\nto learn new factual information through unsupervised fine-\\ntuning. The choice between RAG and FT depends on the\\nspecific needs for data dynamics, customization, and com-\\nputational capabilities in the application context. RAG and\\nFT are not mutually exclusive and can complement each\\nother, enhancing a model’s capabilities at different levels.\\nIn some instances, their combined use may lead to optimal\\nperformance. The optimization process involving RAG and FT\\nmay require multiple iterations to achieve satisfactory results.\\nIII. R ETRIEVAL\\nIn the context of RAG, it is crucial to efficiently retrieve\\nrelevant documents from the data source. There are several\\nkey issues involved, such as the retrieval source, retrieval\\ngranularity, pre-processing of the retrieval, and selection of\\nthe corresponding embedding model.\\nA. Retrieval Source\\nRAG relies on external knowledge to enhance LLMs, while\\nthe type of retrieval source and the granularity of retrieval\\nunits both affect the final generation results.\\n1) Data Structure: Initially, text is s the mainstream source\\nof retrieval. Subsequently, the retrieval source expanded to in-\\nclude semi-structured data (PDF) and structured data (Knowl-\\nedge Graph, KG) for enhancement. In addition to retrieving\\nfrom original external sources, there is also a growing trend in\\nrecent researches towards utilizing content generated by LLMs\\nthemselves for retrieval and enhancement purposes.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='6\\nTABLE I\\nSUMMARY OF RAG METHODS\\nMethod Retrieval Source Retrieval\\nData Type\\nRetrieval\\nGranularity\\nAugmentation\\nStage\\nRetrieval\\nprocess\\nCoG [29] Wikipedia Text Phrase Pre-training Iterative\\nDenseX [30] FactoidWiki Text Proposition Inference Once\\nEAR [31] Dataset-base Text Sentence Tuning Once\\nUPRISE [20] Dataset-base Text Sentence Tuning Once\\nRAST [32] Dataset-base Text Sentence Tuning Once\\nSelf-Mem [17] Dataset-base Text Sentence Tuning Iterative\\nFLARE [24] Search Engine,Wikipedia Text Sentence Tuning Adaptive\\nPGRA [33] Wikipedia Text Sentence Inference Once\\nFILCO [34] Wikipedia Text Sentence Inference Once\\nRADA [35] Dataset-base Text Sentence Inference Once\\nFilter-rerank [36] Synthesized dataset Text Sentence Inference Once\\nR-GQA [37] Dataset-base Text Sentence Pair Tuning Once\\nLLM-R [38] Dataset-base Text Sentence Pair Inference Iterative\\nTIGER [39] Dataset-base Text Item-base Pre-training Once\\nLM-Indexer [40] Dataset-base Text Item-base Tuning Once\\nBEQUE [9] Dataset-base Text Item-base Tuning Once\\nCT-RAG [41] Synthesized dataset Text Item-base Tuning Once\\nAtlas [42] Wikipedia, Common Crawl Text Chunk Pre-training Iterative\\nRA VEN [43] Wikipedia Text Chunk Pre-training Once\\nRETRO++ [44] Pre-training Corpus Text Chunk Pre-training Iterative\\nINSTRUCTRETRO [45] Pre-training corpus Text Chunk Pre-training Iterative\\nRRR [7] Search Engine Text Chunk Tuning Once\\nRA-e2e [46] Dataset-base Text Chunk Tuning Once\\nPROMPTAGATOR [21] BEIR Text Chunk Tuning Once\\nAAR [47] MSMARCO,Wikipedia Text Chunk Tuning Once\\nRA-DIT [27] Common Crawl,Wikipedia Text Chunk Tuning Once\\nRAG-Robust [48] Wikipedia Text Chunk Tuning Once\\nRA-Long-Form [49] Dataset-base Text Chunk Tuning Once\\nCoN [50] Wikipedia Text Chunk Tuning Once\\nSelf-RAG [25] Wikipedia Text Chunk Tuning Adaptive\\nBGM [26] Wikipedia Text Chunk Inference Once\\nCoQ [51] Wikipedia Text Chunk Inference Iterative\\nToken-Elimination [52] Wikipedia Text Chunk Inference Once\\nPaperQA [53] Arxiv,Online Database,PubMed Text Chunk Inference Iterative\\nNoiseRAG [54] FactoidWiki Text Chunk Inference Once\\nIAG [55] Search Engine,Wikipedia Text Chunk Inference Once\\nNoMIRACL [56] Wikipedia Text Chunk Inference Once\\nToC [57] Search Engine,Wikipedia Text Chunk Inference Recursive\\nSKR [58] Dataset-base,Wikipedia Text Chunk Inference Adaptive\\nITRG [59] Wikipedia Text Chunk Inference Iterative\\nRAG-LongContext [60] Dataset-base Text Chunk Inference Once\\nITER-RETGEN [14] Wikipedia Text Chunk Inference Iterative\\nIRCoT [61] Wikipedia Text Chunk Inference Recursive\\nLLM-Knowledge-Boundary [62] Wikipedia Text Chunk Inference Once\\nRAPTOR [63] Dataset-base Text Chunk Inference Recursive\\nRECITE [22] LLMs Text Chunk Inference Once\\nICRALM [64] Pile,Wikipedia Text Chunk Inference Iterative\\nRetrieve-and-Sample [65] Dataset-base Text Doc Tuning Once\\nZemi [66] C4 Text Doc Tuning Once\\nCRAG [67] Arxiv Text Doc Inference Once\\n1-PAGER [68] Wikipedia Text Doc Inference Iterative\\nPRCA [69] Dataset-base Text Doc Inference Once\\nQLM-Doc-ranking [70] Dataset-base Text Doc Inference Once\\nRecomp [71] Wikipedia Text Doc Inference Once\\nDSP [23] Wikipedia Text Doc Inference Iterative\\nRePLUG [72] Pile Text Doc Inference Once\\nARM-RAG [73] Dataset-base Text Doc Inference Iterative\\nGenRead [13] LLMs Text Doc Inference Iterative\\nUniMS-RAG [74] Dataset-base Text Multi Tuning Once\\nCREA-ICL [19] Dataset-base Crosslingual,Text Sentence Inference Once\\nPKG [75] LLM Tabular,Text Chunk Inference Once\\nSANTA [76] Dataset-base Code,Text Item Pre-training Once\\nSURGE [77] Freebase KG Sub-Graph Tuning Once\\nMK-ToD [78] Dataset-base KG Entity Tuning Once\\nDual-Feedback-ToD [79] Dataset-base KG Entity Sequence Tuning Once\\nKnowledGPT [15] Dataset-base KG Triplet Inference Muti-time\\nFABULA [80] Dataset-base,Graph KG Entity Inference Once\\nHyKGE [81] CMeKG KG Entity Inference Once\\nKALMV [82] Wikipedia KG Triplet Inference Iterative\\nRoG [83] Freebase KG Triplet Inference Iterative\\nG-Retriever [84] Dataset-base TextGraph Sub-Graph Inference Once'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='7\\nFig. 4. RAG compared with other model optimization methods in the aspects of “External Knowledge Required” and “Model Adaption Required”. Prompt\\nEngineering requires low modifications to the model and external knowledge, focusing on harnessing the capabilities of LLMs themselves. Fine-tuning, on\\nthe other hand, involves further training the model. In the early stages of RAG (Naive RAG), there is a low demand for model modifications. As research\\nprogresses, Modular RAG has become more integrated with fine-tuning techniques.\\nUnstructured Data , such as text, is the most widely used\\nretrieval source, which are mainly gathered from corpus. For\\nopen-domain question-answering (ODQA) tasks, the primary\\nretrieval sources are Wikipedia Dump with the current major\\nversions including HotpotQA 4 (1st October , 2017), DPR5 (20\\nDecember, 2018). In addition to encyclopedic data, common\\nunstructured data includes cross-lingual text [19] and domain-\\nspecific data (such as medical [67]and legal domains [29]).\\nSemi-structured data. typically refers to data that contains a\\ncombination of text and table information, such as PDF. Han-\\ndling semi-structured data poses challenges for conventional\\nRAG systems due to two main reasons. Firstly, text splitting\\nprocesses may inadvertently separate tables, leading to data\\ncorruption during retrieval. Secondly, incorporating tables into\\nthe data can complicate semantic similarity searches. When\\ndealing with semi-structured data, one approach involves lever-\\naging the code capabilities of LLMs to execute Text-2-SQL\\nqueries on tables within databases, such as TableGPT [85].\\nAlternatively, tables can be transformed into text format for\\nfurther analysis using text-based methods [75]. However, both\\nof these methods are not optimal solutions, indicating substan-\\ntial research opportunities in this area.\\nStructured data , such as knowledge graphs (KGs) [86] ,\\nwhich are typically verified and can provide more precise in-\\nformation. KnowledGPT [15] generates KB search queries and\\nstores knowledge in a personalized base, enhancing the RAG\\nmodel’s knowledge richness. In response to the limitations of\\nLLMs in understanding and answering questions about textual\\ngraphs, G-Retriever [84] integrates Graph Neural Networks\\n4https://hotpotqa.github.io/wiki-readme.html\\n5https://github.com/facebookresearch/DPR\\n(GNNs), LLMs and RAG, enhancing graph comprehension\\nand question-answering capabilities through soft prompting\\nof the LLM, and employs the Prize-Collecting Steiner Tree\\n(PCST) optimization problem for targeted graph retrieval. On\\nthe contrary, it requires additional effort to build, validate,\\nand maintain structured databases. On the contrary, it requires\\nadditional effort to build, validate, and maintain structured\\ndatabases.\\nLLMs-Generated Content. Addressing the limitations of\\nexternal auxiliary information in RAG, some research has\\nfocused on exploiting LLMs’ internal knowledge. SKR [58]\\nclassifies questions as known or unknown, applying retrieval\\nenhancement selectively. GenRead [13] replaces the retriever\\nwith an LLM generator, finding that LLM-generated contexts\\noften contain more accurate answers due to better alignment\\nwith the pre-training objectives of causal language modeling.\\nSelfmem [17] iteratively creates an unbounded memory pool\\nwith a retrieval-enhanced generator, using a memory selec-\\ntor to choose outputs that serve as dual problems to the\\noriginal question, thus self-enhancing the generative model.\\nThese methodologies underscore the breadth of innovative\\ndata source utilization in RAG, striving to improve model\\nperformance and task effectiveness.\\n2) Retrieval Granularity: Another important factor besides\\nthe data format of the retrieval source is the granularity of\\nthe retrieved data. Coarse-grained retrieval units theoretically\\ncan provide more relevant information for the problem, but\\nthey may also contain redundant content, which could distract\\nthe retriever and language models in downstream tasks [50],\\n[87]. On the other hand, fine-grained retrieval unit granularity\\nincreases the burden of retrieval and does not guarantee seman-\\ntic integrity and meeting the required knowledge. Choosing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='8\\nthe appropriate retrieval granularity during inference can be\\na simple and effective strategy to improve the retrieval and\\ndownstream task performance of dense retrievers.\\nIn text, retrieval granularity ranges from fine to coarse,\\nincluding Token, Phrase, Sentence, Proposition, Chunks, Doc-\\nument. Among them, DenseX [30]proposed the concept of\\nusing propositions as retrieval units. Propositions are defined\\nas atomic expressions in the text, each encapsulating a unique\\nfactual segment and presented in a concise, self-contained nat-\\nural language format. This approach aims to enhance retrieval\\nprecision and relevance. On the Knowledge Graph (KG),\\nretrieval granularity includes Entity, Triplet, and sub-Graph.\\nThe granularity of retrieval can also be adapted to downstream\\ntasks, such as retrieving Item IDs [40]in recommendation tasks\\nand Sentence pairs [38]. Detailed information is illustrated in\\nTable I.\\nB. Indexing Optimization\\nIn the Indexing phase, documents will be processed, seg-\\nmented, and transformed into Embeddings to be stored in a\\nvector database. The quality of index construction determines\\nwhether the correct context can be obtained in the retrieval\\nphase.\\n1) Chunking Strategy: The most common method is to split\\nthe document into chunks on a fixed number of tokens (e.g.,\\n100, 256, 512) [88]. Larger chunks can capture more context,\\nbut they also generate more noise, requiring longer processing\\ntime and higher costs. While smaller chunks may not fully\\nconvey the necessary context, they do have less noise. How-\\never, chunks leads to truncation within sentences, prompting\\nthe optimization of a recursive splits and sliding window meth-\\nods, enabling layered retrieval by merging globally related\\ninformation across multiple retrieval processes [89]. Never-\\ntheless, these approaches still cannot strike a balance between\\nsemantic completeness and context length. Therefore, methods\\nlike Small2Big have been proposed, where sentences (small)\\nare used as the retrieval unit, and the preceding and following\\nsentences are provided as (big) context to LLMs [90].\\n2) Metadata Attachments: Chunks can be enriched with\\nmetadata information such as page number, file name, au-\\nthor,category timestamp. Subsequently, retrieval can be filtered\\nbased on this metadata, limiting the scope of the retrieval.\\nAssigning different weights to document timestamps during\\nretrieval can achieve time-aware RAG, ensuring the freshness\\nof knowledge and avoiding outdated information.\\nIn addition to extracting metadata from the original doc-\\numents, metadata can also be artificially constructed. For\\nexample, adding summaries of paragraph, as well as intro-\\nducing hypothetical questions. This method is also known as\\nReverse HyDE. Specifically, using LLM to generate questions\\nthat can be answered by the document, then calculating the\\nsimilarity between the original question and the hypothetical\\nquestion during retrieval to reduce the semantic gap between\\nthe question and the answer.\\n3) Structural Index: One effective method for enhancing\\ninformation retrieval is to establish a hierarchical structure for\\nthe documents. By constructing In structure, RAG system can\\nexpedite the retrieval and processing of pertinent data.\\nHierarchical index structure . File are arranged in parent-\\nchild relationships, with chunks linked to them. Data sum-\\nmaries are stored at each node, aiding in the swift traversal\\nof data and assisting the RAG system in determining which\\nchunks to extract. This approach can also mitigate the illusion\\ncaused by block extraction issues.\\nKnowledge Graph index . Utilize KG in constructing the\\nhierarchical structure of documents contributes to maintaining\\nconsistency. It delineates the connections between different\\nconcepts and entities, markedly reducing the potential for\\nillusions. Another advantage is the transformation of the\\ninformation retrieval process into instructions that LLM can\\ncomprehend, thereby enhancing the accuracy of knowledge\\nretrieval and enabling LLM to generate contextually coherent\\nresponses, thus improving the overall efficiency of the RAG\\nsystem. To capture the logical relationship between document\\ncontent and structure, KGP [91] proposed a method of building\\nan index between multiple documents using KG. This KG\\nconsists of nodes (representing paragraphs or structures in the\\ndocuments, such as pages and tables) and edges (indicating\\nsemantic/lexical similarity between paragraphs or relationships\\nwithin the document structure), effectively addressing knowl-\\nedge retrieval and reasoning problems in a multi-document\\nenvironment.\\nC. Query Optimization\\nOne of the primary challenges with Naive RAG is its\\ndirect reliance on the user’s original query as the basis for\\nretrieval. Formulating a precise and clear question is difficult,\\nand imprudent queries result in subpar retrieval effectiveness.\\nSometimes, the question itself is complex, and the language\\nis not well-organized. Another difficulty lies in language\\ncomplexity ambiguity. Language models often struggle when\\ndealing with specialized vocabulary or ambiguous abbrevi-\\nations with multiple meanings. For instance, they may not\\ndiscern whether “LLM” refers to large language model or a\\nMaster of Laws in a legal context.\\n1) Query Expansion: Expanding a single query into mul-\\ntiple queries enriches the content of the query, providing\\nfurther context to address any lack of specific nuances, thereby\\nensuring the optimal relevance of the generated answers.\\nMulti-Query. By employing prompt engineering to expand\\nqueries via LLMs, these queries can then be executed in\\nparallel. The expansion of queries is not random, but rather\\nmeticulously designed.\\nSub-Query. The process of sub-question planning represents\\nthe generation of the necessary sub-questions to contextualize\\nand fully answer the original question when combined. This\\nprocess of adding relevant context is, in principle, similar\\nto query expansion. Specifically, a complex question can be\\ndecomposed into a series of simpler sub-questions using the\\nleast-to-most prompting method [92].\\nChain-of-Verification(CoVe). The expanded queries undergo\\nvalidation by LLM to achieve the effect of reducing halluci-\\nnations. Validated expanded queries typically exhibit higher\\nreliability [93].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='9\\n2) Query Transformation: The core concept is to retrieve\\nchunks based on a transformed query instead of the user’s\\noriginal query.\\nQuery Rewrite.The original queries are not always optimal\\nfor LLM retrieval, especially in real-world scenarios. There-\\nfore, we can prompt LLM to rewrite the queries. In addition to\\nusing LLM for query rewriting, specialized smaller language\\nmodels, such as RRR (Rewrite-retrieve-read) [7]. The imple-\\nmentation of the query rewrite method in the Taobao, known\\nas BEQUE [9] has notably enhanced recall effectiveness for\\nlong-tail queries, resulting in a rise in GMV .\\nAnother query transformation method is to use prompt\\nengineering to let LLM generate a query based on the original\\nquery for subsequent retrieval. HyDE [11] construct hypothet-\\nical documents (assumed answers to the original query). It\\nfocuses on embedding similarity from answer to answer rather\\nthan seeking embedding similarity for the problem or query.\\nUsing the Step-back Prompting method [10], the original\\nquery is abstracted to generate a high-level concept question\\n(step-back question). In the RAG system, both the step-back\\nquestion and the original query are used for retrieval, and both\\nthe results are utilized as the basis for language model answer\\ngeneration.\\n3) Query Routing: Based on varying queries, routing to\\ndistinct RAG pipeline,which is suitable for a versatile RAG\\nsystem designed to accommodate diverse scenarios.\\nMetadata Router/ Filter . The first step involves extracting\\nkeywords (entity) from the query, followed by filtering based\\non the keywords and metadata within the chunks to narrow\\ndown the search scope.\\nSemantic Router is another method of routing involves\\nleveraging the semantic information of the query. Specific\\napprach see Semantic Router 6. Certainly, a hybrid routing\\napproach can also be employed, combining both semantic and\\nmetadata-based methods for enhanced query routing.\\nD. Embedding\\nIn RAG, retrieval is achieved by calculating the similarity\\n(e.g. cosine similarity) between the embeddings of the ques-\\ntion and document chunks, where the semantic representation\\ncapability of embedding models plays a key role. This mainly\\nincludes a sparse encoder (BM25) and a dense retriever (BERT\\narchitecture Pre-training language models). Recent research\\nhas introduced prominent embedding models such as AngIE,\\nV oyage, BGE,etc [94]–[96], which are benefit from multi-task\\ninstruct tuning. Hugging Face’s MTEB leaderboard 7 evaluates\\nembedding models across 8 tasks, covering 58 datasests. Ad-\\nditionally, C-MTEB focuses on Chinese capability, covering\\n6 tasks and 35 datasets. There is no one-size-fits-all answer\\nto “which embedding model to use.” However, some specific\\nmodels are better suited for particular use cases.\\n1) Mix/hybrid Retrieval : Sparse and dense embedding\\napproaches capture different relevance features and can ben-\\nefit from each other by leveraging complementary relevance\\ninformation. For instance, sparse retrieval models can be used\\n6https://github.com/aurelio-labs/semantic-router\\n7https://huggingface.co/spaces/mteb/leaderboard\\nto provide initial search results for training dense retrieval\\nmodels. Additionally, pre-training language models (PLMs)\\ncan be utilized to learn term weights to enhance sparse\\nretrieval. Specifically, it also demonstrates that sparse retrieval\\nmodels can enhance the zero-shot retrieval capability of dense\\nretrieval models and assist dense retrievers in handling queries\\ncontaining rare entities, thereby improving robustness.\\n2) Fine-tuning Embedding Model: In instances where the\\ncontext significantly deviates from pre-training corpus, partic-\\nularly within highly specialized disciplines such as healthcare,\\nlegal practice, and other sectors replete with proprietary jargon,\\nfine-tuning the embedding model on your own domain dataset\\nbecomes essential to mitigate such discrepancies.\\nIn addition to supplementing domain knowledge, another\\npurpose of fine-tuning is to align the retriever and generator,\\nfor example, using the results of LLM as the supervision signal\\nfor fine-tuning, known as LSR (LM-supervised Retriever).\\nPROMPTAGATOR [21] utilizes the LLM as a few-shot query\\ngenerator to create task-specific retrievers, addressing chal-\\nlenges in supervised fine-tuning, particularly in data-scarce\\ndomains. Another approach, LLM-Embedder [97], exploits\\nLLMs to generate reward signals across multiple downstream\\ntasks. The retriever is fine-tuned with two types of supervised\\nsignals: hard labels for the dataset and soft rewards from\\nthe LLMs. This dual-signal approach fosters a more effective\\nfine-tuning process, tailoring the embedding model to diverse\\ndownstream applications. REPLUG [72] utilizes a retriever\\nand an LLM to calculate the probability distributions of the\\nretrieved documents and then performs supervised training\\nby computing the KL divergence. This straightforward and\\neffective training method enhances the performance of the\\nretrieval model by using an LM as the supervisory signal,\\neliminating the need for specific cross-attention mechanisms.\\nMoreover, inspired by RLHF (Reinforcement Learning from\\nHuman Feedback), utilizing LM-based feedback to reinforce\\nthe retriever through reinforcement learning.\\nE. Adapter\\nFine-tuning models may present challenges, such as in-\\ntegrating functionality through an API or addressing con-\\nstraints arising from limited local computational resources.\\nConsequently, some approaches opt to incorporate an external\\nadapter to aid in alignment.\\nTo optimize the multi-task capabilities of LLM, UP-\\nRISE [20] trained a lightweight prompt retriever that can\\nautomatically retrieve prompts from a pre-built prompt pool\\nthat are suitable for a given zero-shot task input. AAR\\n(Augmentation-Adapted Retriver) [47] introduces a universal\\nadapter designed to accommodate multiple downstream tasks.\\nWhile PRCA [69] add a pluggable reward-driven contextual\\nadapter to enhance performance on specific tasks. BGM [26]\\nkeeps the retriever and LLM fixed,and trains a bridge Seq2Seq\\nmodel in between. The bridge model aims to transform the\\nretrieved information into a format that LLMs can work with\\neffectively, allowing it to not only rerank but also dynami-\\ncally select passages for each query, and potentially employ\\nmore advanced strategies like repetition. Furthermore, PKG'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='10\\nintroduces an innovative method for integrating knowledge\\ninto white-box models via directive fine-tuning [75]. In this\\napproach, the retriever module is directly substituted to gen-\\nerate relevant documents according to a query. This method\\nassists in addressing the difficulties encountered during the\\nfine-tuning process and enhances model performance.\\nIV. G ENERATION\\nAfter retrieval, it is not a good practice to directly input all\\nthe retrieved information to the LLM for answering questions.\\nFollowing will introduce adjustments from two perspectives:\\nadjusting the retrieved content and adjusting the LLM.\\nA. Context Curation\\nRedundant information can interfere with the final gener-\\nation of LLM, and overly long contexts can also lead LLM\\nto the “Lost in the middle” problem [98]. Like humans, LLM\\ntends to only focus on the beginning and end of long texts,\\nwhile forgetting the middle portion. Therefore, in the RAG\\nsystem, we typically need to further process the retrieved\\ncontent.\\n1) Reranking: Reranking fundamentally reorders document\\nchunks to highlight the most pertinent results first, effectively\\nreducing the overall document pool, severing a dual purpose\\nin information retrieval, acting as both an enhancer and a\\nfilter, delivering refined inputs for more precise language\\nmodel processing [70]. Reranking can be performed using\\nrule-based methods that depend on predefined metrics like\\nDiversity, Relevance, and MRR, or model-based approaches\\nlike Encoder-Decoder models from the BERT series (e.g.,\\nSpanBERT), specialized reranking models such as Cohere\\nrerank or bge-raranker-large, and general large language mod-\\nels like GPT [12], [99].\\n2) Context Selection/Compression: A common misconcep-\\ntion in the RAG process is the belief that retrieving as many\\nrelevant documents as possible and concatenating them to form\\na lengthy retrieval prompt is beneficial. However, excessive\\ncontext can introduce more noise, diminishing the LLM’s\\nperception of key information .\\n(Long) LLMLingua [100], [101] utilize small language\\nmodels (SLMs) such as GPT-2 Small or LLaMA-7B, to\\ndetect and remove unimportant tokens, transforming it into\\na form that is challenging for humans to comprehend but\\nwell understood by LLMs. This approach presents a direct\\nand practical method for prompt compression, eliminating the\\nneed for additional training of LLMs while balancing language\\nintegrity and compression ratio. PRCA tackled this issue by\\ntraining an information extractor [69]. Similarly, RECOMP\\nadopts a comparable approach by training an information\\ncondenser using contrastive learning [71]. Each training data\\npoint consists of one positive sample and five negative sam-\\nples, and the encoder undergoes training using contrastive loss\\nthroughout this process [102] .\\nIn addition to compressing the context, reducing the num-\\nber of documents aslo helps improve the accuracy of the\\nmodel’s answers. Ma et al. [103] propose the “Filter-Reranker”\\nparadigm, which combines the strengths of LLMs and SLMs.\\nIn this paradigm, SLMs serve as filters, while LLMs function\\nas reordering agents. The research shows that instructing\\nLLMs to rearrange challenging samples identified by SLMs\\nleads to significant improvements in various Information\\nExtraction (IE) tasks. Another straightforward and effective\\napproach involves having the LLM evaluate the retrieved\\ncontent before generating the final answer. This allows the\\nLLM to filter out documents with poor relevance through LLM\\ncritique. For instance, in Chatlaw [104], the LLM is prompted\\nto self-suggestion on the referenced legal provisions to assess\\ntheir relevance.\\nB. LLM Fine-tuning\\nTargeted fine-tuning based on the scenario and data char-\\nacteristics on LLMs can yield better results. This is also one\\nof the greatest advantages of using on-premise LLMs. When\\nLLMs lack data in a specific domain, additional knowledge can\\nbe provided to the LLM through fine-tuning. Huggingface’s\\nfine-tuning data can also be used as an initial step.\\nAnother benefit of fine-tuning is the ability to adjust the\\nmodel’s input and output. For example, it can enable LLM to\\nadapt to specific data formats and generate responses in a par-\\nticular style as instructed [37]. For retrieval tasks that engage\\nwith structured data, the SANTA framework [76] implements\\na tripartite training regimen to effectively encapsulate both\\nstructural and semantic nuances. The initial phase focuses on\\nthe retriever, where contrastive learning is harnessed to refine\\nthe query and document embeddings.\\nAligning LLM outputs with human or retriever preferences\\nthrough reinforcement learning is a potential approach. For\\ninstance, manually annotating the final generated answers\\nand then providing feedback through reinforcement learning.\\nIn addition to aligning with human preferences, it is also\\npossible to align with the preferences of fine-tuned models\\nand retrievers [79]. When circumstances prevent access to\\npowerful proprietary models or larger parameter open-source\\nmodels, a simple and effective method is to distill the more\\npowerful models(e.g. GPT-4). Fine-tuning of LLM can also\\nbe coordinated with fine-tuning of the retriever to align pref-\\nerences. A typical approach, such as RA-DIT [27], aligns the\\nscoring functions between Retriever and Generator using KL\\ndivergence.\\nV. A UGMENTATION PROCESS IN RAG\\nIn the domain of RAG, the standard practice often involves\\na singular (once) retrieval step followed by generation, which\\ncan lead to inefficiencies and sometimes is typically insuffi-\\ncient for complex problems demanding multi-step reasoning,\\nas it provides a limited scope of information [105]. Many\\nstudies have optimized the retrieval process in response to this\\nissue, and we have summarised them in Figure 5.\\nA. Iterative Retrieval\\nIterative retrieval is a process where the knowledge base\\nis repeatedly searched based on the initial query and the text\\ngenerated so far, providing a more comprehensive knowledge'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='11\\nFig. 5. In addition to the most common once retrieval, RAG also includes three types of retrieval augmentation processes. (left) Iterative retrieval involves\\nalternating between retrieval and generation, allowing for richer and more targeted context from the knowledge base at each step. (Middle) Recursive retrieval\\ninvolves gradually refining the user query and breaking down the problem into sub-problems, then continuously solving complex problems through retrieval\\nand generation. (Right) Adaptive retrieval focuses on enabling the RAG system to autonomously determine whether external knowledge retrieval is necessary\\nand when to stop retrieval and generation, often utilizing LLM-generated special tokens for control.\\nbase for LLMs. This approach has been shown to enhance\\nthe robustness of subsequent answer generation by offering\\nadditional contextual references through multiple retrieval\\niterations. However, it may be affected by semantic discon-\\ntinuity and the accumulation of irrelevant information. ITER-\\nRETGEN [14] employs a synergistic approach that lever-\\nages “retrieval-enhanced generation” alongside “generation-\\nenhanced retrieval” for tasks that necessitate the reproduction\\nof specific information. The model harnesses the content\\nrequired to address the input task as a contextual basis for\\nretrieving pertinent knowledge, which in turn facilitates the\\ngeneration of improved responses in subsequent iterations.\\nB. Recursive Retrieval\\nRecursive retrieval is often used in information retrieval and\\nNLP to improve the depth and relevance of search results.\\nThe process involves iteratively refining search queries based\\non the results obtained from previous searches. Recursive\\nRetrieval aims to enhance the search experience by gradu-\\nally converging on the most pertinent information through a\\nfeedback loop. IRCoT [61] uses chain-of-thought to guide\\nthe retrieval process and refines the CoT with the obtained\\nretrieval results. ToC [57] creates a clarification tree that\\nsystematically optimizes the ambiguous parts in the Query. It\\ncan be particularly useful in complex search scenarios where\\nthe user’s needs are not entirely clear from the outset or where\\nthe information sought is highly specialized or nuanced. The\\nrecursive nature of the process allows for continuous learning\\nand adaptation to the user’s requirements, often resulting in\\nimproved satisfaction with the search outcomes.\\nTo address specific data scenarios, recursive retrieval and\\nmulti-hop retrieval techniques are utilized together. Recursive\\nretrieval involves a structured index to process and retrieve\\ndata in a hierarchical manner, which may include summarizing\\nsections of a document or lengthy PDF before performing a\\nretrieval based on this summary. Subsequently, a secondary\\nretrieval within the document refines the search, embodying\\nthe recursive nature of the process. In contrast, multi-hop\\nretrieval is designed to delve deeper into graph-structured data\\nsources, extracting interconnected information [106].\\nC. Adaptive Retrieval\\nAdaptive retrieval methods, exemplified by Flare [24] and\\nSelf-RAG [25], refine the RAG framework by enabling LLMs\\nto actively determine the optimal moments and content for\\nretrieval, thus enhancing the efficiency and relevance of the\\ninformation sourced.\\nThese methods are part of a broader trend wherein\\nLLMs employ active judgment in their operations, as seen\\nin model agents like AutoGPT, Toolformer, and Graph-\\nToolformer [107]–[109]. Graph-Toolformer, for instance, di-\\nvides its retrieval process into distinct steps where LLMs\\nproactively use retrievers, apply Self-Ask techniques, and em-\\nploy few-shot prompts to initiate search queries. This proactive\\nstance allows LLMs to decide when to search for necessary\\ninformation, akin to how an agent utilizes tools.\\nWebGPT [110] integrates a reinforcement learning frame-\\nwork to train the GPT-3 model in autonomously using a\\nsearch engine during text generation. It navigates this process\\nusing special tokens that facilitate actions such as search\\nengine queries, browsing results, and citing references, thereby\\nexpanding GPT-3’s capabilities through the use of external\\nsearch engines. Flare automates timing retrieval by monitoring\\nthe confidence of the generation process, as indicated by the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='12\\nprobability of generated terms [24]. When the probability falls\\nbelow a certain threshold would activates the retrieval system\\nto collect relevant information, thus optimizing the retrieval\\ncycle. Self-RAG [25] introduces “reflection tokens” that allow\\nthe model to introspect its outputs. These tokens come in\\ntwo varieties: “retrieve” and “critic”. The model autonomously\\ndecides when to activate retrieval, or alternatively, a predefined\\nthreshold may trigger the process. During retrieval, the gen-\\nerator conducts a fragment-level beam search across multiple\\nparagraphs to derive the most coherent sequence. Critic scores\\nare used to update the subdivision scores, with the flexibility\\nto adjust these weights during inference, tailoring the model’s\\nbehavior. Self-RAG’s design obviates the need for additional\\nclassifiers or reliance on Natural Language Inference (NLI)\\nmodels, thus streamlining the decision-making process for\\nwhen to engage retrieval mechanisms and improving the\\nmodel’s autonomous judgment capabilities in generating ac-\\ncurate responses.\\nVI. T ASK AND EVALUATION\\nThe rapid advancement and growing adoption of RAG\\nin the field of NLP have propelled the evaluation of RAG\\nmodels to the forefront of research in the LLMs community.\\nThe primary objective of this evaluation is to comprehend\\nand optimize the performance of RAG models across diverse\\napplication scenarios.This chapter will mainly introduce the\\nmain downstream tasks of RAG, datasets, and how to evaluate\\nRAG systems.\\nA. Downstream Task\\nThe core task of RAG remains Question Answering (QA),\\nincluding traditional single-hop/multi-hop QA, multiple-\\nchoice, domain-specific QA as well as long-form scenarios\\nsuitable for RAG. In addition to QA, RAG is continuously\\nbeing expanded into multiple downstream tasks, such as Infor-\\nmation Extraction (IE), dialogue generation, code search, etc.\\nThe main downstream tasks of RAG and their corresponding\\ndatasets are summarized in Table II.\\nB. Evaluation Target\\nHistorically, RAG models assessments have centered on\\ntheir execution in specific downstream tasks. These evaluations\\nemploy established metrics suitable to the tasks at hand. For\\ninstance, question answering evaluations might rely on EM\\nand F1 scores [7], [45], [59], [72], whereas fact-checking\\ntasks often hinge on Accuracy as the primary metric [4],\\n[14], [42]. BLEU and ROUGE metrics are also commonly\\nused to evaluate answer quality [26], [32], [52], [78]. Tools\\nlike RALLE, designed for the automatic evaluation of RAG\\napplications, similarly base their assessments on these task-\\nspecific metrics [160]. Despite this, there is a notable paucity\\nof research dedicated to evaluating the distinct characteristics\\nof RAG models.The main evaluation objectives include:\\nRetrieval Quality. Evaluating the retrieval quality is crucial\\nfor determining the effectiveness of the context sourced by\\nthe retriever component. Standard metrics from the domains\\nof search engines, recommendation systems, and information\\nretrieval systems are employed to measure the performance of\\nthe RAG retrieval module. Metrics such as Hit Rate, MRR, and\\nNDCG are commonly utilized for this purpose [161], [162].\\nGeneration Quality . The assessment of generation quality\\ncenters on the generator’s capacity to synthesize coherent and\\nrelevant answers from the retrieved context. This evaluation\\ncan be categorized based on the content’s objectives: unlabeled\\nand labeled content. For unlabeled content, the evaluation\\nencompasses the faithfulness, relevance, and non-harmfulness\\nof the generated answers. In contrast, for labeled content,\\nthe focus is on the accuracy of the information produced by\\nthe model [161]. Additionally, both retrieval and generation\\nquality assessments can be conducted through manual or\\nautomatic evaluation methods [29], [161], [163].\\nC. Evaluation Aspects\\nContemporary evaluation practices of RAG models empha-\\nsize three primary quality scores and four essential abilities,\\nwhich collectively inform the evaluation of the two principal\\ntargets of the RAG model: retrieval and generation.\\n1) Quality Scores: Quality scores include context rele-\\nvance, answer faithfulness, and answer relevance. These qual-\\nity scores evaluate the efficiency of the RAG model from\\ndifferent perspectives in the process of information retrieval\\nand generation [164]–[166].\\nContext Relevance evaluates the precision and specificity\\nof the retrieved context, ensuring relevance and minimizing\\nprocessing costs associated with extraneous content.\\nAnswer Faithfulness ensures that the generated answers\\nremain true to the retrieved context, maintaining consistency\\nand avoiding contradictions.\\nAnswer Relevance requires that the generated answers are\\ndirectly pertinent to the posed questions, effectively addressing\\nthe core inquiry.\\n2) Required Abilities: RAG evaluation also encompasses\\nfour abilities indicative of its adaptability and efficiency:\\nnoise robustness, negative rejection, information integration,\\nand counterfactual robustness [167], [168]. These abilities are\\ncritical for the model’s performance under various challenges\\nand complex scenarios, impacting the quality scores.\\nNoise Robustness appraises the model’s capability to man-\\nage noise documents that are question-related but lack sub-\\nstantive information.\\nNegative Rejection assesses the model’s discernment in\\nrefraining from responding when the retrieved documents do\\nnot contain the necessary knowledge to answer a question.\\nInformation Integration evaluates the model’s proficiency in\\nsynthesizing information from multiple documents to address\\ncomplex questions.\\nCounterfactual Robustness tests the model’s ability to rec-\\nognize and disregard known inaccuracies within documents,\\neven when instructed about potential misinformation.\\nContext relevance and noise robustness are important for\\nevaluating the quality of retrieval, while answer faithfulness,\\nanswer relevance, negative rejection, information integration,\\nand counterfactual robustness are important for evaluating the\\nquality of generation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 12, 'page_label': '13', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='13\\nTABLE II\\nDOWNSTREAM TASKS AND DATASETS OF RAG\\nTask Sub Task Dataset Method\\nQA Single-hop Natural Qustion(NQ) [111]\\n[26], [30], [34], [42], [45], [50], [52], [59], [64], [82]\\n[3], [4], [22], [27], [40], [43], [54], [62], [71], [112]\\n[20], [44], [72]\\nTriviaQA(TQA) [113]\\n[13], [30], [34], [45], [50], [64]\\n[4], [27], [59], [62], [112]\\n[22], [25], [43], [44], [71], [72]\\nSQuAD [114] [20], [23], [30], [32], [45], [69], [112]\\nWeb Questions(WebQ) [115] [3], [4], [13], [30], [50], [68]\\nPopQA [116] [7], [25], [67]\\nMS MARCO [117] [4], [40], [52]\\nMulti-hop HotpotQA [118] [23], [26], [31], [34], [47], [51], [61], [82]\\n[7], [14], [22], [27], [59], [62], [69], [71], [91]\\n2WikiMultiHopQA [119] [14], [24], [48], [59], [61], [91]\\nMuSiQue [120] [14], [51], [61], [91]\\nLong-form QA ELI5 [121] [27], [34], [43], [49], [51]\\nNarrativeQA(NQA) [122] [45], [60], [63], [123]\\nASQA [124] [24], [57]\\nQMSum(QM) [125] [60], [123]\\nDomain QA Qasper [126] [60], [63]\\nCOVID-QA [127] [35], [46]\\nCMB [128],MMCU Medical [129] [81]\\nMulti-Choice QA QuALITY [130] [60], [63]\\nARC [131] [25], [67]\\nCommonsenseQA [132] [58], [66]\\nGraph QA GraphQA [84] [84]\\nDialog Dialog Generation Wizard of Wikipedia (WoW) [133] [13], [27], [34], [42]\\nPersonal Dialog KBP [134] [74], [135]\\nDuleMon [136] [74]\\nTask-oriented Dialog CamRest [137] [78], [79]\\nRecommendation Amazon(Toys,Sport,Beauty) [138] [39], [40]\\nIE Event Argument Extraction WikiEvent [139] [13], [27], [37], [42]\\nRAMS [140] [36], [37]\\nRelation Extraction T-REx [141],ZsRE [142] [27], [51]\\nReasoning Commonsense Reasoning HellaSwag [143] [20], [66]\\nCoT Reasoning CoT Reasoning [144] [27]\\nComplex Reasoning CSQA [145] [55]\\nOthers Language Understanding MMLU [146] [7], [27], [28], [42], [43], [47], [72]\\nLanguage Modeling WikiText-103 [147] [5], [29], [64], [71]\\nStrategyQA [148] [14], [24], [48], [51], [55], [58]\\nFact Checking/Verification FEVER [149] [4], [13], [27], [34], [42], [50]\\nPubHealth [150] [25], [67]\\nText Generation Biography [151] [67]\\nText Summarization WikiASP [152] [24]\\nXSum [153] [17]\\nText Classification VioLens [154] [19]\\nTREC [155] [33]\\nSentiment SST-2 [156] [20], [33], [38]\\nCode Search CodeSearchNet [157] [76]\\nRobustness Evaluation NoMIRACL [56] [56]\\nMath GSM8K [158] [73]\\nMachine Translation JRC-Acquis [159] [17]'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='14\\nTABLE III\\nSUMMARY OF METRICS APPLICABLE FOR EVALUATION ASPECTS OF RAG\\nContext\\nRelevance Faithfulness Answer\\nRelevance\\nNoise\\nRobustness\\nNegative\\nRejection\\nInformation\\nIntegration\\nCounterfactual\\nRobustness\\nAccuracy ✓ ✓ ✓ ✓ ✓ ✓ ✓\\nEM ✓\\nRecall ✓\\nPrecision ✓ ✓\\nR-Rate ✓\\nCosine Similarity ✓\\nHit Rate ✓\\nMRR ✓\\nNDCG ✓\\nBLEU ✓ ✓ ✓\\nROUGE/ROUGE-L ✓ ✓ ✓\\nThe specific metrics for each evaluation aspect are sum-\\nmarized in Table III. It is essential to recognize that these\\nmetrics, derived from related work, are traditional measures\\nand do not yet represent a mature or standardized approach for\\nquantifying RAG evaluation aspects. Custom metrics tailored\\nto the nuances of RAG models, though not included here, have\\nalso been developed in some evaluation studies.\\nD. Evaluation Benchmarks and Tools\\nA series of benchmark tests and tools have been proposed\\nto facilitate the evaluation of RAG.These instruments furnish\\nquantitative metrics that not only gauge RAG model perfor-\\nmance but also enhance comprehension of the model’s capabil-\\nities across various evaluation aspects. Prominent benchmarks\\nsuch as RGB, RECALL and CRUD [167]–[169] focus on\\nappraising the essential abilities of RAG models. Concur-\\nrently, state-of-the-art automated tools like RAGAS [164],\\nARES [165], and TruLens 8 employ LLMs to adjudicate the\\nquality scores. These tools and benchmarks collectively form\\na robust framework for the systematic evaluation of RAG\\nmodels, as summarized in Table IV.\\nVII. D ISCUSSION AND FUTURE PROSPECTS\\nDespite the considerable progress in RAG technology, sev-\\neral challenges persist that warrant in-depth research.This\\nchapter will mainly introduce the current challenges and future\\nresearch directions faced by RAG.\\nA. RAG vs Long Context\\nWith the deepening of related research, the context of LLMs\\nis continuously expanding [170]–[172]. Presently, LLMs can\\neffortlessly manage contexts exceeding 200,000 tokens 9. This\\ncapability signifies that long-document question answering,\\npreviously reliant on RAG, can now incorporate the entire\\ndocument directly into the prompt. This has also sparked\\ndiscussions on whether RAG is still necessary when LLMs\\n8https://www.trulens.org/trulens eval/core concepts rag triad/\\n9https://kimi.moonshot.cn\\nare not constrained by context. In fact, RAG still plays an\\nirreplaceable role. On one hand, providing LLMs with a\\nlarge amount of context at once will significantly impact its\\ninference speed, while chunked retrieval and on-demand input\\ncan significantly improve operational efficiency. On the other\\nhand, RAG-based generation can quickly locate the original\\nreferences for LLMs to help users verify the generated an-\\nswers. The entire retrieval and reasoning process is observable,\\nwhile generation solely relying on long context remains a\\nblack box. Conversely, the expansion of context provides new\\nopportunities for the development of RAG, enabling it to\\naddress more complex problems and integrative or summary\\nquestions that require reading a large amount of material to\\nanswer [49]. Developing new RAG methods in the context of\\nsuper-long contexts is one of the future research trends.\\nB. RAG Robustness\\nThe presence of noise or contradictory information during\\nretrieval can detrimentally affect RAG’s output quality. This\\nsituation is figuratively referred to as “Misinformation can\\nbe worse than no information at all”. Improving RAG’s\\nresistance to such adversarial or counterfactual inputs is gain-\\ning research momentum and has become a key performance\\nmetric [48], [50], [82]. Cuconasu et al. [54] analyze which\\ntype of documents should be retrieved, evaluate the relevance\\nof the documents to the prompt, their position, and the\\nnumber included in the context. The research findings reveal\\nthat including irrelevant documents can unexpectedly increase\\naccuracy by over 30%, contradicting the initial assumption\\nof reduced quality. These results underscore the importance\\nof developing specialized strategies to integrate retrieval with\\nlanguage generation models, highlighting the need for further\\nresearch and exploration into the robustness of RAG.\\nC. Hybrid Approaches\\nCombining RAG with fine-tuning is emerging as a leading\\nstrategy. Determining the optimal integration of RAG and\\nfine-tuning whether sequential, alternating, or through end-to-\\nend joint training—and how to harness both parameterized'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='15\\nTABLE IV\\nSUMMARY OF EVALUATION FRAMEWORKS\\nEvaluation Framework Evaluation Targets Evaluation Aspects Quantitative Metrics\\nRGB† Retrieval Quality\\nGeneration Quality\\nNoise Robustness\\nNegative Rejection\\nInformation Integration\\nCounterfactual Robustness\\nAccuracy\\nEM\\nAccuracy\\nAccuracy\\nRECALL† Generation Quality Counterfactual Robustness R-Rate (Reappearance Rate)\\nRAGAS‡ Retrieval Quality\\nGeneration Quality\\nContext Relevance\\nFaithfulness\\nAnswer Relevance\\n*\\n*\\nCosine Similarity\\nARES‡ Retrieval Quality\\nGeneration Quality\\nContext Relevance\\nFaithfulness\\nAnswer Relevance\\nAccuracy\\nAccuracy\\nAccuracy\\nTruLens‡ Retrieval Quality\\nGeneration Quality\\nContext Relevance\\nFaithfulness\\nAnswer Relevance\\n*\\n*\\n*\\nCRUD† Retrieval Quality\\nGeneration Quality\\nCreative Generation\\nKnowledge-intensive QA\\nError Correction\\nSummarization\\nBLEU\\nROUGE-L\\nBertScore\\nRAGQuestEval\\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional\\nmetrics. Readers are encouraged to consult pertinent literature for the specific quantification formulas associated with these\\nmetrics, as required.\\nand non-parameterized advantages are areas ripe for explo-\\nration [27]. Another trend is to introduce SLMs with specific\\nfunctionalities into RAG and fine-tuned by the results of RAG\\nsystem. For example, CRAG [67] trains a lightweight retrieval\\nevaluator to assess the overall quality of the retrieved docu-\\nments for a query and triggers different knowledge retrieval\\nactions based on confidence levels.\\nD. Scaling laws of RAG\\nEnd-to-end RAG models and pre-trained models based\\non RAG are still one of the focuses of current re-\\nsearchers [173].The parameters of these models are one of\\nthe key factors.While scaling laws [174] are established for\\nLLMs, their applicability to RAG remains uncertain. Initial\\nstudies like RETRO++ [44] have begun to address this, yet the\\nparameter count in RAG models still lags behind that of LLMs.\\nThe possibility of an Inverse Scaling Law 10, where smaller\\nmodels outperform larger ones, is particularly intriguing and\\nmerits further investigation.\\nE. Production-Ready RAG\\nRAG’s practicality and alignment with engineering require-\\nments have facilitated its adoption. However, enhancing re-\\ntrieval efficiency, improving document recall in large knowl-\\nedge bases, and ensuring data security—such as preventing\\n10https://github.com/inverse-scaling/prize\\ninadvertent disclosure of document sources or metadata by\\nLLMs—are critical engineering challenges that remain to be\\naddressed [175].\\nThe development of the RAG ecosystem is greatly impacted\\nby the progression of its technical stack. Key tools like\\nLangChain and LLamaIndex have quickly gained popularity\\nwith the emergence of ChatGPT, providing extensive RAG-\\nrelated APIs and becoming essential in the realm of LLMs.The\\nemerging technology stack, while not as rich in features as\\nLangChain and LLamaIndex, stands out through its specialized\\nproducts. For example, Flowise AI prioritizes a low-code\\napproach, allowing users to deploy AI applications, including\\nRAG, through a user-friendly drag-and-drop interface. Other\\ntechnologies like HayStack, Meltano, and Cohere Coral are\\nalso gaining attention for their unique contributions to the field.\\nIn addition to AI-focused vendors, traditional software and\\ncloud service providers are expanding their offerings to include\\nRAG-centric services. Weaviate’s Verba 11 is designed for\\npersonal assistant applications, while Amazon’s Kendra 12\\noffers intelligent enterprise search services, enabling users to\\nbrowse various content repositories using built-in connectors.\\nIn the development of RAG technology, there is a clear\\ntrend towards different specialization directions, such as: 1)\\nCustomization - tailoring RAG to meet specific requirements.\\n2) Simplification - making RAG easier to use to reduce the\\n11https://github.com/weaviate/Verba\\n12https://aws.amazon.com/cn/kendra/'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='16\\nFig. 6. Summary of RAG ecosystem\\ninitial learning curve. 3) Specialization - optimizing RAG to\\nbetter serve production environments.\\nThe mutual growth of RAG models and their technology\\nstacks is evident; technological advancements continuously\\nestablish new standards for existing infrastructure. In turn,\\nenhancements to the technology stack drive the development\\nof RAG capabilities. RAG toolkits are converging into a\\nfoundational technology stack, laying the groundwork for\\nadvanced enterprise applications. However, a fully integrated,\\ncomprehensive platform concept is still in the future, requiring\\nfurther innovation and development.\\nF . Multi-modal RAG\\nRAG has transcended its initial text-based question-\\nanswering confines, embracing a diverse array of modal data.\\nThis expansion has spawned innovative multimodal models\\nthat integrate RAG concepts across various domains:\\nImage. RA-CM3 [176] stands as a pioneering multimodal\\nmodel of both retrieving and generating text and images.\\nBLIP-2 [177] leverages frozen image encoders alongside\\nLLMs for efficient visual language pre-training, enabling zero-\\nshot image-to-text conversions. The “Visualize Before You\\nWrite” method [178] employs image generation to steer the\\nLM’s text generation, showing promise in open-ended text\\ngeneration tasks.\\nAudio and Video . The GSS method retrieves and stitches\\ntogether audio clips to convert machine-translated data into\\nspeech-translated data [179]. UEOP marks a significant ad-\\nvancement in end-to-end automatic speech recognition by\\nincorporating external, offline strategies for voice-to-text con-\\nversion [180]. Additionally, KNN-based attention fusion lever-\\nages audio embeddings and semantically related text embed-\\ndings to refine ASR, thereby accelerating domain adaptation.\\nVid2Seq augments language models with specialized temporal\\nmarkers, facilitating the prediction of event boundaries and\\ntextual descriptions within a unified output sequence [181].\\nCode. RBPS [182] excels in small-scale learning tasks by\\nretrieving code examples that align with developers’ objectives\\nthrough encoding and frequency analysis. This approach has\\ndemonstrated efficacy in tasks such as test assertion genera-\\ntion and program repair. For structured knowledge, the CoK\\nmethod [106] first extracts facts pertinent to the input query\\nfrom a knowledge graph, then integrates these facts as hints\\nwithin the input, enhancing performance in knowledge graph\\nquestion-answering tasks.\\nVIII. C ONCLUSION\\nThe summary of this paper, as depicted in Figure 6, empha-\\nsizes RAG’s significant advancement in enhancing the capa-\\nbilities of LLMs by integrating parameterized knowledge from\\nlanguage models with extensive non-parameterized data from\\nexternal knowledge bases. The survey showcases the evolution\\nof RAG technologies and their application on many different\\ntasks. The analysis outlines three developmental paradigms\\nwithin the RAG framework: Naive, Advanced, and Modu-\\nlar RAG, each representing a progressive enhancement over\\nits predecessors. RAG’s technical integration with other AI\\nmethodologies, such as fine-tuning and reinforcement learning,\\nhas further expanded its capabilities. Despite the progress in\\nRAG technology, there are research opportunities to improve\\nits robustness and its ability to handle extended contexts.\\nRAG’s application scope is expanding into multimodal do-\\nmains, adapting its principles to interpret and process diverse\\ndata forms like images, videos, and code. This expansion high-\\nlights RAG’s significant practical implications for AI deploy-\\nment, attracting interest from academic and industrial sectors.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='17\\nThe growing ecosystem of RAG is evidenced by the rise in\\nRAG-centric AI applications and the continuous development\\nof supportive tools. As RAG’s application landscape broadens,\\nthere is a need to refine evaluation methodologies to keep\\npace with its evolution. Ensuring accurate and representative\\nperformance assessments is crucial for fully capturing RAG’s\\ncontributions to the AI research and development community.\\nREFERENCES\\n[1] N. Kandpal, H. Deng, A. Roberts, E. Wallace, and C. Raffel, “Large\\nlanguage models struggle to learn long-tail knowledge,” in Interna-\\ntional Conference on Machine Learning . PMLR, 2023, pp. 15 696–\\n15 707.\\n[2] Y . Zhang, Y . Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao,\\nY . Zhang, Y . Chenet al., “Siren’s song in the ai ocean: A survey on hal-\\nlucination in large language models,” arXiv preprint arXiv:2309.01219,\\n2023.\\n[3] D. Arora, A. Kini, S. R. Chowdhury, N. Natarajan, G. Sinha, and\\nA. Sharma, “Gar-meets-rag paradigm for zero-shot information re-\\ntrieval,” arXiv preprint arXiv:2310.20158 , 2023.\\n[4] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal,\\nH. K ¨uttler, M. Lewis, W.-t. Yih, T. Rockt ¨aschel et al. , “Retrieval-\\naugmented generation for knowledge-intensive nlp tasks,” Advances in\\nNeural Information Processing Systems, vol. 33, pp. 9459–9474, 2020.\\n[5] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Milli-\\ncan, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clarket al.,\\n“Improving language models by retrieving from trillions of tokens,”\\nin International conference on machine learning . PMLR, 2022, pp.\\n2206–2240.\\n[6] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,\\nC. Zhang, S. Agarwal, K. Slama, A. Ray et al. , “Training language\\nmodels to follow instructions with human feedback,” Advances in\\nneural information processing systems , vol. 35, pp. 27 730–27 744,\\n2022.\\n[7] X. Ma, Y . Gong, P. He, H. Zhao, and N. Duan, “Query rewrit-\\ning for retrieval-augmented large language models,” arXiv preprint\\narXiv:2305.14283, 2023.\\n[8] I. ILIN, “Advanced rag techniques: an il-\\nlustrated overview,” https://pub.towardsai.net/\\nadvanced-rag-techniques-an-illustrated-overview-04d193d8fec6,\\n2023.\\n[9] W. Peng, G. Li, Y . Jiang, Z. Wang, D. Ou, X. Zeng, E. Chen et al. ,\\n“Large language model based long-tail query rewriting in taobao\\nsearch,” arXiv preprint arXiv:2311.03758 , 2023.\\n[10] H. S. Zheng, S. Mishra, X. Chen, H.-T. Cheng, E. H. Chi, Q. V . Le,\\nand D. Zhou, “Take a step back: Evoking reasoning via abstraction in\\nlarge language models,” arXiv preprint arXiv:2310.06117 , 2023.\\n[11] L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense retrieval\\nwithout relevance labels,” arXiv preprint arXiv:2212.10496 , 2022.\\n[12] V . Blagojevi, “Enhancing rag pipelines in haystack: Introducing diver-\\nsityranker and lostinthemiddleranker,” https://towardsdatascience.com/\\nenhancing-rag-pipelines-in-haystack-45f14e2bc9f5, 2023.\\n[13] W. Yu, D. Iter, S. Wang, Y . Xu, M. Ju, S. Sanyal, C. Zhu, M. Zeng,\\nand M. Jiang, “Generate rather than retrieve: Large language models\\nare strong context generators,” arXiv preprint arXiv:2209.10063, 2022.\\n[14] Z. Shao, Y . Gong, Y . Shen, M. Huang, N. Duan, and W. Chen,\\n“Enhancing retrieval-augmented large language models with iterative\\nretrieval-generation synergy,” arXiv preprint arXiv:2305.15294 , 2023.\\n[15] X. Wang, Q. Yang, Y . Qiu, J. Liang, Q. He, Z. Gu, Y . Xiao,\\nand W. Wang, “Knowledgpt: Enhancing large language models with\\nretrieval and storage access on knowledge bases,” arXiv preprint\\narXiv:2308.11761, 2023.\\n[16] A. H. Raudaschl, “Forget rag, the future\\nis rag-fusion,” https://towardsdatascience.com/\\nforget-rag-the-future-is-rag-fusion-1147298d8ad1, 2023.\\n[17] X. Cheng, D. Luo, X. Chen, L. Liu, D. Zhao, and R. Yan, “Lift\\nyourself up: Retrieval-augmented text generation with self memory,”\\narXiv preprint arXiv:2305.02437 , 2023.\\n[18] S. Wang, Y . Xu, Y . Fang, Y . Liu, S. Sun, R. Xu, C. Zhu, and\\nM. Zeng, “Training data is more valuable than you think: A simple\\nand effective method by retrieving from training data,” arXiv preprint\\narXiv:2203.08773, 2022.\\n[19] X. Li, E. Nie, and S. Liang, “From classification to generation:\\nInsights into crosslingual retrieval augmented icl,” arXiv preprint\\narXiv:2311.06595, 2023.\\n[20] D. Cheng, S. Huang, J. Bi, Y . Zhan, J. Liu, Y . Wang, H. Sun,\\nF. Wei, D. Deng, and Q. Zhang, “Uprise: Universal prompt retrieval\\nfor improving zero-shot evaluation,” arXiv preprint arXiv:2303.08518,\\n2023.\\n[21] Z. Dai, V . Y . Zhao, J. Ma, Y . Luan, J. Ni, J. Lu, A. Bakalov, K. Guu,\\nK. B. Hall, and M.-W. Chang, “Promptagator: Few-shot dense retrieval\\nfrom 8 examples,” arXiv preprint arXiv:2209.11755 , 2022.\\n[22] Z. Sun, X. Wang, Y . Tay, Y . Yang, and D. Zhou, “Recitation-augmented\\nlanguage models,” arXiv preprint arXiv:2210.01296 , 2022.\\n[23] O. Khattab, K. Santhanam, X. L. Li, D. Hall, P. Liang, C. Potts,\\nand M. Zaharia, “Demonstrate-search-predict: Composing retrieval\\nand language models for knowledge-intensive nlp,” arXiv preprint\\narXiv:2212.14024, 2022.\\n[24] Z. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y . Yang,\\nJ. Callan, and G. Neubig, “Active retrieval augmented generation,”\\narXiv preprint arXiv:2305.06983 , 2023.\\n[25] A. Asai, Z. Wu, Y . Wang, A. Sil, and H. Hajishirzi, “Self-rag:\\nLearning to retrieve, generate, and critique through self-reflection,”\\narXiv preprint arXiv:2310.11511 , 2023.\\n[26] Z. Ke, W. Kong, C. Li, M. Zhang, Q. Mei, and M. Bendersky,\\n“Bridging the preference gap between retrievers and llms,” arXiv\\npreprint arXiv:2401.06954, 2024.\\n[27] X. V . Lin, X. Chen, M. Chen, W. Shi, M. Lomeli, R. James, P. Ro-\\ndriguez, J. Kahn, G. Szilvasy, M. Lewis et al. , “Ra-dit: Retrieval-\\naugmented dual instruction tuning,” arXiv preprint arXiv:2310.01352 ,\\n2023.\\n[28] O. Ovadia, M. Brief, M. Mishaeli, and O. Elisha, “Fine-tuning or\\nretrieval? comparing knowledge injection in llms,” arXiv preprint\\narXiv:2312.05934, 2023.\\n[29] T. Lan, D. Cai, Y . Wang, H. Huang, and X.-L. Mao, “Copy is all\\nyou need,” in The Eleventh International Conference on Learning\\nRepresentations, 2022.\\n[30] T. Chen, H. Wang, S. Chen, W. Yu, K. Ma, X. Zhao, D. Yu, and\\nH. Zhang, “Dense x retrieval: What retrieval granularity should we\\nuse?” arXiv preprint arXiv:2312.06648 , 2023.\\n[31] F. Luo and M. Surdeanu, “Divide & conquer for entailment-aware\\nmulti-hop evidence retrieval,” arXiv preprint arXiv:2311.02616 , 2023.\\n[32] Q. Gou, Z. Xia, B. Yu, H. Yu, F. Huang, Y . Li, and N. Cam-Tu,\\n“Diversify question generation with retrieval-augmented style transfer,”\\narXiv preprint arXiv:2310.14503 , 2023.\\n[33] Z. Guo, S. Cheng, Y . Wang, P. Li, and Y . Liu, “Prompt-guided re-\\ntrieval augmentation for non-knowledge-intensive tasks,”arXiv preprint\\narXiv:2305.17653, 2023.\\n[34] Z. Wang, J. Araki, Z. Jiang, M. R. Parvez, and G. Neubig, “Learning\\nto filter context for retrieval-augmented generation,” arXiv preprint\\narXiv:2311.08377, 2023.\\n[35] M. Seo, J. Baek, J. Thorne, and S. J. Hwang, “Retrieval-augmented\\ndata augmentation for low-resource domain tasks,” arXiv preprint\\narXiv:2402.13482, 2024.\\n[36] Y . Ma, Y . Cao, Y . Hong, and A. Sun, “Large language model is not\\na good few-shot information extractor, but a good reranker for hard\\nsamples!” arXiv preprint arXiv:2303.08559 , 2023.\\n[37] X. Du and H. Ji, “Retrieval-augmented generative question answering\\nfor event argument extraction,” arXiv preprint arXiv:2211.07067, 2022.\\n[38] L. Wang, N. Yang, and F. Wei, “Learning to retrieve in-context\\nexamples for large language models,”arXiv preprint arXiv:2307.07164,\\n2023.\\n[39] S. Rajput, N. Mehta, A. Singh, R. H. Keshavan, T. Vu, L. Heldt,\\nL. Hong, Y . Tay, V . Q. Tran, J. Samostet al., “Recommender systems\\nwith generative retrieval,” arXiv preprint arXiv:2305.05065 , 2023.\\n[40] B. Jin, H. Zeng, G. Wang, X. Chen, T. Wei, R. Li, Z. Wang, Z. Li,\\nY . Li, H. Lu et al. , “Language models as semantic indexers,” arXiv\\npreprint arXiv:2310.07815, 2023.\\n[41] R. Anantha, T. Bethi, D. V odianik, and S. Chappidi, “Context tuning\\nfor retrieval augmented generation,” arXiv preprint arXiv:2312.05708 ,\\n2023.\\n[42] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick,\\nJ. Dwivedi-Yu, A. Joulin, S. Riedel, and E. Grave, “Few-shot\\nlearning with retrieval augmented language models,” arXiv preprint\\narXiv:2208.03299, 2022.\\n[43] J. Huang, W. Ping, P. Xu, M. Shoeybi, K. C.-C. Chang, and B. Catan-\\nzaro, “Raven: In-context learning with retrieval augmented encoder-\\ndecoder language models,” arXiv preprint arXiv:2308.07922 , 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='18\\n[44] B. Wang, W. Ping, P. Xu, L. McAfee, Z. Liu, M. Shoeybi, Y . Dong,\\nO. Kuchaiev, B. Li, C. Xiao et al. , “Shall we pretrain autoregressive\\nlanguage models with retrieval? a comprehensive study,”arXiv preprint\\narXiv:2304.06762, 2023.\\n[45] B. Wang, W. Ping, L. McAfee, P. Xu, B. Li, M. Shoeybi, and B. Catan-\\nzaro, “Instructretro: Instruction tuning post retrieval-augmented pre-\\ntraining,” arXiv preprint arXiv:2310.07713 , 2023.\\n[46] S. Siriwardhana, R. Weerasekera, E. Wen, T. Kaluarachchi, R. Rana,\\nand S. Nanayakkara, “Improving the domain adaptation of retrieval\\naugmented generation (rag) models for open domain question answer-\\ning,” Transactions of the Association for Computational Linguistics ,\\nvol. 11, pp. 1–17, 2023.\\n[47] Z. Yu, C. Xiong, S. Yu, and Z. Liu, “Augmentation-adapted retriever\\nimproves generalization of language models as generic plug-in,” arXiv\\npreprint arXiv:2305.17331, 2023.\\n[48] O. Yoran, T. Wolfson, O. Ram, and J. Berant, “Making retrieval-\\naugmented language models robust to irrelevant context,” arXiv\\npreprint arXiv:2310.01558, 2023.\\n[49] H.-T. Chen, F. Xu, S. A. Arora, and E. Choi, “Understanding re-\\ntrieval augmentation for long-form question answering,” arXiv preprint\\narXiv:2310.12150, 2023.\\n[50] W. Yu, H. Zhang, X. Pan, K. Ma, H. Wang, and D. Yu, “Chain-of-note:\\nEnhancing robustness in retrieval-augmented language models,” arXiv\\npreprint arXiv:2311.09210, 2023.\\n[51] S. Xu, L. Pang, H. Shen, X. Cheng, and T.-S. Chua, “Search-in-the-\\nchain: Towards accurate, credible and traceable large language models\\nfor knowledgeintensive tasks,” CoRR, vol. abs/2304.14732 , 2023.\\n[52] M. Berchansky, P. Izsak, A. Caciularu, I. Dagan, and M. Wasserblat,\\n“Optimizing retrieval-augmented reader models via token elimination,”\\narXiv preprint arXiv:2310.13682 , 2023.\\n[53] J. L ´ala, O. O’Donoghue, A. Shtedritski, S. Cox, S. G. Rodriques,\\nand A. D. White, “Paperqa: Retrieval-augmented generative agent for\\nscientific research,” arXiv preprint arXiv:2312.07559 , 2023.\\n[54] F. Cuconasu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano,\\nY . Maarek, N. Tonellotto, and F. Silvestri, “The power of noise:\\nRedefining retrieval for rag systems,” arXiv preprint arXiv:2401.14887,\\n2024.\\n[55] Z. Zhang, X. Zhang, Y . Ren, S. Shi, M. Han, Y . Wu, R. Lai, and\\nZ. Cao, “Iag: Induction-augmented generation framework for answer-\\ning reasoning questions,” in Proceedings of the 2023 Conference on\\nEmpirical Methods in Natural Language Processing , 2023, pp. 1–14.\\n[56] N. Thakur, L. Bonifacio, X. Zhang, O. Ogundepo, E. Kamalloo,\\nD. Alfonso-Hermelo, X. Li, Q. Liu, B. Chen, M. Rezagholizadeh et al.,\\n“Nomiracl: Knowing when you don’t know for robust multilingual\\nretrieval-augmented generation,” arXiv preprint arXiv:2312.11361 ,\\n2023.\\n[57] G. Kim, S. Kim, B. Jeon, J. Park, and J. Kang, “Tree of clarifica-\\ntions: Answering ambiguous questions with retrieval-augmented large\\nlanguage models,” arXiv preprint arXiv:2310.14696 , 2023.\\n[58] Y . Wang, P. Li, M. Sun, and Y . Liu, “Self-knowledge guided\\nretrieval augmentation for large language models,” arXiv preprint\\narXiv:2310.05002, 2023.\\n[59] Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin, “Retrieval-\\ngeneration synergy augmented large language models,” arXiv preprint\\narXiv:2310.05149, 2023.\\n[60] P. Xu, W. Ping, X. Wu, L. McAfee, C. Zhu, Z. Liu, S. Subramanian,\\nE. Bakhturina, M. Shoeybi, and B. Catanzaro, “Retrieval meets long\\ncontext large language models,” arXiv preprint arXiv:2310.03025 ,\\n2023.\\n[61] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Interleav-\\ning retrieval with chain-of-thought reasoning for knowledge-intensive\\nmulti-step questions,” arXiv preprint arXiv:2212.10509 , 2022.\\n[62] R. Ren, Y . Wang, Y . Qu, W. X. Zhao, J. Liu, H. Tian, H. Wu, J.-\\nR. Wen, and H. Wang, “Investigating the factual knowledge boundary\\nof large language models with retrieval augmentation,” arXiv preprint\\narXiv:2307.11019, 2023.\\n[63] P. Sarthi, S. Abdullah, A. Tuli, S. Khanna, A. Goldie, and C. D.\\nManning, “Raptor: Recursive abstractive processing for tree-organized\\nretrieval,” arXiv preprint arXiv:2401.18059 , 2024.\\n[64] O. Ram, Y . Levine, I. Dalmedigos, D. Muhlgay, A. Shashua, K. Leyton-\\nBrown, and Y . Shoham, “In-context retrieval-augmented language\\nmodels,” arXiv preprint arXiv:2302.00083 , 2023.\\n[65] Y . Ren, Y . Cao, P. Guo, F. Fang, W. Ma, and Z. Lin, “Retrieve-and-\\nsample: Document-level event argument extraction via hybrid retrieval\\naugmentation,” in Proceedings of the 61st Annual Meeting of the\\nAssociation for Computational Linguistics (Volume 1: Long Papers) ,\\n2023, pp. 293–306.\\n[66] Z. Wang, X. Pan, D. Yu, D. Yu, J. Chen, and H. Ji, “Zemi: Learning\\nzero-shot semi-parametric language models from multiple tasks,” arXiv\\npreprint arXiv:2210.00185, 2022.\\n[67] S.-Q. Yan, J.-C. Gu, Y . Zhu, and Z.-H. Ling, “Corrective retrieval\\naugmented generation,” arXiv preprint arXiv:2401.15884 , 2024.\\n[68] P. Jain, L. B. Soares, and T. Kwiatkowski, “1-pager: One pass answer\\ngeneration and evidence retrieval,” arXiv preprint arXiv:2310.16568 ,\\n2023.\\n[69] H. Yang, Z. Li, Y . Zhang, J. Wang, N. Cheng, M. Li, and J. Xiao, “Prca:\\nFitting black-box large language models for retrieval question answer-\\ning via pluggable reward-driven contextual adapter,” arXiv preprint\\narXiv:2310.18347, 2023.\\n[70] S. Zhuang, B. Liu, B. Koopman, and G. Zuccon, “Open-source large\\nlanguage models are strong zero-shot query likelihood models for\\ndocument ranking,” arXiv preprint arXiv:2310.13243 , 2023.\\n[71] F. Xu, W. Shi, and E. Choi, “Recomp: Improving retrieval-augmented\\nlms with compression and selective augmentation,” arXiv preprint\\narXiv:2310.04408, 2023.\\n[72] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettle-\\nmoyer, and W.-t. Yih, “Replug: Retrieval-augmented black-box lan-\\nguage models,” arXiv preprint arXiv:2301.12652 , 2023.\\n[73] E. Melz, “Enhancing llm intelligence with arm-rag: Auxiliary ra-\\ntionale memory for retrieval augmented generation,” arXiv preprint\\narXiv:2311.04177, 2023.\\n[74] H. Wang, W. Huang, Y . Deng, R. Wang, Z. Wang, Y . Wang, F. Mi,\\nJ. Z. Pan, and K.-F. Wong, “Unims-rag: A unified multi-source\\nretrieval-augmented generation for personalized dialogue systems,”\\narXiv preprint arXiv:2401.13256 , 2024.\\n[75] Z. Luo, C. Xu, P. Zhao, X. Geng, C. Tao, J. Ma, Q. Lin, and D. Jiang,\\n“Augmented large language models with parametric knowledge guid-\\ning,” arXiv preprint arXiv:2305.04757 , 2023.\\n[76] X. Li, Z. Liu, C. Xiong, S. Yu, Y . Gu, Z. Liu, and G. Yu, “Structure-\\naware language model pretraining improves dense retrieval on struc-\\ntured data,” arXiv preprint arXiv:2305.19912 , 2023.\\n[77] M. Kang, J. M. Kwak, J. Baek, and S. J. Hwang, “Knowledge\\ngraph-augmented language models for knowledge-grounded dialogue\\ngeneration,” arXiv preprint arXiv:2305.18846 , 2023.\\n[78] W. Shen, Y . Gao, C. Huang, F. Wan, X. Quan, and W. Bi, “Retrieval-\\ngeneration alignment for end-to-end task-oriented dialogue system,”\\narXiv preprint arXiv:2310.08877 , 2023.\\n[79] T. Shi, L. Li, Z. Lin, T. Yang, X. Quan, and Q. Wang, “Dual-feedback\\nknowledge retrieval for task-oriented dialogue systems,” arXiv preprint\\narXiv:2310.14528, 2023.\\n[80] P. Ranade and A. Joshi, “Fabula: Intelligence report generation\\nusing retrieval-augmented narrative construction,” arXiv preprint\\narXiv:2310.13848, 2023.\\n[81] X. Jiang, R. Zhang, Y . Xu, R. Qiu, Y . Fang, Z. Wang, J. Tang,\\nH. Ding, X. Chu, J. Zhao et al. , “Think and retrieval: A hypothesis\\nknowledge graph enhanced medical large language models,” arXiv\\npreprint arXiv:2312.15883, 2023.\\n[82] J. Baek, S. Jeong, M. Kang, J. C. Park, and S. J. Hwang,\\n“Knowledge-augmented language model verification,” arXiv preprint\\narXiv:2310.12836, 2023.\\n[83] L. Luo, Y .-F. Li, G. Haffari, and S. Pan, “Reasoning on graphs: Faithful\\nand interpretable large language model reasoning,” arXiv preprint\\narXiv:2310.01061, 2023.\\n[84] X. He, Y . Tian, Y . Sun, N. V . Chawla, T. Laurent, Y . LeCun,\\nX. Bresson, and B. Hooi, “G-retriever: Retrieval-augmented generation\\nfor textual graph understanding and question answering,”arXiv preprint\\narXiv:2402.07630, 2024.\\n[85] L. Zha, J. Zhou, L. Li, R. Wang, Q. Huang, S. Yang, J. Yuan, C. Su,\\nX. Li, A. Su et al., “Tablegpt: Towards unifying tables, nature language\\nand commands into one gpt,” arXiv preprint arXiv:2307.08674 , 2023.\\n[86] M. Gaur, K. Gunaratna, V . Srinivasan, and H. Jin, “Iseeq: Information\\nseeking question generation using dynamic meta-information retrieval\\nand knowledge graphs,” in Proceedings of the AAAI Conference on\\nArtificial Intelligence, vol. 36, no. 10, 2022, pp. 10 672–10 680.\\n[87] F. Shi, X. Chen, K. Misra, N. Scales, D. Dohan, E. H. Chi, N. Sch ¨arli,\\nand D. Zhou, “Large language models can be easily distracted by\\nirrelevant context,” in International Conference on Machine Learning .\\nPMLR, 2023, pp. 31 210–31 227.\\n[88] R. Teja, “Evaluating the ideal chunk size for a rag\\nsystem using llamaindex,” https://www.llamaindex.ai/blog/\\nevaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5,\\n2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='19\\n[89] Langchain, “Recursively split by character,” https://python.langchain.\\ncom/docs/modules/data connection/document transformers/recursive\\ntext splitter, 2023.\\n[90] S. Yang, “Advanced rag 01: Small-to-\\nbig retrieval,” https://towardsdatascience.com/\\nadvanced-rag-01-small-to-big-retrieval-172181b396d4, 2023.\\n[91] Y . Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and T. Derr,\\n“Knowledge graph prompting for multi-document question answering,”\\narXiv preprint arXiv:2308.11730 , 2023.\\n[92] D. Zhou, N. Sch ¨arli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schu-\\nurmans, C. Cui, O. Bousquet, Q. Le et al., “Least-to-most prompting\\nenables complex reasoning in large language models,” arXiv preprint\\narXiv:2205.10625, 2022.\\n[93] S. Dhuliawala, M. Komeili, J. Xu, R. Raileanu, X. Li, A. Celikyilmaz,\\nand J. Weston, “Chain-of-verification reduces hallucination in large\\nlanguage models,” arXiv preprint arXiv:2309.11495 , 2023.\\n[94] X. Li and J. Li, “Angle-optimized text embeddings,” arXiv preprint\\narXiv:2309.12871, 2023.\\n[95] V oyageAI, “V oyage’s embedding models,” https://docs.voyageai.com/\\nembeddings/, 2023.\\n[96] BAAI, “Flagembedding,” https://github.com/FlagOpen/\\nFlagEmbedding, 2023.\\n[97] P. Zhang, S. Xiao, Z. Liu, Z. Dou, and J.-Y . Nie, “Retrieve anything\\nto augment large language models,” arXiv preprint arXiv:2310.07554 ,\\n2023.\\n[98] N. F. Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilacqua, F. Petroni,\\nand P. Liang, “Lost in the middle: How language models use long\\ncontexts,” arXiv preprint arXiv:2307.03172 , 2023.\\n[99] Y . Gao, T. Sheng, Y . Xiang, Y . Xiong, H. Wang, and J. Zhang, “Chat-\\nrec: Towards interactive and explainable llms-augmented recommender\\nsystem,” arXiv preprint arXiv:2303.14524 , 2023.\\n[100] N. Anderson, C. Wilson, and S. D. Richardson, “Lingua: Addressing\\nscenarios for live interpretation and automatic dubbing,” inProceedings\\nof the 15th Biennial Conference of the Association for Machine\\nTranslation in the Americas (Volume 2: Users and Providers Track\\nand Government Track) , J. Campbell, S. Larocca, J. Marciano,\\nK. Savenkov, and A. Yanishevsky, Eds. Orlando, USA: Association\\nfor Machine Translation in the Americas, Sep. 2022, pp. 202–209.\\n[Online]. Available: https://aclanthology.org/2022.amta-upg.14\\n[101] H. Jiang, Q. Wu, X. Luo, D. Li, C.-Y . Lin, Y . Yang, and L. Qiu,\\n“Longllmlingua: Accelerating and enhancing llms in long context\\nscenarios via prompt compression,” arXiv preprint arXiv:2310.06839 ,\\n2023.\\n[102] V . Karpukhin, B. O ˘guz, S. Min, P. Lewis, L. Wu, S. Edunov, D. Chen,\\nand W.-t. Yih, “Dense passage retrieval for open-domain question\\nanswering,” arXiv preprint arXiv:2004.04906 , 2020.\\n[103] Y . Ma, Y . Cao, Y . Hong, and A. Sun, “Large language model is\\nnot a good few-shot information extractor, but a good reranker for\\nhard samples!” ArXiv, vol. abs/2303.08559, 2023. [Online]. Available:\\nhttps://api.semanticscholar.org/CorpusID:257532405\\n[104] J. Cui, Z. Li, Y . Yan, B. Chen, and L. Yuan, “Chatlaw: Open-source\\nlegal large language model with integrated external knowledge bases,”\\narXiv preprint arXiv:2306.16092 , 2023.\\n[105] O. Yoran, T. Wolfson, O. Ram, and J. Berant, “Making retrieval-\\naugmented language models robust to irrelevant context,” arXiv\\npreprint arXiv:2310.01558, 2023.\\n[106] X. Li, R. Zhao, Y . K. Chia, B. Ding, L. Bing, S. Joty, and S. Poria,\\n“Chain of knowledge: A framework for grounding large language mod-\\nels with structured knowledge bases,”arXiv preprint arXiv:2305.13269,\\n2023.\\n[107] H. Yang, S. Yue, and Y . He, “Auto-gpt for online decision\\nmaking: Benchmarks and additional opinions,” arXiv preprint\\narXiv:2306.02224, 2023.\\n[108] T. Schick, J. Dwivedi-Yu, R. Dess `ı, R. Raileanu, M. Lomeli, L. Zettle-\\nmoyer, N. Cancedda, and T. Scialom, “Toolformer: Language models\\ncan teach themselves to use tools,” arXiv preprint arXiv:2302.04761 ,\\n2023.\\n[109] J. Zhang, “Graph-toolformer: To empower llms with graph rea-\\nsoning ability via prompt augmented by chatgpt,” arXiv preprint\\narXiv:2304.11116, 2023.\\n[110] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim,\\nC. Hesse, S. Jain, V . Kosaraju, W. Saunders et al., “Webgpt: Browser-\\nassisted question-answering with human feedback,” arXiv preprint\\narXiv:2112.09332, 2021.\\n[111] T. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. Parikh,\\nC. Alberti, D. Epstein, I. Polosukhin, J. Devlin, K. Lee et al., “Natural\\nquestions: a benchmark for question answering research,” Transactions\\nof the Association for Computational Linguistics , vol. 7, pp. 453–466,\\n2019.\\n[112] Y . Liu, S. Yavuz, R. Meng, M. Moorthy, S. Joty, C. Xiong, and Y . Zhou,\\n“Exploring the integration strategies of retriever and large language\\nmodels,” arXiv preprint arXiv:2308.12574 , 2023.\\n[113] M. Joshi, E. Choi, D. S. Weld, and L. Zettlemoyer, “Triviaqa: A large\\nscale distantly supervised challenge dataset for reading comprehen-\\nsion,” arXiv preprint arXiv:1705.03551 , 2017.\\n[114] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, “Squad: 100,000+\\nquestions for machine comprehension of text,” arXiv preprint\\narXiv:1606.05250, 2016.\\n[115] J. Berant, A. Chou, R. Frostig, and P. Liang, “Semantic parsing on\\nfreebase from question-answer pairs,” in Proceedings of the 2013\\nconference on empirical methods in natural language processing, 2013,\\npp. 1533–1544.\\n[116] A. Mallen, A. Asai, V . Zhong, R. Das, H. Hajishirzi, and D. Khashabi,\\n“When not to trust language models: Investigating effectiveness and\\nlimitations of parametric and non-parametric memories,” arXiv preprint\\narXiv:2212.10511, 2022.\\n[117] T. Nguyen, M. Rosenberg, X. Song, J. Gao, S. Tiwary, R. Majumder,\\nand L. Deng, “Ms marco: A human-generated machine reading com-\\nprehension dataset,” 2016.\\n[118] Z. Yang, P. Qi, S. Zhang, Y . Bengio, W. W. Cohen, R. Salakhutdi-\\nnov, and C. D. Manning, “Hotpotqa: A dataset for diverse, explain-\\nable multi-hop question answering,” arXiv preprint arXiv:1809.09600,\\n2018.\\n[119] X. Ho, A.-K. D. Nguyen, S. Sugawara, and A. Aizawa, “Constructing a\\nmulti-hop qa dataset for comprehensive evaluation of reasoning steps,”\\narXiv preprint arXiv:2011.01060 , 2020.\\n[120] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Musique:\\nMultihop questions via single-hop question composition,” Transactions\\nof the Association for Computational Linguistics , vol. 10, pp. 539–554,\\n2022.\\n[121] A. Fan, Y . Jernite, E. Perez, D. Grangier, J. Weston, and M. Auli, “Eli5:\\nLong form question answering,” arXiv preprint arXiv:1907.09190 ,\\n2019.\\n[122] T. Ko ˇcisk`y, J. Schwarz, P. Blunsom, C. Dyer, K. M. Hermann, G. Melis,\\nand E. Grefenstette, “The narrativeqa reading comprehension chal-\\nlenge,” Transactions of the Association for Computational Linguistics ,\\nvol. 6, pp. 317–328, 2018.\\n[123] K.-H. Lee, X. Chen, H. Furuta, J. Canny, and I. Fischer, “A human-\\ninspired reading agent with gist memory of very long contexts,” arXiv\\npreprint arXiv:2402.09727, 2024.\\n[124] I. Stelmakh, Y . Luan, B. Dhingra, and M.-W. Chang, “Asqa: Factoid\\nquestions meet long-form answers,” arXiv preprint arXiv:2204.06092 ,\\n2022.\\n[125] M. Zhong, D. Yin, T. Yu, A. Zaidi, M. Mutuma, R. Jha, A. H.\\nAwadallah, A. Celikyilmaz, Y . Liu, X. Qiu et al. , “Qmsum: A new\\nbenchmark for query-based multi-domain meeting summarization,”\\narXiv preprint arXiv:2104.05938 , 2021.\\n[126] P. Dasigi, K. Lo, I. Beltagy, A. Cohan, N. A. Smith, and M. Gardner,\\n“A dataset of information-seeking questions and answers anchored in\\nresearch papers,” arXiv preprint arXiv:2105.03011 , 2021.\\n[127] T. M ¨oller, A. Reina, R. Jayakumar, and M. Pietsch, “Covid-qa: A\\nquestion answering dataset for covid-19,” in ACL 2020 Workshop on\\nNatural Language Processing for COVID-19 (NLP-COVID) , 2020.\\n[128] X. Wang, G. H. Chen, D. Song, Z. Zhang, Z. Chen, Q. Xiao, F. Jiang,\\nJ. Li, X. Wan, B. Wang et al. , “Cmb: A comprehensive medical\\nbenchmark in chinese,” arXiv preprint arXiv:2308.08833 , 2023.\\n[129] H. Zeng, “Measuring massive multitask chinese understanding,” arXiv\\npreprint arXiv:2304.12986, 2023.\\n[130] R. Y . Pang, A. Parrish, N. Joshi, N. Nangia, J. Phang, A. Chen, V . Pad-\\nmakumar, J. Ma, J. Thompson, H. He et al. , “Quality: Question an-\\nswering with long input texts, yes!” arXiv preprint arXiv:2112.08608 ,\\n2021.\\n[131] P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick,\\nand O. Tafjord, “Think you have solved question answering? try arc,\\nthe ai2 reasoning challenge,” arXiv preprint arXiv:1803.05457 , 2018.\\n[132] A. Talmor, J. Herzig, N. Lourie, and J. Berant, “Commonsenseqa:\\nA question answering challenge targeting commonsense knowledge,”\\narXiv preprint arXiv:1811.00937 , 2018.\\n[133] E. Dinan, S. Roller, K. Shuster, A. Fan, M. Auli, and J. Weston,\\n“Wizard of wikipedia: Knowledge-powered conversational agents,”\\narXiv preprint arXiv:1811.01241 , 2018.\\n[134] H. Wang, M. Hu, Y . Deng, R. Wang, F. Mi, W. Wang, Y . Wang, W.-\\nC. Kwan, I. King, and K.-F. Wong, “Large language models as source'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='20\\nplanner for personalized knowledge-grounded dialogue,” arXiv preprint\\narXiv:2310.08840, 2023.\\n[135] ——, “Large language models as source planner for personal-\\nized knowledge-grounded dialogue,” arXiv preprint arXiv:2310.08840,\\n2023.\\n[136] X. Xu, Z. Gou, W. Wu, Z.-Y . Niu, H. Wu, H. Wang, and S. Wang,\\n“Long time no see! open-domain conversation with long-term persona\\nmemory,” arXiv preprint arXiv:2203.05797 , 2022.\\n[137] T.-H. Wen, M. Gasic, N. Mrksic, L. M. Rojas-Barahona, P.-H.\\nSu, S. Ultes, D. Vandyke, and S. Young, “Conditional generation\\nand snapshot learning in neural dialogue systems,” arXiv preprint\\narXiv:1606.03352, 2016.\\n[138] R. He and J. McAuley, “Ups and downs: Modeling the visual evolution\\nof fashion trends with one-class collaborative filtering,” in proceedings\\nof the 25th international conference on world wide web , 2016, pp.\\n507–517.\\n[139] S. Li, H. Ji, and J. Han, “Document-level event argument extraction\\nby conditional generation,” arXiv preprint arXiv:2104.05919 , 2021.\\n[140] S. Ebner, P. Xia, R. Culkin, K. Rawlins, and B. Van Durme, “Multi-\\nsentence argument linking,” arXiv preprint arXiv:1911.03766 , 2019.\\n[141] H. Elsahar, P. V ougiouklis, A. Remaci, C. Gravier, J. Hare, F. Laforest,\\nand E. Simperl, “T-rex: A large scale alignment of natural language\\nwith knowledge base triples,” in Proceedings of the Eleventh Inter-\\nnational Conference on Language Resources and Evaluation (LREC\\n2018), 2018.\\n[142] O. Levy, M. Seo, E. Choi, and L. Zettlemoyer, “Zero-shot relation ex-\\ntraction via reading comprehension,” arXiv preprint arXiv:1706.04115,\\n2017.\\n[143] R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, “Hel-\\nlaswag: Can a machine really finish your sentence?” arXiv preprint\\narXiv:1905.07830, 2019.\\n[144] S. Kim, S. J. Joo, D. Kim, J. Jang, S. Ye, J. Shin, and M. Seo,\\n“The cot collection: Improving zero-shot and few-shot learning of\\nlanguage models via chain-of-thought fine-tuning,” arXiv preprint\\narXiv:2305.14045, 2023.\\n[145] A. Saha, V . Pahuja, M. Khapra, K. Sankaranarayanan, and S. Chandar,\\n“Complex sequential question answering: Towards learning to converse\\nover linked question answer pairs with a knowledge graph,” inProceed-\\nings of the AAAI conference on artificial intelligence , vol. 32, no. 1,\\n2018.\\n[146] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and\\nJ. Steinhardt, “Measuring massive multitask language understanding,”\\narXiv preprint arXiv:2009.03300 , 2020.\\n[147] S. Merity, C. Xiong, J. Bradbury, and R. Socher, “Pointer sentinel\\nmixture models,” arXiv preprint arXiv:1609.07843 , 2016.\\n[148] M. Geva, D. Khashabi, E. Segal, T. Khot, D. Roth, and J. Berant,\\n“Did aristotle use a laptop? a question answering benchmark with\\nimplicit reasoning strategies,” Transactions of the Association for\\nComputational Linguistics, vol. 9, pp. 346–361, 2021.\\n[149] J. Thorne, A. Vlachos, C. Christodoulopoulos, and A. Mittal, “Fever: a\\nlarge-scale dataset for fact extraction and verification,” arXiv preprint\\narXiv:1803.05355, 2018.\\n[150] N. Kotonya and F. Toni, “Explainable automated fact-checking for\\npublic health claims,” arXiv preprint arXiv:2010.09926 , 2020.\\n[151] R. Lebret, D. Grangier, and M. Auli, “Neural text generation from\\nstructured data with application to the biography domain,” arXiv\\npreprint arXiv:1603.07771, 2016.\\n[152] H. Hayashi, P. Budania, P. Wang, C. Ackerson, R. Neervannan,\\nand G. Neubig, “Wikiasp: A dataset for multi-domain aspect-based\\nsummarization,” Transactions of the Association for Computational\\nLinguistics, vol. 9, pp. 211–225, 2021.\\n[153] S. Narayan, S. B. Cohen, and M. Lapata, “Don’t give me the details,\\njust the summary! topic-aware convolutional neural networks for ex-\\ntreme summarization,” arXiv preprint arXiv:1808.08745 , 2018.\\n[154] S. Saha, J. A. Junaed, M. Saleki, A. S. Sharma, M. R. Rifat, M. Rahouti,\\nS. I. Ahmed, N. Mohammed, and M. R. Amin, “Vio-lens: A novel\\ndataset of annotated social network posts leading to different forms\\nof communal violence and its evaluation,” in Proceedings of the First\\nWorkshop on Bangla Language Processing (BLP-2023), 2023, pp. 72–\\n84.\\n[155] X. Li and D. Roth, “Learning question classifiers,” in COLING 2002:\\nThe 19th International Conference on Computational Linguistics, 2002.\\n[156] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Y . Ng,\\nand C. Potts, “Recursive deep models for semantic compositionality\\nover a sentiment treebank,” in Proceedings of the 2013 conference on\\nempirical methods in natural language processing , 2013, pp. 1631–\\n1642.\\n[157] H. Husain, H.-H. Wu, T. Gazit, M. Allamanis, and M. Brockschmidt,\\n“Codesearchnet challenge: Evaluating the state of semantic code\\nsearch,” arXiv preprint arXiv:1909.09436 , 2019.\\n[158] K. Cobbe, V . Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser,\\nM. Plappert, J. Tworek, J. Hilton, R. Nakano et al., “Training verifiers\\nto solve math word problems,” arXiv preprint arXiv:2110.14168, 2021.\\n[159] R. Steinberger, B. Pouliquen, A. Widiger, C. Ignat, T. Erjavec, D. Tufis,\\nand D. Varga, “The jrc-acquis: A multilingual aligned parallel corpus\\nwith 20+ languages,” arXiv preprint cs/0609058 , 2006.\\n[160] Y . Hoshi, D. Miyashita, Y . Ng, K. Tatsuno, Y . Morioka, O. Torii,\\nand J. Deguchi, “Ralle: A framework for developing and eval-\\nuating retrieval-augmented large language models,” arXiv preprint\\narXiv:2308.10633, 2023.\\n[161] J. Liu, “Building production-ready rag applications,” https://www.ai.\\nengineer/summit/schedule/building-production-ready-rag-applications,\\n2023.\\n[162] I. Nguyen, “Evaluating rag part i: How to evaluate document retrieval,”\\nhttps://www.deepset.ai/blog/rag-evaluation-retrieval, 2023.\\n[163] Q. Leng, K. Uhlenhuth, and A. Polyzotis, “Best practices for\\nllm evaluation of rag applications,” https://www.databricks.com/blog/\\nLLM-auto-eval-best-practices-RAG, 2023.\\n[164] S. Es, J. James, L. Espinosa-Anke, and S. Schockaert, “Ragas: Au-\\ntomated evaluation of retrieval augmented generation,” arXiv preprint\\narXiv:2309.15217, 2023.\\n[165] J. Saad-Falcon, O. Khattab, C. Potts, and M. Zaharia, “Ares: An\\nautomated evaluation framework for retrieval-augmented generation\\nsystems,” arXiv preprint arXiv:2311.09476 , 2023.\\n[166] C. Jarvis and J. Allard, “A survey of techniques for\\nmaximizing llm performance,” https://community.openai.\\ncom/t/openai-dev-day-2023-breakout-sessions/505213#\\na-survey-of-techniques-for-maximizing-llm-performance-2, 2023.\\n[167] J. Chen, H. Lin, X. Han, and L. Sun, “Benchmarking large lan-\\nguage models in retrieval-augmented generation,” arXiv preprint\\narXiv:2309.01431, 2023.\\n[168] Y . Liu, L. Huang, S. Li, S. Chen, H. Zhou, F. Meng, J. Zhou, and\\nX. Sun, “Recall: A benchmark for llms robustness against external\\ncounterfactual knowledge,” arXiv preprint arXiv:2311.08147 , 2023.\\n[169] Y . Lyu, Z. Li, S. Niu, F. Xiong, B. Tang, W. Wang, H. Wu, H. Liu,\\nT. Xu, and E. Chen, “Crud-rag: A comprehensive chinese benchmark\\nfor retrieval-augmented generation of large language models,” arXiv\\npreprint arXiv:2401.17043, 2024.\\n[170] P. Xu, W. Ping, X. Wu, L. McAfee, C. Zhu, Z. Liu, S. Subramanian,\\nE. Bakhturina, M. Shoeybi, and B. Catanzaro, “Retrieval meets long\\ncontext large language models,” arXiv preprint arXiv:2310.03025 ,\\n2023.\\n[171] C. Packer, V . Fang, S. G. Patil, K. Lin, S. Wooders, and J. E. Gon-\\nzalez, “Memgpt: Towards llms as operating systems,” arXiv preprint\\narXiv:2310.08560, 2023.\\n[172] G. Xiao, Y . Tian, B. Chen, S. Han, and M. Lewis, “Efficient\\nstreaming language models with attention sinks,” arXiv preprint\\narXiv:2309.17453, 2023.\\n[173] T. Zhang, S. G. Patil, N. Jain, S. Shen, M. Zaharia, I. Stoica, and J. E.\\nGonzalez, “Raft: Adapting language model to domain specific rag,”\\narXiv preprint arXiv:2403.10131 , 2024.\\n[174] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess,\\nR. Child, S. Gray, A. Radford, J. Wu, and D. Amodei, “Scaling laws\\nfor neural language models,” arXiv preprint arXiv:2001.08361 , 2020.\\n[175] U. Alon, F. Xu, J. He, S. Sengupta, D. Roth, and G. Neubig, “Neuro-\\nsymbolic language modeling with automaton-augmented retrieval,” in\\nInternational Conference on Machine Learning . PMLR, 2022, pp.\\n468–485.\\n[176] M. Yasunaga, A. Aghajanyan, W. Shi, R. James, J. Leskovec, P. Liang,\\nM. Lewis, L. Zettlemoyer, and W.-t. Yih, “Retrieval-augmented multi-\\nmodal language modeling,” arXiv preprint arXiv:2211.12561 , 2022.\\n[177] J. Li, D. Li, S. Savarese, and S. Hoi, “Blip-2: Bootstrapping language-\\nimage pre-training with frozen image encoders and large language\\nmodels,” arXiv preprint arXiv:2301.12597 , 2023.\\n[178] W. Zhu, A. Yan, Y . Lu, W. Xu, X. E. Wang, M. Eckstein, and W. Y .\\nWang, “Visualize before you write: Imagination-guided open-ended\\ntext generation,” arXiv preprint arXiv:2210.03765 , 2022.\\n[179] J. Zhao, G. Haffar, and E. Shareghi, “Generating synthetic speech from\\nspokenvocab for speech translation,” arXiv preprint arXiv:2210.08174,\\n2022.\\n[180] D. M. Chan, S. Ghosh, A. Rastrow, and B. Hoffmeister, “Using external\\noff-policy speech-to-text mappings in contextual end-to-end automated\\nspeech recognition,” arXiv preprint arXiv:2301.02736 , 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 20, 'page_label': '21', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='21\\n[181] A. Yang, A. Nagrani, P. H. Seo, A. Miech, J. Pont-Tuset, I. Laptev,\\nJ. Sivic, and C. Schmid, “Vid2seq: Large-scale pretraining of a visual\\nlanguage model for dense video captioning,” in Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition ,\\n2023, pp. 10 714–10 726.\\n[182] N. Nashid, M. Sintaha, and A. Mesbah, “Retrieval-based prompt\\nselection for code-related few-shot learning,” in 2023 IEEE/ACM 45th\\nInternational Conference on Software Engineering (ICSE) , 2023, pp.\\n2450–2462.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.27', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T16:40:31+00:00', 'author': '', 'keywords': '', 'moddate': '2025-09-21T16:40:31+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.27 (TeX Live 2025) kpathsea version 6.4.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Resume_Latest.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Resume_Latest.pdf', 'file_type': 'pdf'}, page_content='Yash Kumar\\n+919471694118 — yashcoder9187@gmail.com — linkedin.com/in/yashcoder2403 — github.com/Anonymus-Coder2403\\nBegusarai, India\\nSummary\\nApplied AI/Full-Stack engineer building LLM features end-to-end: data refinement to model-ready signals, LangChain/FastAPI APIs, and\\nNext.js/React frontends. Experience in SQL/NoSQL schema design, ETL with Python + SQL, vector search (Pinecone/FAISS)\\nSkills and Interests\\nLanguages:Python, Java, C/C++, JavaScript, TypeScript, SQL\\nAI/LLMs:LangChain, Prompt Engineering, Hugging Face, OpenAI API, Retrieval/Embeddings, Guardrails\\nDevelopment:React.js, Next.js, Tailwind; dashboards and real-time UX, FastAPI, REST, Auth (JWT/RBAC), Webhooks, Caching\\nData:Schema design (PostgreSQL, MongoDB), Vector DBs (Pinecone, Chroma/FAISS), ETL with Python+SQL\\nML Ops/Eval:Offline test sets, prompt/testing harnesses, CI on data/code\\nTools:Git, Docker, GitHub Actions, Power BI, Postman\\nExperience\\nData Analyst Intern Jan 2025 – Mar 2025\\nPawzz Foundation (Remote)\\n–Built interactive Power BI dashboards on donor funnels; improved reporting speed by 35%.\\n–Designed lightweight SQL tables/views and Python transforms to turn raw donations & events into model-ready signals.\\n–Automated extract-clean-load jobs (Python+SQL); reduced weekly manual effort significantly.\\n–Ran small offline experiments for trend prediction; shared insights with ops to iterate on campaigns.\\nGrowth Intern May 2023 – Jul 2023\\nFact App (Remote)\\n–Instrumented event tracking and REST endpoints (JavaScript + FastAPI) to unlock funnel/retention analytics.\\n–Optimized backend handlers and queries; reduced API latency under peak usage.\\n–Built weekly growth reports (SQL + automation) and ran quick A/B style experiments, contributing to +15% retention.\\n–Partnered with product to close the loop between metrics and feature iterations.\\nProjects\\nCareer Compass— Next.js, LangChain, FastAPI\\n–AI career assistant with resume scoring, job matching, and learning roadmaps; Next.js frontend + FastAPI services.\\n–Authored LangChain chains for retrieval & scoring; defined SQL/NoSQL fields to persist user/job signals.\\n–Built a small evaluation harness (sample resumes/jobs) to track recommendation quality (e.g., precision@k).\\nCyber Sentinel— Next.js, FastAPI, Hugging Face, MongoDB\\n–Engineered AI phishing/URL detection using Hugging Face transformers; created a labeled test set to measure 90%+ accuracy.\\n–Implemented FastAPI with JWT/RBAC and a MongoDB schema for scalable alert/log storage; webhook endpoints for actions.\\n–Responsive Next.js dashboard for real-time incidents; tight loop between detections, review, and follow-up.\\nSecure Sentinel Spark— React, Prompt Engineering 2025\\n–Prototype of a phishing workflow using prompt engineering to simulate pipeline logic end-to-end.\\n–Built an interactive React dashboard for classification, reviewer feedback, and iteration on prompts.\\n–Used small curated examples to evaluate prompt changes before demo deployments.\\nAchievements\\n1st Prize Aug 2025\\nQubit Quest 2025, IIIT Delhi\\n–Won 1st place at national hackathon (ESYA’25) for AI-powered quantum solution.\\nFinalist Sept 2025\\nHackShastra 2025\\n–Advanced to Round 2 among 200+ teams nationwide.\\nEducation\\nB.Tech in Electronics & Communication Engineering 2022 – 2026\\nGuru Ghasidas Vishwavidyalaya CGPA: 8.0 / 10.0\\nCertifications\\n–Generative AI with Google Cloud (May 2025)\\n–Large Language Models with Google Cloud (May 2025)\\n–AWS Solutions Architect (Forage) (Jun 2025)\\n–Deep Learning Specialization — Coursera (Ongoing)'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 0, 'page_label': '1', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='As an expert who\\'s witnessed the evolution of AI from its early days, I\\'m excited to guide you\\nthrough what I consider the most comprehensive and practical learning path to becoming an AI\\nEngineer. This roadmap is designed specifically for complete beginners and will transform you\\ninto a capable AI practitioner ready to build modern, cutting-edge AI systems.\\nWhy This Matters: AI isn\\'t just about code—it\\'s fundamentally mathematical. Understanding the\\nmath gives you superpowers to debug, optimize, and innovate beyond just following tutorials.\\nLinear Algebra\\nCalculus\\nStatistics & Probability\\nThe Ultimate AI Engineering Learning Roadmap:\\nFrom Zero to Hero \\x002025\\x00\\nPhase 1\\x00 Foundation Building \\x00Months 1\\x002\\x00\\nMathematical Prerequisites\\n\\x001\\x00\\n\\x002\\x00\\nVector operations: The backbone of neural networks\\nMatrix multiplication: How data flows through networks\\nEigenvalues/eigenvectors: Critical for understanding transformations\\nResource: Khan Academy Linear Algebra + 3Blue1Brown\\'s \"Essence of Linear Algebra\"\\x003\\x00\\n\\x004\\x00\\nDerivatives: How neural networks learn through gradients\\nChain rule: The mathematical foundation of backpropagation\\nPartial derivatives: Essential for optimization\\nResource: Paul\\'s Online Math Notes + 3Blue1Brown\\'s \"Essence of Calculus\"\\nProbability distributions: Understanding uncertainty in AI\\nBayes\\' theorem: Foundation of probabilistic reasoning\\nStatistical inference: Model evaluation and validation\\nResource: Think Stats (free book) + Khan Academy Statistics'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Python Mastery\\nJupyter Notebooks\\nAndrew Ng's Machine Learning Specialization \\x00Coursera)\\nHands-on Practice\\nSupervised Learning\\nProgramming Fundamentals\\nData structures: Lists, dictionaries, sets—the building blocks\\nNumPy: Mathematical operations on arrays\\nPandas: Data manipulation and analysis\\nMatplotlib/Seaborn: Data visualization\\nResource: Automate the Boring Stuff with Python (free) + Python Crash Course\\x005\\x00\\nInteractive development environment\\nEssential for experimentation and learning\\nResource: Jupyter documentation + DataCamp's Jupyter tutorial\\nPhase 2\\x00 Machine Learning Mastery \\x00Months 3\\x004\\x00\\nCore Machine Learning\\n\\x006\\x00\\x007\\x00\\nWhy it's exceptional: Ng breaks down complex concepts with mathematical rigor but\\npractical clarity\\nMost valuable sections:\\nGradient descent visualization and intuition\\nBias-variance tradeoff explanations\\nRegularization techniques\\nModel evaluation strategies\\nTime investment: 3 months, 5\\x0010 hours/week\\nKey outcome: You'll understand WHY algorithms work, not just HOW to use them\\x008\\x00\\nKaggle Learn Courses: Free micro-courses on ML fundamentals\\nMost valuable: Intro to Machine Learning + Intermediate Machine Learning\\nProjects: Start with Titanic, House Prices, then progress to harder competitions\\nEssential Algorithms Deep Dive\\nLinear/Logistic Regression\\nDecision Trees and Random Forests\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 2, 'page_label': '3', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Unsupervised Learning\\nModel Evaluation\\nAndrej Karpathy\\'s \"Neural Networks: Zero to Hero\"\\n3Blue1Brown Neural Network Series\\nAndrew Ng\\'s Deep Learning Specialization\\nSupport Vector Machines\\nk-Nearest Neighbors\\nk-Means Clustering\\nPrincipal Component Analysis \\x00PCA\\x00\\nAnomaly Detection\\nCross-validation techniques\\nPrecision, recall, F1-score\\nROC curves and AUC\\nResource: scikit-learn documentation + hands-on practice\\x002\\x00\\nPhase 3\\x00 Deep Learning Revolution \\x00Months 5\\x006\\x00\\nNeural Networks from First Principles\\n\\x009\\x00\\x0010\\x00\\x0011\\x00\\nWhy it\\'s invaluable: Learn by building everything from scratch in code\\nMost critical sections:\\nMicrograd: Build an autograd engine (understand backpropagation deeply)\\nBuilding GPT from scratch: Modern transformer implementation\\nPyTorch internals: How frameworks actually work\\nUnique value: Unlike other courses, this shows you the \"magic\" behind the frameworks\\x0012\\x00\\n\\x0013\\x00\\x0014\\x00\\x003\\x00\\nWhy it\\'s essential: Visual intuition for mathematical concepts\\nMost valuable videos:\\n\"But what is a neural network?\"—conceptual foundation\\n\"Gradient descent\"—optimization visualization\\n\"Backpropagation\"—the learning algorithm\\nKey benefit: You\\'ll develop intuitive understanding alongside mathematical rigor\\n\\x007\\x00\\x006\\x00\\nCourse 1: Neural Networks and Deep Learning\\nCourse 2: Improving Deep Neural Networks (regularization, optimization)\\nCourse 3: Structuring Machine Learning Projects\\nCourse 4: Convolutional Neural Networks'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 3, 'page_label': '4', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Stanford CS231n: Convolutional Neural Networks\\nFast.ai Practical Deep Learning for Coders\\nHugging Face Course\\nAttention Mechanisms & Transformers\\nCourse 5: Sequence Models\\nWhy it works: Systematic progression from basics to advanced topics\\x008\\x00\\nComputer Vision Mastery\\n\\x0015\\x00\\x0016\\x00\\x0017\\x00\\nWhy it's legendary: Gold standard for computer vision education\\nMost valuable lectures:\\nCNN architectures \\x00AlexNet, VGGNet, ResNet)\\nTransfer learning and fine-tuning\\nObject detection and segmentation\\nAssignments: Build CNNs from scratch, implement backpropagation\\nCareer impact: Many top AI engineers cite this course as transformative\\x0015\\x00\\nPractical Implementation\\n\\x0018\\x00\\x0019\\x00\\x0020\\x00\\x0021\\x00\\nWhy it's revolutionary: Top-down approach—build real applications first\\nMost valuable aspects:\\nDeploy a working model by lesson 2\\nTransfer learning techniques\\nData augmentation strategies\\nProduction deployment methods\\nPhilosophy: Learn by doing, theory follows practice\\x0020\\x00\\nOutcome: You'll be building and deploying real AI applications quickly\\nPhase 4\\x00 Modern AI Systems \\x00Months 7\\x008\\x00\\nLarge Language Models & NLP\\n\\x0022\\x00\\x0023\\x00\\x0024\\x00\\x0025\\x00\\nWhy it's crucial: Industry-standard library for NLP\\nMost valuable sections:\\nChapters 1\\x004: Transformer architecture deep dive\\nChapters 5\\x008: Fine-tuning and tokenization\\nChapters 9\\x0012: Advanced LLM techniques\\nPractical value: You'll learn to work with GPT, BERT, T5, and other SOTA models\\x0022\\x00\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 4, 'page_label': '5', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Building RAG Applications\\nAdvanced RAG Techniques\\nModel Deployment & Monitoring\\nScaling AI Systems\\nComputer Vision Advanced Topics\\n\"Attention Is All You Need\" paper: The foundational research\\nIllustrated Transformer blog post: Visual explanation\\nImplementation: Build a transformer from scratch (following Karpathy\\'s tutorial)\\nGenerative AI & RAG Systems\\n\\x001\\x00\\nLangChain documentation: Framework for LLM applications\\nVector databases: Pinecone, Chroma, Weaviate\\nEmbedding models: OpenAI, Sentence-BERT, instructor-xl\\nReal projects: Build document Q&A, code assistant, research tool\\nAgentic RAG: Multi-step reasoning and tool use\\nRAG optimization: Chunking strategies, retrieval improvement\\nProduction deployment: FastAPI, Docker, cloud platforms\\nPhase 5\\x00 Advanced AI Engineering \\x00Months 9\\x0012\\x00\\nMLOps & Production Systems\\nDocker containerization: Reproducible environments\\nAPI development: FastAPI, Flask\\nCloud platforms: AWS SageMaker, Google Cloud AI, Azure ML\\nModel monitoring: Data drift, performance degradation\\nCI/CD for ML: GitHub Actions, model versioning\\nDistributed training: Multi-GPU, multi-node\\nModel optimization: Quantization, pruning, distillation\\nInference optimization: TensorRT, ONNX, TorchScript\\nResource: MLOps Specialization (DeepLearning.AI)\\nSpecialized Domains\\nObject detection: YOLO, R\\x00CNN family\\nSegmentation: U\\x00Net, Mask R\\x00CNN'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Reinforcement Learning\\nAndrew Ng's Courses (DeepLearning.AI)\\nAndrej Karpathy's Neural Networks: Zero to Hero\\nFast.ai Practical Deep Learning\\nStanford CS231n\\nHugging Face Course\\nGenerative models: GANs, Diffusion models\\nResource: CS231n advanced lectures + papers\\nOpenAI Gymnasium: RL environments\\nDeep Q\\x00Networks \\x00DQN\\x00: Value-based methods\\nPolicy gradients: Actor-critic methods\\nResource: Spinning Up in Deep RL \\x00OpenAI\\x00\\nCritical Learning Resources & Their Value\\nTier 1\\x00 Absolutely Essential\\n\\x006\\x00\\x008\\x00\\nValue: Systematic, rigorous, practical\\nBest for: Building strong fundamentals\\nInvestment: $49/month, worth every penny\\nCareer impact: 9/10\\n\\x0010\\x00\\x009\\x00\\nValue: Unparalleled depth and clarity\\nBest for: Understanding how things actually work\\nInvestment: Free on YouTube\\nCareer impact: 10/10\\n\\x0021\\x00\\x0018\\x00\\nValue: Rapid practical skills development\\nBest for: Building real applications quickly\\nInvestment: Free\\nCareer impact: 9/10\\nTier 2\\x00 Highly Valuable\\n\\x0017\\x00\\x0015\\x00\\nValue: Academic rigor meets practical application\\nBest for: Computer vision specialization\\nInvestment: Free (auditing), challenging time commitment\\nCareer impact: 8/10\\n\\x0022\\x00\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 6, 'page_label': '7', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='3Blue1Brown Visual Series\\nGoogle AI Course \\x00Coursera)\\nIBM AI Foundations\\nValue: Industry-standard NLP skills\\nBest for: Modern NLP applications\\nInvestment: Free\\nCareer impact: 8/10\\n\\x0013\\x00\\x003\\x00\\nValue: Intuitive mathematical understanding\\nBest for: Building deep conceptual knowledge\\nInvestment: Free on YouTube\\nCareer impact: 7/10\\nTier 3\\x00 Supplementary\\n\\x0026\\x00\\nValue: Broad overview, less depth\\nBest for: Business understanding of AI\\nCareer impact: 6/10\\n\\x0027\\x00\\nValue: Beginner-friendly introduction\\nBest for: Absolute beginners\\nCareer impact: 5/10\\nHands-On Project Progression\\nMonths 1\\x002\\x00 Foundation Projects\\n\\x00\\x00\\x00Data Analysis Portfolio: Analyze 3 different datasets with pandas/matplotlib\\n\\x00\\x00\\x00Web Scraping Bot: Extract and analyze web data\\n\\x00\\x00\\x00Statistical Analysis: A/B testing, hypothesis testing\\nMonths 3\\x004\\x00 Machine Learning Projects\\n\\x00\\x00\\x00Prediction Model: House price prediction with feature engineering\\n\\x00\\x00\\x00Classification System: Customer churn prediction\\n\\x00\\x00\\x00Clustering Analysis: Customer segmentation\\n\\x00\\x00\\x00End-to-end ML Pipeline: Data →  Model →  Deployment'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 7, 'page_label': '8', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Months 5\\x006\\x00 Deep Learning Applications\\n\\x00\\x00\\x00Image Classifier: Custom CNN for your domain of interest\\n\\x00\\x00\\x00Text Sentiment Analyzer: RNN/LSTM for sentiment analysis\\n\\x00\\x00\\x00Recommender System: Collaborative filtering with neural networks\\n\\x00\\x00\\x00Transfer Learning Project: Fine-tune pre-trained models\\nMonths 7\\x008\\x00 Modern AI Systems\\n\\x00\\x00\\x00RAG Chatbot: Document Q&A system with vector database\\n\\x00\\x00\\x00Code Assistant: LLM-powered programming helper\\n\\x00\\x00\\x00Multi-modal Application: Text + image processing\\n\\x00\\x00\\x00API Service: Deploy models as production APIs\\nMonths 9\\x0012\\x00 Advanced Projects\\n\\x00\\x00\\x00Distributed Training: Scale model training across multiple GPUs\\n\\x00\\x00\\x00Model Optimization: Quantize and optimize for mobile/edge\\n\\x00\\x00\\x00MLOps Pipeline: Complete CI/CD for ML models\\n\\x00\\x00\\x00Research Project: Implement and improve a recent paper\\nLearning Strategy & Best Practices\\nThe 80/20 Approach\\n80% hands-on coding: Build, experiment, break things\\n20% theory: Understand the \"why\" behind the \"how\"\\nActive learning: Don\\'t just watch videos—implement everything\\nCommunity & Networking\\nDiscord communities: Join course-specific Discord servers\\nGitHub contributions: Build a strong portfolio of projects\\nKaggle competitions: Practice on real datasets\\nTwitter/LinkedIn: Follow AI researchers and practitioners\\nLocal meetups: Connect with other learners\\nCommon Pitfalls to Avoid\\n\\x00\\x00\\x00Tutorial Hell: Don\\'t just consume content—create projects\\n\\x00\\x00\\x00Perfectionism: Start building before you feel \"ready\"\\n\\x00\\x00\\x00Skipping Math: Mathematical understanding accelerates learning'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 8, 'page_label': '9', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"The AI field moves incredibly fast, but these fundamentals will serve you for decades. Focus on\\ndepth over breadth, build constantly, and remember that every expert was once a beginner. The\\ntools and frameworks will change, but the mathematical foundations and problem-solving\\napproaches you learn here will make you adaptable to any future AI development.\\nThis roadmap has been battle-tested by thousands of successful AI engineers. Trust the\\nprocess, stay consistent, and you'll be amazed at what you can build in just one year. The AI\\n\\x00\\x00\\x00Isolation: Learn with others, ask questions, share progress\\n\\x00\\x00\\x00Following Trends: Focus on fundamentals over flashy new techniques\\nTimeline & Milestones\\nMonth 3 Milestone: Machine Learning Practitioner\\nBuild and deploy a simple ML model\\nUnderstand bias-variance tradeoff\\nKnow when to use different algorithms\\nMonth 6 Milestone: Deep Learning Engineer\\nImplement neural networks from scratch\\nBuild computer vision applications\\nUnderstand modern architectures \\x00CNNs, RNNs, Transformers)\\nMonth 9 Milestone: AI Application Developer\\nBuild LLM-powered applications\\nWork with vector databases and RAG systems\\nDeploy models to production\\nMonth 12 Milestone: Senior AI Engineer\\nDesign end-to-end AI systems\\nOptimize models for production\\nContribute to open source projects\\nReady for senior AI engineering roles\\nYour Next Steps\\n\\x00\\x00\\x00Week 1: Set up your development environment \\x00Python, Jupyter, Git)\\n\\x00\\x00\\x00Week 2: Start Andrew Ng's Machine Learning Course\\n\\x00\\x00\\x00Week 3: Begin your first project while following the course\\n\\x00\\x00\\x00Week 4: Join relevant Discord communities and start networking\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"revolution is just beginning, and there's never been a better time to join it.\\n⁂\\n\\x00\\x00\\x00https://github.com/krishnaik06/Complete-RoadMap-To-Learn-AI\\n\\x00\\x00\\x00https://www.geeksforgeeks.org/blogs/machine-learning-roadmap/\\n\\x00\\x00\\x00https://www.3blue1brown.com/lessons/neural-networks\\n\\x00\\x00\\x00https://www.3blue1brown.com/topics/neural-networks\\n\\x00\\x00\\x00https://github.com/aadi1011/AI\\x00ML\\x00Roadmap-from-scratch\\n\\x00\\x00\\x00https://www.coursera.org/specializations/deep-learning\\n\\x00\\x00\\x00https://www.coursera.org/courses?query=machine+learning+andrew+ng\\n\\x00\\x00\\x00https://www.learndatasci.com/best-artificial-intelligence-ai-courses/\\n\\x00\\x00\\x00https://karpathy.ai/zero-to-hero.html\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=VMj-3S1tku0\\n\\x00\\x00\\x00\\x00https://briansigafoos.com/neural-networks-karpathy/\\n\\x00\\x00\\x00\\x00https://www.linkedin.com/posts/sumanth077_neural-networks-zero-to-hero-by-andrej-karpathy-activit\\ny-7366011507102400512-dg3x\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=aircAruvnKk&vl=en\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=IHZwWFHWa-w\\n\\x00\\x00\\x00\\x00https://www.machinelearningmastery.com/stanford-convolutional-neural-networks-for-visual-recogniti\\non-course-review/\\n\\x00\\x00\\x00\\x00https://cs231n.stanford.edu/slides/2025/lecture_1_part_2.pdf\\n\\x00\\x00\\x00\\x00https://cs231n.github.io\\n\\x00\\x00\\x00\\x00https://www.fast.ai/posts/2022\\x0007\\x0021-dl-coders-22.html\\n\\x00\\x00\\x00\\x00https://towardsai.net/p/l/7-lessons-from-fast-ai-deep-learning-course\\n\\x00\\x00\\x00\\x00https://www.machinelearningmastery.com/practical-deep-learning-for-coders-review/\\n\\x00\\x00\\x00\\x00https://course.fast.ai\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/chapter1/1\\n\\x00\\x00\\x00\\x00https://wandb.ai/int_pb/huggingface/reports/An-Introduction-To-HuggingFace-Transformers-for-NLP\\x00-\\nVmlldzoyOTgzMjI5\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/5\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/4\\n\\x00\\x00\\x00\\x00https://www.digitalocean.com/resources/articles/ai-courses\\n\\x00\\x00\\x00\\x00https://zapier.com/blog/best-ai-courses/\\n\\x00\\x00\\x00\\x00https://www.geeksforgeeks.org/blogs/deep-learning-roadmap/\\n\\x00\\x00\\x00\\x00https://www.v7labs.com/blog/deep-learning-guide\\n\\x00\\x00\\x00\\x00https://www.coursera.org/courses?query=artificial+intelligence\\n\\x00\\x00\\x00\\x00https://magnimindacademy.com/blog/deep-learning-structure-guide-for-beginners/\\n\\x00\\x00\\x00\\x00https://roadmap.sh/ai-engineer\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=PUlSon0DIus\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 10, 'page_label': '11', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x00\\x00\\x00\\x00https://cognitiveclass.ai/learn/deep-learning\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=7IgVGSaQPaw\\n\\x00\\x00\\x00\\x00https://grow.google/ai/\\n\\x00\\x00\\x00\\x00https://www.kaggle.com/learn/intro-to-deep-learning\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/learnmachinelearning/comments/1lbs4qi/a_clear_roadmap_to_complete_learni\\nng_aiml_by_the/\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/learnmachinelearning/comments/1j5trra/best_resources_to_learn_pytorch_in_2\\n025/\\n\\x00\\x00\\x00\\x00https://www.geeksforgeeks.org/deep-learning/introduction-deep-learning/\\n\\x00\\x00\\x00\\x00https://www.aimlengineer.io/p/breaking-into-aiml-in-2025-a-step\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/learnmachinelearning/comments/w4\\x00626/the_new_version_of_fastais_practic\\nal_deep/\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/3\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/ai-for-everyone/\\n\\x00\\x00\\x00\\x00https://course.fast.ai/Resources/testimonials.html\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/2\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/generative-ai-for-everyone/\\n\\x00\\x00\\x00\\x00https://news.ycombinator.com/item?id=32186647\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/deeplearning/comments/1dqkqhd/does_andrej_karpathys_neural_networks_z\\nero_to/\\n\\x00\\x00\\x00\\x00https://cs231n.stanford.edu\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=2fq9wYslV0A\\n\\x00\\x00\\x00\\x00https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB\\x003pi\\n\\x00\\x00\\x00\\x00https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ\\n\\x00\\x00\\x00\\x00https://cs231n.stanford.edu/project.html\\n\\x00\\x00\\x00\\x00https://www.youtube.com/c/3blue1brown\\n\\x00\\x00\\x00\\x00http://karpathy.github.io/neuralnets/\\n\\x00\\x00\\x00\\x00https://www.youtube.com/playlist?list=PLoROMvodv4rOmsNzYBMe0gJY2XS8AQg16')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e4d1a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text Splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split Resumes into smaller chunks for better performance\"\"\"\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\",\"\\n\",\" \",\"\"]\n",
    "\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content : {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "012b5003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 82 documents into 359 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content : 12-Month Roadmap to Become a Production-Ready\n",
      "AI Engineer (Agentic AI Specialization)\n",
      "Overview: This roadmap is tailored for Yash – a 4th-year ECE student with basic Python, math, and ML\n",
      "knowledge – t...\n",
      "Metadata: {'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='12-Month Roadmap to Become a Production-Ready\\nAI Engineer (Agentic AI Specialization)\\nOverview: This roadmap is tailored for Yash – a 4th-year ECE student with basic Python, math, and ML\\nknowledge – to transform into a production-ready AI Engineer specialized in Agentic AI over 12 months.\\nYash  will  dedicate  ~8  hours  daily.  The  plan  is  divided  into  monthly  phases  with  clear  goals,  hands-on\\nprojects,  and  curated  resources.  To  minimize  dropout  risk,  we  emphasize  project-based  learning and\\nspaced repetition (regularly revisiting past concepts) to reinforce knowledge. By the end, Yash will have a\\nstrong portfolio (GitHub projects and YouTube content on his channel “Engimemer”) demonstrating skills in\\nbuilding agent-based AI applications (AutoGPT-like systems) and the confidence to pursue FAANG-level\\nroles or AI freelancing.\\nMonth 1: Foundations – Python Mastery & Math Refresher\\nFocus: Build a strong foundation in programming and mathematics for AI.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='roles or AI freelancing.\\nMonth 1: Foundations – Python Mastery & Math Refresher\\nFocus: Build a strong foundation in programming and mathematics for AI.\\nKey Learning Goals: Solidify intermediate Python skills and refresh essential math for ML.\\nSpecifically, master Python language constructs (functions, OOP) and data handling libraries, and\\nreview linear algebra (vectors, matrices, eigenvalues), basic calculus (derivatives, gradients), and\\nprobability/statistics (mean, variance, Bayes’ theorem). \\nCore Concepts & Tools: Python best practices (writing clean, efficient code); using Jupyter/VS Code\\nand Google Colab for experiments; NumPy for matrix operations, Pandas for data manipulation,\\nMatplotlib/Seaborn for plotting. Math concepts like matrix multiplication, differentiation (for\\ngradient descent), and statistical thinking for data analysis. \\nBest Resources:\\nPython: “Automate the Boring Stuff” (for practice scripts) and Real Python tutorials on OOP .'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='gradient descent), and statistical thinking for data analysis. \\nBest Resources:\\nPython: “Automate the Boring Stuff” (for practice scripts) and Real Python tutorials on OOP . \\nMath: Khan Academy or Mathematics for Machine Learning (online book) for linear algebra &\\ncalculus refresh. \\nStatQuest (YouTube) – excellent simple videos on stats and linear algebra concepts (e.g. StatQuest’s\\nlinear regression, PCA videos). \\nfast.ai’s optional math review sections or Gilbert Strang’s MIT lectures for linear algebra (if deeper\\ndive needed). \\nProjects & Portfolio:\\nCode a simple linear regression from scratch (no ML libraries) to predict a small dataset (e.g.\\nhouse prices). This solidifies math-programming synergy. Visualize the fit line and error\\nconvergence. Publish this on GitHub. \\nYouTube Opportunity: Create a vlog-style video explaining how linear regression works and walking\\nthrough your implementation. This helps cement your understanding and kicks off your Engimemer\\nchannel content.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='through your implementation. This helps cement your understanding and kicks off your Engimemer\\nchannel content. \\nSpaced Repetition: Start making flashcards or notes for key formulas (e.g. matrix operations,\\nderivative rules). Review these weekly to build long-term retention.\\n• \\n1\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n1'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Month 2: Machine Learning Basics – Models & Pipeline\\nFocus: Grasp classic ML algorithms and the end-to-end ML workflow by building your first ML projects.\\nKey Learning Goals: Understand the ML pipeline: data preprocessing, feature engineering, model\\ntraining, evaluation, and iteration. Learn core algorithms in supervised learning (regression,\\nclassification) and unsupervised learning. Key topics include train/test splits, overfitting vs.\\ngeneralization, and performance metrics. \\nCore Concepts & Tools: Supervised vs. unsupervised learning; algorithms like linear & logistic\\nregression, decision trees, k-NN, SVMs for basics; clustering (k-means, DBSCAN) for\\nunsupervised. Tools: scikit-learn (implementing algorithms and pipeline), pandas for data cleaning,\\nand matplotlib for result visualization. Also introduce version control (Git/GitHub) to manage code. \\nBest Resources:\\nAndrew Ng’s Machine Learning Specialization (Coursera) – covers regression, classification,'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Best Resources:\\nAndrew Ng’s Machine Learning Specialization (Coursera) – covers regression, classification,\\nclustering, etc., providing a solid theoretical grounding. \\nHands-On Machine Learning with Scikit-Learn & TensorFlow (Aurélien Géron) – a practical book\\nto reference implementations and tips. \\nStatQuest – continue using videos for intuitions on algorithms (e.g. StatQuest’s decision tree and\\nPCA videos). \\nscikit-learn docs & tutorials – to learn API usage for training models and evaluating them. \\nProjects & Portfolio:\\nEnd-to-End ML Project: Pick a simple dataset (e.g. Titanic survival or California housing prices).\\nPerform data cleaning, exploratory analysis (visualize key patterns), then train a model (e.g. logistic\\nregression or decision tree). Evaluate with appropriate metrics (accuracy for classification or RMSE\\nfor regression). Finally, deploy this as a simple app – e.g., a Streamlit or Gradio web app where a'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='for regression). Finally, deploy this as a simple app – e.g., a Streamlit or Gradio web app where a\\nuser can input features and get a prediction. This exposes you to the full lifecycle. \\nOptionally, tackle a second project focusing on unsupervised learning (e.g. use k-means to cluster a\\ndataset and visualize results) to appreciate different ML paradigms. \\nYouTube Opportunity: Create a tutorial video “How I built my first ML model to predict Titanic\\nsurvivors” – show data exploration, model intuition, and a live demo of your app. This not only builds\\nyour portfolio but also reinforces your understanding by teaching it. \\nSpaced Repetition: Continue weekly reviews of last month’s math (e.g., quiz yourself on what\\noverfitting means or the formula for linear regression). Also begin a habit of summarizing each\\ncompleted project’s learning points and revisiting them later .\\nMonth 3: Deep Learning Fundamentals – Neural Networks from\\nScratch'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='completed project’s learning points and revisiting them later .\\nMonth 3: Deep Learning Fundamentals – Neural Networks from\\nScratch\\nFocus: Dive into deep learning basics, learning how neural networks work and training simple networks.\\nKey Learning Goals: Build intuition for neural networks (why and how they learn). Key concepts\\ninclude the perceptron, activation functions (ReLU, sigmoid), forward and backward propagation,\\nloss functions (e.g. cross-entropy), and optimizers like SGD/Adam. By month’s end, you should be\\nable to implement and train a basic neural network and understand the math of backpropagation. \\nCore Concepts & Tools: Neural network architecture (layers, weights, biases), gradient descent and\\nhow gradients are used to update weights, problems like vanishing gradients. Frameworks: PyTorch\\n• \\n2\\n• \\n3\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n2\\n• \\n• \\n• \\n• \\n4\\n• \\n2'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='or TensorFlow – choose one (PyTorch is popular in research/startups, so you might start there). Also\\nfamiliarize with Keras (which can be used via TensorFlow) for quick prototyping. Tools: Google\\nColab for GPU access (since training even simple networks will be faster with a GPU – start utilizing\\nfree Colab GPUs). \\nBest Resources:\\nDeepLearning.AI’s Deep Neural Networks (Andrew Ng) – part of the Deep Learning Specialization,\\nit covers forward/backprop in detail and is math-friendly. \\nfast.ai – Practical Deep Learning for Coders (Part 1) – a top-down approach: you start training\\nstate-of-the-art models (with less math), which can be motivating. Fast.ai’s course is very hands-on\\nand emphasizes experimentation first, aligning well with our project-based philosophy (Hugging\\nFace even recommends doing an intro DL course like fast.ai or DeepLearning.AI before advanced\\ntopics). \\nAndrej Karpathy’s “Neural Networks: Zero to Hero” (YouTube) – Karpathy builds neural nets and'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Face even recommends doing an intro DL course like fast.ai or DeepLearning.AI before advanced\\ntopics). \\nAndrej Karpathy’s “Neural Networks: Zero to Hero” (YouTube) – Karpathy builds neural nets and\\na mini-GPT from scratch in code. The early videos (micrograd, makemore series) are excellent to see\\nbackpropagation and training loop coded line-by-line. This can deeply solidify your\\nunderstanding of how everything works under the hood. \\nPyTorch official tutorials – to learn the basics of tensor operations and autograd, once you grasp\\nthe manual concepts. \\nProjects & Portfolio:\\nNeural Net from Scratch: Implement a simple multilayer perceptron using only NumPy (no high-\\nlevel library) to classify a small dataset (e.g. classify handwritten digits 0–9 from the MNIST dataset).\\nThis means coding the forward pass and backpropagation manually. It’s challenging, but doing this\\nfor even a small network (e.g. one hidden layer) will cement your understanding of how gradients\\nflow.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='for even a small network (e.g. one hidden layer) will cement your understanding of how gradients\\nflow. \\nDeep Learning Project: Using a framework (PyTorch/Keras), train a feed-forward neural network on\\nMNIST or a similar dataset. Aim for good accuracy on validation data. This lets you focus on\\nusing library components (layers, loss functions, optimizers) now that you understand what they do.\\nSave this project to GitHub, including instructions to run it on Colab (since you may not have a local\\nGPU). \\nYouTube Opportunity: Create a video titled “I built a neural network from scratch in Python” –\\nexplain the concept of backpropagation in simple terms and demo your NumPy network learning to\\nrecognize digits. This not only advertises your skill but also helps you review the concept by teaching\\nit. \\nSpaced Repetition: This month introduces many new concepts – make flashcards for definitions\\n(e.g. “What is an activation function? Give examples.” or “What does the derivative of ReLU look'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='it. \\nSpaced Repetition: This month introduces many new concepts – make flashcards for definitions\\n(e.g. “What is an activation function? Give examples.” or “What does the derivative of ReLU look\\nlike?”). Revisit your math cards from prior months to keep the fundamentals fresh, since deep\\nlearning heavily uses them (e.g., understanding gradients).\\nMonth 4: Deep Learning Expanded – Computer Vision and/or NLP\\nBasics\\nFocus: Broaden your deep learning skills to new data types. You can split this month between Computer\\nVision (CNNs)  and  Natural  Language  Processing (RNNs/transformers  basics),  or  focus  more  on  one\\n5\\n• \\n• \\n• \\n6\\n• \\n7 8\\n• \\n• \\n• \\n• \\n9\\n• \\n• \\n3'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='domain based on interest. Given the end-goal of agentic AI (which leans toward NLP/LLMs), prioritize NLP if\\nneeded, but a taste of CV will make you well-rounded.\\nKey Learning Goals (CV): Understand Convolutional Neural Networks (CNNs) for image data –\\nconvolution/pooling operations, architectures like LeNet/ResNet, and why CNNs excel in vision tasks\\n. Learn about using pretrained models and transfer learning (e.g. using a pretrained ResNet on a\\nnew small image dataset). \\nKey Learning Goals (NLP): Understand basics of text representation – text preprocessing\\n(tokenization, embeddings like word2vec), and how sequence models work. Recurrent Neural\\nNetworks (RNNs) and LSTMs were traditional approaches; understand their role and limitations (e.g.\\nvanishing gradients in long sequences). Introduce the concept of the Transformer architecture,\\nwhich overcomes those limitations and forms the backbone of modern LLMs. By the end, you'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='vanishing gradients in long sequences). Introduce the concept of the Transformer architecture,\\nwhich overcomes those limitations and forms the backbone of modern LLMs. By the end, you\\nshould grasp why transformers replaced RNNs for NLP , even if you don’t deeply train an RNN. \\nCore Concepts & Tools:\\nCV: Convolutions, filters/kernels, feature maps, common CNN layers. Tools: PyTorch/TensorFlow\\nwith CNN modules (e.g. torchvision for datasets and pretrained models). Possibly experiment\\nwith OpenCV for basic image processing to augment understanding. \\nNLP: Text cleaning (stopwords, stemming – though less needed with modern models), word\\nembeddings (learn what they are conceptually), sequence modeling. Tools: experiment with a simple\\nRNN using Keras or PyTorch’s nn.LSTM. Also introduce Hugging Face Transformers library at a\\nhigh level – for example, try using a pre-trained BERT or GPT-2 model for a simple task to see the\\ntransformer in action (more on this next month). \\nBest Resources:'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='high level – for example, try using a pre-trained BERT or GPT-2 model for a simple task to see the\\ntransformer in action (more on this next month). \\nBest Resources:\\nDeepLearning.AI’s courses on CNNs and Sequence Models (Andrew Ng) – these provide a solid\\nbase in each domain (CNN course covers ConvNet architectures, Sequence course covers RNN,\\nLSTM, and an intro to attention mechanism). If pressed for time, focus on sequence models because\\nLLMs/Agentic AI will build on that. \\nfast.ai Course (if following) – fast.ai’s early lessons cover CNNs for image classification in a very\\nhands-on way (you build an image classifier in Lesson 1 itself with transfer learning). This is\\nmotivating and teaches practical tips. They also cover an NLP segment where you fine-tune an AWD-\\nLSTM on text – insightful even if LSTMs are now older , because it teaches how to handle text data. \\nStanford CS231n (for CV) – lecture videos or notes (if you want deeper theoretical knowledge of\\nCNNs and vision tasks).'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Stanford CS231n (for CV) – lecture videos or notes (if you want deeper theoretical knowledge of\\nCNNs and vision tasks). \\nStanford CS224n (for NLP) – lectures on NLP and transformers by leading researchers (good to\\ndeepen theory behind attention and transformers). \\nYouTube: 3Blue1Brown’s video “But what is a convolution?” (for an intuitive visualization), and\\nStatQuest’s “RNNs and LSTMs” for simple explanations of these concepts. \\nProjects & Portfolio:\\nComputer Vision Project: Build and deploy a simple image classifier. For example, collect or use a\\ndataset of, say, plant diseases or traffic signs (something small). Train a CNN to categorize images. If\\nusing a small dataset, apply transfer learning with a pretrained model (e.g., fine-tune ResNet on your\\ndataset) – a valuable real-world skill. Aim to achieve decent accuracy, and deploy this model as a web\\ndemo (perhaps on Hugging Face Spaces or a simple Flask app). This demonstrates the ability to\\napply deep learning to real data.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='demo (perhaps on Hugging Face Spaces or a simple Flask app). This demonstrates the ability to\\napply deep learning to real data. \\nNLP Project: Build a text classifier or chatbot. For instance, create a sentiment analysis model for\\nmovie reviews. You could fine-tune a pre-trained transformer (like DistilBERT) on a movie reviews\\ndataset to classify sentiment. This will expose you to the Hugging Face ecosystem and transformer\\n• \\n10\\n• \\n11\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n4'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='fine-tuning in practice. (If computing resources are an issue, use Google Colab with free GPU for\\ntraining, or choose a smaller model and smaller dataset to fine-tune.) By now, you may start\\nChapter 1–4 of Hugging Face’s free Transformers course, which walks through using pre-trained\\nmodels and fine-tuning – it’s a great guided project that will result in a model you can share on\\nHugging Face Hub. \\nYouTube Opportunity: For the CV project, make a video like “Building an AI that recognizes plant\\ndiseases” – show how you collected data and how the CNN performs (people love visual demos). For\\nthe NLP project, consider a video titled “Fine-tuning my first Transformer model” – explain in simple\\nterms what BERT is doing and show your model in action. These not only market your skills but also\\nforce you to articulate complex concepts clearly. \\nSpaced Repetition: This is a content-heavy month. Leverage spaced repetition by frequently'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='force you to articulate complex concepts clearly. \\nSpaced Repetition: This is a content-heavy month. Leverage spaced repetition by frequently\\nrevisiting earlier lessons – e.g., when learning transformers, recall how an RNN works and how a\\nCNN works; this comparative thinking reinforces memory. Quiz yourself: “Why might an LSTM be\\ninsufficient for long text?” or “What does a convolution filter do?”. Also keep using your Anki/flashcards\\nfor math and DL basics (the cumulative knowledge will soon be applied in building LLM-based\\nagents).\\nMonth 5: Mastering Transformers – Hugging Face and LLMs\\nFocus: Deep dive into transformers and large language models (LLMs), and become proficient with the\\nHugging  Face  ecosystem  for  NLP .  This  month  transitions  from  traditional  ML/DL  into  the  realm  of\\ngenerative AI and LLMs, which is core for agentic AI. \\nKey Learning Goals: Gain a solid understanding of how Transformer architectures work (self-'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='generative AI and LLMs, which is core for agentic AI. \\nKey Learning Goals: Gain a solid understanding of how Transformer architectures work (self-\\nattention mechanism, encoder-decoder vs decoder-only models), and how modern LLMs (GPT, BERT,\\netc.) are built on these principles. Learn to use pre-trained LLMs from Hugging Face for various tasks\\nand fine-tune them on custom data. By the end of the month, you should comfortably load a model\\nfrom Hugging Face Hub, use it for inference (text generation, classification, etc.), and know the\\nworkflow for fine-tuning a model on a new dataset. \\nCore Concepts & Tools: Transformers theory (multi-head attention, positional embeddings, etc.),\\ndifferences between model types (e.g. BERT is an encoder-only transformer good for understanding\\ntasks, GPT-3 is decoder-only, etc.), the concept of transfer learning in NLP (pretrain on large corpus,\\nfine-tune on task). Tools: Hugging Face Transformers library (APIs like AutoModel,'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='tasks, GPT-3 is decoder-only, etc.), the concept of transfer learning in NLP (pretrain on large corpus,\\nfine-tune on task). Tools: Hugging Face Transformers library (APIs like AutoModel, \\nAutoTokenizer), Hugging Face Datasets (to load common NLP datasets easily), and using \\nHugging Face Hub to find and use community models. If resources allow, familiarize with Google\\nColab Pro or Kaggle Kernels for longer training jobs. Also, practice using Git and GitHub more as\\nyou handle larger code/projects – this is part of being production-ready. \\nBest Resources:\\nThe Hugging Face Course (Transformers) – complete this course this month. It’s free and covers\\nusing Transformers, fine-tuning, and even deploying models. Chapters 1-8 will teach you how to\\nload models, tokenize data, fine-tune on a dataset, and share your model. (Chapters 9+ go into\\nbuilding demos and advanced topics – which you will find useful for sharing your work and for next'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='load models, tokenize data, fine-tune on a dataset, and share your model. (Chapters 9+ go into\\nbuilding demos and advanced topics – which you will find useful for sharing your work and for next\\nmonth’s advanced LLM techniques.) This course is highly recommended as it’s hands-on and up-to-\\ndate with the latest Hugging Face tools, which are industry-standard. \\nAnnotated Transformer (blog or video by Harvard NLP) – for an in-depth look at the original\\nTransformer model “Attention is All You Need”. This can solidify your theoretical understanding. \\n12\\n• \\n• \\n• \\n• \\n• \\n• \\n12\\n• \\n5'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content=\"Andrej Karpathy’s “Let's build GPT” video – if you haven’t already, watch Karpathy’s video where he\\nlive-codes a GPT-like mini model. It’s a fantastic way to see how pieces of a transformer\\n(tokenization, self-attention, etc.) come together in code. This can be dense, but it connects theory to\\nimplementation. \\nYouTube & Blogs: Look up “Transformers from scratch” by Jay Alammar (famous visual illustrations\\nof how transformer attention works) and Simplilearn or StatQuest summaries on transformers for\\nintuitive explanations. Also consider the Hugging Face YouTube channel – they often have videos\\nfor beginners on using their library. \\nProjects & Portfolio:\\nFine-tune an LLM: Choose a task and fine-tune a pre-trained transformer on it. For example, create\\na Question-Answering system on a niche dataset: use Hugging Face to fine-tune a smaller model\\n(like DistilBERT or RoBERTa) on a QA dataset (SQuAD or a custom set of Q&A pairs you prepare). This\"),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='a Question-Answering system on a niche dataset: use Hugging Face to fine-tune a smaller model\\n(like DistilBERT or RoBERTa) on a QA dataset (SQuAD or a custom set of Q&A pairs you prepare). This\\nteaches you the end-to-end of customizing an LLM. After fine-tuning, evaluate it and upload your\\nmodel to Hugging Face Hub (so others can see/use it, and you can reference it on your resume). \\nHugging Face’s course actually guides you through such a project, so follow that closely. \\nBuild a Language Generation Demo: Using an open-source language model (like GPT-2 or\\nEleutherAI’s GPT-Neo), build a fun demo – e.g., a text generator that completes a sentence or writes\\nshort stories on prompts. You can do this without fine-tuning (just use the pre-trained model with a\\nprompt) or fine-tune it on a specific style (say Shakespearean text) if resources permit. Host this as a\\nHugging Face Space (they support Gradio apps for free) so you have a live demo in your portfolio\\n.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Hugging Face Space (they support Gradio apps for free) so you have a live demo in your portfolio\\n. \\nYouTube Opportunity: Publish a video titled “Fine-tuning a Transformer model (Hugging Face\\nCourse Review)” – share your screen as you walk through the fine-tuning process you did, explaining\\neach step (loading data, training, evaluating). For the generation demo, you could do a creative piece\\nlike “I taught a GPT-2 to write Shakespeare – here’s how!”. These make for engaging content and\\ndemonstrate your practical skills with LLMs. \\nSpaced Repetition: Now that you’re dealing with a lot of new info, use spaced repetition for\\nterminology (e.g., “What is self-attention?”, “What does CLS token mean in BERT?”). Revisit your older\\nflashcards on ML basics – bridging old and new (e.g. compare how a transformer vs a simple neural\\nnet handles inputs). Also, consider writing a weekly summary of what you learned in a short blog or'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='flashcards on ML basics – bridging old and new (e.g. compare how a transformer vs a simple neural\\nnet handles inputs). Also, consider writing a weekly summary of what you learned in a short blog or\\njournal – rephrasing concepts in your own words is a great review technique and can be content for\\nLinkedIn or Medium.\\nMonth 6: Projects & Portfolio Expansion – Applying What You’ve\\nLearned\\nFocus: Consolidate your knowledge by building multiple  portfolio-worthy projects. This month is about\\nlearning by doing – picking projects that integrate the skills from the first half of the year and pushing\\nthem a bit further . By now, you have a range of skills: classical ML, deep learning, and basic LLM usage. It’s\\ntime to showcase them and fill any small gaps in knowledge through practice. \\nKey Learning Goals: Gain confidence in independently scoping and executing AI projects end-to-\\nend. Solidify understanding of the entire workflow: problem formulation, data collection, model'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Key Learning Goals: Gain confidence in independently scoping and executing AI projects end-to-\\nend. Solidify understanding of the entire workflow: problem formulation, data collection, model\\nselection, training, testing, and deployment. Also, learn how to present your projects (readme\\ndocumentation, clean code, brief reports) because employers and freelance clients value clarity. In\\naddition, start exploring Kaggle competitions or AI hackathons to experience real-world problem\\nsolving under constraints, which builds both skill and resume. \\n• \\n13\\n• \\n• \\n• \\n12\\n• \\n14\\n• \\n• \\n• \\n6'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Core Concepts & Tools: End-to-end project development, using mix of techniques (e.g., combining a\\npre-trained model with a custom algorithm). If any tool is still unfamiliar (say you focused on\\nPyTorch, you might try a small TensorFlow/Keras project to be versatile; or if you haven’t touched \\nSQL or data engineering basics, do so now as data handling is crucial in production). Additionally,\\nfamiliarize with basic software engineering practices: writing modular code, using git branches,\\nwriting tests for critical functions – these will elevate your code quality towards production-ready. \\nBest Resources:\\nReddit & Community insights: Browse r/learnmachinelearning and r/MachineLearning for “project\\nideas” threads. The community often shares what’s impactful. Also, review how top Kaggle kernels\\nare written – you’ll learn a lot about clean coding and analysis from them. \\nFull-Stack Deep Learning (fullstackdeeplearning.com) – a course/material that covers the practical'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='are written – you’ll learn a lot about clean coding and analysis from them. \\nFull-Stack Deep Learning (fullstackdeeplearning.com) – a course/material that covers the practical\\naspects of ML projects (like setting up proper experiments, managing data, etc.). Skim relevant\\nsections to get ideas on best practices. \\nCoursera: “AI for Everyone” or “Data Engineering” – not mandatory, but if you feel weak on the\\n“data” side, a quick course or YouTube series on data pipelines, or one on software engineering for\\nML (Google has a free course on ML engineering professionalism) could be beneficial. \\nKaggle’s micro-courses (free) on topics like data cleaning, ML explainability, etc., to fill minor skill\\ngaps while doing projects. \\nProjects & Portfolio:(Aim to complete 2 projects this month, which can be smaller in scope since you’ll\\njuggle multiple.)\\nProject 1 – NLP or CV Application: Build a practical tool, for example an “AI Resume Reviewer.”'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='juggle multiple.)\\nProject 1 – NLP or CV Application: Build a practical tool, for example an “AI Resume Reviewer.”\\nThis could use NLP to parse a resume and give feedback. Concretely: use a spaCy or transformer\\nmodel to extract entities (skills, experience), then some rules/ML model to score or suggest\\nimprovements. This project ties NLP with a real-world use-case and is appealing in a portfolio.\\nAlternatively, build a vision-based tool, e.g., an app that can take a picture of a circuit board and\\nidentify components (leveraging your ECE background) using a trained CNN. Focus on deployability:\\npackage it with a simple UI. \\nProject 2 – Open-Ended Creative Project*: Pick something that excites you – maybe a *generative\\nart or music project using AI, or a chatbot that uses multiple skills (sentiment analysis + response\\ngeneration). The goal is to have fun and be creative, which keeps motivation high. For instance,'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='art or music project using AI, or a chatbot that uses multiple skills (sentiment analysis + response\\ngeneration). The goal is to have fun and be creative, which keeps motivation high. For instance,\\ncreate a chatbot for a specific domain (like a math tutor bot): it might use an LLM for the\\nconversation, but also incorporate a Python-based calculator tool for solving equations (this idea\\nforeshadows agentic AI with tool use). \\nProject 3 (Optional, Hackathon/Kaggle): Participate in a Kaggle competition or an online AI\\nhackathon this month. This will force you to apply your skills under time pressure and teamwork if\\nit’s a team hackathon. Websites like Lablab.ai regularly host GenAI hackathons – joining one\\nfocused on LLMs or agents can give you a taste of building agentic AI in a sprint. Even if you don’t\\nwin, the experience is invaluable and can be mentioned on your resume (“Participated in XYZ\\nHackathon, built a prototype that does …”).'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='win, the experience is invaluable and can be mentioned on your resume (“Participated in XYZ\\nHackathon, built a prototype that does …”). \\nPolish & Presentation: For each project, invest time in making it public-ready: a clean GitHub repo\\nwith a good README (describe the problem, solution, and how to run the code). If possible, deploy\\nthe project (web demo or at least screenshots) and include those in the repo or your portfolio\\nwebsite (if you have one). This will strengthen your profile significantly. \\nYouTube Opportunity: Each project can yield content. For Project 1, you could do a walkthrough\\ntitled “I built an AI Resume Reviewer – Here’s how it works”. For the creative project, maybe a more\\nfun video, “Tour of my AI chatbot that can do math homework!”. Also, consider making a vlog about\\nyour hackathon or Kaggle experience – sharing the approach you took, the mistakes, and lessons\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n15\\n• \\n16\\n• \\n7'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='learned (this humanizes your journey and might resonate with others learning). Regular uploads will\\nsteadily grow your Engimemer channel and also keep you reflecting on your learning. \\nSpaced Repetition: At this midpoint, review everything learned so far in a structured way. Spend a\\nday each week summarizing earlier material: re-derive the formula for backprop, sketch the\\ntransformer architecture from memory, etc. You might even create a “cheat sheet” of key AI concepts\\nlearned in 6 months. This not only helps retention but will be useful in interviews later . Continue\\nusing Anki or your flashcards for any new terms or formulas encountered in projects.\\n(By the end of Month 6, you should have 3-4 solid projects in your portfolio, showcasing different skills – exactly\\nwhat many AI recruiters look for. You’ve also built consistency in learning and doing, which will serve you\\nwell in the next, more specialized phase.)\\nMonth 7: Specialization – Introduction to Agentic AI (LangChain &'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='well in the next, more specialized phase.)\\nMonth 7: Specialization – Introduction to Agentic AI (LangChain &\\nPrompt Engineering)\\nFocus: Enter the world of Agentic AI by learning how LLMs can be used as agents (software programs that\\nperceive, reason, and act). This month, you will learn prompt engineering in depth and start working with\\nframeworks like LangChain that simplify building AI agents. The goal is to understand how to make LLMs\\ndo things – e.g. perform a series of tasks or use external tools – which is the essence of AutoGPT-like\\nsystems.\\nKey Learning Goals: Develop prompt engineering expertise – crafting effective prompts to get\\nreliable outputs from LLMs, and using techniques like few-shot prompting. Understand the concept\\nof an AI agent: an LLM that can take actions (like calling tools or APIs) autonomously based on\\ninstructions. Learn what architectures like AutoGPT or BabyAGI are doing under the hood'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='of an AI agent: an LLM that can take actions (like calling tools or APIs) autonomously based on\\ninstructions. Learn what architectures like AutoGPT or BabyAGI are doing under the hood\\n(planning, tool use, memory) so you can build simpler versions. By end of month, you should be able\\nto create a basic agent that, given a goal, decides on steps and uses some tools to execute them. \\nCore Concepts & Tools: Prompt design principles (clarity, context, constraints). Advanced prompting\\nmethods: e.g., chain-of-thought prompting (getting the LLM to reason step by step) and few-shot\\nexamples to guide style/format. Understand prompt tokens and costs (to be cost-efficient). Tools: \\nOpenAI API (or another LLM API) – practice sending prompts and parsing outputs in code. \\nLangChain – a powerful framework for chaining LLM calls and integrating tools and memory. Learn\\nLangChain’s basics: what are “chains”, what are “agents”, how to use its components (it provides'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='LangChain – a powerful framework for chaining LLM calls and integrating tools and memory. Learn\\nLangChain’s basics: what are “chains”, what are “agents”, how to use its components (it provides\\nabstractions for doing retrieval, using tools, maintaining conversation memory, etc.). Also introduce \\nvector databases conceptually here if you haven’t already (LangChain uses vector DBs for long-term\\nmemory and retrieval of facts). We will dive deeper into vector DB next month, but start thinking in\\nthat direction. \\nBest Resources:\\n“ChatGPT Prompt Engineering for Developers” (DeepLearning.AI short course) – this is a free 1.5-\\nhour course by OpenAI’s Isa Fulford and Andrew Ng that teaches prompt engineering best practices\\nand how to use LLM APIs. It’s concise and extremely relevant, covering how to structure\\nprompts, use temperature, etc., and even how to build a custom chatbot using an API. Go through'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='and how to use LLM APIs. It’s concise and extremely relevant, covering how to structure\\nprompts, use temperature, etc., and even how to build a custom chatbot using an API. Go through\\nthis course early in the month – it will level up your prompting skills quickly with real examples. \\nLangChain for LLM Application Development (DeepLearning.AI short course) – another short\\ncourse, taught by LangChain’s creator Harrison Chase. In ~1.5 hours it covers LangChain’s core\\nconcepts: models, prompts, parsers, memory, chains, and agents. This is a perfect quickstart to\\n• \\n17 18\\n• \\n19\\n• \\n• \\n• \\n20\\n• \\n21\\n22\\n8'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='using LangChain effectively. Take this after the prompt engineering course; it will tie together\\nprompt skills with a framework to build things. \\nLangChain Documentation & Tutorials – LangChain’s official docs have a tutorial “Build an Agent”\\nthat shows how to create an agent that can use a search tool. Follow this step-by-step to build\\nyour first agent. They also explain various types of agents and tools integration – extremely useful\\nreading. \\nOpenAI Cookbook & Examples – OpenAI’s cookbook (on GitHub) has a section on using models\\nwith function calling (letting GPT-4 use tools) and other prompt tactics. Skim these recipes to learn\\npractical tips (e.g. how to format a prompt for a JSON output, etc.). \\nAnthropic’s “Building Effective Agents” guide – a blog post by Anthropic that discusses best\\npractices for AI agents (like when to use agents vs simple chains, how to handle tool use). It’s a great'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Anthropic’s “Building Effective Agents” guide – a blog post by Anthropic that discusses best\\npractices for AI agents (like when to use agents vs simple chains, how to handle tool use). It’s a great\\nread to develop an intuition for agent design choices, and many working AI engineers refer to it\\n. \\nCommunities: Join the r/AI_Agents subreddit and the LangChain community (Discord or forums).\\nSince agentic AI is so new, a lot of knowledge is shared in real-time on forums. Seeing others’\\nexperiments or issues will teach you a lot and keep you updated. \\nProjects & Portfolio:\\nPrompt Engineering Mini-Project: Design a complex prompt that turns GPT-4 (or another LLM) into\\nsomething useful, without coding an agent. For example, a prompt that makes the LLM a helpful \\ntravel planner (“You are a travel agent AI...”). Refine it to handle tricky inputs. This exercise in\\niterative prompt crafting will teach you how small wording changes impact outputs. Document your'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='travel planner (“You are a travel agent AI...”). Refine it to handle tricky inputs. This exercise in\\niterative prompt crafting will teach you how small wording changes impact outputs. Document your\\nfinal prompt and some chat transcripts as a portfolio piece (it shows your ability to coax functionality\\nfrom an API, which is a valuable skill on its own). \\nBuild Your First AI Agent: Using LangChain, create a simple agent that can perform a task using\\ntools. For instance, “Research Assistant Agent”: it takes a query, uses a web search tool (LangChain\\nhas search integrations) and then summarizes an answer . This involves the agent deciding to call the\\nsearch tool, then perhaps a calculator or wiki API, etc. Another idea: an “Email Assistant Agent”\\nthat reads your emails (you can feed it sample emails), and drafts replies using an LLM, possibly\\nusing a calendar API as a tool to check your availability when scheduling meetings. Keep the scope'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='that reads your emails (you can feed it sample emails), and drafts replies using an LLM, possibly\\nusing a calendar API as a tool to check your availability when scheduling meetings. Keep the scope\\nnarrow so it’s achievable – e.g. one that uses 2 tools maximum. The goal is to get hands-on\\nexperience with the agent loop (LLM observes -> decides action -> tool -> new input -> LLM\\ncontinues...). You will encounter challenges like ensuring the agent doesn’t get stuck or making\\noutput formatted, which are great learning opportunities. \\nVectorstore Experiment (mini): Set up a simple vector database (could be as easy as using FAISS in\\nmemory) with a small custom text dataset (maybe a compilation of your own notes or a few articles).\\nHook it up with LangChain’s retrieval API to create a knowledge base. This isn’t a full project by\\nitself, but a tech demo: e.g., ask questions and have the system retrieve relevant info and feed it to'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='itself, but a tech demo: e.g., ask questions and have the system retrieve relevant info and feed it to\\nthe LLM (classic RAG pipeline). This will prepare you for next month where we do this more fully. \\nYouTube Opportunity: Share what you learn about prompt engineering – e.g., “5 Prompt Engineering\\nTricks I Learned” with examples (this can attract a lot of viewers given interest in ChatGPT tips). For\\nthe agent, do a live demo video: “Building my first AI agent with LangChain!” – show the agent in action\\n(maybe split-screen with code and it executing tasks). Even if it’s a simple research bot, viewers find\\nthe concept exciting, and it demonstrates cutting-edge skills. You could also reflect on failures or\\niterations, which shows your problem-solving process. \\nSpaced Repetition: As you venture into new territory, relate back to fundamentals. For example,\\nrecall how transformers and embeddings work (important for vector databases and prompt'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Spaced Repetition: As you venture into new territory, relate back to fundamentals. For example,\\nrecall how transformers and embeddings work (important for vector databases and prompt\\nembeddings), or how the ML pipeline works (when thinking about feeding info to LLMs). Revise\\nprevious notes on evaluation metrics – now you should think: How do I evaluate if my agent is “working\\n• \\n19\\n• \\n• \\n23\\n24\\n• \\n• \\n• \\n• \\n25\\n• \\n• \\n• \\n9'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='well”? Maybe by accuracy of retrieved info or user feedback. This meta-thinking will reinforce old\\nknowledge in a new context. Also, maintain your Anki deck for new LangChain terms or best\\npractices (“What is a LangChain agent?”, “Name 3 best practices for prompt design”). \\nMonth 8: Advanced Applications – Building with LLMs, Memory &\\nRetrieval (RAG)\\nFocus: Develop deep expertise in  Retrieval-Augmented Generation (RAG) and  long-term memory for\\nagents using vector databases, and build a substantial project that utilizes these. Also, get comfortable with\\nvarious LLM APIs/platforms (not just one) to increase your versatility. By the end of this month, you will\\nhave built an AI application that  combines an LLM with external knowledge, a critical capability for\\nagentic systems.\\nKey Learning Goals: Understand how to handle large knowledge with LLMs – since LLMs have\\ncontext length limits, we use embeddings + vector stores to give them relevant info on the fly.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Key Learning Goals: Understand how to handle large knowledge with LLMs – since LLMs have\\ncontext length limits, we use embeddings + vector stores to give them relevant info on the fly.\\nMaster the workflow of creating embeddings for data, storing and querying a vector database. Learn\\nabout popular vector DB solutions (FAISS, Pinecone, Weaviate, etc.) and trade-offs (memory vs\\nspeed, local vs cloud service). Additionally, explore memory management in agent frameworks\\n(keeping conversation history, summarizing to compress memory, etc.). By now, you should also\\ndeepen your knowledge of various LLM providers – experiment with a new model or API (e.g.,\\nCohere, Anthropic Claude, open-source LLaMA2) to broaden your toolset. \\nCore Concepts & Tools: Embeddings (how text is converted to high-dimensional vectors, e.g. using\\nOpenAI’s text-embedding-ada model or Sentence Transformers). Vector database operations: insert,'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Core Concepts & Tools: Embeddings (how text is converted to high-dimensional vectors, e.g. using\\nOpenAI’s text-embedding-ada model or Sentence Transformers). Vector database operations: insert,\\nsimilarity search. LangChain’s RetrievalQA chain or similar: feeding retrieved docs to LLM. Memory\\nin LangChain: short-term (conversation buffers) vs long-term (using a vector store as memory)\\n. Tools: Pick a vector DB – for learning, FAISS (an open-source library) is straightforward to use\\nlocally. You might also try Pinecone or ChromaDB for a managed solution (they have free tiers).\\nContinue with LangChain to integrate these pieces seamlessly. Also consider using Hugging Face\\nHub for embeddings/models if you want to try non-OpenAI models. If you haven’t yet, using a local\\nLLM (like Llama-2 13B on a Colab or smaller model on CPU) could be educational to see how to\\ndeploy models without an API – though this is optional if resources are limited. \\nBest Resources:'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='LLM (like Llama-2 13B on a Colab or smaller model on CPU) could be educational to see how to\\ndeploy models without an API – though this is optional if resources are limited. \\nBest Resources:\\nHugging Face Course, Chapter on “Build Reasoning Agents” – the later chapters of the HF course\\n(Ch. 11-12) cover fine-tuning LLMs and building reasoning models. These might touch on retrieval\\nand advanced use-cases – worth reading for a structured insight. \\nBlogs on RAG: “How to build a QA system with RAG” – many blog posts or Medium articles exist (e.g.\\nby AWS, Cohere, or independent bloggers) that walk through building a document Q&A bot with\\nLangChain + vector DB. Follow one of these tutorials to reinforce your understanding. \\nDeepLearning.AI short course: “Building and Evaluating Advanced RAG Applications” – (as\\nhinted in their site) if available, this could be very relevant. If not, seek out conference talks or'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='DeepLearning.AI short course: “Building and Evaluating Advanced RAG Applications” – (as\\nhinted in their site) if available, this could be very relevant. If not, seek out conference talks or\\nwebinars on RAG. For instance, Pinecone’s blog has articles on designing good RAG systems\\n(covering chunking strategies, etc.). \\nDocumentation: Read Pinecone’s docs or FAISS wiki to understand how vector search works under\\nthe hood (helps if you need to optimize or debug retrieval issues). Also, the LangChain docs on\\nMemory and on VectorStores are crucial – they provide code snippets and explain different types of\\nmemory (short-term vs long-term). \\n• \\n• \\n26\\n27\\n• \\n• \\n• \\n• \\n• \\n28 29\\n10'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Research papers (optional): If curious, skim the Retrieval-Augmented Generation paper by\\nFacebook (if available) or related literature to see the formal approach. And Anthropic’s work on\\n“Claude’s long documents” or OpenAI’s on “Retrieval for GPT” to know the state-of-art thinking\\n(optional but inspiring). \\nProjects & Portfolio:\\nCapstone Project Part 1 – “AI Research Assistant” (RAG System): Begin a major project that will\\nspan this month and next. Build an Agentic AI system that can ingest and use a knowledge base.\\nFor example, an agent that a user can ask questions, and if it doesn’t know the answer it will search a\\ncustom document repository to find relevant info and then answer (akin to an enterprise Q&A bot).\\nThis involves: \\nGathering a knowledge corpus (could be a set of PDFs or markdown notes – perhaps your\\nuniversity lecture notes or a collection of articles in a domain you like). \\nIndexing them: split into chunks, embed each chunk, store in a vector DB.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='university lecture notes or a collection of articles in a domain you like). \\nIndexing them: split into chunks, embed each chunk, store in a vector DB. \\nImplementing retrieval: given a query, get top relevant chunks. \\nFeeding them to an LLM with a proper prompt (prompt engineering to incorporate retrieved\\ninfo and cite sources perhaps). \\n(Optional advanced agent behavior) If the question requires multi-step reasoning, the agent\\nmight break it down. But even a single-step QA with retrieval is a huge accomplishment. \\nTest the system on various queries, refine chunk sizes or prompt as needed for better\\nanswers.\\nThis project solidifies many skills and is highly relevant to real-world applications (companies\\nlove this use-case). Make sure to log how well it answers questions (you can demonstrate it\\nanswering things that vanilla ChatGPT cannot because it has your custom data). \\nExperiment with Multi-LLM or Tools: As part of above or separate small experiment, try using a'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='answering things that vanilla ChatGPT cannot because it has your custom data). \\nExperiment with Multi-LLM or Tools: As part of above or separate small experiment, try using a\\ndifferent model for embedding vs answering. For instance, use OpenAI’s API for answers but a local\\nmodel for embeddings, or vice versa. Or incorporate a new tool into your agent: e.g., a calculator or\\nPython REPL for math problems. This will teach you how to mix and match components for efficiency\\n(an important production consideration is cost and latency – e.g., using a smaller model when\\nappropriate). \\nIntermediate Deliverable: By end of this month, have a working Q&A system (even if not fully an\\nautonomous “agent”), which accepts user queries about your documents and returns answers with\\nreferences. This sets the stage for next month, where you can extend it into more of an “agent” with\\nplanning abilities. \\nYouTube Opportunity: Document this capstone’s development. For instance, “Building a GPT-4'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='planning abilities. \\nYouTube Opportunity: Document this capstone’s development. For instance, “Building a GPT-4\\nPowered Research Assistant – Part 1” where you show how you set up the vector database and got the\\nQA working. This could be a series (audience loves following along a build). Explain concepts like\\nembeddings and RAG in simple terms while demoing. Not only does this educate your viewers, it\\nreinforces your own learning and demonstrates mastery to potential employers who might see it. \\nSpaced Repetition: At this advanced stage, spaced repetition might involve integrating knowledge.\\nFor example, explain to yourself (or in notes) how a concept from Month 2 (say, evaluation metrics)\\napplies when evaluating your QA system (you might think of precision/recall of relevant info). Revisit\\nyour flashcards on prompt engineering and see if your understanding has evolved – update them\\nwith new insights (e.g., you might add notes like “When doing retrieval+LLM, remember to prompt'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='your flashcards on prompt engineering and see if your understanding has evolved – update them\\nwith new insights (e.g., you might add notes like “When doing retrieval+LLM, remember to prompt\\nthe model to only use provided info.”). Regularly revisit fundamentals like big-O complexity or\\nsystem design basics, since soon you’ll be interviewing and those may come up too.\\n• \\n• \\n• \\n◦ \\n◦ \\n◦ \\n◦ \\n◦ \\n◦ \\n• \\n30\\n• \\n• \\n• \\n11'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Month 9: Capstone – Building an Autonomous AI Agent (AutoGPT-\\nLite)\\nFocus: This month, you will integrate everything to build a showcase Agentic AI application – essentially\\nyour own simplified version of AutoGPT catered to a specific use-case. This is the culmination of your\\nspecialization, demonstrating you can orchestrate LLMs, tools, and knowledge bases to perform complex\\ntasks autonomously. Also, you’ll solidify production-level considerations while building this capstone.\\nKey Learning Goals: Learn to design an agent system architecture: breaking a problem into sub-\\ntasks that an AI agent can handle (planning). Implementing a loop where the agent can decide\\nactions (tool use or asking for more info) and stopping criteria. Handling errors or unexpected\\noutputs gracefully (robustness). Additionally, deepen understanding of production concerns: rate\\nlimits of APIs, error handling, logging agent decisions, and cost management. By the end, you’ll have'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='outputs gracefully (robustness). Additionally, deepen understanding of production concerns: rate\\nlimits of APIs, error handling, logging agent decisions, and cost management. By the end, you’ll have\\na functioning multi-step agent and know how to evaluate and improve it. \\nCore Concepts & Tools: Planning algorithms for agents (e.g., the ReAct framework – reasoning and\\nacting iteratively). Tool integration in LangChain: ensure you know how to add custom tools. If not\\nalready, explore LangChain’s AgentExecutor and how it manages the loop. Memory\\nmanagement – possibly use a summary of past interactions to keep context short. Evaluation: learn\\nhow to test agent performance (maybe create specific scenarios to see if it succeeds, and log\\nresults). Continue using your chosen LLM API (perhaps GPT-4 if available for complex reasoning, due\\nto its strength in reasoning) along with cheaper models for simpler tasks (as a production-minded'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='results). Continue using your chosen LLM API (perhaps GPT-4 if available for complex reasoning, due\\nto its strength in reasoning) along with cheaper models for simpler tasks (as a production-minded\\nstrategy). Possibly introduce guardrails (like OpenAI’s function calling or the Guardrails AI library) to\\nconstrain outputs – this is a cutting-edge practice to improve reliability. \\nBest Resources:\\nAuto-GPT and BabyAGI GitHub repos – review their README and maybe part of the code to\\nunderstand how those projects structure the agent loop and memory. You don’t need to replicate\\nthem fully, but it’s insightful to see how others implemented autonomous agents. \\nSoftware Engineering Daily podcast episode “LangChain and Agentic AI” – an interview with\\nHarrison Chase (LangChain creator) or similar talks on YouTube where developers discuss building\\nwith agents. These often reveal pitfalls and best practices (like how to avoid agents going in circles,\\netc.).'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='with agents. These often reveal pitfalls and best practices (like how to avoid agents going in circles,\\netc.). \\nReddit - r/AI_Agents and r/LangChain threads – look for posts like “Lessons learned building an\\nagent” or “Why AutoGPT fails at X”. Community wisdom will teach you what not to do. In fact, one AI\\nengineer on Reddit shared tips: e.g., keep agents’ scope narrow, have each LLM call do one specific\\ntask, and show the agent’s reasoning steps for transparency. Such insights can guide your\\ndesign. \\nLangChain documentation (advanced): Specifically, read about custom Agents and agent policies.\\nLangChain now has features like Multi-Action Agents or using LangSmith for tracing – these are\\nmore advanced, but skimming these can give you ideas on improving your agent. \\nOpenAI/Anthropic docs on usage limits – ensure you know how to set API call limits or monitor\\nusage (OpenAI lets you set a quota) so that during development your agent doesn’t accidentally'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='OpenAI/Anthropic docs on usage limits – ensure you know how to set API call limits or monitor\\nusage (OpenAI lets you set a quota) so that during development your agent doesn’t accidentally\\nrack up huge costs. This is an important production skill (cost management). \\nPossibly revisit Chip Huyen’s blog on LLM applications – especially sections on agents and tool use\\n, and the challenges of making them reliable. It will remind you to think about edge cases\\nand user expectations in production. \\nProjects & Portfolio:\\n• \\n• \\n19\\n• \\n• \\n• \\n• \\n25 31\\n• \\n• \\n32\\n• \\n33 34\\n• \\n12'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Capstone Project Part 2 – Autonomous Agent: Continue and complete the capstone started last\\nmonth by adding autonomous capabilities. Building on the “AI Research Assistant” (or whichever\\nRAG system you made), add a planning and tool-use layer. For example, enable the agent to\\nhandle a complex query like: “Summarize the key differences between these two research papers\\nand email the summary to my colleague.” This would require the agent to break it down: (a) search\\nor retrieve info on paper 1 and 2, (b) summarize differences, (c) formulate an email, (d) possibly\\nactually send an email via an email API (if you choose to integrate that tool). This is just an example –\\ndefine a scenario relevant to your interests. The agent should use multiple steps autonomously:\\nretrieving data, using a writing tool, maybe a calculation or API call, etc., without you intervening in\\neach step. Document the chain of thought: have the agent output or log its reasoning at each step'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='each step. Document the chain of thought: have the agent output or log its reasoning at each step\\n(this is great for demo and debugging). \\nTesting and Refinement: Once built, test your agent on a variety of tasks within its scope. Observe\\nfailure modes (does it get stuck in a loop? Does it ever hallucinate wrong info from outside the\\ndocs?). Refine by adjusting prompts or adding constraints. For instance, if it tends to hallucinate, you\\nmight enforce that it must quote sources for factual info, or if it loops, add a rule to break after N steps\\nwith a graceful response. This process teaches MLOps mindset – iterate to improve reliability. \\nFinalize Deployment: Deploy your capstone if possible. For instance, create a small web interface\\nfor it (a simple frontend where you input a query and see the agent’s plan and answer). If deploying\\nfully is hard, at least record a compelling demo of it working. Also, prepare a technical write-up in'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='fully is hard, at least record a compelling demo of it working. Also, prepare a technical write-up in\\nyour GitHub repo or a Medium article about how you built this agent. This can be gold for your\\nportfolio – it demonstrates end-to-end project execution and thought leadership (few people have\\nwritten detailed guides on building agents – you could!). \\nYouTube Opportunity: This is the big one – create a showcase video: “I built my own Auto-GPT in 30\\ndays” or “Autonomous AI Agent demo – [Your Agent’s Name]”. In this video, present the problem it\\nsolves, show it performing a multi-step task live (with its thinking printed out), and explain how you\\nmade it. This is likely to attract attention given the hype around AI agents, and it serves as a\\ncapstone presentation of your skills. Share this video on LinkedIn, Reddit, etc. for feedback and\\nperhaps it catches the eye of recruiters or potential collaborators.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='capstone presentation of your skills. Share this video on LinkedIn, Reddit, etc. for feedback and\\nperhaps it catches the eye of recruiters or potential collaborators. \\nSpaced Repetition: At this point, spaced repetition is about interview prep and knowledge\\nsynthesis. Start reviewing topics you may not have touched recently: e.g., revisit how SVMs work or\\nhow backprop works – interviews might dig into fundamentals even if your focus was on LLMs. Use\\nflashcards for data structures and algorithms (you’ll need some for coding interviews at FAANG). Also\\nconsider doing a high-level review of all projects: can you summarize each project’s key idea and\\nlearning in a few sentences from memory? If not, review it. This prepares you to talk about them\\nfluently in interviews. Continue using spaced repetition for new things too (e.g., key lessons you\\nlearned about agent design – write those down and revisit).\\nMonth 10: Production Readiness – MLOps, Deployment, and\\nScalability'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='learned about agent design – write those down and revisit).\\nMonth 10: Production Readiness – MLOps, Deployment, and\\nScalability\\nFocus: Shift gears to learn MLOps and deployment best practices. This month is about making sure you can\\ntake an AI model/agent and deploy it in a production environment reliably. You’ll also prepare for the job\\nhunt by aligning your skills with what industry expects (scalability, reliability, collaboration).\\nKey Learning Goals: Learn how to package and deploy models and AI systems as services.\\nUnderstand the concepts of containerization (Docker), CI/CD, and cloud deployment (AWS/GCP/\\nAzure) as applicable to AI apps. Learn to monitor a live AI system (logging, detecting failures or drift).\\n• \\n• \\n• \\n• \\n• \\n• \\n13'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Also, familiarize with ML experiment tracking (tools like MLflow or Weights & Biases) – in\\nproduction roles, being able to track model versions and experiments is valuable. Additionally, gain\\nknowledge of data pipelines: how to regularly update a model or feed it new data, and basics of\\nscheduling jobs. Essentially, aim to bridge the gap between a prototype (which you have built many\\nof) and a production-grade application that can handle real users and data. \\nCore Concepts & Tools: Containerization with Docker (create a Dockerfile for one of your apps,\\ncontainerize it with all dependencies). Serving models: using FastAPI or Flask to create an API\\nendpoint for your model/agent. Possibly look into streaming data and real-time considerations if\\nrelevant (for example, if your agent were to run continuously). CI/CD: using GitHub Actions to\\nautomate tests and deployments when you push updates. Cloud: pick one (say AWS) and learn basics'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='relevant (for example, if your agent were to run continuously). CI/CD: using GitHub Actions to\\nautomate tests and deployments when you push updates. Cloud: pick one (say AWS) and learn basics\\n(AWS has free tier – try deploying your FastAPI app on AWS EC2 or using AWS Lambda for a simple\\nfunction, or use Heroku for simplicity). Learn about scaling: how would you scale an API that gets\\nheavy usage? (e.g., using load balancers, multi-instance). Also consider cost optimization: e.g. using\\nsmaller models or batching calls in a production setting to save cost. Security: understand basic\\nmeasures (storing API keys securely, not exposing secrets, etc.). \\nBest Resources:\\nFull Stack Deep Learning – their material on deployment and monitoring is very relevant (they talk\\nabout packaging models and setting up inference endpoints). \\nCoursera or Udacity MLOps courses – if available, doing a crash course on MLOps will systematize'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='about packaging models and setting up inference endpoints). \\nCoursera or Udacity MLOps courses – if available, doing a crash course on MLOps will systematize\\nthis knowledge. Andrew Ng’s MLOps specialization or Google Cloud’s ML Engineering courses\\ncould be useful. \\nAWS/GCP free tutorials – both AWS and Google have free training for deploying ML models (e.g.,\\nAWS SageMaker tutorials, GCP Vertex AI samples). Even if you don’t use the managed services now,\\nknowing they exist and how they work is good for interviews. \\nDocker Official Docs & DockerCaptain YouTube – to learn writing Dockerfiles and container basics.\\nFastAPI docs – FastAPI is a great tool to wrap your models into web services quickly. Their docs are\\nbeginner-friendly and you can have a simple “Hello World” model API running in minutes. \\n“Building LLM applications for production” by Chip Huyen – this blog (if you haven’t fully read it\\nyet) covers practical challenges in deploying LLM apps (like handling ambiguity in prompts,'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='“Building LLM applications for production” by Chip Huyen – this blog (if you haven’t fully read it\\nyet) covers practical challenges in deploying LLM apps (like handling ambiguity in prompts,\\nversioning, evaluation). It’s basically a checklist of things to keep in mind so that your fancy LLM\\ndemo doesn’t break in the real world. Read it and reflect on how you can apply those principles to\\nyour capstone agent if you deployed it. \\nProjects & Portfolio:\\nDeploy Your Capstone Agent: Take the autonomous agent from last month and deploy it as a\\nservice. For example, wrap it in a FastAPI server where one endpoint /ask triggers the agent with\\na user query and returns the answer . Containerize this with Docker . Then try deploying it to a cloud\\nservice or at least run it on a cloud VM to simulate production. This exercise will expose issues\\n(memory usage, need for loading models efficiently, etc.). Ensure you include logging – have the'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='service or at least run it on a cloud VM to simulate production. This exercise will expose issues\\n(memory usage, need for loading models efficiently, etc.). Ensure you include logging – have the\\nservice log each step of the agent’s reasoning to a file or console for monitoring. If possible, simulate\\na few concurrent users to see how it handles (you might realize the agent is stateful and needs\\nunique sessions or it’s slow – which is normal; note those findings). \\nCI/CD Pipeline: Set up a simple CI pipeline for one of your projects. For instance, use GitHub Actions\\nsuch that when you push to main on your capstone’s repo, it automatically runs tests (if you add any)\\nand maybe deploys to your server . This shows you understand DevOps culture. Document this in\\nyour project readme (“Using GitHub Actions to auto-deploy on update”). It’s a nice touch that many\\ncandidates lack. \\n• \\n30\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n35\\n• \\n• \\n• \\n14'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Freelance Simulation Project: Since one of your goals is freelancing, try a project that simulates a\\nfreelance task. For example, find a real problem on Reddit or Freelance boards – e.g., “I need a\\nscript to categorize a bunch of customer feedback using AI.” Then build a quick solution for it: maybe\\nfine-tune a model or use an off-the-shelf model via API, and deliver it as a script or small app. Do it\\nend-to-end in say 3-4 days as if it were a paid gig. This will teach working under requirements and\\nalso give you a template for similar future freelance tasks. You can write about this experience as\\nwell. \\nYouTube/Blog Opportunity: Create content focusing on the production aspect this time – e.g., \\n“How to deploy an AI model as an API (step-by-step)”. This could be a tutorial where you containerize\\nand deploy a smaller ML model (maybe your Month 2 model or a simple Hugging Face model) to a'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='“How to deploy an AI model as an API (step-by-step)”. This could be a tutorial where you containerize\\nand deploy a smaller ML model (maybe your Month 2 model or a simple Hugging Face model) to a\\nfree service. Many find this educational, and it forces you to articulate the process. Additionally,\\nconsider writing a Medium blog post summarizing your capstone project with a focus on its\\nproduction design (“Building an AutoGPT-style agent and deploying it on AWS”). Writing an article\\ncan increase your visibility in the field (and you can add it to your resume). \\nSpaced Repetition: Now shift some focus to interview preparation content for spaced repetition.\\nFor example, use flashcards to remember key points that you might mention in interviews: big-O\\ncomplexities, definitions of overfitting vs underfitting, the trade-offs of different model types, etc.\\nRevisit any theoretical gaps you feel – e.g., if you skipped some math, review it now. Continue to'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Revisit any theoretical gaps you feel – e.g., if you skipped some math, review it now. Continue to\\nrevisit high-level summaries of each project and each major concept (by now you have a web of\\nknowledge – solidify the connections: how does an embedding from Month 8 relate to the cosine\\nsimilarity you learned in Month 1 math? How does Docker compare to a virtualenv from earlier\\nprojects? Connecting dots is a great memory tool).\\nMonth 11: Job Hunt Preparation – Polishing Skills and Portfolio\\nFocus: This month is about getting ready to land a job or freelance clients. We will polish your resume,\\nportfolio, and online presence, and prepare for technical interviews (both coding and ML system design).\\nWe’ll also ensure you leverage your YouTube channel and network for opportunities.\\nKey Tasks – Resume & Portfolio: Craft a strong resume that highlights your AI projects and skills.\\nEmphasize outcomes: e.g., “Built an autonomous research assistant agent using LangChain and'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Key Tasks – Resume & Portfolio: Craft a strong resume that highlights your AI projects and skills.\\nEmphasize outcomes: e.g., “Built an autonomous research assistant agent using LangChain and\\nGPT-4, integrating vector database for 20k documents (GitHub, demo link)”. Quantify where possible\\n(even if just “achieved 90% accuracy on X” or “improved inference speed by Y% with optimization”).\\nInclude keywords like the tools and frameworks you know (TensorFlow, PyTorch, Hugging Face,\\nLangChain, Docker , etc.) so it passes automated scans. Also update your LinkedIn to reflect your\\nyear of projects – write a summary that you’re an AI engineer specializing in LLMs/agents, open to\\nopportunities. On GitHub, pin your best projects to showcase them. Ensure your project READMEs\\nare clear because recruiters will look at them. If you have a personal portfolio website, update it with\\nlinks to your YouTube videos and project write-ups – make it a one-stop-shop of your expertise.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='links to your YouTube videos and project write-ups – make it a one-stop-shop of your expertise. \\nKey Tasks – Networking: Start actively networking. Announce on LinkedIn the completion of your\\nyear-long learning journey, perhaps with a post sharing your Medium article or YouTube capstone\\ndemo. Engage with communities: e.g., on Twitter (X) share insights or small threads about\\nsomething cool you learned about agents (tagging relevant hashtags like #LangChain, #LLM). This\\ncan get you noticed. Also consider reaching out to people in companies you’re interested in – not\\nasking for a job outright, but commenting on their work or asking for advice given your newly\\nminted experience. Join hackathons or meetups (if available locally or virtually) to meet like-minded\\nfolks. Often job leads come from these connections. \\n• \\n• \\n• \\n• \\n16\\n• \\n15'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Interview Prep – Coding: Dedicate daily time to coding interview prep. Even for AI roles, many top\\ncompanies will have a coding round (FAANG especially). Use platforms like LeetCode or HackerRank.\\nFocus on problems around arrays, strings, hash maps, graphs, etc. Aim to solve at least one\\nmedium-difficulty problem each day, and periodically do timed mock interviews. Use spaced\\nrepetition to remember common patterns (two-pointer , BFS, DP etc.). Since you can code in Python,\\nleverage that, but be familiar with complexity analysis. \\nInterview Prep – ML & System Design: Prepare to answer questions on ML concepts: e.g., explain\\nhow logistic regression works, what is bias vs variance, how do you handle missing data, etc. Review\\nyour flashcards on all fundamental definitions. Practice explaining your projects out loud – you\\nshould be able to crisply discuss the goal, approach, and results of each. Also practice ML system'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='your flashcards on all fundamental definitions. Practice explaining your projects out loud – you\\nshould be able to crisply discuss the goal, approach, and results of each. Also practice ML system\\ndesign questions (common in ML engineer interviews): e.g., “How would you design a system to\\nrecommend products?” or “How would you deploy a model that handles 1 million requests/day?” –\\nhere you draw from your Month 10 knowledge (talk about load balancing, caching, monitoring). If\\napplying to specifically LLM-related roles, prepare for questions like “How do you fine-tune an LLM?\\nWhat are the challenges?” or “How would you improve inference latency for an LLM in production?”.\\nDraw on what you learned about quantization or using smaller models for speed. \\nFreelance Prep: In parallel, if freelancing is a goal, create profiles on platforms like Upwork or\\nFreelancer . Showcase your projects there (many clients will be impressed by an AutoGPT-like project).'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Freelancer . Showcase your projects there (many clients will be impressed by an AutoGPT-like project).\\nPerhaps start by bidding on a small project that matches your skills to get a feel for the freelance\\nworkflow. Even if you plan to take a full-time job, a little freelancing can provide experience and a\\nside income. Also, your YouTube channel is now a portfolio piece – mention it in your bio (“I also run\\na YouTube channel with tutorials on AI, with X subscribers”). Having an audience can set you apart. \\nBest Resources:\\nCracking the Coding Interview (book) – for coding questions patterns. \\nInterview Query or Machine Learning Interview guides – there are blogs and books that list\\ncommon ML engineer interview Qs. Go through those.\\nLeetCode’s database and system design sections – sometimes AI roles ask SQL or basic system\\ndesign; ensure you can write simple SQL queries and outline system architecture.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='LeetCode’s database and system design sections – sometimes AI roles ask SQL or basic system\\ndesign; ensure you can write simple SQL queries and outline system architecture. \\nMock interviews: Try Pramp (free mock interview platform) or interview with a friend/mentor . This\\ncan greatly boost confidence. \\nResume review communities: r/EngineeringResumes on Reddit or others – you can get feedback\\non your resume from peers. \\nProjects (Polish & Present): This month you likely won’t start new technical projects, but you might \\nrevisit an old project to polish it. For example, if one of your earlier projects lacked tests or had\\nsome bugs, fixing those shows growth. You can even do a “v2” of a project using new skills (e.g.,\\nrefactor your Month 2 ML project with proper pipelines or deploy your Month 4 CNN as an API).\\nMinor improvements can be content on your blog (“I revisited my old project with new eyes and\\nhere’s what I improved”). It demonstrates continuous improvement.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Minor improvements can be content on your blog (“I revisited my old project with new eyes and\\nhere’s what I improved”). It demonstrates continuous improvement. \\nYouTube Opportunity: Share your journey now that you have nearly completed it. A video like “How\\nI became an AI Engineer in 12 months” where you candidly discuss the roadmap, challenges, and\\nshow snippets of projects could inspire others and also serve as a self-reflection. Additionally, you\\ncould do live streams solving LeetCode problems or talking about interview prep – this shows you’re\\nserious about the job transition and might even attract leads (somebody could refer you after seeing\\nyour depth). \\nSpaced Repetition: This is where your spaced repetition habit pays off – keep cycling through all\\nthose flashcards on theory and math regularly so everything is fresh. Also, simulate Q&A: have a list\\nof likely interview questions (technical and behavioral) and practice responding out loud or in'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='those flashcards on theory and math regularly so everything is fresh. Also, simulate Q&A: have a list\\nof likely interview questions (technical and behavioral) and practice responding out loud or in\\nwriting. Use Anki for tricky algorithm tips or specific facts (like “What’s the equation for a neuron\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n16'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='output? What’s cross-entropy?”). By now, you should also revisit any ECE core knowledge if relevant\\n– sometimes, roles value that background, so don’t neglect what you learned in your degree; be\\nready to mention how it complements your AI skills (e.g., knowledge of hardware could help\\noptimize models, etc.). Keep your mind fresh but also get enough rest – don’t burn out right before\\ninterviews.\\nMonth 12: Transition – Interviews, Contributions, and Next Steps\\nFocus: This final month, you will be actively interviewing (if things go to plan) or at least aggressively\\napplying. Meanwhile, continue sharpening skills by contributing to open-source and staying up-to-date with\\nthe latest in AI (to discuss in interviews). Also, lay the groundwork for lifelong learning, since this year is just\\nthe beginning of a career .\\nJob Applications: By now, you should apply to a range of companies – FAANG (stretch goals, but'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='the beginning of a career .\\nJob Applications: By now, you should apply to a range of companies – FAANG (stretch goals, but\\nyour strong portfolio gives you a shot!) as well as top startups especially in the AI tooling/LLM space.\\nMany startups would value your experience with LangChain, vector DBs, etc., as those are hot skills.\\nTailor each application – mention your specific experience relevant to their work. Leverage referrals if\\npossible: use LinkedIn to see if you have connections at these companies; a referral plus your project\\nlinks can get you interviews. For freelance, step up outreach: send proposals highlighting similar\\nwork you’ve done. \\nInterview Rounds: Hopefully, you land interviews. In technical rounds, draw confidently on your\\npreparation. For coding, keep practicing problems daily up to the interview day. In ML design\\nrounds, use a structured approach (clarify requirements, explain your approach clearly – you’ve'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='preparation. For coding, keep practicing problems daily up to the interview day. In ML design\\nrounds, use a structured approach (clarify requirements, explain your approach clearly – you’ve\\npracticed by explaining on YouTube, so use those skills). In behavioral rounds, tell the story of this\\nself-driven journey – it demonstrates passion, perseverance, and ability to learn fast, all highly\\nvalued. Be ready with examples of projects: e.g., “Tell me about a challenging problem you solved” –\\nyou can cite debugging your agent’s hallucinations or managing without a GPU by optimizing code,\\netc. Emphasize how you independently initiated and completed a complex roadmap – that’s akin to\\nbeing a self-driven employee. \\nOpen-Source Contribution: This is a good time to contribute to an open-source project related to\\nyour specialization (if you haven’t yet). For example, contribute a small fix or documentation update'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Open-Source Contribution: This is a good time to contribute to an open-source project related to\\nyour specialization (if you haven’t yet). For example, contribute a small fix or documentation update\\nto LangChain or Hugging Face Transformers. It signals to employers that you engage with the\\ncommunity and understand collaborative workflows. It could be as simple as improving an example\\nin LangChain’s docs or fixing a minor bug you encountered. Mention this in interviews (“I even\\ncontributed a bugfix to LangChain that got merged”) – it’s impressive. \\nContinued Learning: The field of AI moves rapidly. Identify a few key sources to stay updated: e.g., \\nDeepLearning.AI’s “The Batch” newsletter for weekly AI news, the r/MachineLearning subreddit\\nfor latest research highlights, and YouTube channels like Yannic Kilcher or Two Minute Papers for\\nresearch summaries. This habit will help you in interviews if asked about recent developments (“Have'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='for latest research highlights, and YouTube channels like Yannic Kilcher or Two Minute Papers for\\nresearch summaries. This habit will help you in interviews if asked about recent developments (“Have\\nyou heard about GPT-4’s new vision capabilities?” – you can give an informed opinion). It will also\\nserve you well on the job. \\nFreelance/SaaS angle: If by end of the year you decide to build an AI SaaS product (another stated\\ngoal), you now have the skills. This month, you could draft a business plan for a tool you built. For\\nexample, maybe your capstone agent can be turned into a SaaS for researchers or students.\\nConsider if you want to pursue that: even if you take a job, this could be a side project or a startup\\nattempt. Evaluate the market, get feedback from potential users (this itself could be a learning\\nproject – building the product mindset). \\n• \\n• \\n• \\n• \\n• \\n17'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Reflect and Plan Ahead: Take time to reflect on how far you’ve come. Identify what you loved most –\\nwas it building end-to-end projects, was it the research aspect of trying new techniques, or making\\ncontent? This can guide your next steps. If working at a big company, you’ll continue learning on the\\njob. If freelancing, you might pick a niche (LLM apps for finance, for example). If doing a startup,\\nyour learning shifts to business. In any case, set aside a little time to update your knowledge: maybe\\nplan to tackle a new advanced topic next (like reinforcement learning or AI for robotics) as a\\ncontinued growth goal. \\nCelebrate: Don’t forget to acknowledge your achievements. Completing such an intensive roadmap\\nis rare and employers will recognize the caliber of effort. Perhaps make a final YouTube video or blog\\npost wrapping up the journey and announcing your next step (whether you got a job or launching'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='is rare and employers will recognize the caliber of effort. Perhaps make a final YouTube video or blog\\npost wrapping up the journey and announcing your next step (whether you got a job or launching\\nsomething). It not only gives closure to your audience but also to you. It can mark the transition\\nfrom “learner” to professional AI Engineer. \\nYouTube/Community: In this month, your YouTube channel might start paying off: with a body of\\ncontent, you could see increased engagement. Engage with your commenters, maybe do a Q&A\\nabout “How I would learn AI in 2026” or similar – this reinforces your own knowledge and establishes\\nyou as part of the community. Being active in the community can lead to job offers or freelance gigs\\nunexpectedly (people might reach out seeing your content). \\nSpaced Repetition: Keep your flashcards routine alive lightly to stay sharp, but also realize that by\\nnow repetition is happening via real-life usage (interviews, projects). Use your spaced repetition'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='now repetition is happening via real-life usage (interviews, projects). Use your spaced repetition\\nmore for maintaining interview readiness until you land an offer . Also, use it for any new on-the-job\\nlearning that might occur if you started working. Essentially, the habit you built will continue to serve\\nyou in your career for continuous learning.\\nConclusion: By following this 12-month roadmap, Yash will have transformed from a student with basic\\nknowledge into a well-rounded AI Engineer capable of building production-grade AI systems. He will have\\na rich portfolio of projects (from simple models to an AutoGPT-like agent), hands-on experience with\\nstate-of-the-art tools (Hugging Face, LangChain, vector DBs, etc.), and a personal brand via his YouTube\\nchannel.  This  journey  emphasizes  active  learning  through  projects  and  consistent  review,  which  keeps\\nmotivation high and knowledge retained.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='channel.  This  journey  emphasizes  active  learning  through  projects  and  consistent  review,  which  keeps\\nmotivation high and knowledge retained. \\nBy focusing on Agentic AI in the latter half, Yash is entering one of the most cutting-edge areas of AI in\\n2025,  positioning  himself  strongly  for  roles  in  AI  startups  or  innovative  teams  at  big  tech.  The\\ncombination  of  foundational  understanding  and  practical  building  experience  means  he  can  not  only\\ndesign solutions but also implement and deploy them – exactly what companies seek in a “production-\\nready” AI engineer. \\nFinally,  the  roadmap’s  emphasis  on  sharing  (GitHub,  YouTube,  blog)  ensures  Yash  gets  feedback  and\\nrecognition for his work, minimizing the risk of losing momentum. Each project built is not an end, but a\\nstepping stone to the next, creating a virtuous cycle of learning. With this approach, by the end of the year'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='stepping stone to the next, creating a virtuous cycle of learning. With this approach, by the end of the year\\nYash will be well-prepared to land a top-tier job or freelance contracts and even have the foundation to\\nlaunch his own AI-powered tools, fulfilling all the goals set out at the start.\\nSources: The roadmap recommendations are informed by industry-aligned curricula and expert insights.\\nFor example, the breakdown of foundational topics and portfolio building follows suggestions from an AI\\nDeveloper  roadmap .  Emphasis  on  LangChain,  LLMs,  and  vector  databases  reflects  current  best\\npractices for building AI agents. The strategy to “learn then build” iteratively is echoed by practitioners\\n• \\n• \\n• \\n• \\n36\\n36\\n35\\n37 38\\n36\\n18'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='on Reddit , who advise swiftly applying new skills to projects (like using LangChain with a dataset).\\nHugging Face’s course is highlighted as a best-in-class resource for mastering transformers, and short\\ncourses by DeepLearning.AI are recommended to quickly pick up prompt engineering and LangChain from\\nthe  experts .  Additionally,  tips  for  agent  design  (e.g.,  limiting  each  LLM  call  to  a  single  task,\\noptimizing  for  cost)  are  drawn  from  experienced  AI  engineers’  lessons.  By  following  this  guided\\napproach,  Yash  can  be  confident  that  he’s  learning  the  most  relevant  skills with  the  most  effective\\nmethods, as validated by the AI community and industry leaders. Good luck, and happy learning!\\nAI Developer Roadmap (2025 Edition) | by CodePicker\\n| Medium\\nhttps://medium.com/@codepicker57/ai-developer-roadmap-2025-edition-e04dddd2ed3a\\nIntroduction - Hugging Face LLM Course\\nhttps://huggingface.co/learn/llm-course/en/chapter1/1\\nNeural Networks: Zero To Hero'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Introduction - Hugging Face LLM Course\\nhttps://huggingface.co/learn/llm-course/en/chapter1/1\\nNeural Networks: Zero To Hero\\nhttps://karpathy.ai/zero-to-hero.html\\nRoadmap to Becoming an AI Engineer in 8 to 12 Months (From Scratch). : r/learnmachinelearning\\nhttps://www.reddit.com/r/learnmachinelearning/comments/1g6d4cz/roadmap_to_becoming_an_ai_engineer_in_8_to_12/\\nBuild an Agent |  LangChain\\nhttps://python.langchain.com/docs/tutorials/agents/\\nChatGPT Prompt Engineering for Developers - DeepLearning.AI\\nhttps://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\\nLangChain for LLM Application Development - DeepLearning.AI\\nhttps://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/\\nAI Agent best practices from one year as AI Engineer : r/AI_Agents\\nhttps://www.reddit.com/r/AI_Agents/comments/1lpj771/ai_agent_best_practices_from_one_year_as_ai/\\nBuilding LLM applications for production\\nhttps://huyenchip.com/2023/04/11/llm-engineering.html\\n39\\n12'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='https://www.reddit.com/r/AI_Agents/comments/1lpj771/ai_agent_best_practices_from_one_year_as_ai/\\nBuilding LLM applications for production\\nhttps://huyenchip.com/2023/04/11/llm-engineering.html\\n39\\n12\\n20 21\\n25\\n1 2 3 4 5 9 10 11 14 16 17 18 36 37 38\\n6 12\\n7 8 13\\n15 39\\n19 28 29\\n20\\n21 22\\n23 24 25 26 27 30 31 32\\n33 34 35\\n19'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 0, 'page_label': '1', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='1 \\n \\nNews Values - Revised \\nTheodora Ivancheva \\n \\n \\n \\nIntroduction. The notion of what makes events become news has been an object of \\nconsiderable research among academics and practitioners of various backgrounds: \\nsociologists, linguists, psychologists, practicing journalists and anthropologists. The theory of \\nnews values was initially pioneered by the Norwegian scholars Johan Galtung and Mari \\nHomboe Ruge. It comprises twelve criteria that the authors claim serve as definition of \\nnewsworthiness. Since its emergence, the news values set of criteria has given rise to many a \\nhot discussions among academics and professionals. \\nThe present artice presents a succinct overview of the existing theory of news values. Apart \\nfrom the seminal work of Galtung and Juge, the conclusions of authors auch as Hardcup and \\nO’Neill, MacShane and Brighton and Foy are discussed. \\n \\nWhat is news?  In the times of globalization we are constantly exposed to messages that claim'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 0, 'page_label': '1', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='O’Neill, MacShane and Brighton and Foy are discussed. \\n \\nWhat is news?  In the times of globalization we are constantly exposed to messages that claim \\nto present us with news of any kind, source and topic. Apart from the traditional news \\nprogrammes streaming through diversified television channels and the countless number of \\nnewspapers on news stalls, our mail boxes are periodically, if not daily, filled with \\nnewsletters, updates, the latest news concerning a topic of our interest/subscription or simply \\na wayward message that promises to contain news, purely as spam.  In other words, the \\nlexical item “news” has numerous connotations depending on the context in which it appears. \\nFor instance, the utterance “Have you heard the latest news?” is open to multiple \\ninterpretations: \\n1.  two people discussing the latest breaking news on TV, national or local \\nnewspapers, or; \\n2.  the development of a news story that hit news reports some time ago;'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 0, 'page_label': '1', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='interpretations: \\n1.  two people discussing the latest breaking news on TV, national or local \\nnewspapers, or; \\n2.  the development of a news story that hit news reports some time ago; \\n3.  the latest findings concerning some scientific research;   \\n4.  two colleagues talking about the latest changes in their working place or a \\ncorporate gossip; \\n5.  spouses chatting about family issues; \\nbrought to you by COREView metadata, citation and similar papers at core.ac.uk\\nprovided by New Bulgarian University Scholar Electronic Repository'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 1, 'page_label': '2', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='2 \\n \\n6.  teenagers gossiping about a friend’s new relationship; \\n7.  elderly ladies commenting the development of the main characters’ life stories of \\ntheir favourite soap opera; \\n8.  the key question of a TV commercial where friends are sharing information about \\nthe irresistibly low interest rates of a bank. \\nThese are just a few possible interpretations and they invariably depend on the writer’s \\nawareness and experience of various contexts as well as cultural identity.  \\nIn further words, the answer to the question “What is news?” may seem more that obvious. \\nNews is everything that is new that is happening. The dictionary of Merriam Webster offers \\nthe following definitions: \\n1.  a : a report of recent events \\nb : previously unknown information  \\nc : something having a specified influence or effect  \\n2.  a : material reported in a newspaper or news periodical or on a newscast \\nb : matter that is newsworthy (see: http://www.merriam-webster.com/dictionary/news )'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 1, 'page_label': '2', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='2.  a : material reported in a newspaper or news periodical or on a newscast \\nb : matter that is newsworthy (see: http://www.merriam-webster.com/dictionary/news ) \\nThe British National Corpus (BNC) http://www.natcorp.ox.ac.uk/  enables a quick check \\nof the different contexts in which the word item “news” appears. The contexts are a collection \\nof over 100 million, wide-range written and spoken language sources, designed to represent \\nthe later part of the 20 th  century, referring both to written and spoken British English, which is \\nof paramount importance for the purposes of the present research as the examples are entirely \\nexcerpted from British online or printed newspapers.  It is also worth noting that each \\nindividual search offers 50 random solutions, i.e the solutions quoted below may differ from \\nany consecutive trial. Furthermore, the initials at the beginning of each item indicate the'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 1, 'page_label': '2', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='individual search offers 50 random solutions, i.e the solutions quoted below may differ from \\nany consecutive trial. Furthermore, the initials at the beginning of each item indicate the \\nsource reference, given here in parenthesis right after the excerpted item to ascertain the \\nreader-friendly nature of the example (see Appendix). \\nThe tables below are a summarized version of the number of general occurrances of \\nthe word “news” in different written and oral contexts. It is worth noting that these are not the \\ntotal number of utterances, which by far outnumber the number of contextual occurrences. A \\nmore detailed study of the use of the item “news” would benefit tremendously of the overall \\nfigure of utterances to exapmlify its broad usage and various semantic fields.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 2, 'page_label': '3', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='3 \\n \\nsource  \\n          \\nOnline \\nnewspaper \\nPrinted \\nnewspaper \\nFiction \\nBook \\nSpecialized \\nliterature \\nother \\noccurrances  6 6 8 7 8 \\nTable 1.  \\nTable 1  illustrates the usage of the word “news” in written corpora. The ratio between newspapers and \\nother written materials is in favour of newspapers – 12 occurrences in printed and online newspapers \\nversus 8 in fiction literature, 7 in specialized literature, and 8 in other types of printed materials like \\nnewsletters or catalogues (see Table 1).  \\nsource \\n  \\n          \\nTV Programme Radio Programme Business Meeting  \\noccurrences  1 2 2 \\nTable 2.  \\nTable 2  shows the appearance of the lexical item “news” in corpora of oral performance. The \\nratio is almost equal - two times in radio programmes and business meetings each compared \\nto just one occurrence in a television programme (see Table 2).  \\nOn balance, the lexical item news has broad applications in terms of language contexts both'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 2, 'page_label': '3', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='to just one occurrence in a television programme (see Table 2).  \\nOn balance, the lexical item news has broad applications in terms of language contexts both \\nwritten and oral. Its polysemy requires plausible limitations for the purposes of the present \\nwork. What we assume as news here is closer to what Merriam Webster’s Dictionary \\nsuggests, i.e a report of recent events and material reported in a newspaper or news periodical \\nor on a newscast  (see: http://www.merriam-webster.com/dictionary/news ). \\nAs the influx of news in our lives is uncontrollable and, thus hard to observe, we will focus \\nour attention on what is reported in media, that is to say what makes events or happenings \\nbecome news items, bearing in mind that new things happen all the time everywhere in the \\nworld and they never find their way into newspapers or onto the air in a newscast. \\nFurthermore, as the number of printed and electronic media is vast, the encuing examples'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 2, 'page_label': '3', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='world and they never find their way into newspapers or onto the air in a newscast. \\nFurthermore, as the number of printed and electronic media is vast, the encuing examples \\nhave been excerpted from the printed or electronic versions of newspapers.  \\nWhat makes a story newsworthy enough to be published or broadcast? It is news values that \\ngive journalists and editors a set of rules by which to work, plan and execute the content of a \\npublication or a broadcast. The types of media are varied. A newspaper is a publication that is \\nissued daily, weekly, bidaily, or bimonthly, and includes local and international news stories, \\nadvertisements, announcements, opinions, cartoons, sports news, television listings,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 3, 'page_label': '4', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='4 \\n \\nclassifieds and other sections. It is an important method of letting the public knows everything \\nthat is happening around the world and in their local area. Even with the advancements in \\ncomputer technology, newspapers continue to be an important aspect of everyday life.  \\nNot only are there a vast number of media types available but there are various types \\nof printed newspaper on offer as well. Newspapers generally are divided into three categories: \\nbroadsheets, the Berliner format, and tabloids. Broadsheets are believed to present high-\\nquality journalism; however, they are unsuited to reading in public transport that is why \\nseveral years ago a more manageable format was adopted, as people have no other time to \\nread newspapers but on their way to work. Thus, the newspaper format can hardly serve as a \\ncritical quality factor of the printed media of today.  The Berliner format is a blending'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 3, 'page_label': '4', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='read newspapers but on their way to work. Thus, the newspaper format can hardly serve as a \\ncritical quality factor of the printed media of today.  The Berliner format is a blending \\nbetween broadsheets and tabloids. Some broadsheet newspapers in Britain have looked to the \\nBerliner format as a portable-size format, without the typically applied negative connotations \\nto tabloids. For example, the Guardian adopted the Berliner format in 2005 right after \\ncompeting broadsheet newspapers had switched to the tabloid format. Tabloids are the \\nsmallest newspapers in terms of format as well as the least reputed ones due to their tendency \\nto present rumors, gossips, and sensational news about celebrities. The Times  was printed in \\nbroadsheet format for 219 years but since 2004 it has switched to a tabloid format, both to \\nease its readers with its user-friendly size and to appeal to a much younger audience. Almost'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 3, 'page_label': '4', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='broadsheet format for 219 years but since 2004 it has switched to a tabloid format, both to \\nease its readers with its user-friendly size and to appeal to a much younger audience. Almost \\nall Bulgarian dailies share the tabloid format and have never had a broadsheet one but the \\ndaily Dnevnik which, when initially published, was the only broadsheet daily on the market. \\nThe other broadsheet in the country is the weekly – Kapital  that carters for the public’s need \\nof political, economic and cultural analyses as well as the demand to offer and search for job \\nvacancies in the high, more sophisticated job market niche. Kapital  still shares the broadsheet \\nformat, which is inkeeping with its content and target audience. The weekly is dedicated \\nprimarily to business analyses and its audience comprises highly educated economists, CEOs \\nand the business community in Bulgaria in general.  \\nTechnological advances have allowed printed newspapers to address audiences of'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 3, 'page_label': '4', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='and the business community in Bulgaria in general.  \\nTechnological advances have allowed printed newspapers to address audiences of \\ndifferent reading habits, those who traditionally prefer to buy and read the printed copy of \\ntheir preffered paper, as well as those who are keener on making use of technologies and, \\nrespectively visit the online version of the paper(s), or users of e-book readers who can simply \\ndownload their favoured newspaper, magazine or e-book.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 4, 'page_label': '5', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='5 \\n \\nWhat is the role of the journalist?  For a layperson, the answer to this question may reach as \\nfar as to simply saying “to report or present news” or “to write articles.” However, the reality \\nis much more complex and is worth reviewing. Strange as it may seem, the features of printed \\nand electronic media are so strikingly diversified that they result in many “journalisms.” That \\ndiversity naturally differs from country to country; however, there are numerous similarities \\nthat unify journalism as a whole. With the rapid development and improvement of \\ntechnologies, every personal computer owner is enabled to disseminate information, \\nsometimes, even much wider than the official news organizations. However well organized a \\nwebsite may seem it may not necessarily offer reliable, trustworthy news. Additionally, news \\nis not a scarce commodity any more and, thus the role of the journalist has become more'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 4, 'page_label': '5', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='website may seem it may not necessarily offer reliable, trustworthy news. Additionally, news \\nis not a scarce commodity any more and, thus the role of the journalist has become more \\nimportant that it has ever been before. News items, whether breaking news, features or even \\nanalyses have to be accurate. For the purpose journalist, unlike gossipers and proponents, \\ncollect the information they need to present a story and verify its validity. Objectivity is \\nanother concern with the profession. Journalists are reasoning, thinking human beings and it \\nwould be naïve to think that what is published does not contain personal opinion. Potter states \\nthat ” By using an objective, scientific method for verifying information, journalists can report \\nstories that do not reflect their own personal views. The story itself, in other words, should be \\nimpartial and fair.” (Potter 2006:11). While opinion reflects on personal thoughts,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 4, 'page_label': '5', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='stories that do not reflect their own personal views. The story itself, in other words, should be \\nimpartial and fair.” (Potter 2006:11). While opinion reflects on personal thoughts, \\nunderstanding and believes, fairness refers to the different angles a story is presented. At the \\ntime of which the present work is being written the British jazz and soul singer Amy \\nWinehouse has been found dead in her apartment in Camden, North Lonon. Let us take, for \\ninstance, the news presentation of this news account in the Telegraph online \\n(http://www.telegraph.co.uk/ ). Five days after the news hit the headlines, the Telegraph \\ncontains an influx of items on the topic. The event is presented from several different angles. \\nFirst, it is explicable that the newspaper does not contain breking-news headlines. i.e large \\ntexts in huge fonts, as that is the fifth day after the dead of the celebrity; the event is not'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 4, 'page_label': '5', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='First, it is explicable that the newspaper does not contain breking-news headlines. i.e large \\ntexts in huge fonts, as that is the fifth day after the dead of the celebrity; the event is not \\ntreated as hard news any more, still it forms prolific follow-ups. However, the Telegraph \\nacknowledges the event in the Obituary section with a detailed bibliographical article, \\npresenting the chronological events and artistical achievements of the life of the renowned, \\nand at the same time notorious, singer. Confiremed fans are offered to watch and listen to \\nsummarized famous videos of the most popular hit tracks together with the official \\nannouncement of the discovery of the deceased read in public by a superintendant. The tone \\nof the announcemet is neutral at the start; however, it finishes with the police, as institution, \\nexpressing deep regrets and sorrow following the tragic news. The section Culture presents a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 5, 'page_label': '6', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"6 \\n \\nfull-length interview with Amy Winehouse that is claimed to be the last ever, conducted by \\nNeil McCormick, who has been the most prominent music critic for the The Telegraph since \\n1996. Concomitant events are featured, albeit short in time and span, related to the funeral \\nceremony of the singer. Here are the headlines directly copied and pasted from the online \\nTelegraph; the size of font and typeface are the original ones. If the selection of typeface and \\nfont size bring about the level of importance of news stories and events being projected on a \\nnewspapers page then the full story of the death of the British jazz and soul singer are given \\nequal prominence (see Hodson 1984:100; Ivancheva 2005:261).  \\n1.Amy Winehouse: police continue investigation into \\nmusician's death \\n2.Amy Winehouse: the final interview by Neil McCormick  \\n 3.Amy Winehouse's last public appearance \\n4. Amy Winehouse 'drunk' on stage in Belgrade \\n5. Amy Winehouse's parents visit singer's Camden home\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 5, 'page_label': '6', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"3.Amy Winehouse's last public appearance \\n4. Amy Winehouse 'drunk' on stage in Belgrade \\n5. Amy Winehouse's parents visit singer's Camden home \\n6. Amy Winehouse 'looked fine' day before death \\n7. Former collaborator Mark Ronson arrives for Amy \\nWinehouse memorial \\nThe representation of the story of Winehouse is an illustrative example of what fair \\njournalism should be, i.e “…to report all significant viewpoints in a way that is fair to those \\ninvolved and that also presents a complete and honest picture to the audience.”(  Potter  \\n2006:16).  \\nTo sum up, contemporary journalists are to perform challanging, complicated multitasking. In \\ntheir pursuit for independence from the people or organizations they write about, journalists \\nstruggle to strike a balance between an objective, fair representation deprived of explicit \\npersonal opinion. They search contrasting views and report them without taking one side or\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 5, 'page_label': '6', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='struggle to strike a balance between an objective, fair representation deprived of explicit \\npersonal opinion. They search contrasting views and report them without taking one side or \\nanother. Journalists do original reporting being able to differentiate between fact, opinion, and \\nrumour.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 6, 'page_label': '7', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='7 \\n \\nWhat is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \\nsociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \\nstudies. Stuart Hall states that:  \\nThe media do not simply and transparently  report events which are \\nnaturally newsworthy in themselves. News is the end product of a \\ncomplex process, which begins with systematic sorting and selecting \\nof events and topics according to a socially constructed set of \\ncategories.  \\n       Stuart Hall ( in Fowler1991:12) \\n  Philo goes on even further to maintain that news is not found or even gathered. It is a \\ncreation of a journalistic process, an artefact, and a commodity ( in Fowler 1991). The last \\nstatement, as discussed above, is hardly applicable in the contemporary era of mass \\ncommunication, where, with the existence of the internet, everybody can have access to \\npractically any nugget of information. Brighton and Foy are of the opinion that:'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 6, 'page_label': '7', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='communication, where, with the existence of the internet, everybody can have access to \\npractically any nugget of information. Brighton and Foy are of the opinion that: \\nIt is news values that give journalists and editors a set of rules – often \\nintangible, informal, almost unconscious elements – by which to work, \\nfrom which to plan and execute the content of a publication or a broadcast. \\nIn its purest sense everything that happens in the world is a new event, and \\nsomebody, somewhere, will have some level of interest in that occurrence. \\nBut what takes it from being new to being news? The set of values applied \\nby different media – local, regional, national and international, print, \\ntelevision, radio, internet, bulleting board – are as varied as the media \\nthemselves.  \\n    Brighton and Foy (2007:1) \\n A classical definition of what constitutes news values was developed by two Norwegian \\nsocial scientists Johan Galtung and Mari Homboe Ruge and officially published back in \\n1965.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 6, 'page_label': '7', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='A classical definition of what constitutes news values was developed by two Norwegian \\nsocial scientists Johan Galtung and Mari Homboe Ruge and officially published back in \\n1965.  \\n  The list of criteria is as follows (in Fowler 1991:13): \\n/head2right Frequency.  An event is more likely to be reported if its duration is close to the \\npublication frequency of the news medium. Because newspapers are published once a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 7, 'page_label': '8', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='8 \\n \\nday, a single event is more likely to be reported rather than a long process one. For \\ninstance, the publication of unemployment figures on a certain day is more \\nnewsworthy than the long-term phenomenon of unemployment itself. \\n/head2right Threshold.  Refers to the ‘size’ needed for an event to become newsworthy. For \\nexample, an accident involving  a hundred people is more likely to be published than \\none involving two or three people. \\n/head2right Unambiguity .  Mysterious events as well as clear ones are newsworthy if they can be \\nrelated to cultural stereotypes, where a stereotype is a socially-constructed mental \\npigeon-hole into which events and individuals can be sorted, thereby making such \\nevents and individuals comprehensible. \\n/head2right Meaningfulness  (with its two subcategories Cultural proximity and Relevance).  \\nRefers to a preoccupation with countries, societies and individuals perceived to be \\nlike oneself.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 7, 'page_label': '8', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='/head2right Meaningfulness  (with its two subcategories Cultural proximity and Relevance).  \\nRefers to a preoccupation with countries, societies and individuals perceived to be \\nlike oneself.  \\n/square4 Cultural proximity.  Relates to geographical closeness of a country. \\nCultural proximity is founded on an ideology of ethnocentrism: a \\npreoccupation with countries, societies and individuals perceived to \\nbe like oneself  (Fowler 1991). \\n/square4 Relevance. If Culture1 and Culture2 i1 are geographically far away but \\nin Culture1 it is likely to happen the same type of event, so Culture1 is \\naffected in the same way as Culture2. \\n/head2right Consonance  with its two sub criteria predictability  and demand  refer to categories of \\nevents which people either expect to happen or want to happen, e.g. Royal weddings \\nand births. \\n/head2right Unexpectedness .  An event is even more newsworthy if it happens without warning or \\nis unusual.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 7, 'page_label': '8', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='and births. \\n/head2right Unexpectedness .  An event is even more newsworthy if it happens without warning or \\nis unusual. \\n/head2right Continuity.  Once an event is defined as news, it will continue to be news even though \\nits amplitude may be less. Moreover, even ‘non-events’ which are part of the story will \\nbe covered. \\n/head2right  Composition . Refers to the balance of a paper bulletin, that is, an item will be more or \\nless newsworthy depending on what else is available for inclusion. \\n/head2right Reference to elite nations. Encodes a ‘superpowers’ ideology of the dominating status \\nof North America, Japan, Europe and Russia in world political and cultural affairs. \\n                                                             \\n1 Where Culture1 is the culture of the recipient of the information and Culture2 is the culture of the target \\ncountry.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 8, 'page_label': '9', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"9 \\n \\n/head2right Reference to elite people. Refers to media's infatuation of celebrities, e.g. Bill Clinton, \\nUS President between 1993 – 2001 more popular among ordinary people with the \\nLewinski Scandal. \\n/head2right Reference to persons (Personalisation). Whenever possible events are seen as the \\nactions of people as individuals. Personalisation varies from paper to paper being most \\nstriking in the popular press. \\n/head2right Reference to something negative.   It suggests that news take the normal for granted, \\nand so is driven to make stories out of deviant: crime, dissidence, disaster. As Fowler \\n(1991) points out, negativity is a value rather than anything more natural: there is no \\nnatural reason why disasters should be more newsworthy than triumphs.  \\nThe set of criteria can also be summarized under the following unifying headings: \\n1.  Impact : frequency, unambiguity, threshold, negativity, unexpectedness\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 8, 'page_label': '9', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='The set of criteria can also be summarized under the following unifying headings: \\n1.  Impact : frequency, unambiguity, threshold, negativity, unexpectedness \\n2.  Audience identification : personalization, meaningfulness, reference to elite nation, \\nreference to elite persons. \\n3.  Pragmatics of media coverage : consonance, continuity, composition \\n \\nJohan Galtung and Mari Ruge’s seminal work on the taxonomy of news values that make an \\nevent become news, or that serves as criteria for selection prior to publication, has been the \\ncore of a great amount of encuing scientific research elaborating on the issue of \\nnewsworthiness.  Several attempts to revise the list of criteria have been made since the \\noriginal publication appeared in the 1965 edition of the Journal of International Peace \\nStudies , entitled Structuring and Selecting News . For example, Denis MacShane 2 (quoted in \\nBrighton and Foy 2007: 8) suggested later in 1979 a new subdivision of newsworthy events'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 8, 'page_label': '9', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='Studies , entitled Structuring and Selecting News . For example, Denis MacShane 2 (quoted in \\nBrighton and Foy 2007: 8) suggested later in 1979 a new subdivision of newsworthy events \\ninto several categoris such as: \\n/head2right Conflict \\n/head2right Hardship and danger to the community \\n/head2right Unusualness (oddity, novelty) \\n/head2right Scandal \\n/head2right Individualism \\n                                                             \\n2 Denis MacShane  is a British politician, who has been theMember of Parliament (MP) for Rotherham since \\nthe 1994 by-election and served as the Minister for Europe from 2002 until 2005. From 1969 to 1977 he worked \\nas a newsreader and reported for  BBC Radio Birmingham. (http://en.wikipedia.org/wiki/Denis_MacShane )'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 9, 'page_label': '10', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='10 \\n \\nMost of the above have more to do with impact like conflict, scandal unusualness, hardship \\nand danger to community; individualism falls into the category of audience identification. \\nWhat MacShane fails to isolate as a criterion is the pragmatic news value of stories in a news \\norganization diary that bring about the balance of any meadia in question.  \\nHardcup and O’Neill argue that Galtung and Ruge’s taxonomy possesses certain problematic \\nareas and, thus the authors pose the following questions: \\n/head2right Frequency . How does this relate to stories that are not about events at all, but about \\ntrends, speculation, or even the absence of events? \\n/head2right Threshold. Isn’t this still open to subjective interpretation? Which is bigger – 20 \\ndeaths in ten road accidents or five deaths in one rail crash? \\n/head2right Unambiguity.  Is the ambiguity in the subject or the journalist’s interpretation?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 9, 'page_label': '10', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='deaths in ten road accidents or five deaths in one rail crash? \\n/head2right Unambiguity.  Is the ambiguity in the subject or the journalist’s interpretation? \\n/head2right Meaningfulness.  This is a slippery concept that changes over time and relies on \\nsubjective interpretation. \\n/head2right Unexpectedness.  How can we tell if the journalist is simply taking an unexpected \\nangle on a predictable event? \\n/head2right Consonance . How useful is this category if it is possible only to guess if and when it \\nhas applied? \\n/head2right Composition . How is it possible to know what was in the selector’s mind when \\nmaking a particular decision? \\n/head2right Elite Nations . The dearth of foreign news in UK tabloids newspapers renders this \\nrelatively infrequently identified factors; does that mean it does not apply? \\n/head2right Elite People . How useful is a category that does not distinguish between the Spice \\nGirls and the President of the USA?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 9, 'page_label': '10', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='/head2right Elite People . How useful is a category that does not distinguish between the Spice \\nGirls and the President of the USA? \\n/head2right Reference to persons . Is this intrinsic to the subject or the journalist’s technique? \\n/head2right Reference to something negative . Negative for whom? Bad news for some might be \\ngood news for others.  \\n   Hardcup and O’Neill, 2001 (in Othman and Tiung 2009 )\\n     \\nAs a result of their study Hardcup and O’Neill (in Brighton and Foy  2007: 8) present their list \\nof criteria.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 10, 'page_label': '11', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='11 \\n \\n/head2right Power elite - powerful individuals, polititians, tycoons, organisations or institutions \\n(e.g Boiko Borisov PM of Bulgaria, Donald Trump, Robert Kiyosaki, etc.); \\n/head2right Celebrity  - people who are already famous or notorious; \\n/head2right Entertainment -  sex, gay couples,  music, theatre, stories of human interest, romantic \\ndrama, intriguing photographs, etc.;   \\n/head2right Surprise  – surprising events, both positive or negative in content; \\n/head2right Bad news – conflicts, tragedies – events with overall negative connotations; \\n/head2right Good news  – rescues, cures, survivals – events with overall positive connotations; \\n/head2right Magnitude  – events whose number of people involved is of paramount importance ,or \\nwhose impact concerns a grat number of people; \\n/head2right Relevance  - events that concern specific groups of people and/or whole nations \\nrelevant to the readership;'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 10, 'page_label': '11', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='whose impact concerns a grat number of people; \\n/head2right Relevance  - events that concern specific groups of people and/or whole nations \\nrelevant to the readership; \\n/head2right Follow-ups  – news items that have already been in the news and continue to develop; \\n/head2right Media agenda  - stories that set or fit the news organisation’s own agenda. \\nHardcup and O’Neill’s classification of news values fall in three major summarized areas. \\nThe first is related to the protagonists within a strory, i.e powr elite, celebrities; the second has \\na conceptual essence, for instance – relevance. The third comprises the notion of media \\npractices – follow-ups, media agenda. \\nJohan Galtung and Mari Homboe Ruge Hardcup and O’Neill \\nFrequency  \\nThreshold Magnitude \\nUnambiguity  \\nMeaningfulness Relevance \\nConsonance  predictability demand  Entertainment \\nUnexpectedness Surprise \\nContinuity Follow-ups \\nComposition Media agenda \\nReference to elite nations  \\nReference to elite people Celebrity'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 10, 'page_label': '11', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='Consonance  predictability demand  Entertainment \\nUnexpectedness Surprise \\nContinuity Follow-ups \\nComposition Media agenda \\nReference to elite nations  \\nReference to elite people Celebrity \\nPersonalisation  \\n Power elite \\nReference to something negative  Bad news, Good news  \\nTable 3'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 11, 'page_label': '12', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='12 \\n \\nMoreover, a brief comparison of the two pairs of scholars’ research reveals a predominant \\noverlap of the news values criteria (see Table 3). Hardcup and O’Neill’s idea of “size” of an \\nevent, termed magnitude, is nothing different from Galtun and Ruge’s threshold. \\nMeaningfulness and relevance both refer to the notion of the acceptance and self-\\nidentification of a culture “preoccupied with countries, societies and individuals perceived to \\nbe like oneself,” as Fowler words it (Fowler 1991). Some might argue that a culture can be a \\nconstruct of many subcultures, which virtually is true, and one event may not be equally \\nrelevant to the whole multitude of cultures; however, that argument, to my mind, reflects on \\nthe type of media and its readership profile’s interest. Consonance and entertainment also \\nhave similar connotations. If consonance refers to peoples’ expectations or need something to'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 11, 'page_label': '12', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='the type of media and its readership profile’s interest. Consonance and entertainment also \\nhave similar connotations. If consonance refers to peoples’ expectations or need something to \\nhappen, then all types of events like, gay weddings, personal drama, organized events \\n(theathre, music concerts, etc) cater for peoples’ demand to satisfy their curiosity, need for \\nrelaxation and quench their thirst for human-interest information. Continuity and follow-ups \\nreflect the tendency for some event to fail to drop news bulletins, having already been in the \\nnews. These events are predominantly of negative nature, such as murders, natural disasters, \\nepidemics; rarely are there follow-ups of good news unless the protagonists are of royal origin \\nor non-royal one, which is the case of the marriage between the British Prince William and \\nCatherine Middelton on 29 th  April, 2011 at Westminster Abbey. As Fowler rightly defines'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 11, 'page_label': '12', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='or non-royal one, which is the case of the marriage between the British Prince William and \\nCatherine Middelton on 29 th  April, 2011 at Westminster Abbey. As Fowler rightly defines \\nsuch negative occurrences in the media as “hysteria in the Press,” especially in the printed (as \\nwell as online, it must be noted) press, giving an illustrative example of a roughly three-month \\ncontinuity of salmonella panic among the British (between late November, 1988 and early \\nMarch, 1989) (Fowler 1991: 148). Composition and media agenda imply technical media \\npractices referring to the choice of media what else is available to include on a specific day. \\nSuch choices could be also dependent on hard news as prominence is heavily dependent on \\njuxtaposed news items, especially in the printed press (see Ivancheva 2005). Reference to elite \\npeople compares to Hardcup and O’Neill’s celebrity where both teams of researchers refer to'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 11, 'page_label': '12', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='juxtaposed news items, especially in the printed press (see Ivancheva 2005). Reference to elite \\npeople compares to Hardcup and O’Neill’s celebrity where both teams of researchers refer to \\nthe notoriety of already popular people whose public behavior frequently makes newspaper \\nheadlines. Last but not least, most of the concepts of both lists totally coincide or repeat each \\nother; their difference is only a matter of synonymy. \\nStuart Hall (ibid) distinguishes between formal and ideological news values. The \\nformer are: \\n/head2right Linkage  – Has the story got any connection with previous events and \\noccurrences, or does it allow journalists to link it to any of the above?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 12, 'page_label': '13', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='13 \\n \\n/head2right  Recency  – Has the event happened lately and how much worthy is it from the \\npoin of view of the present moment? \\n/head2right Newsworthiness of event/person \\nIn their book, News Values  published in 2007 the two practitioner-academics Paul Brighton \\nand Dennis Foy attempt to present a revisited and more contemporary version of the news \\nvalues theory. The authors discuss newspaper, radio and television practices, as well as the \\ninternet news channels. They suggest seven criteria, which are: \\n/head2right Relevance  – the significance of an item to the viewer, listener, or reader.  \\n/head2right Topicality  – Is it new, current, immediately relevant?  \\n/head2right Composition  – How a news item fits with the other items that surround it. \\n/head2right Expectation  – Does the consumer expect to be told about this?  \\n/head2right Unusualness  – What sets it apart from other events, which are not reported?  \\n/head2right Worth  – Does it justify its appearance in the news?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 12, 'page_label': '13', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='/head2right Unusualness  – What sets it apart from other events, which are not reported?  \\n/head2right Worth  – Does it justify its appearance in the news?  \\n/head2right External influences – Is the content of a news item pure, or has it been \\ncorrupted by pressure from outside, such as a proprietor, an advertiser or \\npolitician?          \\n      (Brighton and Foy  2007:26) \\nThe criterion relevance corresponds to Galtung and Ruge’s term of consonance. Relevance is \\na broad notion and, as the writers claim ‘”…it is this aspect of the news values system that is \\ninstinctively deployed by professional news-gatherers, who will often claim to ‘know the \\naudience’.”(Brighton and Foy 2007). A car crash, let us say, in Durhum, UK, with one \\ncasualty will be of direct interest only to those who reside in Durhum. However, if the \\ncasualty happens to be a Bulgarian, then the car- crash accident will, most probably, become a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 12, 'page_label': '13', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='casualty will be of direct interest only to those who reside in Durhum. However, if the \\ncasualty happens to be a Bulgarian, then the car- crash accident will, most probably, become a \\nleading news item for most dailies and electronic newscasts in Bulgaria.  \\nTopicality has to do with events like anniversaries of historical events as 1 9th  February in \\nBulgaria, which commemorates either the birth or the death of the prominent Bulgarian hero – \\nVassil Levski, who idelogised a revolutionary movement to liberate Bulgaria from Ottoman \\nrule. In such cases, there are planned media agendas at work.  \\nComposition is as old criterion as that of Galtung and Ruge’s publication in 1965, \\ncorresponding to the common market law of demand and supply. A news editor will provide \\ntheir readership with what is felt to be the demand and, will respectively strive to achieve a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 13, 'page_label': '14', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='14 \\n \\nbalanced presentation of various news items – the supply, also taking into consideration the \\nmarket competition with other media available in the respective country. \\n Anything that is likely to have an impact on the public falls in the category of expectation. A \\ndrug dealer, caught red handed selling dope to the schoolchildren in the local school; a singer \\nthat is alledgedly thought to have had a love affair with a country’s president (e.g. the \\nBulgarian singer Mariana Popova and the President of the Republic of Bulgaria - Georgi \\nParvanov); a local hospital medicals that ridiculously confirm only two final diagnosis of their  \\npatients as the hospital management has just two clinical pathways contracted with the \\nNational Health Insurance Fund; pediatritians that charge underaged patients a consumer tax; \\na bomb scare in the subway of London. All of the above examples are of information that the \\npublic expects to be told about, locally, nationally, or internationally.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 13, 'page_label': '14', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='a bomb scare in the subway of London. All of the above examples are of information that the \\npublic expects to be told about, locally, nationally, or internationally.  \\nAs far as unusualness is concerned, it is clearly exemplified by the popular journalistic quote -\\nwhen a dog bites a man that is not news, because it happens so often. But if a man bites a dog, \\nthat is news. 3 The quote self-sufficiently identifies the nature if such unexpected, sensational, \\nunplanned events and happenings that inevitably become hard news, forming large-point fonts \\nand specially typefaced headlines in the printed media, as well as the breaking news items of \\nnewscasts. It would not be an exaggeration to state that unusual events turn into hard news – \\nthe staple diet of media.  \\nThe criterion worth, to my mind, is similar to Galtung and Ruge’s ideas of threshold with the \\nsubtle difference that Brighton and Foy attribute not only to the “size” of the event, but to the'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 13, 'page_label': '14', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='The criterion worth, to my mind, is similar to Galtung and Ruge’s ideas of threshold with the \\nsubtle difference that Brighton and Foy attribute not only to the “size” of the event, but to the \\ntype of protagonists involved as well; rather its assimilation with the formers’ reference to \\nelite nations or people.  The authors discuss the newsworthy nature of the subjects whether \\nthey are popular at all to have any impact on the public’s interest and lives of people. The \\nscholars, rightly though, go on to discuss the contemporary implication of the lexical item \\n“celebrity,” which refers not only to politically involved persons but also musicians, actors, \\nactresses, and even soap opera stars.  \\nLast but not least, the writers discuss external influences as a criterion with regard to human-\\ninterest factors that might prevent an event from becoming a news item like, for example the'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 13, 'page_label': '14', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='interest factors that might prevent an event from becoming a news item like, for example the \\n                                                             \\n3 The origin of the popular quote is yet controversial. Several hypotheses exist: 1.It is said to have been coined \\nby Alfred Harmsworth, a British newspaper magnate. 2. It is attributed to Charles Anderson Dana (1819 – 1897) \\nan American journalist, author, and government official; or to 3. John B. Bogart (1848–1921),  New York \\nSun  editor. (see http://en.wikipedia.org/wiki/Man_bites_dog_(journalism))'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 14, 'page_label': '15', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='15 \\n \\nowner of a news corporation’s control over what is published/ aired or not ( see Brighton and \\nFoy 2007:164). \\n \\nConclusion.\\n  The theory of what makes events become potential news has been, as \\nsuccincltly discussed, the focus of attention to scholars of different scientific background. \\nJohan Galtung and Mari Homboe Ruge unarguably set the beginning of a critical approach to \\nmedia practices not only of high relevance to those professionally involved, but also to those \\nwho consume media products. The encuing revisions of the original taxonomy have added \\nnew shades of what news values could be at the dawn of the 21 st  centrury. The widespread \\napplication of technology and all available means of mass communication give rise to the \\napplicability of some of the original criteria. When the Norwegian scholars conducted their \\nresearch in 1965 (or, logically prior to the date of the publication of their results), the internet'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 14, 'page_label': '15', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='applicability of some of the original criteria. When the Norwegian scholars conducted their \\nresearch in 1965 (or, logically prior to the date of the publication of their results), the internet \\nwas non-existent. Hence, a criterion as frequency, in their terminology, has taken new \\nconnotations, especially with new practices of printed media to sell yesterday today’s news \\n(most newspapers are on the stalls the night before the date of their publication in Bulgartia). \\nWhat is more, the online versions of printed newspapers, being advantageous of the \\ncapabilities of technological advances, update hard news as frequently as it is felt to be \\nnecessary; and change the so called news in brief (NIB), which is said to be space fillers. \\nGiven that, composition as criterion calls for further research, albeit some authors (Hardcup \\nand O’Neill; Brighton and Foy 2007) attribute it to media agenda. In contrast, MacShane’s'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 14, 'page_label': '15', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='Given that, composition as criterion calls for further research, albeit some authors (Hardcup \\nand O’Neill; Brighton and Foy 2007) attribute it to media agenda. In contrast, MacShane’s \\nfailure to discuss such pragmatic practicalities of media coverage and focus of attention to \\nimpact and audience identification (see above) could be ascribed to his having been a \\npractitioner, rather than a scholar, thus considering such criterion as a taken-for-granted one \\namong professionals. Moreover, it is worth noting that journalists are critical-thinking \\nmembers of a sociocultural environment and, despite their professional ethics to objectively \\npresent news, they still have an opinion on events and happenings. Personal opinion can be \\nencoded in any utterance by means of special usage of the verb system of the target language \\n(e.g Active vs Passive Voice; positive vs negative connotation; modality);syntax (e.g elliptical'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 14, 'page_label': '15', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='encoded in any utterance by means of special usage of the verb system of the target language \\n(e.g Active vs Passive Voice; positive vs negative connotation; modality);syntax (e.g elliptical \\nsentences; metaphors); nominal syntagms (choice of adjectives); phonostylistical devices, etc. \\nThese phenomena possess their peculiarities as far as languages are concerned and they would \\nbe worth investigating from sociolinguistic/sociocultural point of view in futher research \\npaper work.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 15, 'page_label': '16', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='16 \\n \\nExternal influences in Brighton and Foy’terminology set another aspect of news gathering. \\nMedia ownership self-sufficiently establishes what and, more importantly, whose ideas a \\nmedium voices. Downie and Schudson, 2002 suggest a new perspective of what influences \\nmeadia choices of news presentation: \\n“…the economic foundation of the nation’s newspapers, long supported by advertising, is \\ncollapsing, and newspapers themselves, which have been the country’s (the USA here) chief \\nsource of independent reporting, are shrinking literally. Fewer journalists are reporting less \\nnews in fewer pages. ” \\n      Downie and Schudson 2002( Fenton 2011:3) \\nThe picture is almost identical in Central and Eastern Europe and the Commonwealth of \\nIndependent States: Albania, Armenia, Bosnia and Herzegovina, Bulgaria, Czech Republic, \\nEstonia, Hungary, Kyrguzstan, Latvia, Lithuania, Macedonia, Modlova, Montenegro, Poland,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 15, 'page_label': '16', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='Independent States: Albania, Armenia, Bosnia and Herzegovina, Bulgaria, Czech Republic, \\nEstonia, Hungary, Kyrguzstan, Latvia, Lithuania, Macedonia, Modlova, Montenegro, Poland, \\nRomania, Serbia, Slovakia, and Ukraine, according to an investigation conducted by the Open \\nSociety Institute Media Program (OSI 2010) (ibid).  \\nOn balance, the process of newsgathering is a complex phenomenon. The theoretical \\ntaxonomies in academic literature, on the one hand, present one possible aspect of what types \\nof events are prone to turn into news items. The human interference as a journalistic choice, \\npersonal values, stereotypes, and cultural belonging add to the picture of news selection and \\npresentation. Media ownership together with political and economic factors are other criteria \\nthat influence media contents. Audiences and readership profiles are to be taken into \\nconsideration as well. Finally yet importantly, news values are then to be viewed as qualities'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 15, 'page_label': '16', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"that influence media contents. Audiences and readership profiles are to be taken into \\nconsideration as well. Finally yet importantly, news values are then to be viewed as qualities \\nof potential reports and they are not simply features of selection but features of representation. \\nNews events, being systematically sorted and selected, are to be carefully worded, designed, \\nprojected and given prominence to on the newspaper's pages, computer and television screens.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 16, 'page_label': '17', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"17 \\n \\nBibliography \\n \\nBell, Garret 1998: Bell, Allan, Garrett, Peter. Approaches to Media Discourse. //Oxford: \\nBlackwell Publishers, 1998 \\nBranston, Stafford  1999:  Branston,Gill, Stafford, Roy. The Media Student's Book. London: \\nRoutledge,1999 \\nDijk 1985:   Dijk, Teun, Adrianus, van. Handbook of Discourse Analysis vol.2 Dimensions of \\nDiscourse, Florida: Academic Press, 1985 \\nFedler, Bender,Davenport,Drager 1999: Fedler, Fred, Bender, Jhon, Davenport, Lucinda, \\nDrager, Michalel. Reporting for the Media. Haracourt Brace & Company,1999 \\nFenton 2011:  Fenton, Natelie. Deregulation of democracy? New media, news, neoliberalism and \\nthe public interest.// Continuum: \\n 25: 1, 63 — 72, Routledge \\nFiske 1990: Fiske, John. Introduction to Communication Studies (2 nd ed). London and New York: \\nRoutledge, 1990 \\nFowler 1991: Fowler, Roger. Language in the News: Discourse and Ideology in the Press. \\nLondon: Routledge, 1991\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 16, 'page_label': '17', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"Routledge, 1990 \\nFowler 1991: Fowler, Roger. Language in the News: Discourse and Ideology in the Press. \\nLondon: Routledge, 1991 \\nGaltung, Ruge 1965:  Galtung, Johan, Ruge, Marie, Holmboe. Structure of Foreign News. Sage \\n<\\nhttp://www.blisty.cz/files/2010/07/20/galtung-structure-foreign-news-1965.pdf > (27.08.2011)  \\nHodgson 1984:  Hodgson, F. W. Modern Newspaper Practice. Oxford: Focal Press, 1984 \\nKeeble 1994:  Keeble, Richard.  The Newspapers Handbook. London and New York: Routledge, \\n1994 \\nO'Sullivan, Dutton, Rayner  1994:  O'Sullivan, Tim, Dutton, Brian, Rayner, Philip.  Studying the \\nMedia: An Introduction. London: Arnold, 1994 \\nOthman, Tiung 2009:  Othman, Siti, Suriani, Tiung.Lee,Kuok. The News Types of Two \\nCountries: A Comparative Study of News Values Quality Newspapers and Popular Newspapers in \\nMalaysia and Britain.//Sosiohumanica \\n<\\nhttp://www.sosiohumanikajpssk.com/sh_files/File/siti.lee.usim.ums.pdf > (27.08.2011)\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 16, 'page_label': '17', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='Malaysia and Britain.//Sosiohumanica \\n<\\nhttp://www.sosiohumanikajpssk.com/sh_files/File/siti.lee.usim.ums.pdf > (27.08.2011) \\nPotter 2006: Potter, Deborah., (2006) Handbook of Independent Journalism , Bureau of \\nInternational Information Programmes: U.S Department of State \\n< http://www.america.gov/media/pdf/books/journalism.pdf#popup > (27.08.2011)  \\nReah 1998:  Reah, Danuta. The Language of Newspapers. London: Routledge,1998 \\nSimpson 1993:  Simpson, Paul.  Language Ideology and Point of View. London: Routledge, 1993 \\nIvancheva 2005:   Ivancheva, Theodora. Comparative Analysis of Linguistic and Non-linguistic \\nMethods of Projecting News Values in the Dailies Trud and The Times.// New Bulgarian \\nUniversity, vol. 6. Sofia, 2005'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 17, 'page_label': '18', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='18 \\n \\n \\nWebsites: \\n \\nhttp://en.wikipedia.org/wiki/Denis_MacShane  \\nhttp://en.wikipedia.org/wiki/Man_bites_dog_(journalism) \\nhttp://www.natcorp.ox.ac.uk/  \\nhttp://www.telegraph.co.uk/'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 18, 'page_label': '19', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"19 \\n \\nAPPENDIX \\n(Here is a random selection of 50 solutions from the 14684 found). \\nA1R  3 THE STORY was that Breakfast News (BBC 1), the third relaunch of the cereal \\ntelevision which began in 1983 as Breakfast Time with Frank Bough and Selina Scott \\nchummy in jumpers, was going serious. (A1R  [Independent, electronic edition of 19891003].  \\nLondon: Newspaper Publishing plc, 1989, Arts material, pp. ??. 61 s-units, 1545 words. ) \\nA29  54  The People's Daily, the Communist party organ, published news of his death nearly \\ntwo weeks late but avoided any harsh commentary.( A29  [Independent, electronic edition of \\n19891004].  London: Newspaper Publishing plc, 1989, Gazette material, pp. ??. 133 s-units, \\n3354 words. ) \\nA2F  17  News of the Prague embassy's open door seems likely to provoke a greatly increased \\nflow of new emigrants from East Germany. (A2F  [Independent, electronic edition of \\n19891004].  London: Newspaper Publishing plc, 1989, Title material, pp. ??. 138 s-units, 3149\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 18, 'page_label': '19', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"flow of new emigrants from East Germany. (A2F  [Independent, electronic edition of \\n19891004].  London: Newspaper Publishing plc, 1989, Title material, pp. ??. 138 s-units, 3149 \\nwords. ) \\nA3D  13  Foreign News Page 10 (A3D  [Independent, electronic edition of 19891007].  London: \\nNewspaper Publishing plc, 1989, Foreign material, pp. ??. 439 s-units, 9297 words. ) \\nA8F  406  No wonder he can't bring himself to show much emotion at the news of his family's \\ndemise.( A8F  [Guardian, electronic edition of 19891123].  London: Guardian Newspapers \\nLtd, 1989, Arts material, pp. ??. 888 s-units, 18531 words. ) \\nABH  1649  The prime minister warned MPs that the Gulf war would not be ‘an easy or \\npainless business’ and readied them for ‘difficult news’to come. (ABH  The Economist.  \\nLondon: The Economist Newspaper Ltd, 1991, pp. ??. 3341 s-units, 60150 words. ) \\nAC2  1057  That afternoon the convener communicated his version of the story to the shop\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 18, 'page_label': '19', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"London: The Economist Newspaper Ltd, 1991, pp. ??. 3341 s-units, 60150 words. ) \\nAC2  1057  That afternoon the convener communicated his version of the story to the shop \\nsteward's committee and within an hour every department was buzzing with the news. (AC2  \\nMan at the sharp end.  Kilby, M. Lewes, East Sussex: The Book Guild Ltd, 1991, pp. ??. 2565 \\ns-units, 36227 words. ) \\nACG  1865  Though he sits by the gate of Shiloh, in his blindness watching the road, he is \\nnearly the last in the town to hear the news. (ACG  Lo and behold!  Dennis, Trevor. London: \\nSPCK, 1991, pp. ??. 1987 s-units, 36214 words. ) \\nAKG  none  Daily Telegraph, electronic edition of 1992-04-13: News and features. (AKG  \\n[Daily Telegraph, electronic edition of 19920413].  London: The Daily Telegraph plc, 1992, \\nSocial material, pp. ??. 34 s-units, 677 words. ) \\nAKH  919  In 1970 Hall joined the News of the World, where she was woman's editor until\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 18, 'page_label': '19', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"Social material, pp. ??. 34 s-units, 677 words. ) \\nAKH  919  In 1970 Hall joined the News of the World, where she was woman's editor until \\n1988. (AKH  [Daily Telegraph, electronic edition of 19920413].  London: The Daily \\nTelegraph plc, 1992, World affairs material, pp. ??. 963 s-units, 20012 words. (AKH  [Daily \\nTelegraph, electronic edition of 19920413].  London: The Daily Telegraph plc, 1992, World \\naffairs material, pp. ??. 963 s-units, 20012 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 19, 'page_label': '20', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"20 \\n \\nAPW  879  I did not hear the sailor's words, but Lachlan forbade me to waken Hector, he said \\nthe morning would do for the news. (APW  Quest for a babe.  Hendry, Frances Mary. \\nEdinburgh: Canongate Publishing Ltd, 1990, pp. 43-141. 3543 s-units, 37837 words. ) \\nB1R  1566  This remedy may be needed after a fright, rage, vexation, jealousy or hearing bad \\nnews. (B1R  How to use homeopathy.  Hammond, Christopher. Shaftesbury, Dorset: Element \\nBooks Ltd, 1991, pp. 1-134. 2739 s-units, 35304 words. ) \\nB2E  1373  We began to get worse and worse news from the Continent about Concentration \\nCamps, for Jews and others, that were almost unbelievably brutal. (B2E  Oh! sister I saw the \\nbells go down.  Saunders-Veness, Frances. Lewes, East Sussex: The Book Guild Ltd, 1989, \\npp. 7-73. 1596 s-units, 25384 words. ) \\nC86  1607  When Creed called, Jed was watching a news report about a vulture who'd just \\nbeen arrested on a murder charge. (C86  The five gates of hell.  Thomson, Rupert. London:\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 19, 'page_label': '20', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"C86  1607  When Creed called, Jed was watching a news report about a vulture who'd just \\nbeen arrested on a murder charge. (C86  The five gates of hell.  Thomson, Rupert. London: \\nBloomsbury Publishing Ltd, 1991, pp. 123-226. 4332 s-units, 41866 words. ) \\nCBU  603  The news of the near fatal stabbing of WPC Harrison in Liverpool has focused \\nattention again on the vulnerability of women to physical violence, particularly during their \\nworking lives. (CBU  Accountancy.  London: Institute of Chartered Accountants, 1993, pp. ??. \\n5049 s-units, 102586 words. ) \\nCGD  997  Resistance to uncomfortable news, for example a recommendation to give up one's \\nown home, is as strongly present as in earlier life.( CGD  Family work with elderly people.  \\nFroggatt, Alison. Basingstoke: Macmillan Publishers Ltd, 1990, pp. 1-107. 1936 s-units, \\n37812 words. ) \\nCGL  288  This quarterly publication, available to members of CWH is full of news updates on\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 19, 'page_label': '20', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"Froggatt, Alison. Basingstoke: Macmillan Publishers Ltd, 1990, pp. 1-107. 1936 s-units, \\n37812 words. ) \\nCGL  288  This quarterly publication, available to members of CWH is full of news updates on \\nthe aircraft of the CWH Museum along with articles of an historical nature. (CGL  FlyPast.  \\nStamford, Lincs: Key Publishing, 1992, pp. ??. 1934 s-units, 39395 words. ) \\nCH6  9210  ‘I've got some great news,’ she told her mother Barbara Cooper. (CH6  The Daily \\nMirror.  London: Mirror Group Newspapers, 1992, pp. ??. 9610 s-units, 127906 words.) \\nCH7  2499  The former Kent all-rounder was ‘disgusted’ that news of his sacking — along \\nwith batsman Andrew Brown — was announced before the club had told them.( CH7  The \\nDaily Mirror.  London: Mirror Group Newspapers, 1992, pp. ??. 5437 s-units, 84868 words. ) \\nCKB  3038  ‘Have you heard the news?’ (CKB  The raven on the water.  Taylor, Andrew. \\nLondon: Fontana Press, 1992, pp. 7-136. 3819 s-units, 39288 words.)\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 19, 'page_label': '20', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='CKB  3038  ‘Have you heard the news?’ (CKB  The raven on the water.  Taylor, Andrew. \\nLondon: Fontana Press, 1992, pp. 7-136. 3819 s-units, 39288 words.) \\nCR8  776  They were more reassured by the news that the prince was about to give a lunch, \\nwhich would be attended by his son, Prince Ranariddh, who leads FUNCINPEC, and by Chea \\nSim, the general secretary of the CPP.( CR8  The Economist.  London: The Economist \\nNewspaper Ltd, 1993, pp. ??. 3139 s-units, 57460 words. ) \\nCRA  469  FOR a writer who was put in the ‘Garbage School of Literature’ along with \\nTennessee Williams and William Faulkner by the editor of the Jackson Daily News, Eudora \\nWelty has done well for herself. (CRA  The Economist.  London: The Economist Newspaper \\nLtd, 1993, pp. ??. 3317 s-units, 58734 words. )'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 20, 'page_label': '21', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='21 \\n \\nCRC  2650  It owns 40% of Nikkei Quick, a Japanese-language on-line financial news service \\nwhose cubby-hole is the first in which company announcements are placed. (CRC  The \\nEconomist.  London: The Economist Newspaper Ltd, 1993, pp. ??. 4039 s-units, 71921 \\nwords.) \\nCRU  540  The Gay News Defence Committee organised many forms of protest, including a \\nmarch and meeting in Trafalgar Square which attracted 5,000 people. (CRU  Permission and \\nRegulation.  Newburn, T. London: Routledge & Kegan Paul plc, 1992, pp. 1-70. 1152 s-units, \\n31189 words. ) \\nCTD  49  Not such good news from one of the original players in this arena though, Mac-on-\\nRISC house Quorum Software Systems Inc, Menlo Park, California, has filed suit against \\nApple seeking to counter allegations of patent and copyright infringement made by Apple. \\n(CTD  Unigram x.  APT Data Services Ltd., 1993, pp. ??. 418 s-units, 10171 words. )'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 20, 'page_label': '21', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"Apple seeking to counter allegations of patent and copyright infringement made by Apple. \\n(CTD  Unigram x.  APT Data Services Ltd., 1993, pp. ??. 418 s-units, 10171 words. ) \\nCTE  264  Another piece of what sounds like good news is that the entire Coherent 4.0 consists \\nof six floppy disks and ‘installs in less than an hour’. (CTE  Unigram x.  APT Data Services \\nLtd., 1993, pp. ??. 331 s-units, 8060 words. ) \\nEC2  100  ’(News at Ten, 4.6.91). (EC2  ASH Supporters' News Issue No. 29.  London: Action \\non Smoking & Health, 1991, pp. ??. 375 s-units, 7001 words. ) \\nFM2  855  So that's good news. (FM2  Missprint planning meeting (Business). Recorded on 28 \\nMarch 1993 with 5 participants, totalling 15029 words, 1941 utterances (duration not \\nrecorded).  \\nPS000  17 words, 48 utterances.  \\nPS1S1  (`Wendy', female, 25, lexicographer): 8022 words, 782 utterances.  \\nPS1S2  (`Clare', female, 21, transcriber): 1937 words, 353 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 20, 'page_label': '21', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"recorded).  \\nPS000  17 words, 48 utterances.  \\nPS1S1  (`Wendy', female, 25, lexicographer): 8022 words, 782 utterances.  \\nPS1S2  (`Clare', female, 21, transcriber): 1937 words, 353 utterances.  \\nPS1S3  (`Derek', male, 24, transcriber): 3430 words, 480 utterances.  \\nPS1S4  (`David', male, 24, transcriber): 1623 words, 278 utterances. ) \\nFS0  710  Auque's news appeared to point to the fact that John was being held by an Iranian-\\nbacked group, and in March Hashemi Rafsanjani called a news conference in Tehran during \\nwhich he repeated his request that Britain should help locate the missing Iranians in Beirut if \\nit wanted Iran to help with the British hostages. (FS0  Some other rainbow.  Morrell, J and \\nMcCarthy, J. London: Transworld Publishers Ltd, 1993, pp. ??. 1974 s-units, 35288 words. ) \\nGUK  955  The news of Soeur Dosithée's holy and resigned death came on a black-edged card \\nin a black-edged envelope. (GUK  Daughters of the house.  Roberts, Michele. London: Virago\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 20, 'page_label': '21', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"GUK  955  The news of Soeur Dosithée's holy and resigned death came on a black-edged card \\nin a black-edged envelope. (GUK  Daughters of the house.  Roberts, Michele. London: Virago \\nPress Ltd, 1993, pp. 30-153. 3950 s-units, 41259 words. ) \\nGUU  1404  ‘Any news of Ivor?’ she asked gently. (GUU  Freelance death.  Taylor, Andrew. \\nLondon: Victor Gollancz Ltd, 1993, pp. 52-175. 4337 s-units, 40867 words. ) \\nH0M  543  the fucking news… (H0M  Money.  Amis, Martin. London: Penguin Group, 1985, \\npp. ??. 4072 s-units, 41518 words. ) \\nH46  277  NEWS ( H46  Bookseller.  London: J Whitaker & sons, 1993, pp. ??. 1326 s-units, \\n25503 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 21, 'page_label': '22', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"22 \\n \\nHAF  419  NEWS DIGEST ( HAF  The Sunday People.  pp. ??. 1337 s-units, 19285 words. ) \\nHAK  41  After joining Courage, he used his editing experience on in-house newspapers and \\nmagazines and branched out into video news and promotional programmes. (HAK  BAIE \\nNews for communicators in business.  Dorking: Hardman Press, 1993, pp. ??. 399 s-units, \\n8457 words. ) \\nHP4  616  Wimpey News has teamed up with Kuoni, one of the world's leading travel \\ncompanies, to offer readers the chance of visiting one of three exotic holiday destinations for \\nlittle more than the cost of a European holiday. (HP4  [Misc unpublished -- Wimpey \\nnewsletter].  u.p., n.d., pp. ??. 1680 s-units, 33791 words. ) \\nHS2  616  GOLF NEWS ( HS2  Glenpatrick News.  u.p., n.d., pp. ??. 627 s-units, 11375 words. ) \\nHSY  10  More news? (HSY  CompuAdd. The catalogue.  u.p., n.d., pp. ??. 172 s-units, 2733 \\nwords. ) \\nHU1  797  We await further news of quantitative surveys with interest. (HU1  The Embalmer.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 21, 'page_label': '22', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='HSY  10  More news? (HSY  CompuAdd. The catalogue.  u.p., n.d., pp. ??. 172 s-units, 2733 \\nwords. ) \\nHU1  797  We await further news of quantitative surveys with interest. (HU1  The Embalmer.  \\nKnebworth: British Institute of Embalmers, 1993, pp. 3-35. 960 s-units, 18716 words. ) \\nHY5  259  When Charles Emmanuel II died, in 1675, special envoys bringing news of his \\ndeath were treated in both Paris and London as the representatives of a king: both Charles II \\nand Louis XIV wore violet mourning, the colour appropriate for a royal death. (HY5  The rise \\nof modern diplomacy 1450–1919.  Anderson, M S. Harlow: Longman Group UK Ltd, 1993, \\npp. 41-148. 1543 s-units, 44759 words. ) \\nJ1C  2344  Subject: Youth Team News (J1C  [Leeds United e-mail list].  u.p., n.d., pp. ??. 3437 \\ns-units, 40333 words. ) \\nJ1H  2665  Team news for Saturday eagerly awaited. (J1H  [Leeds United e-mail list].  u.p., \\nn.d., pp. ??. 4079 s-units, 46681 words. )'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 21, 'page_label': '22', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"s-units, 40333 words. ) \\nJ1H  2665  Team news for Saturday eagerly awaited. (J1H  [Leeds United e-mail list].  u.p., \\nn.d., pp. ??. 4079 s-units, 46681 words. ) \\nJ27  25  During his lifetime Jesus challenged the people of his time to accept the message of \\nthe ‘Good News’, or Gospel (Mark 1:15). (J27  Short courses in religious and moral \\neducation.  u.p., n.d., pp. ??. 881 s-units, 14566 words. ) \\nJ54  21  I shall definitely be at the airport to meet you and I hope to have some startling and \\nimportant news to give you in person. (J54  The divided house.  Raymond, Mary. UK: F A \\nThorpe (Publishing) Ltd, 1985, pp. 1-236. 2757 s-units, 35534 words. ) \\nK5M  10539  Meanwhile, Colin and Wendy Parry, of Great Sankey, Warrington, saw hopes \\nfor their son Tim snatched away with the news that his condition has deteriorated in the \\nintensive care unit of Liverpool's Walton neurosurgical centre. (K5M  [Scotsman].  u.p., n.d., \\nWorld affairs material, pp. ??. 12622 s-units, 261981 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 21, 'page_label': '22', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"intensive care unit of Liverpool's Walton neurosurgical centre. (K5M  [Scotsman].  u.p., n.d., \\nWorld affairs material, pp. ??. 12622 s-units, 261981 words. ) \\nKAC  8 We, the Editors of the Medau News, would like to know your views and suggestions \\non this subject and look forward to printing them in the January issue. (KAC  Medau News. \\nUK: The Medau Society, 1979, pp. ??. 207 s-units, 3505 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 22, 'page_label': '23', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"23 \\n \\nKCJ  1256  well it's, it's it's on at one o'clock, one o'clock and er it's on erm half past six \\ntonight, well I've taped it at half past six tonight and after everybody's watched the news I've, \\nI watched it after, er, you know, so, I watch it then an hour (KCJ  2 conversations recorded by \\n`James' (PS1C7) between 3 and 6 April 1992 with 2 interlocutors, totalling 13482 words, \\n1486 utterances, and 1 hour 23 minutes 47 seconds of recordings.  \\nPS1C7  (`James', male, 63, retired, DE, north-east England): 7486 words, 735 utterances.  \\nPS1C8  (`Patricia', female, 72, housewife, DE, north-east England): 2953 words, 429 \\nutterances.  \\nPS1C9  (`Margaret', female, 30, housewife, north-east England): 3043 words, 322 utterances. \\n) \\nKGH  1434  To the news we go with with Wipe Out by the Safaris. (KGH  BBC Radio \\nNottingham: radio broadcast (Leisure). Recorded on 10 November 1993 with 9 participants, \\ntotalling 16523 words, 1149 utterances, and lasting 1 hour 30 minutes.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 22, 'page_label': '23', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"Nottingham: radio broadcast (Leisure). Recorded on 10 November 1993 with 9 participants, \\ntotalling 16523 words, 1149 utterances, and lasting 1 hour 30 minutes.  \\nPS388  (`Geoff', male, radio presenter): 1667 words, 146 utterances.  \\nPS389  (`Sue', female): 605 words, 31 utterances.  \\nPS38A  (`Teresa', female, radio weather forecaster): 530 words, 35 utterances.  \\nPS38B  (male, 10+, schoolchild): 280 words, 24 utterances.  \\nPS38C  (male, 10+, schoolchild): 1021 words, 88 utterances.  \\nPS38D  (male, 10+, schoolchild): 99 words, 15 utterances.  \\nPS38E  (male, 10+, schoolchild): 208 words, 25 utterances.  \\nPS38F  (male, 10+, schoolchild): 6740 words, 508 utterances.  \\nPS38G  (`Trudy', female): 1094 words, 176 utterances. ) \\nKLV  534  So there's some good news there. (KLV  General Portfolio management meeting \\n(Business). Recorded on 7 April 1993 with 9 participants, totalling 16821 words, 834 \\nutterances (duration not recorded).  \\nPS000  4813 words, 478 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 22, 'page_label': '23', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"(Business). Recorded on 7 April 1993 with 9 participants, totalling 16821 words, 834 \\nutterances (duration not recorded).  \\nPS000  4813 words, 478 utterances.  \\nPS3SF  (`Mike', male, 40+, group manager, London): 9438 words, 189 utterances.  \\nPS3SG  (`Robert', male, 45+, team manager, Home Counties): 609 words, 31 utterances.  \\nPS3SH  (`Jackie', female, 35+, team manager, Home Counties): 622 words, 35 utterances.  \\nPS3SJ  (`Steve', male, 50+, team manager, Home Counties): 93 words, 9 utterances.  \\nPS3SK  (`Sheila', female, 45+, team manager, Home Counties): 293 words, 46 utterances.  \\nPS3SL  (`Phil', male, 45+, team manager, Home Counties): 846 words, 33 utterances.  \\nPS3SM  (`Ian', male, 45+, team manager, Home Counties): 36 words, 4 utterances.  \\nPS3SN  (female, 45+, personal assistant, Home Counties): 71 words, 9 utterances. ) \\nKRT  1876  Well, we, we as you correctly say er with the whole industry had a, had a difficult\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 22, 'page_label': '23', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS3SN  (female, 45+, personal assistant, Home Counties): 71 words, 9 utterances. ) \\nKRT  1876  Well, we, we as you correctly say er with the whole industry had a, had a difficult \\nAugust, I think the good news for Rover is that we fell less in volume terms than most of the \\ncompetition, and indeed we marginally increased our market share (KRT  Fox FM News: \\nradio programme. Recorded on [date unknown] with 292 participants, totalling 158242 words, \\n2687 utterances (duration not recorded).  \\nPS63J  (`A', male): 609 words, 18 utterances.  \\nPS63K  (`JM', female): 38152 words, 799 utterances.  \\nPS63L  (`AW', female): 2227 words, 30 utterances.  \\nPS63M  (`PC', male): 543 words, 9 utterances.  \\nPS63N  (`BC', male): 497 words, 8 utterances.  \\nPS63P  (`MT', female): 179 words, 6 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 23, 'page_label': '24', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"24 \\n \\nPS63R  (`NW', male): 372 words, 4 utterances.  \\nPS63S  (`VH', female): 97 words, 1 utterance.  \\nPS63T  (`JG', male): 415 words, 4 utterances.  \\nPS63U  (`DB', male): 615 words, 10 utterances.  \\nPS63V  (`B', male): 777 words, 27 utterances.  \\nPS63W  (`TB', male): 1029 words, 10 utterances.  \\nPS63X  (`NT', male): 576 words, 6 utterances.  \\nPS63Y  (`MN', male): 723 words, 6 utterances.  \\nPS640  (`LB', female): 3539 words, 64 utterances.  \\nPS641  (`TR', male): 199 words, 2 utterances.  \\nPS642  (`MM', female): 57 words, 1 utterance.  \\nPS643  (`PM', male): 2713 words, 48 utterances.  \\nPS644  (`SI', male): 679 words, 13 utterances.  \\nPS645  (`MP', male): 404 words, 9 utterances.  \\nPS646  (`TS', male): 77 words, 2 utterances.  \\nPS647  (`C', male): 440 words, 22 utterances.  \\nPS648  (`JP', male): 1705 words, 14 utterances.  \\nPS649  (`CS', male): 267 words, 3 utterances.  \\nPS64A  (`D', male): 348 words, 21 utterances.  \\nPS64B  (`CM', male): 310 words, 6 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 23, 'page_label': '24', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS648  (`JP', male): 1705 words, 14 utterances.  \\nPS649  (`CS', male): 267 words, 3 utterances.  \\nPS64A  (`D', male): 348 words, 21 utterances.  \\nPS64B  (`CM', male): 310 words, 6 utterances.  \\nPS64C  (`MG', female): 92 words, 1 utterance.  \\nPS64D  (`E', female): 241 words, 9 utterances.  \\nPS64E  (`F', female): 208 words, 9 utterances.  \\nPS64F  (`G', female): 42 words, 2 utterances.  \\nPS64G  (`H', female): 129 words, 8 utterances.  \\nPS64H  (`AS', male): 1243 words, 10 utterances.  \\nPS64J  (`TD', male): 66 words, 1 utterance.  \\nPS64K  (`I', female): 338 words, 5 utterances.  \\nPS64L  (`J', male): 645 words, 33 utterances.  \\nPS64M  (`MB', male): 505 words, 8 utterances.  \\nPS64N  (`BW', male): 83 words, 4 utterances.  \\nPS64P  (`CR', female): 508 words, 4 utterances.  \\nPS64R  (`BF', male): 374 words, 3 utterances.  \\nPS64S  (`K', male): 629 words, 10 utterances.  \\nPS64T  (`TM', male): 327 words, 8 utterances.  \\nPS64U  (`AR', male): 538 words, 10 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 23, 'page_label': '24', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS64R  (`BF', male): 374 words, 3 utterances.  \\nPS64S  (`K', male): 629 words, 10 utterances.  \\nPS64T  (`TM', male): 327 words, 8 utterances.  \\nPS64U  (`AR', male): 538 words, 10 utterances.  \\nPS64V  (`PR', male): 534 words, 10 utterances.  \\nPS64W  (`L', male): 665 words, 11 utterances.  \\nPS64X  (`CP', male): 593 words, 7 utterances.  \\nPS64Y  (`HH', male): 1528 words, 22 utterances.  \\nPS650  (`IP', male): 48 words, 1 utterance.  \\nPS651  (`PP', male): 350 words, 8 utterances.  \\nPS652  (`AD', female): 368 words, 17 utterances.  \\nPS653  (`TC', male): 193 words, 3 utterances.  \\nPS654  (`TA', male): 117 words, 1 utterance.  \\nPS655  (`IW', male): 505 words, 9 utterances.  \\nPS656  (`DO', male): 784 words, 5 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 24, 'page_label': '25', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"25 \\n \\nPS657  (`RP', male): 2475 words, 43 utterances.  \\nPS658  (`DG', male): 438 words, 8 utterances.  \\nPS659  (`CF', female): 74 words, 1 utterance.  \\nPS65A  (`CJ', female): 310 words, 2 utterances.  \\nPS65B  (`GM', male): 913 words, 15 utterances.  \\nPS65C  (`NS', male): 54 words, 1 utterance.  \\nPS65D  (`DM', male): 585 words, 4 utterances.  \\nPS65E  (`RG', female): 826 words, 6 utterances.  \\nPS65F  (`GO', male): 232 words, 2 utterances.  \\nPS65G  (`F', male): 372 words, 17 utterances.  \\nPS65H  (`RJ', male): 526 words, 7 utterances.  \\nPS65J  (`JB', female): 423 words, 9 utterances.  \\nPS65K  (`G', male): 907 words, 26 utterances.  \\nPS65L  (`JM', male): 1503 words, 18 utterances.  \\nPS65M  (`H', male): 583 words, 21 utterances.  \\nPS65N  (`LR', male): 130 words, 3 utterances.  \\nPS65P  (`MU', male): 14 words, 1 utterance.  \\nPS65R  (`HN', male): 368 words, 4 utterances.  \\nPS65S  (`I', male): 344 words, 19 utterances.  \\nPS65T  (`DW', female): 452 words, 3 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 24, 'page_label': '25', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS65P  (`MU', male): 14 words, 1 utterance.  \\nPS65R  (`HN', male): 368 words, 4 utterances.  \\nPS65S  (`I', male): 344 words, 19 utterances.  \\nPS65T  (`DW', female): 452 words, 3 utterances.  \\nPS65U  (`RH', male): 653 words, 6 utterances.  \\nPS65V  (`EA', male): 348 words, 9 utterances.  \\nPS65W  (`JH', male): 561 words, 4 utterances.  \\nPS65X  (`MM', male): 218 words, 3 utterances.  \\nPS65Y  (`DF', male): 349 words, 6 utterances.  \\nPS660  (`NH', male): 237 words, 3 utterances.  \\nPS661  (`IG', male): 216 words, 4 utterances.  \\nPS662  (`NC', male): 686 words, 9 utterances.  \\nPS663  (`MH', male): 342 words, 4 utterances.  \\nPS664  (`TN', male): 457 words, 8 utterances.  \\nPS665  (`CG', male): 1006 words, 16 utterances.  \\nPS666  (`LS', male): 487 words, 8 utterances.  \\nPS667  (`DH', male): 816 words, 11 utterances.  \\nPS668  (`Zippy', male): 17 words, 1 utterance.  \\nPS669  (`SJ', female): 699 words, 5 utterances.  \\nPS66A  (`A', female): 631 words, 16 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 24, 'page_label': '25', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS667  (`DH', male): 816 words, 11 utterances.  \\nPS668  (`Zippy', male): 17 words, 1 utterance.  \\nPS669  (`SJ', female): 699 words, 5 utterances.  \\nPS66A  (`A', female): 631 words, 16 utterances.  \\nPS66B  (`RR', male): 66 words, 2 utterances.  \\nPS66C  (`ML', male): 3676 words, 30 utterances.  \\nPS66D  (`AC', male): 575 words, 7 utterances.  \\nPS66E  (`JZ', female): 641 words, 3 utterances.  \\nPS66F  (`D', female): 256 words, 9 utterances.  \\nPS66G  (`RB', male): 386 words, 6 utterances.  \\nPS66H  (`DS', male): 1486 words, 15 utterances.  \\nPS66J  (`KG', male): 52 words, 1 utterance.  \\nPS66K  (`AH', female): 61 words, 1 utterance.  \\nPS66L  (`SW', male): 256 words, 5 utterances.  \\nPS66M  (`LM', male): 37 words, 1 utterance.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 25, 'page_label': '26', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"26 \\n \\nPS66N  (`RM', male): 1230 words, 11 utterances.  \\nPS66P  (`BG', female): 24 words, 1 utterance.  \\nPS66R  (`E', male): 591 words, 23 utterances.  \\nPS66S  (`CB', female): 576 words, 5 utterances.  \\nPS66T  (`AH', male): 259 words, 1 utterance.  \\nPS66U  (`BH', male): 1512 words, 10 utterances.  \\nPS66V  (`P', male): 74 words, 2 utterances.  \\nPS66W  (`AK', female): 174 words, 7 utterances.  \\nPS66X  (`Q', male): 317 words, 8 utterances.  \\nPS66Y  (`Bungle', male): 158 words, 14 utterances.  \\nPS670  (`Jeffrey', male): 5 words, 1 utterance.  \\nPS671  (`JB', male): 1436 words, 22 utterances.  \\nPS672  (`SH', male): 666 words, 6 utterances.  \\nPS673  (`SK', male): 266 words, 6 utterances.  \\nPS674  (`MS', male): 104 words, 2 utterances.  \\nPS675  (`PS', male): 925 words, 16 utterances.  \\nPS676  (`RV', female): 67 words, 3 utterances.  \\nPS677  (`AA', male): 474 words, 4 utterances.  \\nPS678  (`MH', male): 42 words, 1 utterance.  \\nPS679  (`JE', male): 307 words, 3 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 25, 'page_label': '26', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS676  (`RV', female): 67 words, 3 utterances.  \\nPS677  (`AA', male): 474 words, 4 utterances.  \\nPS678  (`MH', male): 42 words, 1 utterance.  \\nPS679  (`JE', male): 307 words, 3 utterances.  \\nPS67A  (`EL', female): 469 words, 4 utterances.  \\nPS67B  (`NY', female): 256 words, 3 utterances.  \\nPS67C  (`LJ', male): 393 words, 6 utterances.  \\nPS67D  (`IC', male): 472 words, 10 utterances.  \\nPS67E  (`JW', male): 845 words, 14 utterances.  \\nPS67F  (`NA', male): 223 words, 1 utterance.  \\nPS67G  (`PT', male): 601 words, 7 utterances.  \\nPS67H  (`MI', male): 4138 words, 53 utterances.  \\nPS67J  (`PG', male): 91 words, 1 utterance.  \\nPS67K  (`FD', male): 47 words, 1 utterance.  \\nPS67L  (`TK', male): 595 words, 8 utterances.  \\nPS67M  (`TP', male): 87 words, 1 utterance.  \\nPS67N  (`NM', male): 43 words, 1 utterance.  \\nPS67P  (`JS', male): 2060 words, 17 utterances.  \\nPS67R  (`GD', male): 418 words, 7 utterances.  \\nPS67S  (`MR', male): 1035 words, 5 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 25, 'page_label': '26', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS67N  (`NM', male): 43 words, 1 utterance.  \\nPS67P  (`JS', male): 2060 words, 17 utterances.  \\nPS67R  (`GD', male): 418 words, 7 utterances.  \\nPS67S  (`MR', male): 1035 words, 5 utterances.  \\nPS67T  (`PJ', male): 557 words, 5 utterances.  \\nPS67U  (`AT', male): 194 words, 2 utterances.  \\nPS67V  (`GW', male): 518 words, 4 utterances.  \\nPS67W  (`RG', male): 199 words, 4 utterances.  \\nPS67X  (`MJ', male): 393 words, 5 utterances.  \\nPS67Y  (`AP', male): 151 words, 3 utterances.  \\nPS680  (`PA', male): 186 words, 4 utterances.  \\nPS681  (`FJ', male): 407 words, 2 utterances.  \\nPS682  (`VB', female): 419 words, 4 utterances.  \\nPS683  (`RK', male): 366 words, 10 utterances.  \\nPS684  (`B', female): 127 words, 6 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 26, 'page_label': '27', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"27 \\n \\nPS685  (`GB', male): 181 words, 3 utterances.  \\nPS686  (`JT', female): 35 words, 1 utterance.  \\nPS687  (`JK', female): 11 words, 1 utterance.  \\nPS688  (`HC', female): 82 words, 2 utterances.  \\nPS689  (`RA', male): 213 words, 4 utterances.  \\nPS68A  (`AB', female): 89 words, 1 utterance.  \\nPS68B  (`PK', male): 3131 words, 43 utterances.  \\nPS68C  (`AG', female): 325 words, 5 utterances.  \\nPS68D  (`MW', male): 686 words, 7 utterances.  \\nPS68E  (`MH', female): 971 words, 11 utterances.  \\nPS68F  (`SP', female): 22 words, 1 utterance.  \\nPS68G  (`BJ', male): 61 words, 1 utterance.  \\nPS68H  (`BW', female): 51 words, 1 utterance.  \\nPS68J  (`PH', male): 488 words, 4 utterances.  \\nPS68K  (`WT', male): 299 words, 6 utterances.  \\nPS68L  (`KP', male): 33 words, 1 utterance.  \\nPS68M  (`PL', male): 53 words, 1 utterance.  \\nPS68N  (`CW', male): 91 words, 1 utterance.  \\nPS68P  (`MB', female): 279 words, 4 utterances.  \\nPS68R  (`KM', male): 236 words, 5 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 26, 'page_label': '27', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS68M  (`PL', male): 53 words, 1 utterance.  \\nPS68N  (`CW', male): 91 words, 1 utterance.  \\nPS68P  (`MB', female): 279 words, 4 utterances.  \\nPS68R  (`KM', male): 236 words, 5 utterances.  \\nPS68S  (`K', female): 116 words, 4 utterances.  \\nPS68T  (`SS', female): 241 words, 4 utterances.  \\nPS68U  (`AJ', male): 149 words, 8 utterances.  \\nPS68V  (`BG', male): 89 words, 2 utterances.  \\nPS68W  (`GF', male): 106 words, 4 utterances.  \\nPS68X  (`RS', male): 1256 words, 13 utterances.  \\nPS68Y  (`NH', female): 69 words, 1 utterance.  \\nPS690  (`CL', female): 455 words, 7 utterances.  \\nPS691  (`DP', male): 719 words, 7 utterances.  \\nPS692  (`JN', female): 987 words, 13 utterances.  \\nPS693  (`PB', male): 215 words, 4 utterances.  \\nPS694  (`MF', male): 74 words, 2 utterances.  \\nPS695  (`IJ', male): 142 words, 1 utterance.  \\nPS696  (`WH', male): 55 words, 1 utterance.  \\nPS697  (`AK', male): 536 words, 12 utterances.  \\nPS698  (`C', female): 134 words, 7 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 26, 'page_label': '27', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS695  (`IJ', male): 142 words, 1 utterance.  \\nPS696  (`WH', male): 55 words, 1 utterance.  \\nPS697  (`AK', male): 536 words, 12 utterances.  \\nPS698  (`C', female): 134 words, 7 utterances.  \\nPS699  (`JC', male): 110 words, 2 utterances.  \\nPS69A  (`HK', male): 74 words, 1 utterance.  \\nPS69B  (`HM', male): 65 words, 1 utterance.  \\nPS69C  (`EP', female): 649 words, 4 utterances.  \\nPS69D  (`SP', male): 217 words, 2 utterances.  \\nPS69E  (`RL', male): 272 words, 3 utterances.  \\nPS69F  (`TI', male): 47 words, 1 utterance.  \\nPS69G  (`LH', female): 522 words, 12 utterances.  \\nPS69H  (`FW', male): 365 words, 5 utterances.  \\nPS69J  (`LM', female): 132 words, 7 utterances.  \\nPS69K  (`NR', female): 360 words, 5 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 27, 'page_label': '28', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"28 \\n \\nPS69L  (`TF', female): 26 words, 2 utterances.  \\nPS69M  (`GP', female): 356 words, 3 utterances.  \\nPS69N  (`SM', female): 637 words, 10 utterances.  \\nPS69P  (`NK', male): 285 words, 6 utterances.  \\nPS69R  (`WE', male): 97 words, 1 utterance.  \\nPS69S  (`NP', female): 382 words, 3 utterances.  \\nPS69T  (`DC', male): 104 words, 1 utterance.  \\nPS69U  (`CH', female): 77 words, 1 utterance.  \\nPS69V  (`EF', male): 405 words, 4 utterances.  \\nPS69W  (`BS', male): 218 words, 3 utterances.  \\nPS69X  (`MC', female): 45 words, 1 utterance.  \\nPS69Y  (`BH', female): 807 words, 19 utterances.  \\nPS6A0  (`BY', female): 24 words, 1 utterance.  \\nPS6A1  (`CH', male): 362 words, 3 utterances.  \\nPS6A2  (`KS', male): 219 words, 2 utterances.  \\nPS6A3  (`RM', female): 51 words, 1 utterance.  \\nPS6A4  (`JJ', male): 169 words, 1 utterance.  \\nPS6A5  (`CA', female): 107 words, 4 utterances.  \\nPS6A6  (`CC', male): 207 words, 4 utterances.  \\nPS6A7  (`KC', male): 123 words, 2 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 27, 'page_label': '28', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS6A4  (`JJ', male): 169 words, 1 utterance.  \\nPS6A5  (`CA', female): 107 words, 4 utterances.  \\nPS6A6  (`CC', male): 207 words, 4 utterances.  \\nPS6A7  (`KC', male): 123 words, 2 utterances.  \\nPS6A8  (`JW', female): 231 words, 5 utterances.  \\nPS6A9  (`JMC', female): 500 words, 12 utterances.  \\nPS6AA  (`FJM', female): 117 words, 3 utterances.  \\nPS6AB  (`KK', female): 397 words, 5 utterances.  \\nPS6AC  (`BO', male): 63 words, 2 utterances.  \\nPS6AD  (`NP', male): 447 words, 5 utterances.  \\nPS6AE  (`HA', male): 40 words, 1 utterance.  \\nPS6AF  (`DW', male): 910 words, 11 utterances.  \\nPS6AG  (`JV', male): 720 words, 4 utterances.  \\nPS6AH  (`RD', female): 30 words, 1 utterance.  \\nPS6AJ  (`EC', male): 69 words, 1 utterance.  \\nPS6AK  (`WR', male): 526 words, 3 utterances.  \\nPS6AL  (`PD', male): 176 words, 2 utterances.  \\nPS6AM  (`HE', female): 129 words, 5 utterances.  \\nPS6AN  (`DV', male): 725 words, 5 utterances.  \\nPS6AP  (`PE', male): 180 words, 3 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 27, 'page_label': '28', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS6AL  (`PD', male): 176 words, 2 utterances.  \\nPS6AM  (`HE', female): 129 words, 5 utterances.  \\nPS6AN  (`DV', male): 725 words, 5 utterances.  \\nPS6AP  (`PE', male): 180 words, 3 utterances.  \\nPS6AR  (`AF', male): 555 words, 4 utterances.  \\nPS6AS  (`LH', male): 19 words, 1 utterance.  \\nPS6AT  (`LC', male): 22 words, 1 utterance.  \\nPS6AU  (`BN', male): 447 words, 4 utterances.  \\nPS6AV  (`TJ', male): 217 words, 1 utterance.  \\nPS6AW  (`WW', female): 218 words, 2 utterances.  \\nPS6AX  (`SR', male): 531 words, 11 utterances.  \\nPS6AY  (`PW', male): 271 words, 6 utterances.  \\nPS6B0  (`YO', female): 17 words, 1 utterance.  \\nPS6B1  (`FM', male): 212 words, 4 utterances.  \\nPS6B2  (`SA', female): 380 words, 11 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 28, 'page_label': '29', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"29 \\n \\nPS6B3  (`KB', male): 47 words, 1 utterance.  \\nPS6B4 (`WA', male): 32 words, 1 utterance.  \\nPS6B5  (`VB', male): 86 words, 1 utterance.  \\nPS6B6  (`AM', male): 56 words, 1 utterance.  \\nPS6B7  (`HA', female): 92 words, 1 utterance.  \\nPS6B8  (`RJ', female): 364 words, 3 utterances.  \\nPS6B9  (`TF', male): 80 words, 1 utterance.  \\nPS6BA  (`FH', female): 512 words, 4 utterances.  \\nPS6BB  (`AL', male): 171 words, 2 utterances.  \\nPS6BC  (`JL', male): 416 words, 5 utterances.  \\nPS6BD  (`BV', male): 367 words, 3 utterances.  \\nPS6BE  (`CK', female): 402 words, 5 utterances.  \\nPS6BF  (`ZW', female): 136 words, 2 utterances.  \\nPS6BG  (`AC', female): 35 words, 3 utterances.  \\nPS6BH  (`EH', female): 106 words, 1 utterance.  \\nPS6BJ  (`HT', female): 105 words, 2 utterances.  \\nPS6BK  (`JR', male): 293 words, 5 utterances.  \\nPS6BL  (`PK', female): 92 words, 2 utterances.  \\nPS6BM  (`MA', female): 320 words, 10 utterances.  \\nPS6BN  (`JG', female): 147 words, 3 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 28, 'page_label': '29', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS6BK  (`JR', male): 293 words, 5 utterances.  \\nPS6BL  (`PK', female): 92 words, 2 utterances.  \\nPS6BM  (`MA', female): 320 words, 10 utterances.  \\nPS6BN  (`JG', female): 147 words, 3 utterances.  \\nPS6BP  (`M', male): 24 words, 1 utterance.  \\nPS6BS  (`JO', male): 58 words, 2 utterances.  \\nPS6BT  (`LB', male): 282 words, 6 utterances.  \\nPS6BU  (`DD', female): 65 words, 1 utterance.  \\nPS6BV  (`AM', female): 123 words, 3 utterances.  \\nPS6BW  (`NO', male): 239 words, 3 utterances.  \\nPS6BX  (`DJ', male): 440 words, 6 utterances.  \\nPS6BY  (`N', male): 136 words, 5 utterances.  \\nPS6C0  (`EH', male): 252 words, 3 utterances.  \\nPS6C1  (`BM', male): 221 words, 5 utterances.  \\nPS6C2  (`O', male): 51 words, 5 utterances.  \\nPS6C3  (`JH', female): 194 words, 3 utterances.  \\nPS6C4  (`R', male): 176 words, 9 utterances.  \\nPS6C5  (`JS', female): 118 words, 3 utterances.  \\nPS6C6  (`AT', female): 294 words, 3 utterances.  \\nPS6C7  (`DL', male): 56 words, 1 utterance.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 28, 'page_label': '29', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS6C4  (`R', male): 176 words, 9 utterances.  \\nPS6C5  (`JS', female): 118 words, 3 utterances.  \\nPS6C6  (`AT', female): 294 words, 3 utterances.  \\nPS6C7  (`DL', male): 56 words, 1 utterance.  \\nPS6C8  (`KH', male): 67 words, 1 utterance.  \\nPS6C9  (`BS', female): 63 words, 1 utterance.  \\nPS6CA  (`SC', female): 275 words, 3 utterances.  \\nPS6CB  (`LT', male): 236 words, 5 utterances.  \\nPS6CC  (`DM', female): 253 words, 10 utterances.  \\nPS6CD  (`NA', female): 232 words, 3 utterances.  \\nPS6CE  (`J', female): 60 words, 4 utterances.  \\nPS6CF  (`ID', female): 355 words, 3 utterances.  \\nPS6CG  (`CB', male): 255 words, 4 utterances.  \\nPS6CH  (`RD', male): 72 words, 1 utterance.  \\nPS6CJ  (`RO', male): 109 words, 1 utterance.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 29, 'page_label': '30', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"30 \\n \\nPS6CK  (`GH', male): 30 words, 1 utterance.  \\nPS6CL  (`CM', female): 305 words, 6 utterances.  \\nPS6CM  (`LT'): 332 words, 7 utterances.  \\nKRTPS000  95 words, 1 utterance. )” \\n (see it also online for resource details: http://www.natcorp.ox.ac.uk/using/index.xml?ID=simple )\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='1\\nRetrieval-Augmented Generation for Large\\nLanguage Models: A Survey\\nYunfan Gaoa, Yun Xiongb, Xinyu Gao b, Kangxiang Jia b, Jinliu Pan b, Yuxi Bic, Yi Dai a, Jiawei Sun a, Meng\\nWangc, and Haofen Wang a,c\\naShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\\nbShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\\ncCollege of Design and Innovation, Tongji University\\nAbstract—Large Language Models (LLMs) showcase impres-\\nsive capabilities but encounter challenges like hallucination,\\noutdated knowledge, and non-transparent, untraceable reasoning\\nprocesses. Retrieval-Augmented Generation (RAG) has emerged\\nas a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the\\ngeneration, particularly for knowledge-intensive tasks, and allows\\nfor continuous knowledge updates and integration of domain-\\nspecific information. RAG synergistically merges LLMs’ intrin-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='generation, particularly for knowledge-intensive tasks, and allows\\nfor continuous knowledge updates and integration of domain-\\nspecific information. RAG synergistically merges LLMs’ intrin-\\nsic knowledge with the vast, dynamic repositories of external\\ndatabases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing\\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\\nIt meticulously scrutinizes the tripartite foundation of RAG\\nframeworks, which includes the retrieval, the generation and the\\naugmentation techniques. The paper highlights the state-of-the-\\nart technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG\\nsystems. Furthermore, this paper introduces up-to-date evalua-\\ntion framework and benchmark. At the end, this article delineates\\nthe challenges currently faced and points out prospective avenues\\nfor research and development 1.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='tion framework and benchmark. At the end, this article delineates\\nthe challenges currently faced and points out prospective avenues\\nfor research and development 1.\\nIndex Terms—Large language model, retrieval-augmented gen-\\neration, natural language processing, information retrieval\\nI. I NTRODUCTION\\nL\\nARGE language models (LLMs) have achieved remark-\\nable success, though they still face significant limitations,\\nespecially in domain-specific or knowledge-intensive tasks [1],\\nnotably producing “hallucinations” [2] when handling queries\\nbeyond their training data or requiring current information. To\\novercome challenges, Retrieval-Augmented Generation (RAG)\\nenhances LLMs by retrieving relevant document chunks from\\nexternal knowledge base through semantic similarity calcu-\\nlation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='lation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,\\nestablishing RAG as a key technology in advancing chatbots\\nand enhancing the suitability of LLMs for real-world applica-\\ntions.\\nRAG technology has rapidly developed in recent years, and\\nthe technology tree summarizing related research is shown\\nCorresponding Author.Email:haofen.wang@tongji.edu.cn\\n1Resources are available at https://github.com/Tongji-KGLLM/\\nRAG-Survey\\nin Figure 1. The development trajectory of RAG in the era\\nof large models exhibits several distinct stage characteristics.\\nInitially, RAG’s inception coincided with the rise of the\\nTransformer architecture, focusing on enhancing language\\nmodels by incorporating additional knowledge through Pre-\\nTraining Models (PTM). This early stage was characterized\\nby foundational work aimed at refining pre-training techniques'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='models by incorporating additional knowledge through Pre-\\nTraining Models (PTM). This early stage was characterized\\nby foundational work aimed at refining pre-training techniques\\n[3]–[5].The subsequent arrival of ChatGPT [6] marked a\\npivotal moment, with LLM demonstrating powerful in context\\nlearning (ICL) capabilities. RAG research shifted towards\\nproviding better information for LLMs to answer more com-\\nplex and knowledge-intensive tasks during the inference stage,\\nleading to rapid development in RAG studies. As research\\nprogressed, the enhancement of RAG was no longer limited\\nto the inference stage but began to incorporate more with LLM\\nfine-tuning techniques.\\nThe burgeoning field of RAG has experienced swift growth,\\nyet it has not been accompanied by a systematic synthesis that\\ncould clarify its broader trajectory. This survey endeavors to\\nfill this gap by mapping out the RAG process and charting\\nits evolution and anticipated future paths, with a focus on the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='could clarify its broader trajectory. This survey endeavors to\\nfill this gap by mapping out the RAG process and charting\\nits evolution and anticipated future paths, with a focus on the\\nintegration of RAG within LLMs. This paper considers both\\ntechnical paradigms and research methods, summarizing three\\nmain research paradigms from over 100 RAG studies, and\\nanalyzing key technologies in the core stages of “Retrieval,”\\n“Generation,” and “Augmentation.” On the other hand, current\\nresearch tends to focus more on methods, lacking analysis and\\nsummarization of how to evaluate RAG. This paper compre-\\nhensively reviews the downstream tasks, datasets, benchmarks,\\nand evaluation methods applicable to RAG. Overall, this\\npaper sets out to meticulously compile and categorize the\\nfoundational technical concepts, historical progression, and\\nthe spectrum of RAG methodologies and applications that\\nhave emerged post-LLMs. It is designed to equip readers and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='foundational technical concepts, historical progression, and\\nthe spectrum of RAG methodologies and applications that\\nhave emerged post-LLMs. It is designed to equip readers and\\nprofessionals with a detailed and structured understanding of\\nboth large models and RAG. It aims to illuminate the evolution\\nof retrieval augmentation techniques, assess the strengths and\\nweaknesses of various approaches in their respective contexts,\\nand speculate on upcoming trends and innovations.\\nOur contributions are as follows:\\n• In this survey, we present a thorough and systematic\\nreview of the state-of-the-art RAG methods, delineating\\nits evolution through paradigms including naive RAG,\\narXiv:2312.10997v5  [cs.CL]  27 Mar 2024'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2\\nFig. 1. Technology tree of RAG research. The stages of involving RAG mainly include pre-training, fine-tuning, and inference. With the emergence of LLMs,\\nresearch on RAG initially focused on leveraging the powerful in context learning abilities of LLMs, primarily concentrating on the inference stage. Subsequent\\nresearch has delved deeper, gradually integrating more with the fine-tuning of LLMs. Researchers have also been exploring ways to enhance language models\\nin the pre-training stage through retrieval-augmented techniques.\\nadvanced RAG, and modular RAG. This review contex-\\ntualizes the broader scope of RAG research within the\\nlandscape of LLMs.\\n• We identify and discuss the central technologies integral\\nto the RAG process, specifically focusing on the aspects\\nof “Retrieval”, “Generation” and “Augmentation”, and\\ndelve into their synergies, elucidating how these com-\\nponents intricately collaborate to form a cohesive and\\neffective RAG framework.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='of “Retrieval”, “Generation” and “Augmentation”, and\\ndelve into their synergies, elucidating how these com-\\nponents intricately collaborate to form a cohesive and\\neffective RAG framework.\\n• We have summarized the current assessment methods of\\nRAG, covering 26 tasks, nearly 50 datasets, outlining\\nthe evaluation objectives and metrics, as well as the\\ncurrent evaluation benchmarks and tools. Additionally,\\nwe anticipate future directions for RAG, emphasizing\\npotential enhancements to tackle current challenges.\\nThe paper unfolds as follows: Section II introduces the\\nmain concept and current paradigms of RAG. The following\\nthree sections explore core components—“Retrieval”, “Gen-\\neration” and “Augmentation”, respectively. Section III focuses\\non optimization methods in retrieval,including indexing, query\\nand embedding optimization. Section IV concentrates on post-\\nretrieval process and LLM fine-tuning in generation. Section V\\nanalyzes the three augmentation processes. Section VI focuses'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and embedding optimization. Section IV concentrates on post-\\nretrieval process and LLM fine-tuning in generation. Section V\\nanalyzes the three augmentation processes. Section VI focuses\\non RAG’s downstream tasks and evaluation system. Sec-\\ntion VII mainly discusses the challenges that RAG currently\\nfaces and its future development directions. At last, the paper\\nconcludes in Section VIII.\\nII. O VERVIEW OF RAG\\nA typical application of RAG is illustrated in Figure 2.\\nHere, a user poses a question to ChatGPT about a recent,\\nwidely discussed news. Given ChatGPT’s reliance on pre-\\ntraining data, it initially lacks the capacity to provide up-\\ndates on recent developments. RAG bridges this information\\ngap by sourcing and incorporating knowledge from external\\ndatabases. In this case, it gathers relevant news articles related\\nto the user’s query. These articles, combined with the original\\nquestion, form a comprehensive prompt that empowers LLMs\\nto generate a well-informed answer.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='to the user’s query. These articles, combined with the original\\nquestion, form a comprehensive prompt that empowers LLMs\\nto generate a well-informed answer.\\nThe RAG research paradigm is continuously evolving, and\\nwe categorize it into three stages: Naive RAG, Advanced\\nRAG, and Modular RAG, as showed in Figure 3. Despite\\nRAG method are cost-effective and surpass the performance\\nof the native LLM, they also exhibit several limitations.\\nThe development of Advanced RAG and Modular RAG is\\na response to these specific shortcomings in Naive RAG.\\nA. Naive RAG\\nThe Naive RAG research paradigm represents the earli-\\nest methodology, which gained prominence shortly after the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='3\\nFig. 2. A representative instance of the RAG process applied to question answering. It mainly consists of 3 steps. 1) Indexing. Documents are split into chunks,\\nencoded into vectors, and stored in a vector database. 2) Retrieval. Retrieve the Top k chunks most relevant to the question based on semantic similarity. 3)\\nGeneration. Input the original question and the retrieved chunks together into LLM to generate the final answer.\\nwidespread adoption of ChatGPT. The Naive RAG follows\\na traditional process that includes indexing, retrieval, and\\ngeneration, which is also characterized as a “Retrieve-Read”\\nframework [7].\\nIndexing starts with the cleaning and extraction of raw data\\nin diverse formats like PDF, HTML, Word, and Markdown,\\nwhich is then converted into a uniform plain text format. To\\naccommodate the context limitations of language models, text\\nis segmented into smaller, digestible chunks. Chunks are then\\nencoded into vector representations using an embedding model'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='accommodate the context limitations of language models, text\\nis segmented into smaller, digestible chunks. Chunks are then\\nencoded into vector representations using an embedding model\\nand stored in vector database. This step is crucial for enabling\\nefficient similarity searches in the subsequent retrieval phase.\\nRetrieval. Upon receipt of a user query, the RAG system\\nemploys the same encoding model utilized during the indexing\\nphase to transform the query into a vector representation.\\nIt then computes the similarity scores between the query\\nvector and the vector of chunks within the indexed corpus.\\nThe system prioritizes and retrieves the top K chunks that\\ndemonstrate the greatest similarity to the query. These chunks\\nare subsequently used as the expanded context in prompt.\\nGeneration. The posed query and selected documents are\\nsynthesized into a coherent prompt to which a large language\\nmodel is tasked with formulating a response. The model’s'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Generation. The posed query and selected documents are\\nsynthesized into a coherent prompt to which a large language\\nmodel is tasked with formulating a response. The model’s\\napproach to answering may vary depending on task-specific\\ncriteria, allowing it to either draw upon its inherent parametric\\nknowledge or restrict its responses to the information con-\\ntained within the provided documents. In cases of ongoing\\ndialogues, any existing conversational history can be integrated\\ninto the prompt, enabling the model to engage in multi-turn\\ndialogue interactions effectively.\\nHowever, Naive RAG encounters notable drawbacks:\\nRetrieval Challenges . The retrieval phase often struggles\\nwith precision and recall, leading to the selection of misaligned\\nor irrelevant chunks, and the missing of crucial information.\\nGeneration Difficulties. In generating responses, the model\\nmay face the issue of hallucination, where it produces con-\\ntent not supported by the retrieved context. This phase can'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Generation Difficulties. In generating responses, the model\\nmay face the issue of hallucination, where it produces con-\\ntent not supported by the retrieved context. This phase can\\nalso suffer from irrelevance, toxicity, or bias in the outputs,\\ndetracting from the quality and reliability of the responses.\\nAugmentation Hurdles . Integrating retrieved information\\nwith the different task can be challenging, sometimes resulting\\nin disjointed or incoherent outputs. The process may also\\nencounter redundancy when similar information is retrieved\\nfrom multiple sources, leading to repetitive responses. Deter-\\nmining the significance and relevance of various passages and\\nensuring stylistic and tonal consistency add further complexity.\\nFacing complex issues, a single retrieval based on the original\\nquery may not suffice to acquire adequate context information.\\nMoreover, there’s a concern that generation models might\\noverly rely on augmented information, leading to outputs that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='query may not suffice to acquire adequate context information.\\nMoreover, there’s a concern that generation models might\\noverly rely on augmented information, leading to outputs that\\nsimply echo retrieved content without adding insightful or\\nsynthesized information.\\nB. Advanced RAG\\nAdvanced RAG introduces specific improvements to over-\\ncome the limitations of Naive RAG. Focusing on enhancing re-\\ntrieval quality, it employs pre-retrieval and post-retrieval strate-\\ngies. To tackle the indexing issues, Advanced RAG refines\\nits indexing techniques through the use of a sliding window\\napproach, fine-grained segmentation, and the incorporation of\\nmetadata. Additionally, it incorporates several optimization\\nmethods to streamline the retrieval process [8].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='4\\nFig. 3. Comparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\\nchain-like structure. (Right) Modular RAG inherits and develops from the previous paradigm, showcasing greater flexibility overall. This is evident in the\\nintroduction of multiple specific functional modules and the replacement of existing modules. The overall process is not limited to sequential retrieval and\\ngeneration; it includes methods such as iterative and adaptive retrieval.\\nPre-retrieval process. In this stage, the primary focus is\\non optimizing the indexing structure and the original query.\\nThe goal of optimizing indexing is to enhance the quality of\\nthe content being indexed. This involves strategies: enhancing\\ndata granularity, optimizing index structures, adding metadata,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='The goal of optimizing indexing is to enhance the quality of\\nthe content being indexed. This involves strategies: enhancing\\ndata granularity, optimizing index structures, adding metadata,\\nalignment optimization, and mixed retrieval. While the goal\\nof query optimization is to make the user’s original question\\nclearer and more suitable for the retrieval task. Common\\nmethods include query rewriting query transformation, query\\nexpansion and other techniques [7], [9]–[11].\\nPost-Retrieval Process. Once relevant context is retrieved,\\nit’s crucial to integrate it effectively with the query. The main\\nmethods in post-retrieval process include rerank chunks and\\ncontext compressing. Re-ranking the retrieved information to\\nrelocate the most relevant content to the edges of the prompt is\\na key strategy. This concept has been implemented in frame-\\nworks such as LlamaIndex 2, LangChain3, and HayStack [12].\\nFeeding all relevant documents directly into LLMs can lead'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='a key strategy. This concept has been implemented in frame-\\nworks such as LlamaIndex 2, LangChain3, and HayStack [12].\\nFeeding all relevant documents directly into LLMs can lead\\nto information overload, diluting the focus on key details with\\nirrelevant content.To mitigate this, post-retrieval efforts con-\\ncentrate on selecting the essential information, emphasizing\\ncritical sections, and shortening the context to be processed.\\n2https://www.llamaindex.ai\\n3https://www.langchain.com/\\nC. Modular RAG\\nThe modular RAG architecture advances beyond the for-\\nmer two RAG paradigms, offering enhanced adaptability and\\nversatility. It incorporates diverse strategies for improving its\\ncomponents, such as adding a search module for similarity\\nsearches and refining the retriever through fine-tuning. Inno-\\nvations like restructured RAG modules [13] and rearranged\\nRAG pipelines [14] have been introduced to tackle specific\\nchallenges. The shift towards a modular RAG approach is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='vations like restructured RAG modules [13] and rearranged\\nRAG pipelines [14] have been introduced to tackle specific\\nchallenges. The shift towards a modular RAG approach is\\nbecoming prevalent, supporting both sequential processing and\\nintegrated end-to-end training across its components. Despite\\nits distinctiveness, Modular RAG builds upon the foundational\\nprinciples of Advanced and Naive RAG, illustrating a progres-\\nsion and refinement within the RAG family.\\n1) New Modules: The Modular RAG framework introduces\\nadditional specialized components to enhance retrieval and\\nprocessing capabilities. The Search module adapts to spe-\\ncific scenarios, enabling direct searches across various data\\nsources like search engines, databases, and knowledge graphs,\\nusing LLM-generated code and query languages [15]. RAG-\\nFusion addresses traditional search limitations by employing\\na multi-query strategy that expands user queries into diverse'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='using LLM-generated code and query languages [15]. RAG-\\nFusion addresses traditional search limitations by employing\\na multi-query strategy that expands user queries into diverse\\nperspectives, utilizing parallel vector searches and intelligent\\nre-ranking to uncover both explicit and transformative knowl-\\nedge [16]. The Memory module leverages the LLM’s memory\\nto guide retrieval, creating an unbounded memory pool that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='5\\naligns the text more closely with data distribution through iter-\\native self-enhancement [17], [18]. Routing in the RAG system\\nnavigates through diverse data sources, selecting the optimal\\npathway for a query, whether it involves summarization,\\nspecific database searches, or merging different information\\nstreams [19]. The Predict module aims to reduce redundancy\\nand noise by generating context directly through the LLM,\\nensuring relevance and accuracy [13]. Lastly, the Task Adapter\\nmodule tailors RAG to various downstream tasks, automating\\nprompt retrieval for zero-shot inputs and creating task-specific\\nretrievers through few-shot query generation [20], [21] .This\\ncomprehensive approach not only streamlines the retrieval pro-\\ncess but also significantly improves the quality and relevance\\nof the information retrieved, catering to a wide array of tasks\\nand queries with enhanced precision and flexibility.\\n2) New Patterns: Modular RAG offers remarkable adapt-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='of the information retrieved, catering to a wide array of tasks\\nand queries with enhanced precision and flexibility.\\n2) New Patterns: Modular RAG offers remarkable adapt-\\nability by allowing module substitution or reconfiguration\\nto address specific challenges. This goes beyond the fixed\\nstructures of Naive and Advanced RAG, characterized by a\\nsimple “Retrieve” and “Read” mechanism. Moreover, Modular\\nRAG expands this flexibility by integrating new modules or\\nadjusting interaction flow among existing ones, enhancing its\\napplicability across different tasks.\\nInnovations such as the Rewrite-Retrieve-Read [7]model\\nleverage the LLM’s capabilities to refine retrieval queries\\nthrough a rewriting module and a LM-feedback mechanism\\nto update rewriting model., improving task performance.\\nSimilarly, approaches like Generate-Read [13] replace tradi-\\ntional retrieval with LLM-generated content, while Recite-\\nRead [22] emphasizes retrieval from model weights, enhanc-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Similarly, approaches like Generate-Read [13] replace tradi-\\ntional retrieval with LLM-generated content, while Recite-\\nRead [22] emphasizes retrieval from model weights, enhanc-\\ning the model’s ability to handle knowledge-intensive tasks.\\nHybrid retrieval strategies integrate keyword, semantic, and\\nvector searches to cater to diverse queries. Additionally, em-\\nploying sub-queries and hypothetical document embeddings\\n(HyDE) [11] seeks to improve retrieval relevance by focusing\\non embedding similarities between generated answers and real\\ndocuments.\\nAdjustments in module arrangement and interaction, such\\nas the Demonstrate-Search-Predict (DSP) [23] framework\\nand the iterative Retrieve-Read-Retrieve-Read flow of ITER-\\nRETGEN [14], showcase the dynamic use of module out-\\nputs to bolster another module’s functionality, illustrating a\\nsophisticated understanding of enhancing module synergy.\\nThe flexible orchestration of Modular RAG Flow showcases'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='puts to bolster another module’s functionality, illustrating a\\nsophisticated understanding of enhancing module synergy.\\nThe flexible orchestration of Modular RAG Flow showcases\\nthe benefits of adaptive retrieval through techniques such as\\nFLARE [24] and Self-RAG [25]. This approach transcends\\nthe fixed RAG retrieval process by evaluating the necessity\\nof retrieval based on different scenarios. Another benefit of\\na flexible architecture is that the RAG system can more\\neasily integrate with other technologies (such as fine-tuning\\nor reinforcement learning) [26]. For example, this can involve\\nfine-tuning the retriever for better retrieval results, fine-tuning\\nthe generator for more personalized outputs, or engaging in\\ncollaborative fine-tuning [27].\\nD. RAG vs Fine-tuning\\nThe augmentation of LLMs has attracted considerable atten-\\ntion due to their growing prevalence. Among the optimization\\nmethods for LLMs, RAG is often compared with Fine-tuning'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='D. RAG vs Fine-tuning\\nThe augmentation of LLMs has attracted considerable atten-\\ntion due to their growing prevalence. Among the optimization\\nmethods for LLMs, RAG is often compared with Fine-tuning\\n(FT) and prompt engineering. Each method has distinct charac-\\nteristics as illustrated in Figure 4. We used a quadrant chart to\\nillustrate the differences among three methods in two dimen-\\nsions: external knowledge requirements and model adaption\\nrequirements. Prompt engineering leverages a model’s inherent\\ncapabilities with minimum necessity for external knowledge\\nand model adaption. RAG can be likened to providing a model\\nwith a tailored textbook for information retrieval, ideal for pre-\\ncise information retrieval tasks. In contrast, FT is comparable\\nto a student internalizing knowledge over time, suitable for\\nscenarios requiring replication of specific structures, styles, or\\nformats.\\nRAG excels in dynamic environments by offering real-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='to a student internalizing knowledge over time, suitable for\\nscenarios requiring replication of specific structures, styles, or\\nformats.\\nRAG excels in dynamic environments by offering real-\\ntime knowledge updates and effective utilization of external\\nknowledge sources with high interpretability. However, it\\ncomes with higher latency and ethical considerations regarding\\ndata retrieval. On the other hand, FT is more static, requiring\\nretraining for updates but enabling deep customization of the\\nmodel’s behavior and style. It demands significant compu-\\ntational resources for dataset preparation and training, and\\nwhile it can reduce hallucinations, it may face challenges with\\nunfamiliar data.\\nIn multiple evaluations of their performance on various\\nknowledge-intensive tasks across different topics, [28] re-\\nvealed that while unsupervised fine-tuning shows some im-\\nprovement, RAG consistently outperforms it, for both exist-\\ning knowledge encountered during training and entirely new'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='vealed that while unsupervised fine-tuning shows some im-\\nprovement, RAG consistently outperforms it, for both exist-\\ning knowledge encountered during training and entirely new\\nknowledge. Additionally, it was found that LLMs struggle\\nto learn new factual information through unsupervised fine-\\ntuning. The choice between RAG and FT depends on the\\nspecific needs for data dynamics, customization, and com-\\nputational capabilities in the application context. RAG and\\nFT are not mutually exclusive and can complement each\\nother, enhancing a model’s capabilities at different levels.\\nIn some instances, their combined use may lead to optimal\\nperformance. The optimization process involving RAG and FT\\nmay require multiple iterations to achieve satisfactory results.\\nIII. R ETRIEVAL\\nIn the context of RAG, it is crucial to efficiently retrieve\\nrelevant documents from the data source. There are several\\nkey issues involved, such as the retrieval source, retrieval'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='III. R ETRIEVAL\\nIn the context of RAG, it is crucial to efficiently retrieve\\nrelevant documents from the data source. There are several\\nkey issues involved, such as the retrieval source, retrieval\\ngranularity, pre-processing of the retrieval, and selection of\\nthe corresponding embedding model.\\nA. Retrieval Source\\nRAG relies on external knowledge to enhance LLMs, while\\nthe type of retrieval source and the granularity of retrieval\\nunits both affect the final generation results.\\n1) Data Structure: Initially, text is s the mainstream source\\nof retrieval. Subsequently, the retrieval source expanded to in-\\nclude semi-structured data (PDF) and structured data (Knowl-\\nedge Graph, KG) for enhancement. In addition to retrieving\\nfrom original external sources, there is also a growing trend in\\nrecent researches towards utilizing content generated by LLMs\\nthemselves for retrieval and enhancement purposes.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='6\\nTABLE I\\nSUMMARY OF RAG METHODS\\nMethod Retrieval Source Retrieval\\nData Type\\nRetrieval\\nGranularity\\nAugmentation\\nStage\\nRetrieval\\nprocess\\nCoG [29] Wikipedia Text Phrase Pre-training Iterative\\nDenseX [30] FactoidWiki Text Proposition Inference Once\\nEAR [31] Dataset-base Text Sentence Tuning Once\\nUPRISE [20] Dataset-base Text Sentence Tuning Once\\nRAST [32] Dataset-base Text Sentence Tuning Once\\nSelf-Mem [17] Dataset-base Text Sentence Tuning Iterative\\nFLARE [24] Search Engine,Wikipedia Text Sentence Tuning Adaptive\\nPGRA [33] Wikipedia Text Sentence Inference Once\\nFILCO [34] Wikipedia Text Sentence Inference Once\\nRADA [35] Dataset-base Text Sentence Inference Once\\nFilter-rerank [36] Synthesized dataset Text Sentence Inference Once\\nR-GQA [37] Dataset-base Text Sentence Pair Tuning Once\\nLLM-R [38] Dataset-base Text Sentence Pair Inference Iterative\\nTIGER [39] Dataset-base Text Item-base Pre-training Once\\nLM-Indexer [40] Dataset-base Text Item-base Tuning Once'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='LLM-R [38] Dataset-base Text Sentence Pair Inference Iterative\\nTIGER [39] Dataset-base Text Item-base Pre-training Once\\nLM-Indexer [40] Dataset-base Text Item-base Tuning Once\\nBEQUE [9] Dataset-base Text Item-base Tuning Once\\nCT-RAG [41] Synthesized dataset Text Item-base Tuning Once\\nAtlas [42] Wikipedia, Common Crawl Text Chunk Pre-training Iterative\\nRA VEN [43] Wikipedia Text Chunk Pre-training Once\\nRETRO++ [44] Pre-training Corpus Text Chunk Pre-training Iterative\\nINSTRUCTRETRO [45] Pre-training corpus Text Chunk Pre-training Iterative\\nRRR [7] Search Engine Text Chunk Tuning Once\\nRA-e2e [46] Dataset-base Text Chunk Tuning Once\\nPROMPTAGATOR [21] BEIR Text Chunk Tuning Once\\nAAR [47] MSMARCO,Wikipedia Text Chunk Tuning Once\\nRA-DIT [27] Common Crawl,Wikipedia Text Chunk Tuning Once\\nRAG-Robust [48] Wikipedia Text Chunk Tuning Once\\nRA-Long-Form [49] Dataset-base Text Chunk Tuning Once\\nCoN [50] Wikipedia Text Chunk Tuning Once\\nSelf-RAG [25] Wikipedia Text Chunk Tuning Adaptive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='RAG-Robust [48] Wikipedia Text Chunk Tuning Once\\nRA-Long-Form [49] Dataset-base Text Chunk Tuning Once\\nCoN [50] Wikipedia Text Chunk Tuning Once\\nSelf-RAG [25] Wikipedia Text Chunk Tuning Adaptive\\nBGM [26] Wikipedia Text Chunk Inference Once\\nCoQ [51] Wikipedia Text Chunk Inference Iterative\\nToken-Elimination [52] Wikipedia Text Chunk Inference Once\\nPaperQA [53] Arxiv,Online Database,PubMed Text Chunk Inference Iterative\\nNoiseRAG [54] FactoidWiki Text Chunk Inference Once\\nIAG [55] Search Engine,Wikipedia Text Chunk Inference Once\\nNoMIRACL [56] Wikipedia Text Chunk Inference Once\\nToC [57] Search Engine,Wikipedia Text Chunk Inference Recursive\\nSKR [58] Dataset-base,Wikipedia Text Chunk Inference Adaptive\\nITRG [59] Wikipedia Text Chunk Inference Iterative\\nRAG-LongContext [60] Dataset-base Text Chunk Inference Once\\nITER-RETGEN [14] Wikipedia Text Chunk Inference Iterative\\nIRCoT [61] Wikipedia Text Chunk Inference Recursive\\nLLM-Knowledge-Boundary [62] Wikipedia Text Chunk Inference Once'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='ITER-RETGEN [14] Wikipedia Text Chunk Inference Iterative\\nIRCoT [61] Wikipedia Text Chunk Inference Recursive\\nLLM-Knowledge-Boundary [62] Wikipedia Text Chunk Inference Once\\nRAPTOR [63] Dataset-base Text Chunk Inference Recursive\\nRECITE [22] LLMs Text Chunk Inference Once\\nICRALM [64] Pile,Wikipedia Text Chunk Inference Iterative\\nRetrieve-and-Sample [65] Dataset-base Text Doc Tuning Once\\nZemi [66] C4 Text Doc Tuning Once\\nCRAG [67] Arxiv Text Doc Inference Once\\n1-PAGER [68] Wikipedia Text Doc Inference Iterative\\nPRCA [69] Dataset-base Text Doc Inference Once\\nQLM-Doc-ranking [70] Dataset-base Text Doc Inference Once\\nRecomp [71] Wikipedia Text Doc Inference Once\\nDSP [23] Wikipedia Text Doc Inference Iterative\\nRePLUG [72] Pile Text Doc Inference Once\\nARM-RAG [73] Dataset-base Text Doc Inference Iterative\\nGenRead [13] LLMs Text Doc Inference Iterative\\nUniMS-RAG [74] Dataset-base Text Multi Tuning Once\\nCREA-ICL [19] Dataset-base Crosslingual,Text Sentence Inference Once'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='GenRead [13] LLMs Text Doc Inference Iterative\\nUniMS-RAG [74] Dataset-base Text Multi Tuning Once\\nCREA-ICL [19] Dataset-base Crosslingual,Text Sentence Inference Once\\nPKG [75] LLM Tabular,Text Chunk Inference Once\\nSANTA [76] Dataset-base Code,Text Item Pre-training Once\\nSURGE [77] Freebase KG Sub-Graph Tuning Once\\nMK-ToD [78] Dataset-base KG Entity Tuning Once\\nDual-Feedback-ToD [79] Dataset-base KG Entity Sequence Tuning Once\\nKnowledGPT [15] Dataset-base KG Triplet Inference Muti-time\\nFABULA [80] Dataset-base,Graph KG Entity Inference Once\\nHyKGE [81] CMeKG KG Entity Inference Once\\nKALMV [82] Wikipedia KG Triplet Inference Iterative\\nRoG [83] Freebase KG Triplet Inference Iterative\\nG-Retriever [84] Dataset-base TextGraph Sub-Graph Inference Once'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='7\\nFig. 4. RAG compared with other model optimization methods in the aspects of “External Knowledge Required” and “Model Adaption Required”. Prompt\\nEngineering requires low modifications to the model and external knowledge, focusing on harnessing the capabilities of LLMs themselves. Fine-tuning, on\\nthe other hand, involves further training the model. In the early stages of RAG (Naive RAG), there is a low demand for model modifications. As research\\nprogresses, Modular RAG has become more integrated with fine-tuning techniques.\\nUnstructured Data , such as text, is the most widely used\\nretrieval source, which are mainly gathered from corpus. For\\nopen-domain question-answering (ODQA) tasks, the primary\\nretrieval sources are Wikipedia Dump with the current major\\nversions including HotpotQA 4 (1st October , 2017), DPR5 (20\\nDecember, 2018). In addition to encyclopedic data, common\\nunstructured data includes cross-lingual text [19] and domain-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='versions including HotpotQA 4 (1st October , 2017), DPR5 (20\\nDecember, 2018). In addition to encyclopedic data, common\\nunstructured data includes cross-lingual text [19] and domain-\\nspecific data (such as medical [67]and legal domains [29]).\\nSemi-structured data. typically refers to data that contains a\\ncombination of text and table information, such as PDF. Han-\\ndling semi-structured data poses challenges for conventional\\nRAG systems due to two main reasons. Firstly, text splitting\\nprocesses may inadvertently separate tables, leading to data\\ncorruption during retrieval. Secondly, incorporating tables into\\nthe data can complicate semantic similarity searches. When\\ndealing with semi-structured data, one approach involves lever-\\naging the code capabilities of LLMs to execute Text-2-SQL\\nqueries on tables within databases, such as TableGPT [85].\\nAlternatively, tables can be transformed into text format for\\nfurther analysis using text-based methods [75]. However, both'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='queries on tables within databases, such as TableGPT [85].\\nAlternatively, tables can be transformed into text format for\\nfurther analysis using text-based methods [75]. However, both\\nof these methods are not optimal solutions, indicating substan-\\ntial research opportunities in this area.\\nStructured data , such as knowledge graphs (KGs) [86] ,\\nwhich are typically verified and can provide more precise in-\\nformation. KnowledGPT [15] generates KB search queries and\\nstores knowledge in a personalized base, enhancing the RAG\\nmodel’s knowledge richness. In response to the limitations of\\nLLMs in understanding and answering questions about textual\\ngraphs, G-Retriever [84] integrates Graph Neural Networks\\n4https://hotpotqa.github.io/wiki-readme.html\\n5https://github.com/facebookresearch/DPR\\n(GNNs), LLMs and RAG, enhancing graph comprehension\\nand question-answering capabilities through soft prompting\\nof the LLM, and employs the Prize-Collecting Steiner Tree'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='(GNNs), LLMs and RAG, enhancing graph comprehension\\nand question-answering capabilities through soft prompting\\nof the LLM, and employs the Prize-Collecting Steiner Tree\\n(PCST) optimization problem for targeted graph retrieval. On\\nthe contrary, it requires additional effort to build, validate,\\nand maintain structured databases. On the contrary, it requires\\nadditional effort to build, validate, and maintain structured\\ndatabases.\\nLLMs-Generated Content. Addressing the limitations of\\nexternal auxiliary information in RAG, some research has\\nfocused on exploiting LLMs’ internal knowledge. SKR [58]\\nclassifies questions as known or unknown, applying retrieval\\nenhancement selectively. GenRead [13] replaces the retriever\\nwith an LLM generator, finding that LLM-generated contexts\\noften contain more accurate answers due to better alignment\\nwith the pre-training objectives of causal language modeling.\\nSelfmem [17] iteratively creates an unbounded memory pool'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='often contain more accurate answers due to better alignment\\nwith the pre-training objectives of causal language modeling.\\nSelfmem [17] iteratively creates an unbounded memory pool\\nwith a retrieval-enhanced generator, using a memory selec-\\ntor to choose outputs that serve as dual problems to the\\noriginal question, thus self-enhancing the generative model.\\nThese methodologies underscore the breadth of innovative\\ndata source utilization in RAG, striving to improve model\\nperformance and task effectiveness.\\n2) Retrieval Granularity: Another important factor besides\\nthe data format of the retrieval source is the granularity of\\nthe retrieved data. Coarse-grained retrieval units theoretically\\ncan provide more relevant information for the problem, but\\nthey may also contain redundant content, which could distract\\nthe retriever and language models in downstream tasks [50],\\n[87]. On the other hand, fine-grained retrieval unit granularity'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='they may also contain redundant content, which could distract\\nthe retriever and language models in downstream tasks [50],\\n[87]. On the other hand, fine-grained retrieval unit granularity\\nincreases the burden of retrieval and does not guarantee seman-\\ntic integrity and meeting the required knowledge. Choosing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='8\\nthe appropriate retrieval granularity during inference can be\\na simple and effective strategy to improve the retrieval and\\ndownstream task performance of dense retrievers.\\nIn text, retrieval granularity ranges from fine to coarse,\\nincluding Token, Phrase, Sentence, Proposition, Chunks, Doc-\\nument. Among them, DenseX [30]proposed the concept of\\nusing propositions as retrieval units. Propositions are defined\\nas atomic expressions in the text, each encapsulating a unique\\nfactual segment and presented in a concise, self-contained nat-\\nural language format. This approach aims to enhance retrieval\\nprecision and relevance. On the Knowledge Graph (KG),\\nretrieval granularity includes Entity, Triplet, and sub-Graph.\\nThe granularity of retrieval can also be adapted to downstream\\ntasks, such as retrieving Item IDs [40]in recommendation tasks\\nand Sentence pairs [38]. Detailed information is illustrated in\\nTable I.\\nB. Indexing Optimization\\nIn the Indexing phase, documents will be processed, seg-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and Sentence pairs [38]. Detailed information is illustrated in\\nTable I.\\nB. Indexing Optimization\\nIn the Indexing phase, documents will be processed, seg-\\nmented, and transformed into Embeddings to be stored in a\\nvector database. The quality of index construction determines\\nwhether the correct context can be obtained in the retrieval\\nphase.\\n1) Chunking Strategy: The most common method is to split\\nthe document into chunks on a fixed number of tokens (e.g.,\\n100, 256, 512) [88]. Larger chunks can capture more context,\\nbut they also generate more noise, requiring longer processing\\ntime and higher costs. While smaller chunks may not fully\\nconvey the necessary context, they do have less noise. How-\\never, chunks leads to truncation within sentences, prompting\\nthe optimization of a recursive splits and sliding window meth-\\nods, enabling layered retrieval by merging globally related\\ninformation across multiple retrieval processes [89]. Never-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='the optimization of a recursive splits and sliding window meth-\\nods, enabling layered retrieval by merging globally related\\ninformation across multiple retrieval processes [89]. Never-\\ntheless, these approaches still cannot strike a balance between\\nsemantic completeness and context length. Therefore, methods\\nlike Small2Big have been proposed, where sentences (small)\\nare used as the retrieval unit, and the preceding and following\\nsentences are provided as (big) context to LLMs [90].\\n2) Metadata Attachments: Chunks can be enriched with\\nmetadata information such as page number, file name, au-\\nthor,category timestamp. Subsequently, retrieval can be filtered\\nbased on this metadata, limiting the scope of the retrieval.\\nAssigning different weights to document timestamps during\\nretrieval can achieve time-aware RAG, ensuring the freshness\\nof knowledge and avoiding outdated information.\\nIn addition to extracting metadata from the original doc-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='retrieval can achieve time-aware RAG, ensuring the freshness\\nof knowledge and avoiding outdated information.\\nIn addition to extracting metadata from the original doc-\\numents, metadata can also be artificially constructed. For\\nexample, adding summaries of paragraph, as well as intro-\\nducing hypothetical questions. This method is also known as\\nReverse HyDE. Specifically, using LLM to generate questions\\nthat can be answered by the document, then calculating the\\nsimilarity between the original question and the hypothetical\\nquestion during retrieval to reduce the semantic gap between\\nthe question and the answer.\\n3) Structural Index: One effective method for enhancing\\ninformation retrieval is to establish a hierarchical structure for\\nthe documents. By constructing In structure, RAG system can\\nexpedite the retrieval and processing of pertinent data.\\nHierarchical index structure . File are arranged in parent-\\nchild relationships, with chunks linked to them. Data sum-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='expedite the retrieval and processing of pertinent data.\\nHierarchical index structure . File are arranged in parent-\\nchild relationships, with chunks linked to them. Data sum-\\nmaries are stored at each node, aiding in the swift traversal\\nof data and assisting the RAG system in determining which\\nchunks to extract. This approach can also mitigate the illusion\\ncaused by block extraction issues.\\nKnowledge Graph index . Utilize KG in constructing the\\nhierarchical structure of documents contributes to maintaining\\nconsistency. It delineates the connections between different\\nconcepts and entities, markedly reducing the potential for\\nillusions. Another advantage is the transformation of the\\ninformation retrieval process into instructions that LLM can\\ncomprehend, thereby enhancing the accuracy of knowledge\\nretrieval and enabling LLM to generate contextually coherent\\nresponses, thus improving the overall efficiency of the RAG\\nsystem. To capture the logical relationship between document'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='retrieval and enabling LLM to generate contextually coherent\\nresponses, thus improving the overall efficiency of the RAG\\nsystem. To capture the logical relationship between document\\ncontent and structure, KGP [91] proposed a method of building\\nan index between multiple documents using KG. This KG\\nconsists of nodes (representing paragraphs or structures in the\\ndocuments, such as pages and tables) and edges (indicating\\nsemantic/lexical similarity between paragraphs or relationships\\nwithin the document structure), effectively addressing knowl-\\nedge retrieval and reasoning problems in a multi-document\\nenvironment.\\nC. Query Optimization\\nOne of the primary challenges with Naive RAG is its\\ndirect reliance on the user’s original query as the basis for\\nretrieval. Formulating a precise and clear question is difficult,\\nand imprudent queries result in subpar retrieval effectiveness.\\nSometimes, the question itself is complex, and the language'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='retrieval. Formulating a precise and clear question is difficult,\\nand imprudent queries result in subpar retrieval effectiveness.\\nSometimes, the question itself is complex, and the language\\nis not well-organized. Another difficulty lies in language\\ncomplexity ambiguity. Language models often struggle when\\ndealing with specialized vocabulary or ambiguous abbrevi-\\nations with multiple meanings. For instance, they may not\\ndiscern whether “LLM” refers to large language model or a\\nMaster of Laws in a legal context.\\n1) Query Expansion: Expanding a single query into mul-\\ntiple queries enriches the content of the query, providing\\nfurther context to address any lack of specific nuances, thereby\\nensuring the optimal relevance of the generated answers.\\nMulti-Query. By employing prompt engineering to expand\\nqueries via LLMs, these queries can then be executed in\\nparallel. The expansion of queries is not random, but rather\\nmeticulously designed.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Multi-Query. By employing prompt engineering to expand\\nqueries via LLMs, these queries can then be executed in\\nparallel. The expansion of queries is not random, but rather\\nmeticulously designed.\\nSub-Query. The process of sub-question planning represents\\nthe generation of the necessary sub-questions to contextualize\\nand fully answer the original question when combined. This\\nprocess of adding relevant context is, in principle, similar\\nto query expansion. Specifically, a complex question can be\\ndecomposed into a series of simpler sub-questions using the\\nleast-to-most prompting method [92].\\nChain-of-Verification(CoVe). The expanded queries undergo\\nvalidation by LLM to achieve the effect of reducing halluci-\\nnations. Validated expanded queries typically exhibit higher\\nreliability [93].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='9\\n2) Query Transformation: The core concept is to retrieve\\nchunks based on a transformed query instead of the user’s\\noriginal query.\\nQuery Rewrite.The original queries are not always optimal\\nfor LLM retrieval, especially in real-world scenarios. There-\\nfore, we can prompt LLM to rewrite the queries. In addition to\\nusing LLM for query rewriting, specialized smaller language\\nmodels, such as RRR (Rewrite-retrieve-read) [7]. The imple-\\nmentation of the query rewrite method in the Taobao, known\\nas BEQUE [9] has notably enhanced recall effectiveness for\\nlong-tail queries, resulting in a rise in GMV .\\nAnother query transformation method is to use prompt\\nengineering to let LLM generate a query based on the original\\nquery for subsequent retrieval. HyDE [11] construct hypothet-\\nical documents (assumed answers to the original query). It\\nfocuses on embedding similarity from answer to answer rather\\nthan seeking embedding similarity for the problem or query.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='ical documents (assumed answers to the original query). It\\nfocuses on embedding similarity from answer to answer rather\\nthan seeking embedding similarity for the problem or query.\\nUsing the Step-back Prompting method [10], the original\\nquery is abstracted to generate a high-level concept question\\n(step-back question). In the RAG system, both the step-back\\nquestion and the original query are used for retrieval, and both\\nthe results are utilized as the basis for language model answer\\ngeneration.\\n3) Query Routing: Based on varying queries, routing to\\ndistinct RAG pipeline,which is suitable for a versatile RAG\\nsystem designed to accommodate diverse scenarios.\\nMetadata Router/ Filter . The first step involves extracting\\nkeywords (entity) from the query, followed by filtering based\\non the keywords and metadata within the chunks to narrow\\ndown the search scope.\\nSemantic Router is another method of routing involves\\nleveraging the semantic information of the query. Specific'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='on the keywords and metadata within the chunks to narrow\\ndown the search scope.\\nSemantic Router is another method of routing involves\\nleveraging the semantic information of the query. Specific\\napprach see Semantic Router 6. Certainly, a hybrid routing\\napproach can also be employed, combining both semantic and\\nmetadata-based methods for enhanced query routing.\\nD. Embedding\\nIn RAG, retrieval is achieved by calculating the similarity\\n(e.g. cosine similarity) between the embeddings of the ques-\\ntion and document chunks, where the semantic representation\\ncapability of embedding models plays a key role. This mainly\\nincludes a sparse encoder (BM25) and a dense retriever (BERT\\narchitecture Pre-training language models). Recent research\\nhas introduced prominent embedding models such as AngIE,\\nV oyage, BGE,etc [94]–[96], which are benefit from multi-task\\ninstruct tuning. Hugging Face’s MTEB leaderboard 7 evaluates\\nembedding models across 8 tasks, covering 58 datasests. Ad-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='V oyage, BGE,etc [94]–[96], which are benefit from multi-task\\ninstruct tuning. Hugging Face’s MTEB leaderboard 7 evaluates\\nembedding models across 8 tasks, covering 58 datasests. Ad-\\nditionally, C-MTEB focuses on Chinese capability, covering\\n6 tasks and 35 datasets. There is no one-size-fits-all answer\\nto “which embedding model to use.” However, some specific\\nmodels are better suited for particular use cases.\\n1) Mix/hybrid Retrieval : Sparse and dense embedding\\napproaches capture different relevance features and can ben-\\nefit from each other by leveraging complementary relevance\\ninformation. For instance, sparse retrieval models can be used\\n6https://github.com/aurelio-labs/semantic-router\\n7https://huggingface.co/spaces/mteb/leaderboard\\nto provide initial search results for training dense retrieval\\nmodels. Additionally, pre-training language models (PLMs)\\ncan be utilized to learn term weights to enhance sparse\\nretrieval. Specifically, it also demonstrates that sparse retrieval'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='models. Additionally, pre-training language models (PLMs)\\ncan be utilized to learn term weights to enhance sparse\\nretrieval. Specifically, it also demonstrates that sparse retrieval\\nmodels can enhance the zero-shot retrieval capability of dense\\nretrieval models and assist dense retrievers in handling queries\\ncontaining rare entities, thereby improving robustness.\\n2) Fine-tuning Embedding Model: In instances where the\\ncontext significantly deviates from pre-training corpus, partic-\\nularly within highly specialized disciplines such as healthcare,\\nlegal practice, and other sectors replete with proprietary jargon,\\nfine-tuning the embedding model on your own domain dataset\\nbecomes essential to mitigate such discrepancies.\\nIn addition to supplementing domain knowledge, another\\npurpose of fine-tuning is to align the retriever and generator,\\nfor example, using the results of LLM as the supervision signal\\nfor fine-tuning, known as LSR (LM-supervised Retriever).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='purpose of fine-tuning is to align the retriever and generator,\\nfor example, using the results of LLM as the supervision signal\\nfor fine-tuning, known as LSR (LM-supervised Retriever).\\nPROMPTAGATOR [21] utilizes the LLM as a few-shot query\\ngenerator to create task-specific retrievers, addressing chal-\\nlenges in supervised fine-tuning, particularly in data-scarce\\ndomains. Another approach, LLM-Embedder [97], exploits\\nLLMs to generate reward signals across multiple downstream\\ntasks. The retriever is fine-tuned with two types of supervised\\nsignals: hard labels for the dataset and soft rewards from\\nthe LLMs. This dual-signal approach fosters a more effective\\nfine-tuning process, tailoring the embedding model to diverse\\ndownstream applications. REPLUG [72] utilizes a retriever\\nand an LLM to calculate the probability distributions of the\\nretrieved documents and then performs supervised training\\nby computing the KL divergence. This straightforward and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and an LLM to calculate the probability distributions of the\\nretrieved documents and then performs supervised training\\nby computing the KL divergence. This straightforward and\\neffective training method enhances the performance of the\\nretrieval model by using an LM as the supervisory signal,\\neliminating the need for specific cross-attention mechanisms.\\nMoreover, inspired by RLHF (Reinforcement Learning from\\nHuman Feedback), utilizing LM-based feedback to reinforce\\nthe retriever through reinforcement learning.\\nE. Adapter\\nFine-tuning models may present challenges, such as in-\\ntegrating functionality through an API or addressing con-\\nstraints arising from limited local computational resources.\\nConsequently, some approaches opt to incorporate an external\\nadapter to aid in alignment.\\nTo optimize the multi-task capabilities of LLM, UP-\\nRISE [20] trained a lightweight prompt retriever that can\\nautomatically retrieve prompts from a pre-built prompt pool'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='adapter to aid in alignment.\\nTo optimize the multi-task capabilities of LLM, UP-\\nRISE [20] trained a lightweight prompt retriever that can\\nautomatically retrieve prompts from a pre-built prompt pool\\nthat are suitable for a given zero-shot task input. AAR\\n(Augmentation-Adapted Retriver) [47] introduces a universal\\nadapter designed to accommodate multiple downstream tasks.\\nWhile PRCA [69] add a pluggable reward-driven contextual\\nadapter to enhance performance on specific tasks. BGM [26]\\nkeeps the retriever and LLM fixed,and trains a bridge Seq2Seq\\nmodel in between. The bridge model aims to transform the\\nretrieved information into a format that LLMs can work with\\neffectively, allowing it to not only rerank but also dynami-\\ncally select passages for each query, and potentially employ\\nmore advanced strategies like repetition. Furthermore, PKG'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='10\\nintroduces an innovative method for integrating knowledge\\ninto white-box models via directive fine-tuning [75]. In this\\napproach, the retriever module is directly substituted to gen-\\nerate relevant documents according to a query. This method\\nassists in addressing the difficulties encountered during the\\nfine-tuning process and enhances model performance.\\nIV. G ENERATION\\nAfter retrieval, it is not a good practice to directly input all\\nthe retrieved information to the LLM for answering questions.\\nFollowing will introduce adjustments from two perspectives:\\nadjusting the retrieved content and adjusting the LLM.\\nA. Context Curation\\nRedundant information can interfere with the final gener-\\nation of LLM, and overly long contexts can also lead LLM\\nto the “Lost in the middle” problem [98]. Like humans, LLM\\ntends to only focus on the beginning and end of long texts,\\nwhile forgetting the middle portion. Therefore, in the RAG\\nsystem, we typically need to further process the retrieved\\ncontent.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='tends to only focus on the beginning and end of long texts,\\nwhile forgetting the middle portion. Therefore, in the RAG\\nsystem, we typically need to further process the retrieved\\ncontent.\\n1) Reranking: Reranking fundamentally reorders document\\nchunks to highlight the most pertinent results first, effectively\\nreducing the overall document pool, severing a dual purpose\\nin information retrieval, acting as both an enhancer and a\\nfilter, delivering refined inputs for more precise language\\nmodel processing [70]. Reranking can be performed using\\nrule-based methods that depend on predefined metrics like\\nDiversity, Relevance, and MRR, or model-based approaches\\nlike Encoder-Decoder models from the BERT series (e.g.,\\nSpanBERT), specialized reranking models such as Cohere\\nrerank or bge-raranker-large, and general large language mod-\\nels like GPT [12], [99].\\n2) Context Selection/Compression: A common misconcep-\\ntion in the RAG process is the belief that retrieving as many'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='els like GPT [12], [99].\\n2) Context Selection/Compression: A common misconcep-\\ntion in the RAG process is the belief that retrieving as many\\nrelevant documents as possible and concatenating them to form\\na lengthy retrieval prompt is beneficial. However, excessive\\ncontext can introduce more noise, diminishing the LLM’s\\nperception of key information .\\n(Long) LLMLingua [100], [101] utilize small language\\nmodels (SLMs) such as GPT-2 Small or LLaMA-7B, to\\ndetect and remove unimportant tokens, transforming it into\\na form that is challenging for humans to comprehend but\\nwell understood by LLMs. This approach presents a direct\\nand practical method for prompt compression, eliminating the\\nneed for additional training of LLMs while balancing language\\nintegrity and compression ratio. PRCA tackled this issue by\\ntraining an information extractor [69]. Similarly, RECOMP\\nadopts a comparable approach by training an information\\ncondenser using contrastive learning [71]. Each training data'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='training an information extractor [69]. Similarly, RECOMP\\nadopts a comparable approach by training an information\\ncondenser using contrastive learning [71]. Each training data\\npoint consists of one positive sample and five negative sam-\\nples, and the encoder undergoes training using contrastive loss\\nthroughout this process [102] .\\nIn addition to compressing the context, reducing the num-\\nber of documents aslo helps improve the accuracy of the\\nmodel’s answers. Ma et al. [103] propose the “Filter-Reranker”\\nparadigm, which combines the strengths of LLMs and SLMs.\\nIn this paradigm, SLMs serve as filters, while LLMs function\\nas reordering agents. The research shows that instructing\\nLLMs to rearrange challenging samples identified by SLMs\\nleads to significant improvements in various Information\\nExtraction (IE) tasks. Another straightforward and effective\\napproach involves having the LLM evaluate the retrieved\\ncontent before generating the final answer. This allows the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Extraction (IE) tasks. Another straightforward and effective\\napproach involves having the LLM evaluate the retrieved\\ncontent before generating the final answer. This allows the\\nLLM to filter out documents with poor relevance through LLM\\ncritique. For instance, in Chatlaw [104], the LLM is prompted\\nto self-suggestion on the referenced legal provisions to assess\\ntheir relevance.\\nB. LLM Fine-tuning\\nTargeted fine-tuning based on the scenario and data char-\\nacteristics on LLMs can yield better results. This is also one\\nof the greatest advantages of using on-premise LLMs. When\\nLLMs lack data in a specific domain, additional knowledge can\\nbe provided to the LLM through fine-tuning. Huggingface’s\\nfine-tuning data can also be used as an initial step.\\nAnother benefit of fine-tuning is the ability to adjust the\\nmodel’s input and output. For example, it can enable LLM to\\nadapt to specific data formats and generate responses in a par-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Another benefit of fine-tuning is the ability to adjust the\\nmodel’s input and output. For example, it can enable LLM to\\nadapt to specific data formats and generate responses in a par-\\nticular style as instructed [37]. For retrieval tasks that engage\\nwith structured data, the SANTA framework [76] implements\\na tripartite training regimen to effectively encapsulate both\\nstructural and semantic nuances. The initial phase focuses on\\nthe retriever, where contrastive learning is harnessed to refine\\nthe query and document embeddings.\\nAligning LLM outputs with human or retriever preferences\\nthrough reinforcement learning is a potential approach. For\\ninstance, manually annotating the final generated answers\\nand then providing feedback through reinforcement learning.\\nIn addition to aligning with human preferences, it is also\\npossible to align with the preferences of fine-tuned models\\nand retrievers [79]. When circumstances prevent access to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='In addition to aligning with human preferences, it is also\\npossible to align with the preferences of fine-tuned models\\nand retrievers [79]. When circumstances prevent access to\\npowerful proprietary models or larger parameter open-source\\nmodels, a simple and effective method is to distill the more\\npowerful models(e.g. GPT-4). Fine-tuning of LLM can also\\nbe coordinated with fine-tuning of the retriever to align pref-\\nerences. A typical approach, such as RA-DIT [27], aligns the\\nscoring functions between Retriever and Generator using KL\\ndivergence.\\nV. A UGMENTATION PROCESS IN RAG\\nIn the domain of RAG, the standard practice often involves\\na singular (once) retrieval step followed by generation, which\\ncan lead to inefficiencies and sometimes is typically insuffi-\\ncient for complex problems demanding multi-step reasoning,\\nas it provides a limited scope of information [105]. Many\\nstudies have optimized the retrieval process in response to this\\nissue, and we have summarised them in Figure 5.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='as it provides a limited scope of information [105]. Many\\nstudies have optimized the retrieval process in response to this\\nissue, and we have summarised them in Figure 5.\\nA. Iterative Retrieval\\nIterative retrieval is a process where the knowledge base\\nis repeatedly searched based on the initial query and the text\\ngenerated so far, providing a more comprehensive knowledge'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='11\\nFig. 5. In addition to the most common once retrieval, RAG also includes three types of retrieval augmentation processes. (left) Iterative retrieval involves\\nalternating between retrieval and generation, allowing for richer and more targeted context from the knowledge base at each step. (Middle) Recursive retrieval\\ninvolves gradually refining the user query and breaking down the problem into sub-problems, then continuously solving complex problems through retrieval\\nand generation. (Right) Adaptive retrieval focuses on enabling the RAG system to autonomously determine whether external knowledge retrieval is necessary\\nand when to stop retrieval and generation, often utilizing LLM-generated special tokens for control.\\nbase for LLMs. This approach has been shown to enhance\\nthe robustness of subsequent answer generation by offering\\nadditional contextual references through multiple retrieval\\niterations. However, it may be affected by semantic discon-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='the robustness of subsequent answer generation by offering\\nadditional contextual references through multiple retrieval\\niterations. However, it may be affected by semantic discon-\\ntinuity and the accumulation of irrelevant information. ITER-\\nRETGEN [14] employs a synergistic approach that lever-\\nages “retrieval-enhanced generation” alongside “generation-\\nenhanced retrieval” for tasks that necessitate the reproduction\\nof specific information. The model harnesses the content\\nrequired to address the input task as a contextual basis for\\nretrieving pertinent knowledge, which in turn facilitates the\\ngeneration of improved responses in subsequent iterations.\\nB. Recursive Retrieval\\nRecursive retrieval is often used in information retrieval and\\nNLP to improve the depth and relevance of search results.\\nThe process involves iteratively refining search queries based\\non the results obtained from previous searches. Recursive\\nRetrieval aims to enhance the search experience by gradu-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='The process involves iteratively refining search queries based\\non the results obtained from previous searches. Recursive\\nRetrieval aims to enhance the search experience by gradu-\\nally converging on the most pertinent information through a\\nfeedback loop. IRCoT [61] uses chain-of-thought to guide\\nthe retrieval process and refines the CoT with the obtained\\nretrieval results. ToC [57] creates a clarification tree that\\nsystematically optimizes the ambiguous parts in the Query. It\\ncan be particularly useful in complex search scenarios where\\nthe user’s needs are not entirely clear from the outset or where\\nthe information sought is highly specialized or nuanced. The\\nrecursive nature of the process allows for continuous learning\\nand adaptation to the user’s requirements, often resulting in\\nimproved satisfaction with the search outcomes.\\nTo address specific data scenarios, recursive retrieval and\\nmulti-hop retrieval techniques are utilized together. Recursive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='improved satisfaction with the search outcomes.\\nTo address specific data scenarios, recursive retrieval and\\nmulti-hop retrieval techniques are utilized together. Recursive\\nretrieval involves a structured index to process and retrieve\\ndata in a hierarchical manner, which may include summarizing\\nsections of a document or lengthy PDF before performing a\\nretrieval based on this summary. Subsequently, a secondary\\nretrieval within the document refines the search, embodying\\nthe recursive nature of the process. In contrast, multi-hop\\nretrieval is designed to delve deeper into graph-structured data\\nsources, extracting interconnected information [106].\\nC. Adaptive Retrieval\\nAdaptive retrieval methods, exemplified by Flare [24] and\\nSelf-RAG [25], refine the RAG framework by enabling LLMs\\nto actively determine the optimal moments and content for\\nretrieval, thus enhancing the efficiency and relevance of the\\ninformation sourced.\\nThese methods are part of a broader trend wherein'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='to actively determine the optimal moments and content for\\nretrieval, thus enhancing the efficiency and relevance of the\\ninformation sourced.\\nThese methods are part of a broader trend wherein\\nLLMs employ active judgment in their operations, as seen\\nin model agents like AutoGPT, Toolformer, and Graph-\\nToolformer [107]–[109]. Graph-Toolformer, for instance, di-\\nvides its retrieval process into distinct steps where LLMs\\nproactively use retrievers, apply Self-Ask techniques, and em-\\nploy few-shot prompts to initiate search queries. This proactive\\nstance allows LLMs to decide when to search for necessary\\ninformation, akin to how an agent utilizes tools.\\nWebGPT [110] integrates a reinforcement learning frame-\\nwork to train the GPT-3 model in autonomously using a\\nsearch engine during text generation. It navigates this process\\nusing special tokens that facilitate actions such as search\\nengine queries, browsing results, and citing references, thereby'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='search engine during text generation. It navigates this process\\nusing special tokens that facilitate actions such as search\\nengine queries, browsing results, and citing references, thereby\\nexpanding GPT-3’s capabilities through the use of external\\nsearch engines. Flare automates timing retrieval by monitoring\\nthe confidence of the generation process, as indicated by the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='12\\nprobability of generated terms [24]. When the probability falls\\nbelow a certain threshold would activates the retrieval system\\nto collect relevant information, thus optimizing the retrieval\\ncycle. Self-RAG [25] introduces “reflection tokens” that allow\\nthe model to introspect its outputs. These tokens come in\\ntwo varieties: “retrieve” and “critic”. The model autonomously\\ndecides when to activate retrieval, or alternatively, a predefined\\nthreshold may trigger the process. During retrieval, the gen-\\nerator conducts a fragment-level beam search across multiple\\nparagraphs to derive the most coherent sequence. Critic scores\\nare used to update the subdivision scores, with the flexibility\\nto adjust these weights during inference, tailoring the model’s\\nbehavior. Self-RAG’s design obviates the need for additional\\nclassifiers or reliance on Natural Language Inference (NLI)\\nmodels, thus streamlining the decision-making process for\\nwhen to engage retrieval mechanisms and improving the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='classifiers or reliance on Natural Language Inference (NLI)\\nmodels, thus streamlining the decision-making process for\\nwhen to engage retrieval mechanisms and improving the\\nmodel’s autonomous judgment capabilities in generating ac-\\ncurate responses.\\nVI. T ASK AND EVALUATION\\nThe rapid advancement and growing adoption of RAG\\nin the field of NLP have propelled the evaluation of RAG\\nmodels to the forefront of research in the LLMs community.\\nThe primary objective of this evaluation is to comprehend\\nand optimize the performance of RAG models across diverse\\napplication scenarios.This chapter will mainly introduce the\\nmain downstream tasks of RAG, datasets, and how to evaluate\\nRAG systems.\\nA. Downstream Task\\nThe core task of RAG remains Question Answering (QA),\\nincluding traditional single-hop/multi-hop QA, multiple-\\nchoice, domain-specific QA as well as long-form scenarios\\nsuitable for RAG. In addition to QA, RAG is continuously\\nbeing expanded into multiple downstream tasks, such as Infor-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='choice, domain-specific QA as well as long-form scenarios\\nsuitable for RAG. In addition to QA, RAG is continuously\\nbeing expanded into multiple downstream tasks, such as Infor-\\nmation Extraction (IE), dialogue generation, code search, etc.\\nThe main downstream tasks of RAG and their corresponding\\ndatasets are summarized in Table II.\\nB. Evaluation Target\\nHistorically, RAG models assessments have centered on\\ntheir execution in specific downstream tasks. These evaluations\\nemploy established metrics suitable to the tasks at hand. For\\ninstance, question answering evaluations might rely on EM\\nand F1 scores [7], [45], [59], [72], whereas fact-checking\\ntasks often hinge on Accuracy as the primary metric [4],\\n[14], [42]. BLEU and ROUGE metrics are also commonly\\nused to evaluate answer quality [26], [32], [52], [78]. Tools\\nlike RALLE, designed for the automatic evaluation of RAG\\napplications, similarly base their assessments on these task-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='used to evaluate answer quality [26], [32], [52], [78]. Tools\\nlike RALLE, designed for the automatic evaluation of RAG\\napplications, similarly base their assessments on these task-\\nspecific metrics [160]. Despite this, there is a notable paucity\\nof research dedicated to evaluating the distinct characteristics\\nof RAG models.The main evaluation objectives include:\\nRetrieval Quality. Evaluating the retrieval quality is crucial\\nfor determining the effectiveness of the context sourced by\\nthe retriever component. Standard metrics from the domains\\nof search engines, recommendation systems, and information\\nretrieval systems are employed to measure the performance of\\nthe RAG retrieval module. Metrics such as Hit Rate, MRR, and\\nNDCG are commonly utilized for this purpose [161], [162].\\nGeneration Quality . The assessment of generation quality\\ncenters on the generator’s capacity to synthesize coherent and\\nrelevant answers from the retrieved context. This evaluation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Generation Quality . The assessment of generation quality\\ncenters on the generator’s capacity to synthesize coherent and\\nrelevant answers from the retrieved context. This evaluation\\ncan be categorized based on the content’s objectives: unlabeled\\nand labeled content. For unlabeled content, the evaluation\\nencompasses the faithfulness, relevance, and non-harmfulness\\nof the generated answers. In contrast, for labeled content,\\nthe focus is on the accuracy of the information produced by\\nthe model [161]. Additionally, both retrieval and generation\\nquality assessments can be conducted through manual or\\nautomatic evaluation methods [29], [161], [163].\\nC. Evaluation Aspects\\nContemporary evaluation practices of RAG models empha-\\nsize three primary quality scores and four essential abilities,\\nwhich collectively inform the evaluation of the two principal\\ntargets of the RAG model: retrieval and generation.\\n1) Quality Scores: Quality scores include context rele-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='which collectively inform the evaluation of the two principal\\ntargets of the RAG model: retrieval and generation.\\n1) Quality Scores: Quality scores include context rele-\\nvance, answer faithfulness, and answer relevance. These qual-\\nity scores evaluate the efficiency of the RAG model from\\ndifferent perspectives in the process of information retrieval\\nand generation [164]–[166].\\nContext Relevance evaluates the precision and specificity\\nof the retrieved context, ensuring relevance and minimizing\\nprocessing costs associated with extraneous content.\\nAnswer Faithfulness ensures that the generated answers\\nremain true to the retrieved context, maintaining consistency\\nand avoiding contradictions.\\nAnswer Relevance requires that the generated answers are\\ndirectly pertinent to the posed questions, effectively addressing\\nthe core inquiry.\\n2) Required Abilities: RAG evaluation also encompasses\\nfour abilities indicative of its adaptability and efficiency:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='the core inquiry.\\n2) Required Abilities: RAG evaluation also encompasses\\nfour abilities indicative of its adaptability and efficiency:\\nnoise robustness, negative rejection, information integration,\\nand counterfactual robustness [167], [168]. These abilities are\\ncritical for the model’s performance under various challenges\\nand complex scenarios, impacting the quality scores.\\nNoise Robustness appraises the model’s capability to man-\\nage noise documents that are question-related but lack sub-\\nstantive information.\\nNegative Rejection assesses the model’s discernment in\\nrefraining from responding when the retrieved documents do\\nnot contain the necessary knowledge to answer a question.\\nInformation Integration evaluates the model’s proficiency in\\nsynthesizing information from multiple documents to address\\ncomplex questions.\\nCounterfactual Robustness tests the model’s ability to rec-\\nognize and disregard known inaccuracies within documents,\\neven when instructed about potential misinformation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='complex questions.\\nCounterfactual Robustness tests the model’s ability to rec-\\nognize and disregard known inaccuracies within documents,\\neven when instructed about potential misinformation.\\nContext relevance and noise robustness are important for\\nevaluating the quality of retrieval, while answer faithfulness,\\nanswer relevance, negative rejection, information integration,\\nand counterfactual robustness are important for evaluating the\\nquality of generation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 12, 'page_label': '13', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='13\\nTABLE II\\nDOWNSTREAM TASKS AND DATASETS OF RAG\\nTask Sub Task Dataset Method\\nQA Single-hop Natural Qustion(NQ) [111]\\n[26], [30], [34], [42], [45], [50], [52], [59], [64], [82]\\n[3], [4], [22], [27], [40], [43], [54], [62], [71], [112]\\n[20], [44], [72]\\nTriviaQA(TQA) [113]\\n[13], [30], [34], [45], [50], [64]\\n[4], [27], [59], [62], [112]\\n[22], [25], [43], [44], [71], [72]\\nSQuAD [114] [20], [23], [30], [32], [45], [69], [112]\\nWeb Questions(WebQ) [115] [3], [4], [13], [30], [50], [68]\\nPopQA [116] [7], [25], [67]\\nMS MARCO [117] [4], [40], [52]\\nMulti-hop HotpotQA [118] [23], [26], [31], [34], [47], [51], [61], [82]\\n[7], [14], [22], [27], [59], [62], [69], [71], [91]\\n2WikiMultiHopQA [119] [14], [24], [48], [59], [61], [91]\\nMuSiQue [120] [14], [51], [61], [91]\\nLong-form QA ELI5 [121] [27], [34], [43], [49], [51]\\nNarrativeQA(NQA) [122] [45], [60], [63], [123]\\nASQA [124] [24], [57]\\nQMSum(QM) [125] [60], [123]\\nDomain QA Qasper [126] [60], [63]\\nCOVID-QA [127] [35], [46]'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 12, 'page_label': '13', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='NarrativeQA(NQA) [122] [45], [60], [63], [123]\\nASQA [124] [24], [57]\\nQMSum(QM) [125] [60], [123]\\nDomain QA Qasper [126] [60], [63]\\nCOVID-QA [127] [35], [46]\\nCMB [128],MMCU Medical [129] [81]\\nMulti-Choice QA QuALITY [130] [60], [63]\\nARC [131] [25], [67]\\nCommonsenseQA [132] [58], [66]\\nGraph QA GraphQA [84] [84]\\nDialog Dialog Generation Wizard of Wikipedia (WoW) [133] [13], [27], [34], [42]\\nPersonal Dialog KBP [134] [74], [135]\\nDuleMon [136] [74]\\nTask-oriented Dialog CamRest [137] [78], [79]\\nRecommendation Amazon(Toys,Sport,Beauty) [138] [39], [40]\\nIE Event Argument Extraction WikiEvent [139] [13], [27], [37], [42]\\nRAMS [140] [36], [37]\\nRelation Extraction T-REx [141],ZsRE [142] [27], [51]\\nReasoning Commonsense Reasoning HellaSwag [143] [20], [66]\\nCoT Reasoning CoT Reasoning [144] [27]\\nComplex Reasoning CSQA [145] [55]\\nOthers Language Understanding MMLU [146] [7], [27], [28], [42], [43], [47], [72]\\nLanguage Modeling WikiText-103 [147] [5], [29], [64], [71]'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 12, 'page_label': '13', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Complex Reasoning CSQA [145] [55]\\nOthers Language Understanding MMLU [146] [7], [27], [28], [42], [43], [47], [72]\\nLanguage Modeling WikiText-103 [147] [5], [29], [64], [71]\\nStrategyQA [148] [14], [24], [48], [51], [55], [58]\\nFact Checking/Verification FEVER [149] [4], [13], [27], [34], [42], [50]\\nPubHealth [150] [25], [67]\\nText Generation Biography [151] [67]\\nText Summarization WikiASP [152] [24]\\nXSum [153] [17]\\nText Classification VioLens [154] [19]\\nTREC [155] [33]\\nSentiment SST-2 [156] [20], [33], [38]\\nCode Search CodeSearchNet [157] [76]\\nRobustness Evaluation NoMIRACL [56] [56]\\nMath GSM8K [158] [73]\\nMachine Translation JRC-Acquis [159] [17]'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='14\\nTABLE III\\nSUMMARY OF METRICS APPLICABLE FOR EVALUATION ASPECTS OF RAG\\nContext\\nRelevance Faithfulness Answer\\nRelevance\\nNoise\\nRobustness\\nNegative\\nRejection\\nInformation\\nIntegration\\nCounterfactual\\nRobustness\\nAccuracy ✓ ✓ ✓ ✓ ✓ ✓ ✓\\nEM ✓\\nRecall ✓\\nPrecision ✓ ✓\\nR-Rate ✓\\nCosine Similarity ✓\\nHit Rate ✓\\nMRR ✓\\nNDCG ✓\\nBLEU ✓ ✓ ✓\\nROUGE/ROUGE-L ✓ ✓ ✓\\nThe specific metrics for each evaluation aspect are sum-\\nmarized in Table III. It is essential to recognize that these\\nmetrics, derived from related work, are traditional measures\\nand do not yet represent a mature or standardized approach for\\nquantifying RAG evaluation aspects. Custom metrics tailored\\nto the nuances of RAG models, though not included here, have\\nalso been developed in some evaluation studies.\\nD. Evaluation Benchmarks and Tools\\nA series of benchmark tests and tools have been proposed\\nto facilitate the evaluation of RAG.These instruments furnish\\nquantitative metrics that not only gauge RAG model perfor-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='A series of benchmark tests and tools have been proposed\\nto facilitate the evaluation of RAG.These instruments furnish\\nquantitative metrics that not only gauge RAG model perfor-\\nmance but also enhance comprehension of the model’s capabil-\\nities across various evaluation aspects. Prominent benchmarks\\nsuch as RGB, RECALL and CRUD [167]–[169] focus on\\nappraising the essential abilities of RAG models. Concur-\\nrently, state-of-the-art automated tools like RAGAS [164],\\nARES [165], and TruLens 8 employ LLMs to adjudicate the\\nquality scores. These tools and benchmarks collectively form\\na robust framework for the systematic evaluation of RAG\\nmodels, as summarized in Table IV.\\nVII. D ISCUSSION AND FUTURE PROSPECTS\\nDespite the considerable progress in RAG technology, sev-\\neral challenges persist that warrant in-depth research.This\\nchapter will mainly introduce the current challenges and future\\nresearch directions faced by RAG.\\nA. RAG vs Long Context'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='eral challenges persist that warrant in-depth research.This\\nchapter will mainly introduce the current challenges and future\\nresearch directions faced by RAG.\\nA. RAG vs Long Context\\nWith the deepening of related research, the context of LLMs\\nis continuously expanding [170]–[172]. Presently, LLMs can\\neffortlessly manage contexts exceeding 200,000 tokens 9. This\\ncapability signifies that long-document question answering,\\npreviously reliant on RAG, can now incorporate the entire\\ndocument directly into the prompt. This has also sparked\\ndiscussions on whether RAG is still necessary when LLMs\\n8https://www.trulens.org/trulens eval/core concepts rag triad/\\n9https://kimi.moonshot.cn\\nare not constrained by context. In fact, RAG still plays an\\nirreplaceable role. On one hand, providing LLMs with a\\nlarge amount of context at once will significantly impact its\\ninference speed, while chunked retrieval and on-demand input\\ncan significantly improve operational efficiency. On the other'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='large amount of context at once will significantly impact its\\ninference speed, while chunked retrieval and on-demand input\\ncan significantly improve operational efficiency. On the other\\nhand, RAG-based generation can quickly locate the original\\nreferences for LLMs to help users verify the generated an-\\nswers. The entire retrieval and reasoning process is observable,\\nwhile generation solely relying on long context remains a\\nblack box. Conversely, the expansion of context provides new\\nopportunities for the development of RAG, enabling it to\\naddress more complex problems and integrative or summary\\nquestions that require reading a large amount of material to\\nanswer [49]. Developing new RAG methods in the context of\\nsuper-long contexts is one of the future research trends.\\nB. RAG Robustness\\nThe presence of noise or contradictory information during\\nretrieval can detrimentally affect RAG’s output quality. This\\nsituation is figuratively referred to as “Misinformation can'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='B. RAG Robustness\\nThe presence of noise or contradictory information during\\nretrieval can detrimentally affect RAG’s output quality. This\\nsituation is figuratively referred to as “Misinformation can\\nbe worse than no information at all”. Improving RAG’s\\nresistance to such adversarial or counterfactual inputs is gain-\\ning research momentum and has become a key performance\\nmetric [48], [50], [82]. Cuconasu et al. [54] analyze which\\ntype of documents should be retrieved, evaluate the relevance\\nof the documents to the prompt, their position, and the\\nnumber included in the context. The research findings reveal\\nthat including irrelevant documents can unexpectedly increase\\naccuracy by over 30%, contradicting the initial assumption\\nof reduced quality. These results underscore the importance\\nof developing specialized strategies to integrate retrieval with\\nlanguage generation models, highlighting the need for further\\nresearch and exploration into the robustness of RAG.\\nC. Hybrid Approaches'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='language generation models, highlighting the need for further\\nresearch and exploration into the robustness of RAG.\\nC. Hybrid Approaches\\nCombining RAG with fine-tuning is emerging as a leading\\nstrategy. Determining the optimal integration of RAG and\\nfine-tuning whether sequential, alternating, or through end-to-\\nend joint training—and how to harness both parameterized'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='15\\nTABLE IV\\nSUMMARY OF EVALUATION FRAMEWORKS\\nEvaluation Framework Evaluation Targets Evaluation Aspects Quantitative Metrics\\nRGB† Retrieval Quality\\nGeneration Quality\\nNoise Robustness\\nNegative Rejection\\nInformation Integration\\nCounterfactual Robustness\\nAccuracy\\nEM\\nAccuracy\\nAccuracy\\nRECALL† Generation Quality Counterfactual Robustness R-Rate (Reappearance Rate)\\nRAGAS‡ Retrieval Quality\\nGeneration Quality\\nContext Relevance\\nFaithfulness\\nAnswer Relevance\\n*\\n*\\nCosine Similarity\\nARES‡ Retrieval Quality\\nGeneration Quality\\nContext Relevance\\nFaithfulness\\nAnswer Relevance\\nAccuracy\\nAccuracy\\nAccuracy\\nTruLens‡ Retrieval Quality\\nGeneration Quality\\nContext Relevance\\nFaithfulness\\nAnswer Relevance\\n*\\n*\\n*\\nCRUD† Retrieval Quality\\nGeneration Quality\\nCreative Generation\\nKnowledge-intensive QA\\nError Correction\\nSummarization\\nBLEU\\nROUGE-L\\nBertScore\\nRAGQuestEval\\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Error Correction\\nSummarization\\nBLEU\\nROUGE-L\\nBertScore\\nRAGQuestEval\\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional\\nmetrics. Readers are encouraged to consult pertinent literature for the specific quantification formulas associated with these\\nmetrics, as required.\\nand non-parameterized advantages are areas ripe for explo-\\nration [27]. Another trend is to introduce SLMs with specific\\nfunctionalities into RAG and fine-tuned by the results of RAG\\nsystem. For example, CRAG [67] trains a lightweight retrieval\\nevaluator to assess the overall quality of the retrieved docu-\\nments for a query and triggers different knowledge retrieval\\nactions based on confidence levels.\\nD. Scaling laws of RAG\\nEnd-to-end RAG models and pre-trained models based\\non RAG are still one of the focuses of current re-\\nsearchers [173].The parameters of these models are one of\\nthe key factors.While scaling laws [174] are established for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='on RAG are still one of the focuses of current re-\\nsearchers [173].The parameters of these models are one of\\nthe key factors.While scaling laws [174] are established for\\nLLMs, their applicability to RAG remains uncertain. Initial\\nstudies like RETRO++ [44] have begun to address this, yet the\\nparameter count in RAG models still lags behind that of LLMs.\\nThe possibility of an Inverse Scaling Law 10, where smaller\\nmodels outperform larger ones, is particularly intriguing and\\nmerits further investigation.\\nE. Production-Ready RAG\\nRAG’s practicality and alignment with engineering require-\\nments have facilitated its adoption. However, enhancing re-\\ntrieval efficiency, improving document recall in large knowl-\\nedge bases, and ensuring data security—such as preventing\\n10https://github.com/inverse-scaling/prize\\ninadvertent disclosure of document sources or metadata by\\nLLMs—are critical engineering challenges that remain to be\\naddressed [175].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='10https://github.com/inverse-scaling/prize\\ninadvertent disclosure of document sources or metadata by\\nLLMs—are critical engineering challenges that remain to be\\naddressed [175].\\nThe development of the RAG ecosystem is greatly impacted\\nby the progression of its technical stack. Key tools like\\nLangChain and LLamaIndex have quickly gained popularity\\nwith the emergence of ChatGPT, providing extensive RAG-\\nrelated APIs and becoming essential in the realm of LLMs.The\\nemerging technology stack, while not as rich in features as\\nLangChain and LLamaIndex, stands out through its specialized\\nproducts. For example, Flowise AI prioritizes a low-code\\napproach, allowing users to deploy AI applications, including\\nRAG, through a user-friendly drag-and-drop interface. Other\\ntechnologies like HayStack, Meltano, and Cohere Coral are\\nalso gaining attention for their unique contributions to the field.\\nIn addition to AI-focused vendors, traditional software and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='technologies like HayStack, Meltano, and Cohere Coral are\\nalso gaining attention for their unique contributions to the field.\\nIn addition to AI-focused vendors, traditional software and\\ncloud service providers are expanding their offerings to include\\nRAG-centric services. Weaviate’s Verba 11 is designed for\\npersonal assistant applications, while Amazon’s Kendra 12\\noffers intelligent enterprise search services, enabling users to\\nbrowse various content repositories using built-in connectors.\\nIn the development of RAG technology, there is a clear\\ntrend towards different specialization directions, such as: 1)\\nCustomization - tailoring RAG to meet specific requirements.\\n2) Simplification - making RAG easier to use to reduce the\\n11https://github.com/weaviate/Verba\\n12https://aws.amazon.com/cn/kendra/'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='16\\nFig. 6. Summary of RAG ecosystem\\ninitial learning curve. 3) Specialization - optimizing RAG to\\nbetter serve production environments.\\nThe mutual growth of RAG models and their technology\\nstacks is evident; technological advancements continuously\\nestablish new standards for existing infrastructure. In turn,\\nenhancements to the technology stack drive the development\\nof RAG capabilities. RAG toolkits are converging into a\\nfoundational technology stack, laying the groundwork for\\nadvanced enterprise applications. However, a fully integrated,\\ncomprehensive platform concept is still in the future, requiring\\nfurther innovation and development.\\nF . Multi-modal RAG\\nRAG has transcended its initial text-based question-\\nanswering confines, embracing a diverse array of modal data.\\nThis expansion has spawned innovative multimodal models\\nthat integrate RAG concepts across various domains:\\nImage. RA-CM3 [176] stands as a pioneering multimodal\\nmodel of both retrieving and generating text and images.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='that integrate RAG concepts across various domains:\\nImage. RA-CM3 [176] stands as a pioneering multimodal\\nmodel of both retrieving and generating text and images.\\nBLIP-2 [177] leverages frozen image encoders alongside\\nLLMs for efficient visual language pre-training, enabling zero-\\nshot image-to-text conversions. The “Visualize Before You\\nWrite” method [178] employs image generation to steer the\\nLM’s text generation, showing promise in open-ended text\\ngeneration tasks.\\nAudio and Video . The GSS method retrieves and stitches\\ntogether audio clips to convert machine-translated data into\\nspeech-translated data [179]. UEOP marks a significant ad-\\nvancement in end-to-end automatic speech recognition by\\nincorporating external, offline strategies for voice-to-text con-\\nversion [180]. Additionally, KNN-based attention fusion lever-\\nages audio embeddings and semantically related text embed-\\ndings to refine ASR, thereby accelerating domain adaptation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='version [180]. Additionally, KNN-based attention fusion lever-\\nages audio embeddings and semantically related text embed-\\ndings to refine ASR, thereby accelerating domain adaptation.\\nVid2Seq augments language models with specialized temporal\\nmarkers, facilitating the prediction of event boundaries and\\ntextual descriptions within a unified output sequence [181].\\nCode. RBPS [182] excels in small-scale learning tasks by\\nretrieving code examples that align with developers’ objectives\\nthrough encoding and frequency analysis. This approach has\\ndemonstrated efficacy in tasks such as test assertion genera-\\ntion and program repair. For structured knowledge, the CoK\\nmethod [106] first extracts facts pertinent to the input query\\nfrom a knowledge graph, then integrates these facts as hints\\nwithin the input, enhancing performance in knowledge graph\\nquestion-answering tasks.\\nVIII. C ONCLUSION\\nThe summary of this paper, as depicted in Figure 6, empha-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='within the input, enhancing performance in knowledge graph\\nquestion-answering tasks.\\nVIII. C ONCLUSION\\nThe summary of this paper, as depicted in Figure 6, empha-\\nsizes RAG’s significant advancement in enhancing the capa-\\nbilities of LLMs by integrating parameterized knowledge from\\nlanguage models with extensive non-parameterized data from\\nexternal knowledge bases. The survey showcases the evolution\\nof RAG technologies and their application on many different\\ntasks. The analysis outlines three developmental paradigms\\nwithin the RAG framework: Naive, Advanced, and Modu-\\nlar RAG, each representing a progressive enhancement over\\nits predecessors. RAG’s technical integration with other AI\\nmethodologies, such as fine-tuning and reinforcement learning,\\nhas further expanded its capabilities. Despite the progress in\\nRAG technology, there are research opportunities to improve\\nits robustness and its ability to handle extended contexts.\\nRAG’s application scope is expanding into multimodal do-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='RAG technology, there are research opportunities to improve\\nits robustness and its ability to handle extended contexts.\\nRAG’s application scope is expanding into multimodal do-\\nmains, adapting its principles to interpret and process diverse\\ndata forms like images, videos, and code. This expansion high-\\nlights RAG’s significant practical implications for AI deploy-\\nment, attracting interest from academic and industrial sectors.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='17\\nThe growing ecosystem of RAG is evidenced by the rise in\\nRAG-centric AI applications and the continuous development\\nof supportive tools. As RAG’s application landscape broadens,\\nthere is a need to refine evaluation methodologies to keep\\npace with its evolution. Ensuring accurate and representative\\nperformance assessments is crucial for fully capturing RAG’s\\ncontributions to the AI research and development community.\\nREFERENCES\\n[1] N. Kandpal, H. Deng, A. Roberts, E. Wallace, and C. Raffel, “Large\\nlanguage models struggle to learn long-tail knowledge,” in Interna-\\ntional Conference on Machine Learning . PMLR, 2023, pp. 15 696–\\n15 707.\\n[2] Y . Zhang, Y . Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao,\\nY . Zhang, Y . Chenet al., “Siren’s song in the ai ocean: A survey on hal-\\nlucination in large language models,” arXiv preprint arXiv:2309.01219,\\n2023.\\n[3] D. Arora, A. Kini, S. R. Chowdhury, N. Natarajan, G. Sinha, and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='lucination in large language models,” arXiv preprint arXiv:2309.01219,\\n2023.\\n[3] D. Arora, A. Kini, S. R. Chowdhury, N. Natarajan, G. Sinha, and\\nA. Sharma, “Gar-meets-rag paradigm for zero-shot information re-\\ntrieval,” arXiv preprint arXiv:2310.20158 , 2023.\\n[4] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal,\\nH. K ¨uttler, M. Lewis, W.-t. Yih, T. Rockt ¨aschel et al. , “Retrieval-\\naugmented generation for knowledge-intensive nlp tasks,” Advances in\\nNeural Information Processing Systems, vol. 33, pp. 9459–9474, 2020.\\n[5] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Milli-\\ncan, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clarket al.,\\n“Improving language models by retrieving from trillions of tokens,”\\nin International conference on machine learning . PMLR, 2022, pp.\\n2206–2240.\\n[6] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,\\nC. Zhang, S. Agarwal, K. Slama, A. Ray et al. , “Training language'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2206–2240.\\n[6] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,\\nC. Zhang, S. Agarwal, K. Slama, A. Ray et al. , “Training language\\nmodels to follow instructions with human feedback,” Advances in\\nneural information processing systems , vol. 35, pp. 27 730–27 744,\\n2022.\\n[7] X. Ma, Y . Gong, P. He, H. Zhao, and N. Duan, “Query rewrit-\\ning for retrieval-augmented large language models,” arXiv preprint\\narXiv:2305.14283, 2023.\\n[8] I. ILIN, “Advanced rag techniques: an il-\\nlustrated overview,” https://pub.towardsai.net/\\nadvanced-rag-techniques-an-illustrated-overview-04d193d8fec6,\\n2023.\\n[9] W. Peng, G. Li, Y . Jiang, Z. Wang, D. Ou, X. Zeng, E. Chen et al. ,\\n“Large language model based long-tail query rewriting in taobao\\nsearch,” arXiv preprint arXiv:2311.03758 , 2023.\\n[10] H. S. Zheng, S. Mishra, X. Chen, H.-T. Cheng, E. H. Chi, Q. V . Le,\\nand D. Zhou, “Take a step back: Evoking reasoning via abstraction in\\nlarge language models,” arXiv preprint arXiv:2310.06117 , 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and D. Zhou, “Take a step back: Evoking reasoning via abstraction in\\nlarge language models,” arXiv preprint arXiv:2310.06117 , 2023.\\n[11] L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense retrieval\\nwithout relevance labels,” arXiv preprint arXiv:2212.10496 , 2022.\\n[12] V . Blagojevi, “Enhancing rag pipelines in haystack: Introducing diver-\\nsityranker and lostinthemiddleranker,” https://towardsdatascience.com/\\nenhancing-rag-pipelines-in-haystack-45f14e2bc9f5, 2023.\\n[13] W. Yu, D. Iter, S. Wang, Y . Xu, M. Ju, S. Sanyal, C. Zhu, M. Zeng,\\nand M. Jiang, “Generate rather than retrieve: Large language models\\nare strong context generators,” arXiv preprint arXiv:2209.10063, 2022.\\n[14] Z. Shao, Y . Gong, Y . Shen, M. Huang, N. Duan, and W. Chen,\\n“Enhancing retrieval-augmented large language models with iterative\\nretrieval-generation synergy,” arXiv preprint arXiv:2305.15294 , 2023.\\n[15] X. Wang, Q. Yang, Y . Qiu, J. Liang, Q. He, Z. Gu, Y . Xiao,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='retrieval-generation synergy,” arXiv preprint arXiv:2305.15294 , 2023.\\n[15] X. Wang, Q. Yang, Y . Qiu, J. Liang, Q. He, Z. Gu, Y . Xiao,\\nand W. Wang, “Knowledgpt: Enhancing large language models with\\nretrieval and storage access on knowledge bases,” arXiv preprint\\narXiv:2308.11761, 2023.\\n[16] A. H. Raudaschl, “Forget rag, the future\\nis rag-fusion,” https://towardsdatascience.com/\\nforget-rag-the-future-is-rag-fusion-1147298d8ad1, 2023.\\n[17] X. Cheng, D. Luo, X. Chen, L. Liu, D. Zhao, and R. Yan, “Lift\\nyourself up: Retrieval-augmented text generation with self memory,”\\narXiv preprint arXiv:2305.02437 , 2023.\\n[18] S. Wang, Y . Xu, Y . Fang, Y . Liu, S. Sun, R. Xu, C. Zhu, and\\nM. Zeng, “Training data is more valuable than you think: A simple\\nand effective method by retrieving from training data,” arXiv preprint\\narXiv:2203.08773, 2022.\\n[19] X. Li, E. Nie, and S. Liang, “From classification to generation:\\nInsights into crosslingual retrieval augmented icl,” arXiv preprint'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='arXiv:2203.08773, 2022.\\n[19] X. Li, E. Nie, and S. Liang, “From classification to generation:\\nInsights into crosslingual retrieval augmented icl,” arXiv preprint\\narXiv:2311.06595, 2023.\\n[20] D. Cheng, S. Huang, J. Bi, Y . Zhan, J. Liu, Y . Wang, H. Sun,\\nF. Wei, D. Deng, and Q. Zhang, “Uprise: Universal prompt retrieval\\nfor improving zero-shot evaluation,” arXiv preprint arXiv:2303.08518,\\n2023.\\n[21] Z. Dai, V . Y . Zhao, J. Ma, Y . Luan, J. Ni, J. Lu, A. Bakalov, K. Guu,\\nK. B. Hall, and M.-W. Chang, “Promptagator: Few-shot dense retrieval\\nfrom 8 examples,” arXiv preprint arXiv:2209.11755 , 2022.\\n[22] Z. Sun, X. Wang, Y . Tay, Y . Yang, and D. Zhou, “Recitation-augmented\\nlanguage models,” arXiv preprint arXiv:2210.01296 , 2022.\\n[23] O. Khattab, K. Santhanam, X. L. Li, D. Hall, P. Liang, C. Potts,\\nand M. Zaharia, “Demonstrate-search-predict: Composing retrieval\\nand language models for knowledge-intensive nlp,” arXiv preprint\\narXiv:2212.14024, 2022.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and M. Zaharia, “Demonstrate-search-predict: Composing retrieval\\nand language models for knowledge-intensive nlp,” arXiv preprint\\narXiv:2212.14024, 2022.\\n[24] Z. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y . Yang,\\nJ. Callan, and G. Neubig, “Active retrieval augmented generation,”\\narXiv preprint arXiv:2305.06983 , 2023.\\n[25] A. Asai, Z. Wu, Y . Wang, A. Sil, and H. Hajishirzi, “Self-rag:\\nLearning to retrieve, generate, and critique through self-reflection,”\\narXiv preprint arXiv:2310.11511 , 2023.\\n[26] Z. Ke, W. Kong, C. Li, M. Zhang, Q. Mei, and M. Bendersky,\\n“Bridging the preference gap between retrievers and llms,” arXiv\\npreprint arXiv:2401.06954, 2024.\\n[27] X. V . Lin, X. Chen, M. Chen, W. Shi, M. Lomeli, R. James, P. Ro-\\ndriguez, J. Kahn, G. Szilvasy, M. Lewis et al. , “Ra-dit: Retrieval-\\naugmented dual instruction tuning,” arXiv preprint arXiv:2310.01352 ,\\n2023.\\n[28] O. Ovadia, M. Brief, M. Mishaeli, and O. Elisha, “Fine-tuning or'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='augmented dual instruction tuning,” arXiv preprint arXiv:2310.01352 ,\\n2023.\\n[28] O. Ovadia, M. Brief, M. Mishaeli, and O. Elisha, “Fine-tuning or\\nretrieval? comparing knowledge injection in llms,” arXiv preprint\\narXiv:2312.05934, 2023.\\n[29] T. Lan, D. Cai, Y . Wang, H. Huang, and X.-L. Mao, “Copy is all\\nyou need,” in The Eleventh International Conference on Learning\\nRepresentations, 2022.\\n[30] T. Chen, H. Wang, S. Chen, W. Yu, K. Ma, X. Zhao, D. Yu, and\\nH. Zhang, “Dense x retrieval: What retrieval granularity should we\\nuse?” arXiv preprint arXiv:2312.06648 , 2023.\\n[31] F. Luo and M. Surdeanu, “Divide & conquer for entailment-aware\\nmulti-hop evidence retrieval,” arXiv preprint arXiv:2311.02616 , 2023.\\n[32] Q. Gou, Z. Xia, B. Yu, H. Yu, F. Huang, Y . Li, and N. Cam-Tu,\\n“Diversify question generation with retrieval-augmented style transfer,”\\narXiv preprint arXiv:2310.14503 , 2023.\\n[33] Z. Guo, S. Cheng, Y . Wang, P. Li, and Y . Liu, “Prompt-guided re-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='“Diversify question generation with retrieval-augmented style transfer,”\\narXiv preprint arXiv:2310.14503 , 2023.\\n[33] Z. Guo, S. Cheng, Y . Wang, P. Li, and Y . Liu, “Prompt-guided re-\\ntrieval augmentation for non-knowledge-intensive tasks,”arXiv preprint\\narXiv:2305.17653, 2023.\\n[34] Z. Wang, J. Araki, Z. Jiang, M. R. Parvez, and G. Neubig, “Learning\\nto filter context for retrieval-augmented generation,” arXiv preprint\\narXiv:2311.08377, 2023.\\n[35] M. Seo, J. Baek, J. Thorne, and S. J. Hwang, “Retrieval-augmented\\ndata augmentation for low-resource domain tasks,” arXiv preprint\\narXiv:2402.13482, 2024.\\n[36] Y . Ma, Y . Cao, Y . Hong, and A. Sun, “Large language model is not\\na good few-shot information extractor, but a good reranker for hard\\nsamples!” arXiv preprint arXiv:2303.08559 , 2023.\\n[37] X. Du and H. Ji, “Retrieval-augmented generative question answering\\nfor event argument extraction,” arXiv preprint arXiv:2211.07067, 2022.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='samples!” arXiv preprint arXiv:2303.08559 , 2023.\\n[37] X. Du and H. Ji, “Retrieval-augmented generative question answering\\nfor event argument extraction,” arXiv preprint arXiv:2211.07067, 2022.\\n[38] L. Wang, N. Yang, and F. Wei, “Learning to retrieve in-context\\nexamples for large language models,”arXiv preprint arXiv:2307.07164,\\n2023.\\n[39] S. Rajput, N. Mehta, A. Singh, R. H. Keshavan, T. Vu, L. Heldt,\\nL. Hong, Y . Tay, V . Q. Tran, J. Samostet al., “Recommender systems\\nwith generative retrieval,” arXiv preprint arXiv:2305.05065 , 2023.\\n[40] B. Jin, H. Zeng, G. Wang, X. Chen, T. Wei, R. Li, Z. Wang, Z. Li,\\nY . Li, H. Lu et al. , “Language models as semantic indexers,” arXiv\\npreprint arXiv:2310.07815, 2023.\\n[41] R. Anantha, T. Bethi, D. V odianik, and S. Chappidi, “Context tuning\\nfor retrieval augmented generation,” arXiv preprint arXiv:2312.05708 ,\\n2023.\\n[42] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='for retrieval augmented generation,” arXiv preprint arXiv:2312.05708 ,\\n2023.\\n[42] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick,\\nJ. Dwivedi-Yu, A. Joulin, S. Riedel, and E. Grave, “Few-shot\\nlearning with retrieval augmented language models,” arXiv preprint\\narXiv:2208.03299, 2022.\\n[43] J. Huang, W. Ping, P. Xu, M. Shoeybi, K. C.-C. Chang, and B. Catan-\\nzaro, “Raven: In-context learning with retrieval augmented encoder-\\ndecoder language models,” arXiv preprint arXiv:2308.07922 , 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='18\\n[44] B. Wang, W. Ping, P. Xu, L. McAfee, Z. Liu, M. Shoeybi, Y . Dong,\\nO. Kuchaiev, B. Li, C. Xiao et al. , “Shall we pretrain autoregressive\\nlanguage models with retrieval? a comprehensive study,”arXiv preprint\\narXiv:2304.06762, 2023.\\n[45] B. Wang, W. Ping, L. McAfee, P. Xu, B. Li, M. Shoeybi, and B. Catan-\\nzaro, “Instructretro: Instruction tuning post retrieval-augmented pre-\\ntraining,” arXiv preprint arXiv:2310.07713 , 2023.\\n[46] S. Siriwardhana, R. Weerasekera, E. Wen, T. Kaluarachchi, R. Rana,\\nand S. Nanayakkara, “Improving the domain adaptation of retrieval\\naugmented generation (rag) models for open domain question answer-\\ning,” Transactions of the Association for Computational Linguistics ,\\nvol. 11, pp. 1–17, 2023.\\n[47] Z. Yu, C. Xiong, S. Yu, and Z. Liu, “Augmentation-adapted retriever\\nimproves generalization of language models as generic plug-in,” arXiv\\npreprint arXiv:2305.17331, 2023.\\n[48] O. Yoran, T. Wolfson, O. Ram, and J. Berant, “Making retrieval-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='improves generalization of language models as generic plug-in,” arXiv\\npreprint arXiv:2305.17331, 2023.\\n[48] O. Yoran, T. Wolfson, O. Ram, and J. Berant, “Making retrieval-\\naugmented language models robust to irrelevant context,” arXiv\\npreprint arXiv:2310.01558, 2023.\\n[49] H.-T. Chen, F. Xu, S. A. Arora, and E. Choi, “Understanding re-\\ntrieval augmentation for long-form question answering,” arXiv preprint\\narXiv:2310.12150, 2023.\\n[50] W. Yu, H. Zhang, X. Pan, K. Ma, H. Wang, and D. Yu, “Chain-of-note:\\nEnhancing robustness in retrieval-augmented language models,” arXiv\\npreprint arXiv:2311.09210, 2023.\\n[51] S. Xu, L. Pang, H. Shen, X. Cheng, and T.-S. Chua, “Search-in-the-\\nchain: Towards accurate, credible and traceable large language models\\nfor knowledgeintensive tasks,” CoRR, vol. abs/2304.14732 , 2023.\\n[52] M. Berchansky, P. Izsak, A. Caciularu, I. Dagan, and M. Wasserblat,\\n“Optimizing retrieval-augmented reader models via token elimination,”\\narXiv preprint arXiv:2310.13682 , 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='[52] M. Berchansky, P. Izsak, A. Caciularu, I. Dagan, and M. Wasserblat,\\n“Optimizing retrieval-augmented reader models via token elimination,”\\narXiv preprint arXiv:2310.13682 , 2023.\\n[53] J. L ´ala, O. O’Donoghue, A. Shtedritski, S. Cox, S. G. Rodriques,\\nand A. D. White, “Paperqa: Retrieval-augmented generative agent for\\nscientific research,” arXiv preprint arXiv:2312.07559 , 2023.\\n[54] F. Cuconasu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano,\\nY . Maarek, N. Tonellotto, and F. Silvestri, “The power of noise:\\nRedefining retrieval for rag systems,” arXiv preprint arXiv:2401.14887,\\n2024.\\n[55] Z. Zhang, X. Zhang, Y . Ren, S. Shi, M. Han, Y . Wu, R. Lai, and\\nZ. Cao, “Iag: Induction-augmented generation framework for answer-\\ning reasoning questions,” in Proceedings of the 2023 Conference on\\nEmpirical Methods in Natural Language Processing , 2023, pp. 1–14.\\n[56] N. Thakur, L. Bonifacio, X. Zhang, O. Ogundepo, E. Kamalloo,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='ing reasoning questions,” in Proceedings of the 2023 Conference on\\nEmpirical Methods in Natural Language Processing , 2023, pp. 1–14.\\n[56] N. Thakur, L. Bonifacio, X. Zhang, O. Ogundepo, E. Kamalloo,\\nD. Alfonso-Hermelo, X. Li, Q. Liu, B. Chen, M. Rezagholizadeh et al.,\\n“Nomiracl: Knowing when you don’t know for robust multilingual\\nretrieval-augmented generation,” arXiv preprint arXiv:2312.11361 ,\\n2023.\\n[57] G. Kim, S. Kim, B. Jeon, J. Park, and J. Kang, “Tree of clarifica-\\ntions: Answering ambiguous questions with retrieval-augmented large\\nlanguage models,” arXiv preprint arXiv:2310.14696 , 2023.\\n[58] Y . Wang, P. Li, M. Sun, and Y . Liu, “Self-knowledge guided\\nretrieval augmentation for large language models,” arXiv preprint\\narXiv:2310.05002, 2023.\\n[59] Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin, “Retrieval-\\ngeneration synergy augmented large language models,” arXiv preprint\\narXiv:2310.05149, 2023.\\n[60] P. Xu, W. Ping, X. Wu, L. McAfee, C. Zhu, Z. Liu, S. Subramanian,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='generation synergy augmented large language models,” arXiv preprint\\narXiv:2310.05149, 2023.\\n[60] P. Xu, W. Ping, X. Wu, L. McAfee, C. Zhu, Z. Liu, S. Subramanian,\\nE. Bakhturina, M. Shoeybi, and B. Catanzaro, “Retrieval meets long\\ncontext large language models,” arXiv preprint arXiv:2310.03025 ,\\n2023.\\n[61] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Interleav-\\ning retrieval with chain-of-thought reasoning for knowledge-intensive\\nmulti-step questions,” arXiv preprint arXiv:2212.10509 , 2022.\\n[62] R. Ren, Y . Wang, Y . Qu, W. X. Zhao, J. Liu, H. Tian, H. Wu, J.-\\nR. Wen, and H. Wang, “Investigating the factual knowledge boundary\\nof large language models with retrieval augmentation,” arXiv preprint\\narXiv:2307.11019, 2023.\\n[63] P. Sarthi, S. Abdullah, A. Tuli, S. Khanna, A. Goldie, and C. D.\\nManning, “Raptor: Recursive abstractive processing for tree-organized\\nretrieval,” arXiv preprint arXiv:2401.18059 , 2024.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='[63] P. Sarthi, S. Abdullah, A. Tuli, S. Khanna, A. Goldie, and C. D.\\nManning, “Raptor: Recursive abstractive processing for tree-organized\\nretrieval,” arXiv preprint arXiv:2401.18059 , 2024.\\n[64] O. Ram, Y . Levine, I. Dalmedigos, D. Muhlgay, A. Shashua, K. Leyton-\\nBrown, and Y . Shoham, “In-context retrieval-augmented language\\nmodels,” arXiv preprint arXiv:2302.00083 , 2023.\\n[65] Y . Ren, Y . Cao, P. Guo, F. Fang, W. Ma, and Z. Lin, “Retrieve-and-\\nsample: Document-level event argument extraction via hybrid retrieval\\naugmentation,” in Proceedings of the 61st Annual Meeting of the\\nAssociation for Computational Linguistics (Volume 1: Long Papers) ,\\n2023, pp. 293–306.\\n[66] Z. Wang, X. Pan, D. Yu, D. Yu, J. Chen, and H. Ji, “Zemi: Learning\\nzero-shot semi-parametric language models from multiple tasks,” arXiv\\npreprint arXiv:2210.00185, 2022.\\n[67] S.-Q. Yan, J.-C. Gu, Y . Zhu, and Z.-H. Ling, “Corrective retrieval\\naugmented generation,” arXiv preprint arXiv:2401.15884 , 2024.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='preprint arXiv:2210.00185, 2022.\\n[67] S.-Q. Yan, J.-C. Gu, Y . Zhu, and Z.-H. Ling, “Corrective retrieval\\naugmented generation,” arXiv preprint arXiv:2401.15884 , 2024.\\n[68] P. Jain, L. B. Soares, and T. Kwiatkowski, “1-pager: One pass answer\\ngeneration and evidence retrieval,” arXiv preprint arXiv:2310.16568 ,\\n2023.\\n[69] H. Yang, Z. Li, Y . Zhang, J. Wang, N. Cheng, M. Li, and J. Xiao, “Prca:\\nFitting black-box large language models for retrieval question answer-\\ning via pluggable reward-driven contextual adapter,” arXiv preprint\\narXiv:2310.18347, 2023.\\n[70] S. Zhuang, B. Liu, B. Koopman, and G. Zuccon, “Open-source large\\nlanguage models are strong zero-shot query likelihood models for\\ndocument ranking,” arXiv preprint arXiv:2310.13243 , 2023.\\n[71] F. Xu, W. Shi, and E. Choi, “Recomp: Improving retrieval-augmented\\nlms with compression and selective augmentation,” arXiv preprint\\narXiv:2310.04408, 2023.\\n[72] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettle-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='lms with compression and selective augmentation,” arXiv preprint\\narXiv:2310.04408, 2023.\\n[72] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettle-\\nmoyer, and W.-t. Yih, “Replug: Retrieval-augmented black-box lan-\\nguage models,” arXiv preprint arXiv:2301.12652 , 2023.\\n[73] E. Melz, “Enhancing llm intelligence with arm-rag: Auxiliary ra-\\ntionale memory for retrieval augmented generation,” arXiv preprint\\narXiv:2311.04177, 2023.\\n[74] H. Wang, W. Huang, Y . Deng, R. Wang, Z. Wang, Y . Wang, F. Mi,\\nJ. Z. Pan, and K.-F. Wong, “Unims-rag: A unified multi-source\\nretrieval-augmented generation for personalized dialogue systems,”\\narXiv preprint arXiv:2401.13256 , 2024.\\n[75] Z. Luo, C. Xu, P. Zhao, X. Geng, C. Tao, J. Ma, Q. Lin, and D. Jiang,\\n“Augmented large language models with parametric knowledge guid-\\ning,” arXiv preprint arXiv:2305.04757 , 2023.\\n[76] X. Li, Z. Liu, C. Xiong, S. Yu, Y . Gu, Z. Liu, and G. Yu, “Structure-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='“Augmented large language models with parametric knowledge guid-\\ning,” arXiv preprint arXiv:2305.04757 , 2023.\\n[76] X. Li, Z. Liu, C. Xiong, S. Yu, Y . Gu, Z. Liu, and G. Yu, “Structure-\\naware language model pretraining improves dense retrieval on struc-\\ntured data,” arXiv preprint arXiv:2305.19912 , 2023.\\n[77] M. Kang, J. M. Kwak, J. Baek, and S. J. Hwang, “Knowledge\\ngraph-augmented language models for knowledge-grounded dialogue\\ngeneration,” arXiv preprint arXiv:2305.18846 , 2023.\\n[78] W. Shen, Y . Gao, C. Huang, F. Wan, X. Quan, and W. Bi, “Retrieval-\\ngeneration alignment for end-to-end task-oriented dialogue system,”\\narXiv preprint arXiv:2310.08877 , 2023.\\n[79] T. Shi, L. Li, Z. Lin, T. Yang, X. Quan, and Q. Wang, “Dual-feedback\\nknowledge retrieval for task-oriented dialogue systems,” arXiv preprint\\narXiv:2310.14528, 2023.\\n[80] P. Ranade and A. Joshi, “Fabula: Intelligence report generation\\nusing retrieval-augmented narrative construction,” arXiv preprint\\narXiv:2310.13848, 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='arXiv:2310.14528, 2023.\\n[80] P. Ranade and A. Joshi, “Fabula: Intelligence report generation\\nusing retrieval-augmented narrative construction,” arXiv preprint\\narXiv:2310.13848, 2023.\\n[81] X. Jiang, R. Zhang, Y . Xu, R. Qiu, Y . Fang, Z. Wang, J. Tang,\\nH. Ding, X. Chu, J. Zhao et al. , “Think and retrieval: A hypothesis\\nknowledge graph enhanced medical large language models,” arXiv\\npreprint arXiv:2312.15883, 2023.\\n[82] J. Baek, S. Jeong, M. Kang, J. C. Park, and S. J. Hwang,\\n“Knowledge-augmented language model verification,” arXiv preprint\\narXiv:2310.12836, 2023.\\n[83] L. Luo, Y .-F. Li, G. Haffari, and S. Pan, “Reasoning on graphs: Faithful\\nand interpretable large language model reasoning,” arXiv preprint\\narXiv:2310.01061, 2023.\\n[84] X. He, Y . Tian, Y . Sun, N. V . Chawla, T. Laurent, Y . LeCun,\\nX. Bresson, and B. Hooi, “G-retriever: Retrieval-augmented generation\\nfor textual graph understanding and question answering,”arXiv preprint\\narXiv:2402.07630, 2024.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='X. Bresson, and B. Hooi, “G-retriever: Retrieval-augmented generation\\nfor textual graph understanding and question answering,”arXiv preprint\\narXiv:2402.07630, 2024.\\n[85] L. Zha, J. Zhou, L. Li, R. Wang, Q. Huang, S. Yang, J. Yuan, C. Su,\\nX. Li, A. Su et al., “Tablegpt: Towards unifying tables, nature language\\nand commands into one gpt,” arXiv preprint arXiv:2307.08674 , 2023.\\n[86] M. Gaur, K. Gunaratna, V . Srinivasan, and H. Jin, “Iseeq: Information\\nseeking question generation using dynamic meta-information retrieval\\nand knowledge graphs,” in Proceedings of the AAAI Conference on\\nArtificial Intelligence, vol. 36, no. 10, 2022, pp. 10 672–10 680.\\n[87] F. Shi, X. Chen, K. Misra, N. Scales, D. Dohan, E. H. Chi, N. Sch ¨arli,\\nand D. Zhou, “Large language models can be easily distracted by\\nirrelevant context,” in International Conference on Machine Learning .\\nPMLR, 2023, pp. 31 210–31 227.\\n[88] R. Teja, “Evaluating the ideal chunk size for a rag'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='irrelevant context,” in International Conference on Machine Learning .\\nPMLR, 2023, pp. 31 210–31 227.\\n[88] R. Teja, “Evaluating the ideal chunk size for a rag\\nsystem using llamaindex,” https://www.llamaindex.ai/blog/\\nevaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5,\\n2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='19\\n[89] Langchain, “Recursively split by character,” https://python.langchain.\\ncom/docs/modules/data connection/document transformers/recursive\\ntext splitter, 2023.\\n[90] S. Yang, “Advanced rag 01: Small-to-\\nbig retrieval,” https://towardsdatascience.com/\\nadvanced-rag-01-small-to-big-retrieval-172181b396d4, 2023.\\n[91] Y . Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and T. Derr,\\n“Knowledge graph prompting for multi-document question answering,”\\narXiv preprint arXiv:2308.11730 , 2023.\\n[92] D. Zhou, N. Sch ¨arli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schu-\\nurmans, C. Cui, O. Bousquet, Q. Le et al., “Least-to-most prompting\\nenables complex reasoning in large language models,” arXiv preprint\\narXiv:2205.10625, 2022.\\n[93] S. Dhuliawala, M. Komeili, J. Xu, R. Raileanu, X. Li, A. Celikyilmaz,\\nand J. Weston, “Chain-of-verification reduces hallucination in large\\nlanguage models,” arXiv preprint arXiv:2309.11495 , 2023.\\n[94] X. Li and J. Li, “Angle-optimized text embeddings,” arXiv preprint'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and J. Weston, “Chain-of-verification reduces hallucination in large\\nlanguage models,” arXiv preprint arXiv:2309.11495 , 2023.\\n[94] X. Li and J. Li, “Angle-optimized text embeddings,” arXiv preprint\\narXiv:2309.12871, 2023.\\n[95] V oyageAI, “V oyage’s embedding models,” https://docs.voyageai.com/\\nembeddings/, 2023.\\n[96] BAAI, “Flagembedding,” https://github.com/FlagOpen/\\nFlagEmbedding, 2023.\\n[97] P. Zhang, S. Xiao, Z. Liu, Z. Dou, and J.-Y . Nie, “Retrieve anything\\nto augment large language models,” arXiv preprint arXiv:2310.07554 ,\\n2023.\\n[98] N. F. Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilacqua, F. Petroni,\\nand P. Liang, “Lost in the middle: How language models use long\\ncontexts,” arXiv preprint arXiv:2307.03172 , 2023.\\n[99] Y . Gao, T. Sheng, Y . Xiang, Y . Xiong, H. Wang, and J. Zhang, “Chat-\\nrec: Towards interactive and explainable llms-augmented recommender\\nsystem,” arXiv preprint arXiv:2303.14524 , 2023.\\n[100] N. Anderson, C. Wilson, and S. D. Richardson, “Lingua: Addressing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='rec: Towards interactive and explainable llms-augmented recommender\\nsystem,” arXiv preprint arXiv:2303.14524 , 2023.\\n[100] N. Anderson, C. Wilson, and S. D. Richardson, “Lingua: Addressing\\nscenarios for live interpretation and automatic dubbing,” inProceedings\\nof the 15th Biennial Conference of the Association for Machine\\nTranslation in the Americas (Volume 2: Users and Providers Track\\nand Government Track) , J. Campbell, S. Larocca, J. Marciano,\\nK. Savenkov, and A. Yanishevsky, Eds. Orlando, USA: Association\\nfor Machine Translation in the Americas, Sep. 2022, pp. 202–209.\\n[Online]. Available: https://aclanthology.org/2022.amta-upg.14\\n[101] H. Jiang, Q. Wu, X. Luo, D. Li, C.-Y . Lin, Y . Yang, and L. Qiu,\\n“Longllmlingua: Accelerating and enhancing llms in long context\\nscenarios via prompt compression,” arXiv preprint arXiv:2310.06839 ,\\n2023.\\n[102] V . Karpukhin, B. O ˘guz, S. Min, P. Lewis, L. Wu, S. Edunov, D. Chen,\\nand W.-t. Yih, “Dense passage retrieval for open-domain question'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2023.\\n[102] V . Karpukhin, B. O ˘guz, S. Min, P. Lewis, L. Wu, S. Edunov, D. Chen,\\nand W.-t. Yih, “Dense passage retrieval for open-domain question\\nanswering,” arXiv preprint arXiv:2004.04906 , 2020.\\n[103] Y . Ma, Y . Cao, Y . Hong, and A. Sun, “Large language model is\\nnot a good few-shot information extractor, but a good reranker for\\nhard samples!” ArXiv, vol. abs/2303.08559, 2023. [Online]. Available:\\nhttps://api.semanticscholar.org/CorpusID:257532405\\n[104] J. Cui, Z. Li, Y . Yan, B. Chen, and L. Yuan, “Chatlaw: Open-source\\nlegal large language model with integrated external knowledge bases,”\\narXiv preprint arXiv:2306.16092 , 2023.\\n[105] O. Yoran, T. Wolfson, O. Ram, and J. Berant, “Making retrieval-\\naugmented language models robust to irrelevant context,” arXiv\\npreprint arXiv:2310.01558, 2023.\\n[106] X. Li, R. Zhao, Y . K. Chia, B. Ding, L. Bing, S. Joty, and S. Poria,\\n“Chain of knowledge: A framework for grounding large language mod-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='preprint arXiv:2310.01558, 2023.\\n[106] X. Li, R. Zhao, Y . K. Chia, B. Ding, L. Bing, S. Joty, and S. Poria,\\n“Chain of knowledge: A framework for grounding large language mod-\\nels with structured knowledge bases,”arXiv preprint arXiv:2305.13269,\\n2023.\\n[107] H. Yang, S. Yue, and Y . He, “Auto-gpt for online decision\\nmaking: Benchmarks and additional opinions,” arXiv preprint\\narXiv:2306.02224, 2023.\\n[108] T. Schick, J. Dwivedi-Yu, R. Dess `ı, R. Raileanu, M. Lomeli, L. Zettle-\\nmoyer, N. Cancedda, and T. Scialom, “Toolformer: Language models\\ncan teach themselves to use tools,” arXiv preprint arXiv:2302.04761 ,\\n2023.\\n[109] J. Zhang, “Graph-toolformer: To empower llms with graph rea-\\nsoning ability via prompt augmented by chatgpt,” arXiv preprint\\narXiv:2304.11116, 2023.\\n[110] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim,\\nC. Hesse, S. Jain, V . Kosaraju, W. Saunders et al., “Webgpt: Browser-\\nassisted question-answering with human feedback,” arXiv preprint'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='C. Hesse, S. Jain, V . Kosaraju, W. Saunders et al., “Webgpt: Browser-\\nassisted question-answering with human feedback,” arXiv preprint\\narXiv:2112.09332, 2021.\\n[111] T. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. Parikh,\\nC. Alberti, D. Epstein, I. Polosukhin, J. Devlin, K. Lee et al., “Natural\\nquestions: a benchmark for question answering research,” Transactions\\nof the Association for Computational Linguistics , vol. 7, pp. 453–466,\\n2019.\\n[112] Y . Liu, S. Yavuz, R. Meng, M. Moorthy, S. Joty, C. Xiong, and Y . Zhou,\\n“Exploring the integration strategies of retriever and large language\\nmodels,” arXiv preprint arXiv:2308.12574 , 2023.\\n[113] M. Joshi, E. Choi, D. S. Weld, and L. Zettlemoyer, “Triviaqa: A large\\nscale distantly supervised challenge dataset for reading comprehen-\\nsion,” arXiv preprint arXiv:1705.03551 , 2017.\\n[114] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, “Squad: 100,000+\\nquestions for machine comprehension of text,” arXiv preprint\\narXiv:1606.05250, 2016.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='[114] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, “Squad: 100,000+\\nquestions for machine comprehension of text,” arXiv preprint\\narXiv:1606.05250, 2016.\\n[115] J. Berant, A. Chou, R. Frostig, and P. Liang, “Semantic parsing on\\nfreebase from question-answer pairs,” in Proceedings of the 2013\\nconference on empirical methods in natural language processing, 2013,\\npp. 1533–1544.\\n[116] A. Mallen, A. Asai, V . Zhong, R. Das, H. Hajishirzi, and D. Khashabi,\\n“When not to trust language models: Investigating effectiveness and\\nlimitations of parametric and non-parametric memories,” arXiv preprint\\narXiv:2212.10511, 2022.\\n[117] T. Nguyen, M. Rosenberg, X. Song, J. Gao, S. Tiwary, R. Majumder,\\nand L. Deng, “Ms marco: A human-generated machine reading com-\\nprehension dataset,” 2016.\\n[118] Z. Yang, P. Qi, S. Zhang, Y . Bengio, W. W. Cohen, R. Salakhutdi-\\nnov, and C. D. Manning, “Hotpotqa: A dataset for diverse, explain-\\nable multi-hop question answering,” arXiv preprint arXiv:1809.09600,\\n2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='nov, and C. D. Manning, “Hotpotqa: A dataset for diverse, explain-\\nable multi-hop question answering,” arXiv preprint arXiv:1809.09600,\\n2018.\\n[119] X. Ho, A.-K. D. Nguyen, S. Sugawara, and A. Aizawa, “Constructing a\\nmulti-hop qa dataset for comprehensive evaluation of reasoning steps,”\\narXiv preprint arXiv:2011.01060 , 2020.\\n[120] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Musique:\\nMultihop questions via single-hop question composition,” Transactions\\nof the Association for Computational Linguistics , vol. 10, pp. 539–554,\\n2022.\\n[121] A. Fan, Y . Jernite, E. Perez, D. Grangier, J. Weston, and M. Auli, “Eli5:\\nLong form question answering,” arXiv preprint arXiv:1907.09190 ,\\n2019.\\n[122] T. Ko ˇcisk`y, J. Schwarz, P. Blunsom, C. Dyer, K. M. Hermann, G. Melis,\\nand E. Grefenstette, “The narrativeqa reading comprehension chal-\\nlenge,” Transactions of the Association for Computational Linguistics ,\\nvol. 6, pp. 317–328, 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and E. Grefenstette, “The narrativeqa reading comprehension chal-\\nlenge,” Transactions of the Association for Computational Linguistics ,\\nvol. 6, pp. 317–328, 2018.\\n[123] K.-H. Lee, X. Chen, H. Furuta, J. Canny, and I. Fischer, “A human-\\ninspired reading agent with gist memory of very long contexts,” arXiv\\npreprint arXiv:2402.09727, 2024.\\n[124] I. Stelmakh, Y . Luan, B. Dhingra, and M.-W. Chang, “Asqa: Factoid\\nquestions meet long-form answers,” arXiv preprint arXiv:2204.06092 ,\\n2022.\\n[125] M. Zhong, D. Yin, T. Yu, A. Zaidi, M. Mutuma, R. Jha, A. H.\\nAwadallah, A. Celikyilmaz, Y . Liu, X. Qiu et al. , “Qmsum: A new\\nbenchmark for query-based multi-domain meeting summarization,”\\narXiv preprint arXiv:2104.05938 , 2021.\\n[126] P. Dasigi, K. Lo, I. Beltagy, A. Cohan, N. A. Smith, and M. Gardner,\\n“A dataset of information-seeking questions and answers anchored in\\nresearch papers,” arXiv preprint arXiv:2105.03011 , 2021.\\n[127] T. M ¨oller, A. Reina, R. Jayakumar, and M. Pietsch, “Covid-qa: A'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='“A dataset of information-seeking questions and answers anchored in\\nresearch papers,” arXiv preprint arXiv:2105.03011 , 2021.\\n[127] T. M ¨oller, A. Reina, R. Jayakumar, and M. Pietsch, “Covid-qa: A\\nquestion answering dataset for covid-19,” in ACL 2020 Workshop on\\nNatural Language Processing for COVID-19 (NLP-COVID) , 2020.\\n[128] X. Wang, G. H. Chen, D. Song, Z. Zhang, Z. Chen, Q. Xiao, F. Jiang,\\nJ. Li, X. Wan, B. Wang et al. , “Cmb: A comprehensive medical\\nbenchmark in chinese,” arXiv preprint arXiv:2308.08833 , 2023.\\n[129] H. Zeng, “Measuring massive multitask chinese understanding,” arXiv\\npreprint arXiv:2304.12986, 2023.\\n[130] R. Y . Pang, A. Parrish, N. Joshi, N. Nangia, J. Phang, A. Chen, V . Pad-\\nmakumar, J. Ma, J. Thompson, H. He et al. , “Quality: Question an-\\nswering with long input texts, yes!” arXiv preprint arXiv:2112.08608 ,\\n2021.\\n[131] P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick,\\nand O. Tafjord, “Think you have solved question answering? try arc,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2021.\\n[131] P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick,\\nand O. Tafjord, “Think you have solved question answering? try arc,\\nthe ai2 reasoning challenge,” arXiv preprint arXiv:1803.05457 , 2018.\\n[132] A. Talmor, J. Herzig, N. Lourie, and J. Berant, “Commonsenseqa:\\nA question answering challenge targeting commonsense knowledge,”\\narXiv preprint arXiv:1811.00937 , 2018.\\n[133] E. Dinan, S. Roller, K. Shuster, A. Fan, M. Auli, and J. Weston,\\n“Wizard of wikipedia: Knowledge-powered conversational agents,”\\narXiv preprint arXiv:1811.01241 , 2018.\\n[134] H. Wang, M. Hu, Y . Deng, R. Wang, F. Mi, W. Wang, Y . Wang, W.-\\nC. Kwan, I. King, and K.-F. Wong, “Large language models as source'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='20\\nplanner for personalized knowledge-grounded dialogue,” arXiv preprint\\narXiv:2310.08840, 2023.\\n[135] ——, “Large language models as source planner for personal-\\nized knowledge-grounded dialogue,” arXiv preprint arXiv:2310.08840,\\n2023.\\n[136] X. Xu, Z. Gou, W. Wu, Z.-Y . Niu, H. Wu, H. Wang, and S. Wang,\\n“Long time no see! open-domain conversation with long-term persona\\nmemory,” arXiv preprint arXiv:2203.05797 , 2022.\\n[137] T.-H. Wen, M. Gasic, N. Mrksic, L. M. Rojas-Barahona, P.-H.\\nSu, S. Ultes, D. Vandyke, and S. Young, “Conditional generation\\nand snapshot learning in neural dialogue systems,” arXiv preprint\\narXiv:1606.03352, 2016.\\n[138] R. He and J. McAuley, “Ups and downs: Modeling the visual evolution\\nof fashion trends with one-class collaborative filtering,” in proceedings\\nof the 25th international conference on world wide web , 2016, pp.\\n507–517.\\n[139] S. Li, H. Ji, and J. Han, “Document-level event argument extraction'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='of the 25th international conference on world wide web , 2016, pp.\\n507–517.\\n[139] S. Li, H. Ji, and J. Han, “Document-level event argument extraction\\nby conditional generation,” arXiv preprint arXiv:2104.05919 , 2021.\\n[140] S. Ebner, P. Xia, R. Culkin, K. Rawlins, and B. Van Durme, “Multi-\\nsentence argument linking,” arXiv preprint arXiv:1911.03766 , 2019.\\n[141] H. Elsahar, P. V ougiouklis, A. Remaci, C. Gravier, J. Hare, F. Laforest,\\nand E. Simperl, “T-rex: A large scale alignment of natural language\\nwith knowledge base triples,” in Proceedings of the Eleventh Inter-\\nnational Conference on Language Resources and Evaluation (LREC\\n2018), 2018.\\n[142] O. Levy, M. Seo, E. Choi, and L. Zettlemoyer, “Zero-shot relation ex-\\ntraction via reading comprehension,” arXiv preprint arXiv:1706.04115,\\n2017.\\n[143] R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, “Hel-\\nlaswag: Can a machine really finish your sentence?” arXiv preprint\\narXiv:1905.07830, 2019.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2017.\\n[143] R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, “Hel-\\nlaswag: Can a machine really finish your sentence?” arXiv preprint\\narXiv:1905.07830, 2019.\\n[144] S. Kim, S. J. Joo, D. Kim, J. Jang, S. Ye, J. Shin, and M. Seo,\\n“The cot collection: Improving zero-shot and few-shot learning of\\nlanguage models via chain-of-thought fine-tuning,” arXiv preprint\\narXiv:2305.14045, 2023.\\n[145] A. Saha, V . Pahuja, M. Khapra, K. Sankaranarayanan, and S. Chandar,\\n“Complex sequential question answering: Towards learning to converse\\nover linked question answer pairs with a knowledge graph,” inProceed-\\nings of the AAAI conference on artificial intelligence , vol. 32, no. 1,\\n2018.\\n[146] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and\\nJ. Steinhardt, “Measuring massive multitask language understanding,”\\narXiv preprint arXiv:2009.03300 , 2020.\\n[147] S. Merity, C. Xiong, J. Bradbury, and R. Socher, “Pointer sentinel'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='J. Steinhardt, “Measuring massive multitask language understanding,”\\narXiv preprint arXiv:2009.03300 , 2020.\\n[147] S. Merity, C. Xiong, J. Bradbury, and R. Socher, “Pointer sentinel\\nmixture models,” arXiv preprint arXiv:1609.07843 , 2016.\\n[148] M. Geva, D. Khashabi, E. Segal, T. Khot, D. Roth, and J. Berant,\\n“Did aristotle use a laptop? a question answering benchmark with\\nimplicit reasoning strategies,” Transactions of the Association for\\nComputational Linguistics, vol. 9, pp. 346–361, 2021.\\n[149] J. Thorne, A. Vlachos, C. Christodoulopoulos, and A. Mittal, “Fever: a\\nlarge-scale dataset for fact extraction and verification,” arXiv preprint\\narXiv:1803.05355, 2018.\\n[150] N. Kotonya and F. Toni, “Explainable automated fact-checking for\\npublic health claims,” arXiv preprint arXiv:2010.09926 , 2020.\\n[151] R. Lebret, D. Grangier, and M. Auli, “Neural text generation from\\nstructured data with application to the biography domain,” arXiv\\npreprint arXiv:1603.07771, 2016.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='[151] R. Lebret, D. Grangier, and M. Auli, “Neural text generation from\\nstructured data with application to the biography domain,” arXiv\\npreprint arXiv:1603.07771, 2016.\\n[152] H. Hayashi, P. Budania, P. Wang, C. Ackerson, R. Neervannan,\\nand G. Neubig, “Wikiasp: A dataset for multi-domain aspect-based\\nsummarization,” Transactions of the Association for Computational\\nLinguistics, vol. 9, pp. 211–225, 2021.\\n[153] S. Narayan, S. B. Cohen, and M. Lapata, “Don’t give me the details,\\njust the summary! topic-aware convolutional neural networks for ex-\\ntreme summarization,” arXiv preprint arXiv:1808.08745 , 2018.\\n[154] S. Saha, J. A. Junaed, M. Saleki, A. S. Sharma, M. R. Rifat, M. Rahouti,\\nS. I. Ahmed, N. Mohammed, and M. R. Amin, “Vio-lens: A novel\\ndataset of annotated social network posts leading to different forms\\nof communal violence and its evaluation,” in Proceedings of the First\\nWorkshop on Bangla Language Processing (BLP-2023), 2023, pp. 72–\\n84.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='of communal violence and its evaluation,” in Proceedings of the First\\nWorkshop on Bangla Language Processing (BLP-2023), 2023, pp. 72–\\n84.\\n[155] X. Li and D. Roth, “Learning question classifiers,” in COLING 2002:\\nThe 19th International Conference on Computational Linguistics, 2002.\\n[156] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Y . Ng,\\nand C. Potts, “Recursive deep models for semantic compositionality\\nover a sentiment treebank,” in Proceedings of the 2013 conference on\\nempirical methods in natural language processing , 2013, pp. 1631–\\n1642.\\n[157] H. Husain, H.-H. Wu, T. Gazit, M. Allamanis, and M. Brockschmidt,\\n“Codesearchnet challenge: Evaluating the state of semantic code\\nsearch,” arXiv preprint arXiv:1909.09436 , 2019.\\n[158] K. Cobbe, V . Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser,\\nM. Plappert, J. Tworek, J. Hilton, R. Nakano et al., “Training verifiers\\nto solve math word problems,” arXiv preprint arXiv:2110.14168, 2021.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='M. Plappert, J. Tworek, J. Hilton, R. Nakano et al., “Training verifiers\\nto solve math word problems,” arXiv preprint arXiv:2110.14168, 2021.\\n[159] R. Steinberger, B. Pouliquen, A. Widiger, C. Ignat, T. Erjavec, D. Tufis,\\nand D. Varga, “The jrc-acquis: A multilingual aligned parallel corpus\\nwith 20+ languages,” arXiv preprint cs/0609058 , 2006.\\n[160] Y . Hoshi, D. Miyashita, Y . Ng, K. Tatsuno, Y . Morioka, O. Torii,\\nand J. Deguchi, “Ralle: A framework for developing and eval-\\nuating retrieval-augmented large language models,” arXiv preprint\\narXiv:2308.10633, 2023.\\n[161] J. Liu, “Building production-ready rag applications,” https://www.ai.\\nengineer/summit/schedule/building-production-ready-rag-applications,\\n2023.\\n[162] I. Nguyen, “Evaluating rag part i: How to evaluate document retrieval,”\\nhttps://www.deepset.ai/blog/rag-evaluation-retrieval, 2023.\\n[163] Q. Leng, K. Uhlenhuth, and A. Polyzotis, “Best practices for\\nllm evaluation of rag applications,” https://www.databricks.com/blog/'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='https://www.deepset.ai/blog/rag-evaluation-retrieval, 2023.\\n[163] Q. Leng, K. Uhlenhuth, and A. Polyzotis, “Best practices for\\nllm evaluation of rag applications,” https://www.databricks.com/blog/\\nLLM-auto-eval-best-practices-RAG, 2023.\\n[164] S. Es, J. James, L. Espinosa-Anke, and S. Schockaert, “Ragas: Au-\\ntomated evaluation of retrieval augmented generation,” arXiv preprint\\narXiv:2309.15217, 2023.\\n[165] J. Saad-Falcon, O. Khattab, C. Potts, and M. Zaharia, “Ares: An\\nautomated evaluation framework for retrieval-augmented generation\\nsystems,” arXiv preprint arXiv:2311.09476 , 2023.\\n[166] C. Jarvis and J. Allard, “A survey of techniques for\\nmaximizing llm performance,” https://community.openai.\\ncom/t/openai-dev-day-2023-breakout-sessions/505213#\\na-survey-of-techniques-for-maximizing-llm-performance-2, 2023.\\n[167] J. Chen, H. Lin, X. Han, and L. Sun, “Benchmarking large lan-\\nguage models in retrieval-augmented generation,” arXiv preprint\\narXiv:2309.01431, 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='[167] J. Chen, H. Lin, X. Han, and L. Sun, “Benchmarking large lan-\\nguage models in retrieval-augmented generation,” arXiv preprint\\narXiv:2309.01431, 2023.\\n[168] Y . Liu, L. Huang, S. Li, S. Chen, H. Zhou, F. Meng, J. Zhou, and\\nX. Sun, “Recall: A benchmark for llms robustness against external\\ncounterfactual knowledge,” arXiv preprint arXiv:2311.08147 , 2023.\\n[169] Y . Lyu, Z. Li, S. Niu, F. Xiong, B. Tang, W. Wang, H. Wu, H. Liu,\\nT. Xu, and E. Chen, “Crud-rag: A comprehensive chinese benchmark\\nfor retrieval-augmented generation of large language models,” arXiv\\npreprint arXiv:2401.17043, 2024.\\n[170] P. Xu, W. Ping, X. Wu, L. McAfee, C. Zhu, Z. Liu, S. Subramanian,\\nE. Bakhturina, M. Shoeybi, and B. Catanzaro, “Retrieval meets long\\ncontext large language models,” arXiv preprint arXiv:2310.03025 ,\\n2023.\\n[171] C. Packer, V . Fang, S. G. Patil, K. Lin, S. Wooders, and J. E. Gon-\\nzalez, “Memgpt: Towards llms as operating systems,” arXiv preprint\\narXiv:2310.08560, 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2023.\\n[171] C. Packer, V . Fang, S. G. Patil, K. Lin, S. Wooders, and J. E. Gon-\\nzalez, “Memgpt: Towards llms as operating systems,” arXiv preprint\\narXiv:2310.08560, 2023.\\n[172] G. Xiao, Y . Tian, B. Chen, S. Han, and M. Lewis, “Efficient\\nstreaming language models with attention sinks,” arXiv preprint\\narXiv:2309.17453, 2023.\\n[173] T. Zhang, S. G. Patil, N. Jain, S. Shen, M. Zaharia, I. Stoica, and J. E.\\nGonzalez, “Raft: Adapting language model to domain specific rag,”\\narXiv preprint arXiv:2403.10131 , 2024.\\n[174] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess,\\nR. Child, S. Gray, A. Radford, J. Wu, and D. Amodei, “Scaling laws\\nfor neural language models,” arXiv preprint arXiv:2001.08361 , 2020.\\n[175] U. Alon, F. Xu, J. He, S. Sengupta, D. Roth, and G. Neubig, “Neuro-\\nsymbolic language modeling with automaton-augmented retrieval,” in\\nInternational Conference on Machine Learning . PMLR, 2022, pp.\\n468–485.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='symbolic language modeling with automaton-augmented retrieval,” in\\nInternational Conference on Machine Learning . PMLR, 2022, pp.\\n468–485.\\n[176] M. Yasunaga, A. Aghajanyan, W. Shi, R. James, J. Leskovec, P. Liang,\\nM. Lewis, L. Zettlemoyer, and W.-t. Yih, “Retrieval-augmented multi-\\nmodal language modeling,” arXiv preprint arXiv:2211.12561 , 2022.\\n[177] J. Li, D. Li, S. Savarese, and S. Hoi, “Blip-2: Bootstrapping language-\\nimage pre-training with frozen image encoders and large language\\nmodels,” arXiv preprint arXiv:2301.12597 , 2023.\\n[178] W. Zhu, A. Yan, Y . Lu, W. Xu, X. E. Wang, M. Eckstein, and W. Y .\\nWang, “Visualize before you write: Imagination-guided open-ended\\ntext generation,” arXiv preprint arXiv:2210.03765 , 2022.\\n[179] J. Zhao, G. Haffar, and E. Shareghi, “Generating synthetic speech from\\nspokenvocab for speech translation,” arXiv preprint arXiv:2210.08174,\\n2022.\\n[180] D. M. Chan, S. Ghosh, A. Rastrow, and B. Hoffmeister, “Using external'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='spokenvocab for speech translation,” arXiv preprint arXiv:2210.08174,\\n2022.\\n[180] D. M. Chan, S. Ghosh, A. Rastrow, and B. Hoffmeister, “Using external\\noff-policy speech-to-text mappings in contextual end-to-end automated\\nspeech recognition,” arXiv preprint arXiv:2301.02736 , 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 20, 'page_label': '21', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='21\\n[181] A. Yang, A. Nagrani, P. H. Seo, A. Miech, J. Pont-Tuset, I. Laptev,\\nJ. Sivic, and C. Schmid, “Vid2seq: Large-scale pretraining of a visual\\nlanguage model for dense video captioning,” in Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition ,\\n2023, pp. 10 714–10 726.\\n[182] N. Nashid, M. Sintaha, and A. Mesbah, “Retrieval-based prompt\\nselection for code-related few-shot learning,” in 2023 IEEE/ACM 45th\\nInternational Conference on Software Engineering (ICSE) , 2023, pp.\\n2450–2462.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.27', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T16:40:31+00:00', 'author': '', 'keywords': '', 'moddate': '2025-09-21T16:40:31+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.27 (TeX Live 2025) kpathsea version 6.4.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Resume_Latest.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Resume_Latest.pdf', 'file_type': 'pdf'}, page_content='Yash Kumar\\n+919471694118 — yashcoder9187@gmail.com — linkedin.com/in/yashcoder2403 — github.com/Anonymus-Coder2403\\nBegusarai, India\\nSummary\\nApplied AI/Full-Stack engineer building LLM features end-to-end: data refinement to model-ready signals, LangChain/FastAPI APIs, and\\nNext.js/React frontends. Experience in SQL/NoSQL schema design, ETL with Python + SQL, vector search (Pinecone/FAISS)\\nSkills and Interests\\nLanguages:Python, Java, C/C++, JavaScript, TypeScript, SQL\\nAI/LLMs:LangChain, Prompt Engineering, Hugging Face, OpenAI API, Retrieval/Embeddings, Guardrails\\nDevelopment:React.js, Next.js, Tailwind; dashboards and real-time UX, FastAPI, REST, Auth (JWT/RBAC), Webhooks, Caching\\nData:Schema design (PostgreSQL, MongoDB), Vector DBs (Pinecone, Chroma/FAISS), ETL with Python+SQL\\nML Ops/Eval:Offline test sets, prompt/testing harnesses, CI on data/code\\nTools:Git, Docker, GitHub Actions, Power BI, Postman\\nExperience\\nData Analyst Intern Jan 2025 – Mar 2025\\nPawzz Foundation (Remote)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.27', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T16:40:31+00:00', 'author': '', 'keywords': '', 'moddate': '2025-09-21T16:40:31+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.27 (TeX Live 2025) kpathsea version 6.4.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Resume_Latest.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Resume_Latest.pdf', 'file_type': 'pdf'}, page_content='Tools:Git, Docker, GitHub Actions, Power BI, Postman\\nExperience\\nData Analyst Intern Jan 2025 – Mar 2025\\nPawzz Foundation (Remote)\\n–Built interactive Power BI dashboards on donor funnels; improved reporting speed by 35%.\\n–Designed lightweight SQL tables/views and Python transforms to turn raw donations & events into model-ready signals.\\n–Automated extract-clean-load jobs (Python+SQL); reduced weekly manual effort significantly.\\n–Ran small offline experiments for trend prediction; shared insights with ops to iterate on campaigns.\\nGrowth Intern May 2023 – Jul 2023\\nFact App (Remote)\\n–Instrumented event tracking and REST endpoints (JavaScript + FastAPI) to unlock funnel/retention analytics.\\n–Optimized backend handlers and queries; reduced API latency under peak usage.\\n–Built weekly growth reports (SQL + automation) and ran quick A/B style experiments, contributing to +15% retention.\\n–Partnered with product to close the loop between metrics and feature iterations.\\nProjects'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.27', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T16:40:31+00:00', 'author': '', 'keywords': '', 'moddate': '2025-09-21T16:40:31+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.27 (TeX Live 2025) kpathsea version 6.4.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Resume_Latest.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Resume_Latest.pdf', 'file_type': 'pdf'}, page_content='–Partnered with product to close the loop between metrics and feature iterations.\\nProjects\\nCareer Compass— Next.js, LangChain, FastAPI\\n–AI career assistant with resume scoring, job matching, and learning roadmaps; Next.js frontend + FastAPI services.\\n–Authored LangChain chains for retrieval & scoring; defined SQL/NoSQL fields to persist user/job signals.\\n–Built a small evaluation harness (sample resumes/jobs) to track recommendation quality (e.g., precision@k).\\nCyber Sentinel— Next.js, FastAPI, Hugging Face, MongoDB\\n–Engineered AI phishing/URL detection using Hugging Face transformers; created a labeled test set to measure 90%+ accuracy.\\n–Implemented FastAPI with JWT/RBAC and a MongoDB schema for scalable alert/log storage; webhook endpoints for actions.\\n–Responsive Next.js dashboard for real-time incidents; tight loop between detections, review, and follow-up.\\nSecure Sentinel Spark— React, Prompt Engineering 2025'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.27', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T16:40:31+00:00', 'author': '', 'keywords': '', 'moddate': '2025-09-21T16:40:31+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.27 (TeX Live 2025) kpathsea version 6.4.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Resume_Latest.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Resume_Latest.pdf', 'file_type': 'pdf'}, page_content='–Responsive Next.js dashboard for real-time incidents; tight loop between detections, review, and follow-up.\\nSecure Sentinel Spark— React, Prompt Engineering 2025\\n–Prototype of a phishing workflow using prompt engineering to simulate pipeline logic end-to-end.\\n–Built an interactive React dashboard for classification, reviewer feedback, and iteration on prompts.\\n–Used small curated examples to evaluate prompt changes before demo deployments.\\nAchievements\\n1st Prize Aug 2025\\nQubit Quest 2025, IIIT Delhi\\n–Won 1st place at national hackathon (ESYA’25) for AI-powered quantum solution.\\nFinalist Sept 2025\\nHackShastra 2025\\n–Advanced to Round 2 among 200+ teams nationwide.\\nEducation\\nB.Tech in Electronics & Communication Engineering 2022 – 2026\\nGuru Ghasidas Vishwavidyalaya CGPA: 8.0 / 10.0\\nCertifications\\n–Generative AI with Google Cloud (May 2025)\\n–Large Language Models with Google Cloud (May 2025)\\n–AWS Solutions Architect (Forage) (Jun 2025)\\n–Deep Learning Specialization — Coursera (Ongoing)'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 0, 'page_label': '1', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"As an expert who's witnessed the evolution of AI from its early days, I'm excited to guide you\\nthrough what I consider the most comprehensive and practical learning path to becoming an AI\\nEngineer. This roadmap is designed specifically for complete beginners and will transform you\\ninto a capable AI practitioner ready to build modern, cutting-edge AI systems.\\nWhy This Matters: AI isn't just about code—it's fundamentally mathematical. Understanding the\\nmath gives you superpowers to debug, optimize, and innovate beyond just following tutorials.\\nLinear Algebra\\nCalculus\\nStatistics & Probability\\nThe Ultimate AI Engineering Learning Roadmap:\\nFrom Zero to Hero \\x002025\\x00\\nPhase 1\\x00 Foundation Building \\x00Months 1\\x002\\x00\\nMathematical Prerequisites\\n\\x001\\x00\\n\\x002\\x00\\nVector operations: The backbone of neural networks\\nMatrix multiplication: How data flows through networks\\nEigenvalues/eigenvectors: Critical for understanding transformations\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 0, 'page_label': '1', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x001\\x00\\n\\x002\\x00\\nVector operations: The backbone of neural networks\\nMatrix multiplication: How data flows through networks\\nEigenvalues/eigenvectors: Critical for understanding transformations\\nResource: Khan Academy Linear Algebra + 3Blue1Brown\\'s \"Essence of Linear Algebra\"\\x003\\x00\\n\\x004\\x00\\nDerivatives: How neural networks learn through gradients\\nChain rule: The mathematical foundation of backpropagation\\nPartial derivatives: Essential for optimization\\nResource: Paul\\'s Online Math Notes + 3Blue1Brown\\'s \"Essence of Calculus\"\\nProbability distributions: Understanding uncertainty in AI\\nBayes\\' theorem: Foundation of probabilistic reasoning\\nStatistical inference: Model evaluation and validation\\nResource: Think Stats (free book) + Khan Academy Statistics'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Python Mastery\\nJupyter Notebooks\\nAndrew Ng's Machine Learning Specialization \\x00Coursera)\\nHands-on Practice\\nSupervised Learning\\nProgramming Fundamentals\\nData structures: Lists, dictionaries, sets—the building blocks\\nNumPy: Mathematical operations on arrays\\nPandas: Data manipulation and analysis\\nMatplotlib/Seaborn: Data visualization\\nResource: Automate the Boring Stuff with Python (free) + Python Crash Course\\x005\\x00\\nInteractive development environment\\nEssential for experimentation and learning\\nResource: Jupyter documentation + DataCamp's Jupyter tutorial\\nPhase 2\\x00 Machine Learning Mastery \\x00Months 3\\x004\\x00\\nCore Machine Learning\\n\\x006\\x00\\x007\\x00\\nWhy it's exceptional: Ng breaks down complex concepts with mathematical rigor but\\npractical clarity\\nMost valuable sections:\\nGradient descent visualization and intuition\\nBias-variance tradeoff explanations\\nRegularization techniques\\nModel evaluation strategies\\nTime investment: 3 months, 5\\x0010 hours/week\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Gradient descent visualization and intuition\\nBias-variance tradeoff explanations\\nRegularization techniques\\nModel evaluation strategies\\nTime investment: 3 months, 5\\x0010 hours/week\\nKey outcome: You'll understand WHY algorithms work, not just HOW to use them\\x008\\x00\\nKaggle Learn Courses: Free micro-courses on ML fundamentals\\nMost valuable: Intro to Machine Learning + Intermediate Machine Learning\\nProjects: Start with Titanic, House Prices, then progress to harder competitions\\nEssential Algorithms Deep Dive\\nLinear/Logistic Regression\\nDecision Trees and Random Forests\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 2, 'page_label': '3', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Unsupervised Learning\\nModel Evaluation\\nAndrej Karpathy\\'s \"Neural Networks: Zero to Hero\"\\n3Blue1Brown Neural Network Series\\nAndrew Ng\\'s Deep Learning Specialization\\nSupport Vector Machines\\nk-Nearest Neighbors\\nk-Means Clustering\\nPrincipal Component Analysis \\x00PCA\\x00\\nAnomaly Detection\\nCross-validation techniques\\nPrecision, recall, F1-score\\nROC curves and AUC\\nResource: scikit-learn documentation + hands-on practice\\x002\\x00\\nPhase 3\\x00 Deep Learning Revolution \\x00Months 5\\x006\\x00\\nNeural Networks from First Principles\\n\\x009\\x00\\x0010\\x00\\x0011\\x00\\nWhy it\\'s invaluable: Learn by building everything from scratch in code\\nMost critical sections:\\nMicrograd: Build an autograd engine (understand backpropagation deeply)\\nBuilding GPT from scratch: Modern transformer implementation\\nPyTorch internals: How frameworks actually work\\nUnique value: Unlike other courses, this shows you the \"magic\" behind the frameworks\\x0012\\x00\\n\\x0013\\x00\\x0014\\x00\\x003\\x00\\nWhy it\\'s essential: Visual intuition for mathematical concepts\\nMost valuable videos:'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 2, 'page_label': '3', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Unique value: Unlike other courses, this shows you the \"magic\" behind the frameworks\\x0012\\x00\\n\\x0013\\x00\\x0014\\x00\\x003\\x00\\nWhy it\\'s essential: Visual intuition for mathematical concepts\\nMost valuable videos:\\n\"But what is a neural network?\"—conceptual foundation\\n\"Gradient descent\"—optimization visualization\\n\"Backpropagation\"—the learning algorithm\\nKey benefit: You\\'ll develop intuitive understanding alongside mathematical rigor\\n\\x007\\x00\\x006\\x00\\nCourse 1: Neural Networks and Deep Learning\\nCourse 2: Improving Deep Neural Networks (regularization, optimization)\\nCourse 3: Structuring Machine Learning Projects\\nCourse 4: Convolutional Neural Networks'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 3, 'page_label': '4', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Stanford CS231n: Convolutional Neural Networks\\nFast.ai Practical Deep Learning for Coders\\nHugging Face Course\\nAttention Mechanisms & Transformers\\nCourse 5: Sequence Models\\nWhy it works: Systematic progression from basics to advanced topics\\x008\\x00\\nComputer Vision Mastery\\n\\x0015\\x00\\x0016\\x00\\x0017\\x00\\nWhy it's legendary: Gold standard for computer vision education\\nMost valuable lectures:\\nCNN architectures \\x00AlexNet, VGGNet, ResNet)\\nTransfer learning and fine-tuning\\nObject detection and segmentation\\nAssignments: Build CNNs from scratch, implement backpropagation\\nCareer impact: Many top AI engineers cite this course as transformative\\x0015\\x00\\nPractical Implementation\\n\\x0018\\x00\\x0019\\x00\\x0020\\x00\\x0021\\x00\\nWhy it's revolutionary: Top-down approach—build real applications first\\nMost valuable aspects:\\nDeploy a working model by lesson 2\\nTransfer learning techniques\\nData augmentation strategies\\nProduction deployment methods\\nPhilosophy: Learn by doing, theory follows practice\\x0020\\x00\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 3, 'page_label': '4', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Deploy a working model by lesson 2\\nTransfer learning techniques\\nData augmentation strategies\\nProduction deployment methods\\nPhilosophy: Learn by doing, theory follows practice\\x0020\\x00\\nOutcome: You'll be building and deploying real AI applications quickly\\nPhase 4\\x00 Modern AI Systems \\x00Months 7\\x008\\x00\\nLarge Language Models & NLP\\n\\x0022\\x00\\x0023\\x00\\x0024\\x00\\x0025\\x00\\nWhy it's crucial: Industry-standard library for NLP\\nMost valuable sections:\\nChapters 1\\x004: Transformer architecture deep dive\\nChapters 5\\x008: Fine-tuning and tokenization\\nChapters 9\\x0012: Advanced LLM techniques\\nPractical value: You'll learn to work with GPT, BERT, T5, and other SOTA models\\x0022\\x00\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 4, 'page_label': '5', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Building RAG Applications\\nAdvanced RAG Techniques\\nModel Deployment & Monitoring\\nScaling AI Systems\\nComputer Vision Advanced Topics\\n\"Attention Is All You Need\" paper: The foundational research\\nIllustrated Transformer blog post: Visual explanation\\nImplementation: Build a transformer from scratch (following Karpathy\\'s tutorial)\\nGenerative AI & RAG Systems\\n\\x001\\x00\\nLangChain documentation: Framework for LLM applications\\nVector databases: Pinecone, Chroma, Weaviate\\nEmbedding models: OpenAI, Sentence-BERT, instructor-xl\\nReal projects: Build document Q&A, code assistant, research tool\\nAgentic RAG: Multi-step reasoning and tool use\\nRAG optimization: Chunking strategies, retrieval improvement\\nProduction deployment: FastAPI, Docker, cloud platforms\\nPhase 5\\x00 Advanced AI Engineering \\x00Months 9\\x0012\\x00\\nMLOps & Production Systems\\nDocker containerization: Reproducible environments\\nAPI development: FastAPI, Flask\\nCloud platforms: AWS SageMaker, Google Cloud AI, Azure ML'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 4, 'page_label': '5', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='MLOps & Production Systems\\nDocker containerization: Reproducible environments\\nAPI development: FastAPI, Flask\\nCloud platforms: AWS SageMaker, Google Cloud AI, Azure ML\\nModel monitoring: Data drift, performance degradation\\nCI/CD for ML: GitHub Actions, model versioning\\nDistributed training: Multi-GPU, multi-node\\nModel optimization: Quantization, pruning, distillation\\nInference optimization: TensorRT, ONNX, TorchScript\\nResource: MLOps Specialization (DeepLearning.AI)\\nSpecialized Domains\\nObject detection: YOLO, R\\x00CNN family\\nSegmentation: U\\x00Net, Mask R\\x00CNN'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Reinforcement Learning\\nAndrew Ng's Courses (DeepLearning.AI)\\nAndrej Karpathy's Neural Networks: Zero to Hero\\nFast.ai Practical Deep Learning\\nStanford CS231n\\nHugging Face Course\\nGenerative models: GANs, Diffusion models\\nResource: CS231n advanced lectures + papers\\nOpenAI Gymnasium: RL environments\\nDeep Q\\x00Networks \\x00DQN\\x00: Value-based methods\\nPolicy gradients: Actor-critic methods\\nResource: Spinning Up in Deep RL \\x00OpenAI\\x00\\nCritical Learning Resources & Their Value\\nTier 1\\x00 Absolutely Essential\\n\\x006\\x00\\x008\\x00\\nValue: Systematic, rigorous, practical\\nBest for: Building strong fundamentals\\nInvestment: $49/month, worth every penny\\nCareer impact: 9/10\\n\\x0010\\x00\\x009\\x00\\nValue: Unparalleled depth and clarity\\nBest for: Understanding how things actually work\\nInvestment: Free on YouTube\\nCareer impact: 10/10\\n\\x0021\\x00\\x0018\\x00\\nValue: Rapid practical skills development\\nBest for: Building real applications quickly\\nInvestment: Free\\nCareer impact: 9/10\\nTier 2\\x00 Highly Valuable\\n\\x0017\\x00\\x0015\\x00\\nValue: Academic rigor meets practical application\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Best for: Building real applications quickly\\nInvestment: Free\\nCareer impact: 9/10\\nTier 2\\x00 Highly Valuable\\n\\x0017\\x00\\x0015\\x00\\nValue: Academic rigor meets practical application\\nBest for: Computer vision specialization\\nInvestment: Free (auditing), challenging time commitment\\nCareer impact: 8/10\\n\\x0022\\x00'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 6, 'page_label': '7', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='3Blue1Brown Visual Series\\nGoogle AI Course \\x00Coursera)\\nIBM AI Foundations\\nValue: Industry-standard NLP skills\\nBest for: Modern NLP applications\\nInvestment: Free\\nCareer impact: 8/10\\n\\x0013\\x00\\x003\\x00\\nValue: Intuitive mathematical understanding\\nBest for: Building deep conceptual knowledge\\nInvestment: Free on YouTube\\nCareer impact: 7/10\\nTier 3\\x00 Supplementary\\n\\x0026\\x00\\nValue: Broad overview, less depth\\nBest for: Business understanding of AI\\nCareer impact: 6/10\\n\\x0027\\x00\\nValue: Beginner-friendly introduction\\nBest for: Absolute beginners\\nCareer impact: 5/10\\nHands-On Project Progression\\nMonths 1\\x002\\x00 Foundation Projects\\n\\x00\\x00\\x00Data Analysis Portfolio: Analyze 3 different datasets with pandas/matplotlib\\n\\x00\\x00\\x00Web Scraping Bot: Extract and analyze web data\\n\\x00\\x00\\x00Statistical Analysis: A/B testing, hypothesis testing\\nMonths 3\\x004\\x00 Machine Learning Projects\\n\\x00\\x00\\x00Prediction Model: House price prediction with feature engineering\\n\\x00\\x00\\x00Classification System: Customer churn prediction\\n\\x00\\x00\\x00Clustering Analysis: Customer segmentation'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 6, 'page_label': '7', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x00\\x00\\x00Prediction Model: House price prediction with feature engineering\\n\\x00\\x00\\x00Classification System: Customer churn prediction\\n\\x00\\x00\\x00Clustering Analysis: Customer segmentation\\n\\x00\\x00\\x00End-to-end ML Pipeline: Data →  Model →  Deployment'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 7, 'page_label': '8', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Months 5\\x006\\x00 Deep Learning Applications\\n\\x00\\x00\\x00Image Classifier: Custom CNN for your domain of interest\\n\\x00\\x00\\x00Text Sentiment Analyzer: RNN/LSTM for sentiment analysis\\n\\x00\\x00\\x00Recommender System: Collaborative filtering with neural networks\\n\\x00\\x00\\x00Transfer Learning Project: Fine-tune pre-trained models\\nMonths 7\\x008\\x00 Modern AI Systems\\n\\x00\\x00\\x00RAG Chatbot: Document Q&A system with vector database\\n\\x00\\x00\\x00Code Assistant: LLM-powered programming helper\\n\\x00\\x00\\x00Multi-modal Application: Text + image processing\\n\\x00\\x00\\x00API Service: Deploy models as production APIs\\nMonths 9\\x0012\\x00 Advanced Projects\\n\\x00\\x00\\x00Distributed Training: Scale model training across multiple GPUs\\n\\x00\\x00\\x00Model Optimization: Quantize and optimize for mobile/edge\\n\\x00\\x00\\x00MLOps Pipeline: Complete CI/CD for ML models\\n\\x00\\x00\\x00Research Project: Implement and improve a recent paper\\nLearning Strategy & Best Practices\\nThe 80/20 Approach\\n80% hands-on coding: Build, experiment, break things\\n20% theory: Understand the \"why\" behind the \"how\"'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 7, 'page_label': '8', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Learning Strategy & Best Practices\\nThe 80/20 Approach\\n80% hands-on coding: Build, experiment, break things\\n20% theory: Understand the \"why\" behind the \"how\"\\nActive learning: Don\\'t just watch videos—implement everything\\nCommunity & Networking\\nDiscord communities: Join course-specific Discord servers\\nGitHub contributions: Build a strong portfolio of projects\\nKaggle competitions: Practice on real datasets\\nTwitter/LinkedIn: Follow AI researchers and practitioners\\nLocal meetups: Connect with other learners\\nCommon Pitfalls to Avoid\\n\\x00\\x00\\x00Tutorial Hell: Don\\'t just consume content—create projects\\n\\x00\\x00\\x00Perfectionism: Start building before you feel \"ready\"\\n\\x00\\x00\\x00Skipping Math: Mathematical understanding accelerates learning'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 8, 'page_label': '9', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"The AI field moves incredibly fast, but these fundamentals will serve you for decades. Focus on\\ndepth over breadth, build constantly, and remember that every expert was once a beginner. The\\ntools and frameworks will change, but the mathematical foundations and problem-solving\\napproaches you learn here will make you adaptable to any future AI development.\\nThis roadmap has been battle-tested by thousands of successful AI engineers. Trust the\\nprocess, stay consistent, and you'll be amazed at what you can build in just one year. The AI\\n\\x00\\x00\\x00Isolation: Learn with others, ask questions, share progress\\n\\x00\\x00\\x00Following Trends: Focus on fundamentals over flashy new techniques\\nTimeline & Milestones\\nMonth 3 Milestone: Machine Learning Practitioner\\nBuild and deploy a simple ML model\\nUnderstand bias-variance tradeoff\\nKnow when to use different algorithms\\nMonth 6 Milestone: Deep Learning Engineer\\nImplement neural networks from scratch\\nBuild computer vision applications\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 8, 'page_label': '9', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Understand bias-variance tradeoff\\nKnow when to use different algorithms\\nMonth 6 Milestone: Deep Learning Engineer\\nImplement neural networks from scratch\\nBuild computer vision applications\\nUnderstand modern architectures \\x00CNNs, RNNs, Transformers)\\nMonth 9 Milestone: AI Application Developer\\nBuild LLM-powered applications\\nWork with vector databases and RAG systems\\nDeploy models to production\\nMonth 12 Milestone: Senior AI Engineer\\nDesign end-to-end AI systems\\nOptimize models for production\\nContribute to open source projects\\nReady for senior AI engineering roles\\nYour Next Steps\\n\\x00\\x00\\x00Week 1: Set up your development environment \\x00Python, Jupyter, Git)\\n\\x00\\x00\\x00Week 2: Start Andrew Ng's Machine Learning Course\\n\\x00\\x00\\x00Week 3: Begin your first project while following the course\\n\\x00\\x00\\x00Week 4: Join relevant Discord communities and start networking\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"revolution is just beginning, and there's never been a better time to join it.\\n⁂\\n\\x00\\x00\\x00https://github.com/krishnaik06/Complete-RoadMap-To-Learn-AI\\n\\x00\\x00\\x00https://www.geeksforgeeks.org/blogs/machine-learning-roadmap/\\n\\x00\\x00\\x00https://www.3blue1brown.com/lessons/neural-networks\\n\\x00\\x00\\x00https://www.3blue1brown.com/topics/neural-networks\\n\\x00\\x00\\x00https://github.com/aadi1011/AI\\x00ML\\x00Roadmap-from-scratch\\n\\x00\\x00\\x00https://www.coursera.org/specializations/deep-learning\\n\\x00\\x00\\x00https://www.coursera.org/courses?query=machine+learning+andrew+ng\\n\\x00\\x00\\x00https://www.learndatasci.com/best-artificial-intelligence-ai-courses/\\n\\x00\\x00\\x00https://karpathy.ai/zero-to-hero.html\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=VMj-3S1tku0\\n\\x00\\x00\\x00\\x00https://briansigafoos.com/neural-networks-karpathy/\\n\\x00\\x00\\x00\\x00https://www.linkedin.com/posts/sumanth077_neural-networks-zero-to-hero-by-andrej-karpathy-activit\\ny-7366011507102400512-dg3x\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=aircAruvnKk&vl=en\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=IHZwWFHWa-w\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='y-7366011507102400512-dg3x\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=aircAruvnKk&vl=en\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=IHZwWFHWa-w\\n\\x00\\x00\\x00\\x00https://www.machinelearningmastery.com/stanford-convolutional-neural-networks-for-visual-recogniti\\non-course-review/\\n\\x00\\x00\\x00\\x00https://cs231n.stanford.edu/slides/2025/lecture_1_part_2.pdf\\n\\x00\\x00\\x00\\x00https://cs231n.github.io\\n\\x00\\x00\\x00\\x00https://www.fast.ai/posts/2022\\x0007\\x0021-dl-coders-22.html\\n\\x00\\x00\\x00\\x00https://towardsai.net/p/l/7-lessons-from-fast-ai-deep-learning-course\\n\\x00\\x00\\x00\\x00https://www.machinelearningmastery.com/practical-deep-learning-for-coders-review/\\n\\x00\\x00\\x00\\x00https://course.fast.ai\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/chapter1/1\\n\\x00\\x00\\x00\\x00https://wandb.ai/int_pb/huggingface/reports/An-Introduction-To-HuggingFace-Transformers-for-NLP\\x00-\\nVmlldzoyOTgzMjI5\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/5\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/4\\n\\x00\\x00\\x00\\x00https://www.digitalocean.com/resources/articles/ai-courses\\n\\x00\\x00\\x00\\x00https://zapier.com/blog/best-ai-courses/'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/4\\n\\x00\\x00\\x00\\x00https://www.digitalocean.com/resources/articles/ai-courses\\n\\x00\\x00\\x00\\x00https://zapier.com/blog/best-ai-courses/\\n\\x00\\x00\\x00\\x00https://www.geeksforgeeks.org/blogs/deep-learning-roadmap/\\n\\x00\\x00\\x00\\x00https://www.v7labs.com/blog/deep-learning-guide\\n\\x00\\x00\\x00\\x00https://www.coursera.org/courses?query=artificial+intelligence\\n\\x00\\x00\\x00\\x00https://magnimindacademy.com/blog/deep-learning-structure-guide-for-beginners/\\n\\x00\\x00\\x00\\x00https://roadmap.sh/ai-engineer\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=PUlSon0DIus'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 10, 'page_label': '11', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x00\\x00\\x00\\x00https://cognitiveclass.ai/learn/deep-learning\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=7IgVGSaQPaw\\n\\x00\\x00\\x00\\x00https://grow.google/ai/\\n\\x00\\x00\\x00\\x00https://www.kaggle.com/learn/intro-to-deep-learning\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/learnmachinelearning/comments/1lbs4qi/a_clear_roadmap_to_complete_learni\\nng_aiml_by_the/\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/learnmachinelearning/comments/1j5trra/best_resources_to_learn_pytorch_in_2\\n025/\\n\\x00\\x00\\x00\\x00https://www.geeksforgeeks.org/deep-learning/introduction-deep-learning/\\n\\x00\\x00\\x00\\x00https://www.aimlengineer.io/p/breaking-into-aiml-in-2025-a-step\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/learnmachinelearning/comments/w4\\x00626/the_new_version_of_fastais_practic\\nal_deep/\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/3\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/ai-for-everyone/\\n\\x00\\x00\\x00\\x00https://course.fast.ai/Resources/testimonials.html\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/2'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 10, 'page_label': '11', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/ai-for-everyone/\\n\\x00\\x00\\x00\\x00https://course.fast.ai/Resources/testimonials.html\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/2\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/generative-ai-for-everyone/\\n\\x00\\x00\\x00\\x00https://news.ycombinator.com/item?id=32186647\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/deeplearning/comments/1dqkqhd/does_andrej_karpathys_neural_networks_z\\nero_to/\\n\\x00\\x00\\x00\\x00https://cs231n.stanford.edu\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=2fq9wYslV0A\\n\\x00\\x00\\x00\\x00https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB\\x003pi\\n\\x00\\x00\\x00\\x00https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ\\n\\x00\\x00\\x00\\x00https://cs231n.stanford.edu/project.html\\n\\x00\\x00\\x00\\x00https://www.youtube.com/c/3blue1brown\\n\\x00\\x00\\x00\\x00http://karpathy.github.io/neuralnets/\\n\\x00\\x00\\x00\\x00https://www.youtube.com/playlist?list=PLoROMvodv4rOmsNzYBMe0gJY2XS8AQg16')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0412f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29780ee2",
   "metadata": {},
   "source": [
    "### Embeddings and VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9840b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict , Any , Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a20c23dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x1e09e96ec90>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "## initialize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99dad6",
   "metadata": {},
   "source": [
    "### VectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "027f8388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 2417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x1e09ecfce10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "\n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "            \n",
    "vectorstore=VectorStore()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "826946da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='12-Month Roadmap to Become a Production-Ready\\nAI Engineer (Agentic AI Specialization)\\nOverview: This roadmap is tailored for Yash – a 4th-year ECE student with basic Python, math, and ML\\nknowledge – to transform into a production-ready AI Engineer specialized in Agentic AI over 12 months.\\nYash  will  dedicate  ~8  hours  daily.  The  plan  is  divided  into  monthly  phases  with  clear  goals,  hands-on\\nprojects,  and  curated  resources.  To  minimize  dropout  risk,  we  emphasize  project-based  learning and\\nspaced repetition (regularly revisiting past concepts) to reinforce knowledge. By the end, Yash will have a\\nstrong portfolio (GitHub projects and YouTube content on his channel “Engimemer”) demonstrating skills in\\nbuilding agent-based AI applications (AutoGPT-like systems) and the confidence to pursue FAANG-level\\nroles or AI freelancing.\\nMonth 1: Foundations – Python Mastery & Math Refresher\\nFocus: Build a strong foundation in programming and mathematics for AI.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='roles or AI freelancing.\\nMonth 1: Foundations – Python Mastery & Math Refresher\\nFocus: Build a strong foundation in programming and mathematics for AI.\\nKey Learning Goals: Solidify intermediate Python skills and refresh essential math for ML.\\nSpecifically, master Python language constructs (functions, OOP) and data handling libraries, and\\nreview linear algebra (vectors, matrices, eigenvalues), basic calculus (derivatives, gradients), and\\nprobability/statistics (mean, variance, Bayes’ theorem). \\nCore Concepts & Tools: Python best practices (writing clean, efficient code); using Jupyter/VS Code\\nand Google Colab for experiments; NumPy for matrix operations, Pandas for data manipulation,\\nMatplotlib/Seaborn for plotting. Math concepts like matrix multiplication, differentiation (for\\ngradient descent), and statistical thinking for data analysis. \\nBest Resources:\\nPython: “Automate the Boring Stuff” (for practice scripts) and Real Python tutorials on OOP .'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='gradient descent), and statistical thinking for data analysis. \\nBest Resources:\\nPython: “Automate the Boring Stuff” (for practice scripts) and Real Python tutorials on OOP . \\nMath: Khan Academy or Mathematics for Machine Learning (online book) for linear algebra &\\ncalculus refresh. \\nStatQuest (YouTube) – excellent simple videos on stats and linear algebra concepts (e.g. StatQuest’s\\nlinear regression, PCA videos). \\nfast.ai’s optional math review sections or Gilbert Strang’s MIT lectures for linear algebra (if deeper\\ndive needed). \\nProjects & Portfolio:\\nCode a simple linear regression from scratch (no ML libraries) to predict a small dataset (e.g.\\nhouse prices). This solidifies math-programming synergy. Visualize the fit line and error\\nconvergence. Publish this on GitHub. \\nYouTube Opportunity: Create a vlog-style video explaining how linear regression works and walking\\nthrough your implementation. This helps cement your understanding and kicks off your Engimemer\\nchannel content.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='through your implementation. This helps cement your understanding and kicks off your Engimemer\\nchannel content. \\nSpaced Repetition: Start making flashcards or notes for key formulas (e.g. matrix operations,\\nderivative rules). Review these weekly to build long-term retention.\\n• \\n1\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n1'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Month 2: Machine Learning Basics – Models & Pipeline\\nFocus: Grasp classic ML algorithms and the end-to-end ML workflow by building your first ML projects.\\nKey Learning Goals: Understand the ML pipeline: data preprocessing, feature engineering, model\\ntraining, evaluation, and iteration. Learn core algorithms in supervised learning (regression,\\nclassification) and unsupervised learning. Key topics include train/test splits, overfitting vs.\\ngeneralization, and performance metrics. \\nCore Concepts & Tools: Supervised vs. unsupervised learning; algorithms like linear & logistic\\nregression, decision trees, k-NN, SVMs for basics; clustering (k-means, DBSCAN) for\\nunsupervised. Tools: scikit-learn (implementing algorithms and pipeline), pandas for data cleaning,\\nand matplotlib for result visualization. Also introduce version control (Git/GitHub) to manage code. \\nBest Resources:\\nAndrew Ng’s Machine Learning Specialization (Coursera) – covers regression, classification,'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Best Resources:\\nAndrew Ng’s Machine Learning Specialization (Coursera) – covers regression, classification,\\nclustering, etc., providing a solid theoretical grounding. \\nHands-On Machine Learning with Scikit-Learn & TensorFlow (Aurélien Géron) – a practical book\\nto reference implementations and tips. \\nStatQuest – continue using videos for intuitions on algorithms (e.g. StatQuest’s decision tree and\\nPCA videos). \\nscikit-learn docs & tutorials – to learn API usage for training models and evaluating them. \\nProjects & Portfolio:\\nEnd-to-End ML Project: Pick a simple dataset (e.g. Titanic survival or California housing prices).\\nPerform data cleaning, exploratory analysis (visualize key patterns), then train a model (e.g. logistic\\nregression or decision tree). Evaluate with appropriate metrics (accuracy for classification or RMSE\\nfor regression). Finally, deploy this as a simple app – e.g., a Streamlit or Gradio web app where a'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='for regression). Finally, deploy this as a simple app – e.g., a Streamlit or Gradio web app where a\\nuser can input features and get a prediction. This exposes you to the full lifecycle. \\nOptionally, tackle a second project focusing on unsupervised learning (e.g. use k-means to cluster a\\ndataset and visualize results) to appreciate different ML paradigms. \\nYouTube Opportunity: Create a tutorial video “How I built my first ML model to predict Titanic\\nsurvivors” – show data exploration, model intuition, and a live demo of your app. This not only builds\\nyour portfolio but also reinforces your understanding by teaching it. \\nSpaced Repetition: Continue weekly reviews of last month’s math (e.g., quiz yourself on what\\noverfitting means or the formula for linear regression). Also begin a habit of summarizing each\\ncompleted project’s learning points and revisiting them later .\\nMonth 3: Deep Learning Fundamentals – Neural Networks from\\nScratch'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='completed project’s learning points and revisiting them later .\\nMonth 3: Deep Learning Fundamentals – Neural Networks from\\nScratch\\nFocus: Dive into deep learning basics, learning how neural networks work and training simple networks.\\nKey Learning Goals: Build intuition for neural networks (why and how they learn). Key concepts\\ninclude the perceptron, activation functions (ReLU, sigmoid), forward and backward propagation,\\nloss functions (e.g. cross-entropy), and optimizers like SGD/Adam. By month’s end, you should be\\nable to implement and train a basic neural network and understand the math of backpropagation. \\nCore Concepts & Tools: Neural network architecture (layers, weights, biases), gradient descent and\\nhow gradients are used to update weights, problems like vanishing gradients. Frameworks: PyTorch\\n• \\n2\\n• \\n3\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n2\\n• \\n• \\n• \\n• \\n4\\n• \\n2'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='or TensorFlow – choose one (PyTorch is popular in research/startups, so you might start there). Also\\nfamiliarize with Keras (which can be used via TensorFlow) for quick prototyping. Tools: Google\\nColab for GPU access (since training even simple networks will be faster with a GPU – start utilizing\\nfree Colab GPUs). \\nBest Resources:\\nDeepLearning.AI’s Deep Neural Networks (Andrew Ng) – part of the Deep Learning Specialization,\\nit covers forward/backprop in detail and is math-friendly. \\nfast.ai – Practical Deep Learning for Coders (Part 1) – a top-down approach: you start training\\nstate-of-the-art models (with less math), which can be motivating. Fast.ai’s course is very hands-on\\nand emphasizes experimentation first, aligning well with our project-based philosophy (Hugging\\nFace even recommends doing an intro DL course like fast.ai or DeepLearning.AI before advanced\\ntopics). \\nAndrej Karpathy’s “Neural Networks: Zero to Hero” (YouTube) – Karpathy builds neural nets and'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Face even recommends doing an intro DL course like fast.ai or DeepLearning.AI before advanced\\ntopics). \\nAndrej Karpathy’s “Neural Networks: Zero to Hero” (YouTube) – Karpathy builds neural nets and\\na mini-GPT from scratch in code. The early videos (micrograd, makemore series) are excellent to see\\nbackpropagation and training loop coded line-by-line. This can deeply solidify your\\nunderstanding of how everything works under the hood. \\nPyTorch official tutorials – to learn the basics of tensor operations and autograd, once you grasp\\nthe manual concepts. \\nProjects & Portfolio:\\nNeural Net from Scratch: Implement a simple multilayer perceptron using only NumPy (no high-\\nlevel library) to classify a small dataset (e.g. classify handwritten digits 0–9 from the MNIST dataset).\\nThis means coding the forward pass and backpropagation manually. It’s challenging, but doing this\\nfor even a small network (e.g. one hidden layer) will cement your understanding of how gradients\\nflow.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='for even a small network (e.g. one hidden layer) will cement your understanding of how gradients\\nflow. \\nDeep Learning Project: Using a framework (PyTorch/Keras), train a feed-forward neural network on\\nMNIST or a similar dataset. Aim for good accuracy on validation data. This lets you focus on\\nusing library components (layers, loss functions, optimizers) now that you understand what they do.\\nSave this project to GitHub, including instructions to run it on Colab (since you may not have a local\\nGPU). \\nYouTube Opportunity: Create a video titled “I built a neural network from scratch in Python” –\\nexplain the concept of backpropagation in simple terms and demo your NumPy network learning to\\nrecognize digits. This not only advertises your skill but also helps you review the concept by teaching\\nit. \\nSpaced Repetition: This month introduces many new concepts – make flashcards for definitions\\n(e.g. “What is an activation function? Give examples.” or “What does the derivative of ReLU look'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='it. \\nSpaced Repetition: This month introduces many new concepts – make flashcards for definitions\\n(e.g. “What is an activation function? Give examples.” or “What does the derivative of ReLU look\\nlike?”). Revisit your math cards from prior months to keep the fundamentals fresh, since deep\\nlearning heavily uses them (e.g., understanding gradients).\\nMonth 4: Deep Learning Expanded – Computer Vision and/or NLP\\nBasics\\nFocus: Broaden your deep learning skills to new data types. You can split this month between Computer\\nVision (CNNs)  and  Natural  Language  Processing (RNNs/transformers  basics),  or  focus  more  on  one\\n5\\n• \\n• \\n• \\n6\\n• \\n7 8\\n• \\n• \\n• \\n• \\n9\\n• \\n• \\n3'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='domain based on interest. Given the end-goal of agentic AI (which leans toward NLP/LLMs), prioritize NLP if\\nneeded, but a taste of CV will make you well-rounded.\\nKey Learning Goals (CV): Understand Convolutional Neural Networks (CNNs) for image data –\\nconvolution/pooling operations, architectures like LeNet/ResNet, and why CNNs excel in vision tasks\\n. Learn about using pretrained models and transfer learning (e.g. using a pretrained ResNet on a\\nnew small image dataset). \\nKey Learning Goals (NLP): Understand basics of text representation – text preprocessing\\n(tokenization, embeddings like word2vec), and how sequence models work. Recurrent Neural\\nNetworks (RNNs) and LSTMs were traditional approaches; understand their role and limitations (e.g.\\nvanishing gradients in long sequences). Introduce the concept of the Transformer architecture,\\nwhich overcomes those limitations and forms the backbone of modern LLMs. By the end, you'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='vanishing gradients in long sequences). Introduce the concept of the Transformer architecture,\\nwhich overcomes those limitations and forms the backbone of modern LLMs. By the end, you\\nshould grasp why transformers replaced RNNs for NLP , even if you don’t deeply train an RNN. \\nCore Concepts & Tools:\\nCV: Convolutions, filters/kernels, feature maps, common CNN layers. Tools: PyTorch/TensorFlow\\nwith CNN modules (e.g. torchvision for datasets and pretrained models). Possibly experiment\\nwith OpenCV for basic image processing to augment understanding. \\nNLP: Text cleaning (stopwords, stemming – though less needed with modern models), word\\nembeddings (learn what they are conceptually), sequence modeling. Tools: experiment with a simple\\nRNN using Keras or PyTorch’s nn.LSTM. Also introduce Hugging Face Transformers library at a\\nhigh level – for example, try using a pre-trained BERT or GPT-2 model for a simple task to see the\\ntransformer in action (more on this next month). \\nBest Resources:'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='high level – for example, try using a pre-trained BERT or GPT-2 model for a simple task to see the\\ntransformer in action (more on this next month). \\nBest Resources:\\nDeepLearning.AI’s courses on CNNs and Sequence Models (Andrew Ng) – these provide a solid\\nbase in each domain (CNN course covers ConvNet architectures, Sequence course covers RNN,\\nLSTM, and an intro to attention mechanism). If pressed for time, focus on sequence models because\\nLLMs/Agentic AI will build on that. \\nfast.ai Course (if following) – fast.ai’s early lessons cover CNNs for image classification in a very\\nhands-on way (you build an image classifier in Lesson 1 itself with transfer learning). This is\\nmotivating and teaches practical tips. They also cover an NLP segment where you fine-tune an AWD-\\nLSTM on text – insightful even if LSTMs are now older , because it teaches how to handle text data. \\nStanford CS231n (for CV) – lecture videos or notes (if you want deeper theoretical knowledge of\\nCNNs and vision tasks).'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Stanford CS231n (for CV) – lecture videos or notes (if you want deeper theoretical knowledge of\\nCNNs and vision tasks). \\nStanford CS224n (for NLP) – lectures on NLP and transformers by leading researchers (good to\\ndeepen theory behind attention and transformers). \\nYouTube: 3Blue1Brown’s video “But what is a convolution?” (for an intuitive visualization), and\\nStatQuest’s “RNNs and LSTMs” for simple explanations of these concepts. \\nProjects & Portfolio:\\nComputer Vision Project: Build and deploy a simple image classifier. For example, collect or use a\\ndataset of, say, plant diseases or traffic signs (something small). Train a CNN to categorize images. If\\nusing a small dataset, apply transfer learning with a pretrained model (e.g., fine-tune ResNet on your\\ndataset) – a valuable real-world skill. Aim to achieve decent accuracy, and deploy this model as a web\\ndemo (perhaps on Hugging Face Spaces or a simple Flask app). This demonstrates the ability to\\napply deep learning to real data.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='demo (perhaps on Hugging Face Spaces or a simple Flask app). This demonstrates the ability to\\napply deep learning to real data. \\nNLP Project: Build a text classifier or chatbot. For instance, create a sentiment analysis model for\\nmovie reviews. You could fine-tune a pre-trained transformer (like DistilBERT) on a movie reviews\\ndataset to classify sentiment. This will expose you to the Hugging Face ecosystem and transformer\\n• \\n10\\n• \\n11\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n4'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='fine-tuning in practice. (If computing resources are an issue, use Google Colab with free GPU for\\ntraining, or choose a smaller model and smaller dataset to fine-tune.) By now, you may start\\nChapter 1–4 of Hugging Face’s free Transformers course, which walks through using pre-trained\\nmodels and fine-tuning – it’s a great guided project that will result in a model you can share on\\nHugging Face Hub. \\nYouTube Opportunity: For the CV project, make a video like “Building an AI that recognizes plant\\ndiseases” – show how you collected data and how the CNN performs (people love visual demos). For\\nthe NLP project, consider a video titled “Fine-tuning my first Transformer model” – explain in simple\\nterms what BERT is doing and show your model in action. These not only market your skills but also\\nforce you to articulate complex concepts clearly. \\nSpaced Repetition: This is a content-heavy month. Leverage spaced repetition by frequently'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='force you to articulate complex concepts clearly. \\nSpaced Repetition: This is a content-heavy month. Leverage spaced repetition by frequently\\nrevisiting earlier lessons – e.g., when learning transformers, recall how an RNN works and how a\\nCNN works; this comparative thinking reinforces memory. Quiz yourself: “Why might an LSTM be\\ninsufficient for long text?” or “What does a convolution filter do?”. Also keep using your Anki/flashcards\\nfor math and DL basics (the cumulative knowledge will soon be applied in building LLM-based\\nagents).\\nMonth 5: Mastering Transformers – Hugging Face and LLMs\\nFocus: Deep dive into transformers and large language models (LLMs), and become proficient with the\\nHugging  Face  ecosystem  for  NLP .  This  month  transitions  from  traditional  ML/DL  into  the  realm  of\\ngenerative AI and LLMs, which is core for agentic AI. \\nKey Learning Goals: Gain a solid understanding of how Transformer architectures work (self-'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='generative AI and LLMs, which is core for agentic AI. \\nKey Learning Goals: Gain a solid understanding of how Transformer architectures work (self-\\nattention mechanism, encoder-decoder vs decoder-only models), and how modern LLMs (GPT, BERT,\\netc.) are built on these principles. Learn to use pre-trained LLMs from Hugging Face for various tasks\\nand fine-tune them on custom data. By the end of the month, you should comfortably load a model\\nfrom Hugging Face Hub, use it for inference (text generation, classification, etc.), and know the\\nworkflow for fine-tuning a model on a new dataset. \\nCore Concepts & Tools: Transformers theory (multi-head attention, positional embeddings, etc.),\\ndifferences between model types (e.g. BERT is an encoder-only transformer good for understanding\\ntasks, GPT-3 is decoder-only, etc.), the concept of transfer learning in NLP (pretrain on large corpus,\\nfine-tune on task). Tools: Hugging Face Transformers library (APIs like AutoModel,'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='tasks, GPT-3 is decoder-only, etc.), the concept of transfer learning in NLP (pretrain on large corpus,\\nfine-tune on task). Tools: Hugging Face Transformers library (APIs like AutoModel, \\nAutoTokenizer), Hugging Face Datasets (to load common NLP datasets easily), and using \\nHugging Face Hub to find and use community models. If resources allow, familiarize with Google\\nColab Pro or Kaggle Kernels for longer training jobs. Also, practice using Git and GitHub more as\\nyou handle larger code/projects – this is part of being production-ready. \\nBest Resources:\\nThe Hugging Face Course (Transformers) – complete this course this month. It’s free and covers\\nusing Transformers, fine-tuning, and even deploying models. Chapters 1-8 will teach you how to\\nload models, tokenize data, fine-tune on a dataset, and share your model. (Chapters 9+ go into\\nbuilding demos and advanced topics – which you will find useful for sharing your work and for next'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='load models, tokenize data, fine-tune on a dataset, and share your model. (Chapters 9+ go into\\nbuilding demos and advanced topics – which you will find useful for sharing your work and for next\\nmonth’s advanced LLM techniques.) This course is highly recommended as it’s hands-on and up-to-\\ndate with the latest Hugging Face tools, which are industry-standard. \\nAnnotated Transformer (blog or video by Harvard NLP) – for an in-depth look at the original\\nTransformer model “Attention is All You Need”. This can solidify your theoretical understanding. \\n12\\n• \\n• \\n• \\n• \\n• \\n• \\n12\\n• \\n5'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content=\"Andrej Karpathy’s “Let's build GPT” video – if you haven’t already, watch Karpathy’s video where he\\nlive-codes a GPT-like mini model. It’s a fantastic way to see how pieces of a transformer\\n(tokenization, self-attention, etc.) come together in code. This can be dense, but it connects theory to\\nimplementation. \\nYouTube & Blogs: Look up “Transformers from scratch” by Jay Alammar (famous visual illustrations\\nof how transformer attention works) and Simplilearn or StatQuest summaries on transformers for\\nintuitive explanations. Also consider the Hugging Face YouTube channel – they often have videos\\nfor beginners on using their library. \\nProjects & Portfolio:\\nFine-tune an LLM: Choose a task and fine-tune a pre-trained transformer on it. For example, create\\na Question-Answering system on a niche dataset: use Hugging Face to fine-tune a smaller model\\n(like DistilBERT or RoBERTa) on a QA dataset (SQuAD or a custom set of Q&A pairs you prepare). This\"),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='a Question-Answering system on a niche dataset: use Hugging Face to fine-tune a smaller model\\n(like DistilBERT or RoBERTa) on a QA dataset (SQuAD or a custom set of Q&A pairs you prepare). This\\nteaches you the end-to-end of customizing an LLM. After fine-tuning, evaluate it and upload your\\nmodel to Hugging Face Hub (so others can see/use it, and you can reference it on your resume). \\nHugging Face’s course actually guides you through such a project, so follow that closely. \\nBuild a Language Generation Demo: Using an open-source language model (like GPT-2 or\\nEleutherAI’s GPT-Neo), build a fun demo – e.g., a text generator that completes a sentence or writes\\nshort stories on prompts. You can do this without fine-tuning (just use the pre-trained model with a\\nprompt) or fine-tune it on a specific style (say Shakespearean text) if resources permit. Host this as a\\nHugging Face Space (they support Gradio apps for free) so you have a live demo in your portfolio\\n.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Hugging Face Space (they support Gradio apps for free) so you have a live demo in your portfolio\\n. \\nYouTube Opportunity: Publish a video titled “Fine-tuning a Transformer model (Hugging Face\\nCourse Review)” – share your screen as you walk through the fine-tuning process you did, explaining\\neach step (loading data, training, evaluating). For the generation demo, you could do a creative piece\\nlike “I taught a GPT-2 to write Shakespeare – here’s how!”. These make for engaging content and\\ndemonstrate your practical skills with LLMs. \\nSpaced Repetition: Now that you’re dealing with a lot of new info, use spaced repetition for\\nterminology (e.g., “What is self-attention?”, “What does CLS token mean in BERT?”). Revisit your older\\nflashcards on ML basics – bridging old and new (e.g. compare how a transformer vs a simple neural\\nnet handles inputs). Also, consider writing a weekly summary of what you learned in a short blog or'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='flashcards on ML basics – bridging old and new (e.g. compare how a transformer vs a simple neural\\nnet handles inputs). Also, consider writing a weekly summary of what you learned in a short blog or\\njournal – rephrasing concepts in your own words is a great review technique and can be content for\\nLinkedIn or Medium.\\nMonth 6: Projects & Portfolio Expansion – Applying What You’ve\\nLearned\\nFocus: Consolidate your knowledge by building multiple  portfolio-worthy projects. This month is about\\nlearning by doing – picking projects that integrate the skills from the first half of the year and pushing\\nthem a bit further . By now, you have a range of skills: classical ML, deep learning, and basic LLM usage. It’s\\ntime to showcase them and fill any small gaps in knowledge through practice. \\nKey Learning Goals: Gain confidence in independently scoping and executing AI projects end-to-\\nend. Solidify understanding of the entire workflow: problem formulation, data collection, model'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Key Learning Goals: Gain confidence in independently scoping and executing AI projects end-to-\\nend. Solidify understanding of the entire workflow: problem formulation, data collection, model\\nselection, training, testing, and deployment. Also, learn how to present your projects (readme\\ndocumentation, clean code, brief reports) because employers and freelance clients value clarity. In\\naddition, start exploring Kaggle competitions or AI hackathons to experience real-world problem\\nsolving under constraints, which builds both skill and resume. \\n• \\n13\\n• \\n• \\n• \\n12\\n• \\n14\\n• \\n• \\n• \\n6'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Core Concepts & Tools: End-to-end project development, using mix of techniques (e.g., combining a\\npre-trained model with a custom algorithm). If any tool is still unfamiliar (say you focused on\\nPyTorch, you might try a small TensorFlow/Keras project to be versatile; or if you haven’t touched \\nSQL or data engineering basics, do so now as data handling is crucial in production). Additionally,\\nfamiliarize with basic software engineering practices: writing modular code, using git branches,\\nwriting tests for critical functions – these will elevate your code quality towards production-ready. \\nBest Resources:\\nReddit & Community insights: Browse r/learnmachinelearning and r/MachineLearning for “project\\nideas” threads. The community often shares what’s impactful. Also, review how top Kaggle kernels\\nare written – you’ll learn a lot about clean coding and analysis from them. \\nFull-Stack Deep Learning (fullstackdeeplearning.com) – a course/material that covers the practical'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='are written – you’ll learn a lot about clean coding and analysis from them. \\nFull-Stack Deep Learning (fullstackdeeplearning.com) – a course/material that covers the practical\\naspects of ML projects (like setting up proper experiments, managing data, etc.). Skim relevant\\nsections to get ideas on best practices. \\nCoursera: “AI for Everyone” or “Data Engineering” – not mandatory, but if you feel weak on the\\n“data” side, a quick course or YouTube series on data pipelines, or one on software engineering for\\nML (Google has a free course on ML engineering professionalism) could be beneficial. \\nKaggle’s micro-courses (free) on topics like data cleaning, ML explainability, etc., to fill minor skill\\ngaps while doing projects. \\nProjects & Portfolio:(Aim to complete 2 projects this month, which can be smaller in scope since you’ll\\njuggle multiple.)\\nProject 1 – NLP or CV Application: Build a practical tool, for example an “AI Resume Reviewer.”'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='juggle multiple.)\\nProject 1 – NLP or CV Application: Build a practical tool, for example an “AI Resume Reviewer.”\\nThis could use NLP to parse a resume and give feedback. Concretely: use a spaCy or transformer\\nmodel to extract entities (skills, experience), then some rules/ML model to score or suggest\\nimprovements. This project ties NLP with a real-world use-case and is appealing in a portfolio.\\nAlternatively, build a vision-based tool, e.g., an app that can take a picture of a circuit board and\\nidentify components (leveraging your ECE background) using a trained CNN. Focus on deployability:\\npackage it with a simple UI. \\nProject 2 – Open-Ended Creative Project*: Pick something that excites you – maybe a *generative\\nart or music project using AI, or a chatbot that uses multiple skills (sentiment analysis + response\\ngeneration). The goal is to have fun and be creative, which keeps motivation high. For instance,'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='art or music project using AI, or a chatbot that uses multiple skills (sentiment analysis + response\\ngeneration). The goal is to have fun and be creative, which keeps motivation high. For instance,\\ncreate a chatbot for a specific domain (like a math tutor bot): it might use an LLM for the\\nconversation, but also incorporate a Python-based calculator tool for solving equations (this idea\\nforeshadows agentic AI with tool use). \\nProject 3 (Optional, Hackathon/Kaggle): Participate in a Kaggle competition or an online AI\\nhackathon this month. This will force you to apply your skills under time pressure and teamwork if\\nit’s a team hackathon. Websites like Lablab.ai regularly host GenAI hackathons – joining one\\nfocused on LLMs or agents can give you a taste of building agentic AI in a sprint. Even if you don’t\\nwin, the experience is invaluable and can be mentioned on your resume (“Participated in XYZ\\nHackathon, built a prototype that does …”).'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='win, the experience is invaluable and can be mentioned on your resume (“Participated in XYZ\\nHackathon, built a prototype that does …”). \\nPolish & Presentation: For each project, invest time in making it public-ready: a clean GitHub repo\\nwith a good README (describe the problem, solution, and how to run the code). If possible, deploy\\nthe project (web demo or at least screenshots) and include those in the repo or your portfolio\\nwebsite (if you have one). This will strengthen your profile significantly. \\nYouTube Opportunity: Each project can yield content. For Project 1, you could do a walkthrough\\ntitled “I built an AI Resume Reviewer – Here’s how it works”. For the creative project, maybe a more\\nfun video, “Tour of my AI chatbot that can do math homework!”. Also, consider making a vlog about\\nyour hackathon or Kaggle experience – sharing the approach you took, the mistakes, and lessons\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n15\\n• \\n16\\n• \\n7'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='learned (this humanizes your journey and might resonate with others learning). Regular uploads will\\nsteadily grow your Engimemer channel and also keep you reflecting on your learning. \\nSpaced Repetition: At this midpoint, review everything learned so far in a structured way. Spend a\\nday each week summarizing earlier material: re-derive the formula for backprop, sketch the\\ntransformer architecture from memory, etc. You might even create a “cheat sheet” of key AI concepts\\nlearned in 6 months. This not only helps retention but will be useful in interviews later . Continue\\nusing Anki or your flashcards for any new terms or formulas encountered in projects.\\n(By the end of Month 6, you should have 3-4 solid projects in your portfolio, showcasing different skills – exactly\\nwhat many AI recruiters look for. You’ve also built consistency in learning and doing, which will serve you\\nwell in the next, more specialized phase.)\\nMonth 7: Specialization – Introduction to Agentic AI (LangChain &'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='well in the next, more specialized phase.)\\nMonth 7: Specialization – Introduction to Agentic AI (LangChain &\\nPrompt Engineering)\\nFocus: Enter the world of Agentic AI by learning how LLMs can be used as agents (software programs that\\nperceive, reason, and act). This month, you will learn prompt engineering in depth and start working with\\nframeworks like LangChain that simplify building AI agents. The goal is to understand how to make LLMs\\ndo things – e.g. perform a series of tasks or use external tools – which is the essence of AutoGPT-like\\nsystems.\\nKey Learning Goals: Develop prompt engineering expertise – crafting effective prompts to get\\nreliable outputs from LLMs, and using techniques like few-shot prompting. Understand the concept\\nof an AI agent: an LLM that can take actions (like calling tools or APIs) autonomously based on\\ninstructions. Learn what architectures like AutoGPT or BabyAGI are doing under the hood'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='of an AI agent: an LLM that can take actions (like calling tools or APIs) autonomously based on\\ninstructions. Learn what architectures like AutoGPT or BabyAGI are doing under the hood\\n(planning, tool use, memory) so you can build simpler versions. By end of month, you should be able\\nto create a basic agent that, given a goal, decides on steps and uses some tools to execute them. \\nCore Concepts & Tools: Prompt design principles (clarity, context, constraints). Advanced prompting\\nmethods: e.g., chain-of-thought prompting (getting the LLM to reason step by step) and few-shot\\nexamples to guide style/format. Understand prompt tokens and costs (to be cost-efficient). Tools: \\nOpenAI API (or another LLM API) – practice sending prompts and parsing outputs in code. \\nLangChain – a powerful framework for chaining LLM calls and integrating tools and memory. Learn\\nLangChain’s basics: what are “chains”, what are “agents”, how to use its components (it provides'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='LangChain – a powerful framework for chaining LLM calls and integrating tools and memory. Learn\\nLangChain’s basics: what are “chains”, what are “agents”, how to use its components (it provides\\nabstractions for doing retrieval, using tools, maintaining conversation memory, etc.). Also introduce \\nvector databases conceptually here if you haven’t already (LangChain uses vector DBs for long-term\\nmemory and retrieval of facts). We will dive deeper into vector DB next month, but start thinking in\\nthat direction. \\nBest Resources:\\n“ChatGPT Prompt Engineering for Developers” (DeepLearning.AI short course) – this is a free 1.5-\\nhour course by OpenAI’s Isa Fulford and Andrew Ng that teaches prompt engineering best practices\\nand how to use LLM APIs. It’s concise and extremely relevant, covering how to structure\\nprompts, use temperature, etc., and even how to build a custom chatbot using an API. Go through'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='and how to use LLM APIs. It’s concise and extremely relevant, covering how to structure\\nprompts, use temperature, etc., and even how to build a custom chatbot using an API. Go through\\nthis course early in the month – it will level up your prompting skills quickly with real examples. \\nLangChain for LLM Application Development (DeepLearning.AI short course) – another short\\ncourse, taught by LangChain’s creator Harrison Chase. In ~1.5 hours it covers LangChain’s core\\nconcepts: models, prompts, parsers, memory, chains, and agents. This is a perfect quickstart to\\n• \\n17 18\\n• \\n19\\n• \\n• \\n• \\n20\\n• \\n21\\n22\\n8'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='using LangChain effectively. Take this after the prompt engineering course; it will tie together\\nprompt skills with a framework to build things. \\nLangChain Documentation & Tutorials – LangChain’s official docs have a tutorial “Build an Agent”\\nthat shows how to create an agent that can use a search tool. Follow this step-by-step to build\\nyour first agent. They also explain various types of agents and tools integration – extremely useful\\nreading. \\nOpenAI Cookbook & Examples – OpenAI’s cookbook (on GitHub) has a section on using models\\nwith function calling (letting GPT-4 use tools) and other prompt tactics. Skim these recipes to learn\\npractical tips (e.g. how to format a prompt for a JSON output, etc.). \\nAnthropic’s “Building Effective Agents” guide – a blog post by Anthropic that discusses best\\npractices for AI agents (like when to use agents vs simple chains, how to handle tool use). It’s a great'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Anthropic’s “Building Effective Agents” guide – a blog post by Anthropic that discusses best\\npractices for AI agents (like when to use agents vs simple chains, how to handle tool use). It’s a great\\nread to develop an intuition for agent design choices, and many working AI engineers refer to it\\n. \\nCommunities: Join the r/AI_Agents subreddit and the LangChain community (Discord or forums).\\nSince agentic AI is so new, a lot of knowledge is shared in real-time on forums. Seeing others’\\nexperiments or issues will teach you a lot and keep you updated. \\nProjects & Portfolio:\\nPrompt Engineering Mini-Project: Design a complex prompt that turns GPT-4 (or another LLM) into\\nsomething useful, without coding an agent. For example, a prompt that makes the LLM a helpful \\ntravel planner (“You are a travel agent AI...”). Refine it to handle tricky inputs. This exercise in\\niterative prompt crafting will teach you how small wording changes impact outputs. Document your'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='travel planner (“You are a travel agent AI...”). Refine it to handle tricky inputs. This exercise in\\niterative prompt crafting will teach you how small wording changes impact outputs. Document your\\nfinal prompt and some chat transcripts as a portfolio piece (it shows your ability to coax functionality\\nfrom an API, which is a valuable skill on its own). \\nBuild Your First AI Agent: Using LangChain, create a simple agent that can perform a task using\\ntools. For instance, “Research Assistant Agent”: it takes a query, uses a web search tool (LangChain\\nhas search integrations) and then summarizes an answer . This involves the agent deciding to call the\\nsearch tool, then perhaps a calculator or wiki API, etc. Another idea: an “Email Assistant Agent”\\nthat reads your emails (you can feed it sample emails), and drafts replies using an LLM, possibly\\nusing a calendar API as a tool to check your availability when scheduling meetings. Keep the scope'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='that reads your emails (you can feed it sample emails), and drafts replies using an LLM, possibly\\nusing a calendar API as a tool to check your availability when scheduling meetings. Keep the scope\\nnarrow so it’s achievable – e.g. one that uses 2 tools maximum. The goal is to get hands-on\\nexperience with the agent loop (LLM observes -> decides action -> tool -> new input -> LLM\\ncontinues...). You will encounter challenges like ensuring the agent doesn’t get stuck or making\\noutput formatted, which are great learning opportunities. \\nVectorstore Experiment (mini): Set up a simple vector database (could be as easy as using FAISS in\\nmemory) with a small custom text dataset (maybe a compilation of your own notes or a few articles).\\nHook it up with LangChain’s retrieval API to create a knowledge base. This isn’t a full project by\\nitself, but a tech demo: e.g., ask questions and have the system retrieve relevant info and feed it to'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='itself, but a tech demo: e.g., ask questions and have the system retrieve relevant info and feed it to\\nthe LLM (classic RAG pipeline). This will prepare you for next month where we do this more fully. \\nYouTube Opportunity: Share what you learn about prompt engineering – e.g., “5 Prompt Engineering\\nTricks I Learned” with examples (this can attract a lot of viewers given interest in ChatGPT tips). For\\nthe agent, do a live demo video: “Building my first AI agent with LangChain!” – show the agent in action\\n(maybe split-screen with code and it executing tasks). Even if it’s a simple research bot, viewers find\\nthe concept exciting, and it demonstrates cutting-edge skills. You could also reflect on failures or\\niterations, which shows your problem-solving process. \\nSpaced Repetition: As you venture into new territory, relate back to fundamentals. For example,\\nrecall how transformers and embeddings work (important for vector databases and prompt'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Spaced Repetition: As you venture into new territory, relate back to fundamentals. For example,\\nrecall how transformers and embeddings work (important for vector databases and prompt\\nembeddings), or how the ML pipeline works (when thinking about feeding info to LLMs). Revise\\nprevious notes on evaluation metrics – now you should think: How do I evaluate if my agent is “working\\n• \\n19\\n• \\n• \\n23\\n24\\n• \\n• \\n• \\n• \\n25\\n• \\n• \\n• \\n9'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='well”? Maybe by accuracy of retrieved info or user feedback. This meta-thinking will reinforce old\\nknowledge in a new context. Also, maintain your Anki deck for new LangChain terms or best\\npractices (“What is a LangChain agent?”, “Name 3 best practices for prompt design”). \\nMonth 8: Advanced Applications – Building with LLMs, Memory &\\nRetrieval (RAG)\\nFocus: Develop deep expertise in  Retrieval-Augmented Generation (RAG) and  long-term memory for\\nagents using vector databases, and build a substantial project that utilizes these. Also, get comfortable with\\nvarious LLM APIs/platforms (not just one) to increase your versatility. By the end of this month, you will\\nhave built an AI application that  combines an LLM with external knowledge, a critical capability for\\nagentic systems.\\nKey Learning Goals: Understand how to handle large knowledge with LLMs – since LLMs have\\ncontext length limits, we use embeddings + vector stores to give them relevant info on the fly.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Key Learning Goals: Understand how to handle large knowledge with LLMs – since LLMs have\\ncontext length limits, we use embeddings + vector stores to give them relevant info on the fly.\\nMaster the workflow of creating embeddings for data, storing and querying a vector database. Learn\\nabout popular vector DB solutions (FAISS, Pinecone, Weaviate, etc.) and trade-offs (memory vs\\nspeed, local vs cloud service). Additionally, explore memory management in agent frameworks\\n(keeping conversation history, summarizing to compress memory, etc.). By now, you should also\\ndeepen your knowledge of various LLM providers – experiment with a new model or API (e.g.,\\nCohere, Anthropic Claude, open-source LLaMA2) to broaden your toolset. \\nCore Concepts & Tools: Embeddings (how text is converted to high-dimensional vectors, e.g. using\\nOpenAI’s text-embedding-ada model or Sentence Transformers). Vector database operations: insert,'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Core Concepts & Tools: Embeddings (how text is converted to high-dimensional vectors, e.g. using\\nOpenAI’s text-embedding-ada model or Sentence Transformers). Vector database operations: insert,\\nsimilarity search. LangChain’s RetrievalQA chain or similar: feeding retrieved docs to LLM. Memory\\nin LangChain: short-term (conversation buffers) vs long-term (using a vector store as memory)\\n. Tools: Pick a vector DB – for learning, FAISS (an open-source library) is straightforward to use\\nlocally. You might also try Pinecone or ChromaDB for a managed solution (they have free tiers).\\nContinue with LangChain to integrate these pieces seamlessly. Also consider using Hugging Face\\nHub for embeddings/models if you want to try non-OpenAI models. If you haven’t yet, using a local\\nLLM (like Llama-2 13B on a Colab or smaller model on CPU) could be educational to see how to\\ndeploy models without an API – though this is optional if resources are limited. \\nBest Resources:'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='LLM (like Llama-2 13B on a Colab or smaller model on CPU) could be educational to see how to\\ndeploy models without an API – though this is optional if resources are limited. \\nBest Resources:\\nHugging Face Course, Chapter on “Build Reasoning Agents” – the later chapters of the HF course\\n(Ch. 11-12) cover fine-tuning LLMs and building reasoning models. These might touch on retrieval\\nand advanced use-cases – worth reading for a structured insight. \\nBlogs on RAG: “How to build a QA system with RAG” – many blog posts or Medium articles exist (e.g.\\nby AWS, Cohere, or independent bloggers) that walk through building a document Q&A bot with\\nLangChain + vector DB. Follow one of these tutorials to reinforce your understanding. \\nDeepLearning.AI short course: “Building and Evaluating Advanced RAG Applications” – (as\\nhinted in their site) if available, this could be very relevant. If not, seek out conference talks or'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='DeepLearning.AI short course: “Building and Evaluating Advanced RAG Applications” – (as\\nhinted in their site) if available, this could be very relevant. If not, seek out conference talks or\\nwebinars on RAG. For instance, Pinecone’s blog has articles on designing good RAG systems\\n(covering chunking strategies, etc.). \\nDocumentation: Read Pinecone’s docs or FAISS wiki to understand how vector search works under\\nthe hood (helps if you need to optimize or debug retrieval issues). Also, the LangChain docs on\\nMemory and on VectorStores are crucial – they provide code snippets and explain different types of\\nmemory (short-term vs long-term). \\n• \\n• \\n26\\n27\\n• \\n• \\n• \\n• \\n• \\n28 29\\n10'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Research papers (optional): If curious, skim the Retrieval-Augmented Generation paper by\\nFacebook (if available) or related literature to see the formal approach. And Anthropic’s work on\\n“Claude’s long documents” or OpenAI’s on “Retrieval for GPT” to know the state-of-art thinking\\n(optional but inspiring). \\nProjects & Portfolio:\\nCapstone Project Part 1 – “AI Research Assistant” (RAG System): Begin a major project that will\\nspan this month and next. Build an Agentic AI system that can ingest and use a knowledge base.\\nFor example, an agent that a user can ask questions, and if it doesn’t know the answer it will search a\\ncustom document repository to find relevant info and then answer (akin to an enterprise Q&A bot).\\nThis involves: \\nGathering a knowledge corpus (could be a set of PDFs or markdown notes – perhaps your\\nuniversity lecture notes or a collection of articles in a domain you like). \\nIndexing them: split into chunks, embed each chunk, store in a vector DB.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='university lecture notes or a collection of articles in a domain you like). \\nIndexing them: split into chunks, embed each chunk, store in a vector DB. \\nImplementing retrieval: given a query, get top relevant chunks. \\nFeeding them to an LLM with a proper prompt (prompt engineering to incorporate retrieved\\ninfo and cite sources perhaps). \\n(Optional advanced agent behavior) If the question requires multi-step reasoning, the agent\\nmight break it down. But even a single-step QA with retrieval is a huge accomplishment. \\nTest the system on various queries, refine chunk sizes or prompt as needed for better\\nanswers.\\nThis project solidifies many skills and is highly relevant to real-world applications (companies\\nlove this use-case). Make sure to log how well it answers questions (you can demonstrate it\\nanswering things that vanilla ChatGPT cannot because it has your custom data). \\nExperiment with Multi-LLM or Tools: As part of above or separate small experiment, try using a'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='answering things that vanilla ChatGPT cannot because it has your custom data). \\nExperiment with Multi-LLM or Tools: As part of above or separate small experiment, try using a\\ndifferent model for embedding vs answering. For instance, use OpenAI’s API for answers but a local\\nmodel for embeddings, or vice versa. Or incorporate a new tool into your agent: e.g., a calculator or\\nPython REPL for math problems. This will teach you how to mix and match components for efficiency\\n(an important production consideration is cost and latency – e.g., using a smaller model when\\nappropriate). \\nIntermediate Deliverable: By end of this month, have a working Q&A system (even if not fully an\\nautonomous “agent”), which accepts user queries about your documents and returns answers with\\nreferences. This sets the stage for next month, where you can extend it into more of an “agent” with\\nplanning abilities. \\nYouTube Opportunity: Document this capstone’s development. For instance, “Building a GPT-4'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='planning abilities. \\nYouTube Opportunity: Document this capstone’s development. For instance, “Building a GPT-4\\nPowered Research Assistant – Part 1” where you show how you set up the vector database and got the\\nQA working. This could be a series (audience loves following along a build). Explain concepts like\\nembeddings and RAG in simple terms while demoing. Not only does this educate your viewers, it\\nreinforces your own learning and demonstrates mastery to potential employers who might see it. \\nSpaced Repetition: At this advanced stage, spaced repetition might involve integrating knowledge.\\nFor example, explain to yourself (or in notes) how a concept from Month 2 (say, evaluation metrics)\\napplies when evaluating your QA system (you might think of precision/recall of relevant info). Revisit\\nyour flashcards on prompt engineering and see if your understanding has evolved – update them\\nwith new insights (e.g., you might add notes like “When doing retrieval+LLM, remember to prompt'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='your flashcards on prompt engineering and see if your understanding has evolved – update them\\nwith new insights (e.g., you might add notes like “When doing retrieval+LLM, remember to prompt\\nthe model to only use provided info.”). Regularly revisit fundamentals like big-O complexity or\\nsystem design basics, since soon you’ll be interviewing and those may come up too.\\n• \\n• \\n• \\n◦ \\n◦ \\n◦ \\n◦ \\n◦ \\n◦ \\n• \\n30\\n• \\n• \\n• \\n11'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Month 9: Capstone – Building an Autonomous AI Agent (AutoGPT-\\nLite)\\nFocus: This month, you will integrate everything to build a showcase Agentic AI application – essentially\\nyour own simplified version of AutoGPT catered to a specific use-case. This is the culmination of your\\nspecialization, demonstrating you can orchestrate LLMs, tools, and knowledge bases to perform complex\\ntasks autonomously. Also, you’ll solidify production-level considerations while building this capstone.\\nKey Learning Goals: Learn to design an agent system architecture: breaking a problem into sub-\\ntasks that an AI agent can handle (planning). Implementing a loop where the agent can decide\\nactions (tool use or asking for more info) and stopping criteria. Handling errors or unexpected\\noutputs gracefully (robustness). Additionally, deepen understanding of production concerns: rate\\nlimits of APIs, error handling, logging agent decisions, and cost management. By the end, you’ll have'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='outputs gracefully (robustness). Additionally, deepen understanding of production concerns: rate\\nlimits of APIs, error handling, logging agent decisions, and cost management. By the end, you’ll have\\na functioning multi-step agent and know how to evaluate and improve it. \\nCore Concepts & Tools: Planning algorithms for agents (e.g., the ReAct framework – reasoning and\\nacting iteratively). Tool integration in LangChain: ensure you know how to add custom tools. If not\\nalready, explore LangChain’s AgentExecutor and how it manages the loop. Memory\\nmanagement – possibly use a summary of past interactions to keep context short. Evaluation: learn\\nhow to test agent performance (maybe create specific scenarios to see if it succeeds, and log\\nresults). Continue using your chosen LLM API (perhaps GPT-4 if available for complex reasoning, due\\nto its strength in reasoning) along with cheaper models for simpler tasks (as a production-minded'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='results). Continue using your chosen LLM API (perhaps GPT-4 if available for complex reasoning, due\\nto its strength in reasoning) along with cheaper models for simpler tasks (as a production-minded\\nstrategy). Possibly introduce guardrails (like OpenAI’s function calling or the Guardrails AI library) to\\nconstrain outputs – this is a cutting-edge practice to improve reliability. \\nBest Resources:\\nAuto-GPT and BabyAGI GitHub repos – review their README and maybe part of the code to\\nunderstand how those projects structure the agent loop and memory. You don’t need to replicate\\nthem fully, but it’s insightful to see how others implemented autonomous agents. \\nSoftware Engineering Daily podcast episode “LangChain and Agentic AI” – an interview with\\nHarrison Chase (LangChain creator) or similar talks on YouTube where developers discuss building\\nwith agents. These often reveal pitfalls and best practices (like how to avoid agents going in circles,\\netc.).'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='with agents. These often reveal pitfalls and best practices (like how to avoid agents going in circles,\\netc.). \\nReddit - r/AI_Agents and r/LangChain threads – look for posts like “Lessons learned building an\\nagent” or “Why AutoGPT fails at X”. Community wisdom will teach you what not to do. In fact, one AI\\nengineer on Reddit shared tips: e.g., keep agents’ scope narrow, have each LLM call do one specific\\ntask, and show the agent’s reasoning steps for transparency. Such insights can guide your\\ndesign. \\nLangChain documentation (advanced): Specifically, read about custom Agents and agent policies.\\nLangChain now has features like Multi-Action Agents or using LangSmith for tracing – these are\\nmore advanced, but skimming these can give you ideas on improving your agent. \\nOpenAI/Anthropic docs on usage limits – ensure you know how to set API call limits or monitor\\nusage (OpenAI lets you set a quota) so that during development your agent doesn’t accidentally'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='OpenAI/Anthropic docs on usage limits – ensure you know how to set API call limits or monitor\\nusage (OpenAI lets you set a quota) so that during development your agent doesn’t accidentally\\nrack up huge costs. This is an important production skill (cost management). \\nPossibly revisit Chip Huyen’s blog on LLM applications – especially sections on agents and tool use\\n, and the challenges of making them reliable. It will remind you to think about edge cases\\nand user expectations in production. \\nProjects & Portfolio:\\n• \\n• \\n19\\n• \\n• \\n• \\n• \\n25 31\\n• \\n• \\n32\\n• \\n33 34\\n• \\n12'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Capstone Project Part 2 – Autonomous Agent: Continue and complete the capstone started last\\nmonth by adding autonomous capabilities. Building on the “AI Research Assistant” (or whichever\\nRAG system you made), add a planning and tool-use layer. For example, enable the agent to\\nhandle a complex query like: “Summarize the key differences between these two research papers\\nand email the summary to my colleague.” This would require the agent to break it down: (a) search\\nor retrieve info on paper 1 and 2, (b) summarize differences, (c) formulate an email, (d) possibly\\nactually send an email via an email API (if you choose to integrate that tool). This is just an example –\\ndefine a scenario relevant to your interests. The agent should use multiple steps autonomously:\\nretrieving data, using a writing tool, maybe a calculation or API call, etc., without you intervening in\\neach step. Document the chain of thought: have the agent output or log its reasoning at each step'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='each step. Document the chain of thought: have the agent output or log its reasoning at each step\\n(this is great for demo and debugging). \\nTesting and Refinement: Once built, test your agent on a variety of tasks within its scope. Observe\\nfailure modes (does it get stuck in a loop? Does it ever hallucinate wrong info from outside the\\ndocs?). Refine by adjusting prompts or adding constraints. For instance, if it tends to hallucinate, you\\nmight enforce that it must quote sources for factual info, or if it loops, add a rule to break after N steps\\nwith a graceful response. This process teaches MLOps mindset – iterate to improve reliability. \\nFinalize Deployment: Deploy your capstone if possible. For instance, create a small web interface\\nfor it (a simple frontend where you input a query and see the agent’s plan and answer). If deploying\\nfully is hard, at least record a compelling demo of it working. Also, prepare a technical write-up in'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='fully is hard, at least record a compelling demo of it working. Also, prepare a technical write-up in\\nyour GitHub repo or a Medium article about how you built this agent. This can be gold for your\\nportfolio – it demonstrates end-to-end project execution and thought leadership (few people have\\nwritten detailed guides on building agents – you could!). \\nYouTube Opportunity: This is the big one – create a showcase video: “I built my own Auto-GPT in 30\\ndays” or “Autonomous AI Agent demo – [Your Agent’s Name]”. In this video, present the problem it\\nsolves, show it performing a multi-step task live (with its thinking printed out), and explain how you\\nmade it. This is likely to attract attention given the hype around AI agents, and it serves as a\\ncapstone presentation of your skills. Share this video on LinkedIn, Reddit, etc. for feedback and\\nperhaps it catches the eye of recruiters or potential collaborators.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='capstone presentation of your skills. Share this video on LinkedIn, Reddit, etc. for feedback and\\nperhaps it catches the eye of recruiters or potential collaborators. \\nSpaced Repetition: At this point, spaced repetition is about interview prep and knowledge\\nsynthesis. Start reviewing topics you may not have touched recently: e.g., revisit how SVMs work or\\nhow backprop works – interviews might dig into fundamentals even if your focus was on LLMs. Use\\nflashcards for data structures and algorithms (you’ll need some for coding interviews at FAANG). Also\\nconsider doing a high-level review of all projects: can you summarize each project’s key idea and\\nlearning in a few sentences from memory? If not, review it. This prepares you to talk about them\\nfluently in interviews. Continue using spaced repetition for new things too (e.g., key lessons you\\nlearned about agent design – write those down and revisit).\\nMonth 10: Production Readiness – MLOps, Deployment, and\\nScalability'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='learned about agent design – write those down and revisit).\\nMonth 10: Production Readiness – MLOps, Deployment, and\\nScalability\\nFocus: Shift gears to learn MLOps and deployment best practices. This month is about making sure you can\\ntake an AI model/agent and deploy it in a production environment reliably. You’ll also prepare for the job\\nhunt by aligning your skills with what industry expects (scalability, reliability, collaboration).\\nKey Learning Goals: Learn how to package and deploy models and AI systems as services.\\nUnderstand the concepts of containerization (Docker), CI/CD, and cloud deployment (AWS/GCP/\\nAzure) as applicable to AI apps. Learn to monitor a live AI system (logging, detecting failures or drift).\\n• \\n• \\n• \\n• \\n• \\n• \\n13'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Also, familiarize with ML experiment tracking (tools like MLflow or Weights & Biases) – in\\nproduction roles, being able to track model versions and experiments is valuable. Additionally, gain\\nknowledge of data pipelines: how to regularly update a model or feed it new data, and basics of\\nscheduling jobs. Essentially, aim to bridge the gap between a prototype (which you have built many\\nof) and a production-grade application that can handle real users and data. \\nCore Concepts & Tools: Containerization with Docker (create a Dockerfile for one of your apps,\\ncontainerize it with all dependencies). Serving models: using FastAPI or Flask to create an API\\nendpoint for your model/agent. Possibly look into streaming data and real-time considerations if\\nrelevant (for example, if your agent were to run continuously). CI/CD: using GitHub Actions to\\nautomate tests and deployments when you push updates. Cloud: pick one (say AWS) and learn basics'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='relevant (for example, if your agent were to run continuously). CI/CD: using GitHub Actions to\\nautomate tests and deployments when you push updates. Cloud: pick one (say AWS) and learn basics\\n(AWS has free tier – try deploying your FastAPI app on AWS EC2 or using AWS Lambda for a simple\\nfunction, or use Heroku for simplicity). Learn about scaling: how would you scale an API that gets\\nheavy usage? (e.g., using load balancers, multi-instance). Also consider cost optimization: e.g. using\\nsmaller models or batching calls in a production setting to save cost. Security: understand basic\\nmeasures (storing API keys securely, not exposing secrets, etc.). \\nBest Resources:\\nFull Stack Deep Learning – their material on deployment and monitoring is very relevant (they talk\\nabout packaging models and setting up inference endpoints). \\nCoursera or Udacity MLOps courses – if available, doing a crash course on MLOps will systematize'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='about packaging models and setting up inference endpoints). \\nCoursera or Udacity MLOps courses – if available, doing a crash course on MLOps will systematize\\nthis knowledge. Andrew Ng’s MLOps specialization or Google Cloud’s ML Engineering courses\\ncould be useful. \\nAWS/GCP free tutorials – both AWS and Google have free training for deploying ML models (e.g.,\\nAWS SageMaker tutorials, GCP Vertex AI samples). Even if you don’t use the managed services now,\\nknowing they exist and how they work is good for interviews. \\nDocker Official Docs & DockerCaptain YouTube – to learn writing Dockerfiles and container basics.\\nFastAPI docs – FastAPI is a great tool to wrap your models into web services quickly. Their docs are\\nbeginner-friendly and you can have a simple “Hello World” model API running in minutes. \\n“Building LLM applications for production” by Chip Huyen – this blog (if you haven’t fully read it\\nyet) covers practical challenges in deploying LLM apps (like handling ambiguity in prompts,'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='“Building LLM applications for production” by Chip Huyen – this blog (if you haven’t fully read it\\nyet) covers practical challenges in deploying LLM apps (like handling ambiguity in prompts,\\nversioning, evaluation). It’s basically a checklist of things to keep in mind so that your fancy LLM\\ndemo doesn’t break in the real world. Read it and reflect on how you can apply those principles to\\nyour capstone agent if you deployed it. \\nProjects & Portfolio:\\nDeploy Your Capstone Agent: Take the autonomous agent from last month and deploy it as a\\nservice. For example, wrap it in a FastAPI server where one endpoint /ask triggers the agent with\\na user query and returns the answer . Containerize this with Docker . Then try deploying it to a cloud\\nservice or at least run it on a cloud VM to simulate production. This exercise will expose issues\\n(memory usage, need for loading models efficiently, etc.). Ensure you include logging – have the'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='service or at least run it on a cloud VM to simulate production. This exercise will expose issues\\n(memory usage, need for loading models efficiently, etc.). Ensure you include logging – have the\\nservice log each step of the agent’s reasoning to a file or console for monitoring. If possible, simulate\\na few concurrent users to see how it handles (you might realize the agent is stateful and needs\\nunique sessions or it’s slow – which is normal; note those findings). \\nCI/CD Pipeline: Set up a simple CI pipeline for one of your projects. For instance, use GitHub Actions\\nsuch that when you push to main on your capstone’s repo, it automatically runs tests (if you add any)\\nand maybe deploys to your server . This shows you understand DevOps culture. Document this in\\nyour project readme (“Using GitHub Actions to auto-deploy on update”). It’s a nice touch that many\\ncandidates lack. \\n• \\n30\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n35\\n• \\n• \\n• \\n14'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Freelance Simulation Project: Since one of your goals is freelancing, try a project that simulates a\\nfreelance task. For example, find a real problem on Reddit or Freelance boards – e.g., “I need a\\nscript to categorize a bunch of customer feedback using AI.” Then build a quick solution for it: maybe\\nfine-tune a model or use an off-the-shelf model via API, and deliver it as a script or small app. Do it\\nend-to-end in say 3-4 days as if it were a paid gig. This will teach working under requirements and\\nalso give you a template for similar future freelance tasks. You can write about this experience as\\nwell. \\nYouTube/Blog Opportunity: Create content focusing on the production aspect this time – e.g., \\n“How to deploy an AI model as an API (step-by-step)”. This could be a tutorial where you containerize\\nand deploy a smaller ML model (maybe your Month 2 model or a simple Hugging Face model) to a'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='“How to deploy an AI model as an API (step-by-step)”. This could be a tutorial where you containerize\\nand deploy a smaller ML model (maybe your Month 2 model or a simple Hugging Face model) to a\\nfree service. Many find this educational, and it forces you to articulate the process. Additionally,\\nconsider writing a Medium blog post summarizing your capstone project with a focus on its\\nproduction design (“Building an AutoGPT-style agent and deploying it on AWS”). Writing an article\\ncan increase your visibility in the field (and you can add it to your resume). \\nSpaced Repetition: Now shift some focus to interview preparation content for spaced repetition.\\nFor example, use flashcards to remember key points that you might mention in interviews: big-O\\ncomplexities, definitions of overfitting vs underfitting, the trade-offs of different model types, etc.\\nRevisit any theoretical gaps you feel – e.g., if you skipped some math, review it now. Continue to'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Revisit any theoretical gaps you feel – e.g., if you skipped some math, review it now. Continue to\\nrevisit high-level summaries of each project and each major concept (by now you have a web of\\nknowledge – solidify the connections: how does an embedding from Month 8 relate to the cosine\\nsimilarity you learned in Month 1 math? How does Docker compare to a virtualenv from earlier\\nprojects? Connecting dots is a great memory tool).\\nMonth 11: Job Hunt Preparation – Polishing Skills and Portfolio\\nFocus: This month is about getting ready to land a job or freelance clients. We will polish your resume,\\nportfolio, and online presence, and prepare for technical interviews (both coding and ML system design).\\nWe’ll also ensure you leverage your YouTube channel and network for opportunities.\\nKey Tasks – Resume & Portfolio: Craft a strong resume that highlights your AI projects and skills.\\nEmphasize outcomes: e.g., “Built an autonomous research assistant agent using LangChain and'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Key Tasks – Resume & Portfolio: Craft a strong resume that highlights your AI projects and skills.\\nEmphasize outcomes: e.g., “Built an autonomous research assistant agent using LangChain and\\nGPT-4, integrating vector database for 20k documents (GitHub, demo link)”. Quantify where possible\\n(even if just “achieved 90% accuracy on X” or “improved inference speed by Y% with optimization”).\\nInclude keywords like the tools and frameworks you know (TensorFlow, PyTorch, Hugging Face,\\nLangChain, Docker , etc.) so it passes automated scans. Also update your LinkedIn to reflect your\\nyear of projects – write a summary that you’re an AI engineer specializing in LLMs/agents, open to\\nopportunities. On GitHub, pin your best projects to showcase them. Ensure your project READMEs\\nare clear because recruiters will look at them. If you have a personal portfolio website, update it with\\nlinks to your YouTube videos and project write-ups – make it a one-stop-shop of your expertise.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='links to your YouTube videos and project write-ups – make it a one-stop-shop of your expertise. \\nKey Tasks – Networking: Start actively networking. Announce on LinkedIn the completion of your\\nyear-long learning journey, perhaps with a post sharing your Medium article or YouTube capstone\\ndemo. Engage with communities: e.g., on Twitter (X) share insights or small threads about\\nsomething cool you learned about agents (tagging relevant hashtags like #LangChain, #LLM). This\\ncan get you noticed. Also consider reaching out to people in companies you’re interested in – not\\nasking for a job outright, but commenting on their work or asking for advice given your newly\\nminted experience. Join hackathons or meetups (if available locally or virtually) to meet like-minded\\nfolks. Often job leads come from these connections. \\n• \\n• \\n• \\n• \\n16\\n• \\n15'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Interview Prep – Coding: Dedicate daily time to coding interview prep. Even for AI roles, many top\\ncompanies will have a coding round (FAANG especially). Use platforms like LeetCode or HackerRank.\\nFocus on problems around arrays, strings, hash maps, graphs, etc. Aim to solve at least one\\nmedium-difficulty problem each day, and periodically do timed mock interviews. Use spaced\\nrepetition to remember common patterns (two-pointer , BFS, DP etc.). Since you can code in Python,\\nleverage that, but be familiar with complexity analysis. \\nInterview Prep – ML & System Design: Prepare to answer questions on ML concepts: e.g., explain\\nhow logistic regression works, what is bias vs variance, how do you handle missing data, etc. Review\\nyour flashcards on all fundamental definitions. Practice explaining your projects out loud – you\\nshould be able to crisply discuss the goal, approach, and results of each. Also practice ML system'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='your flashcards on all fundamental definitions. Practice explaining your projects out loud – you\\nshould be able to crisply discuss the goal, approach, and results of each. Also practice ML system\\ndesign questions (common in ML engineer interviews): e.g., “How would you design a system to\\nrecommend products?” or “How would you deploy a model that handles 1 million requests/day?” –\\nhere you draw from your Month 10 knowledge (talk about load balancing, caching, monitoring). If\\napplying to specifically LLM-related roles, prepare for questions like “How do you fine-tune an LLM?\\nWhat are the challenges?” or “How would you improve inference latency for an LLM in production?”.\\nDraw on what you learned about quantization or using smaller models for speed. \\nFreelance Prep: In parallel, if freelancing is a goal, create profiles on platforms like Upwork or\\nFreelancer . Showcase your projects there (many clients will be impressed by an AutoGPT-like project).'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Freelancer . Showcase your projects there (many clients will be impressed by an AutoGPT-like project).\\nPerhaps start by bidding on a small project that matches your skills to get a feel for the freelance\\nworkflow. Even if you plan to take a full-time job, a little freelancing can provide experience and a\\nside income. Also, your YouTube channel is now a portfolio piece – mention it in your bio (“I also run\\na YouTube channel with tutorials on AI, with X subscribers”). Having an audience can set you apart. \\nBest Resources:\\nCracking the Coding Interview (book) – for coding questions patterns. \\nInterview Query or Machine Learning Interview guides – there are blogs and books that list\\ncommon ML engineer interview Qs. Go through those.\\nLeetCode’s database and system design sections – sometimes AI roles ask SQL or basic system\\ndesign; ensure you can write simple SQL queries and outline system architecture.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='LeetCode’s database and system design sections – sometimes AI roles ask SQL or basic system\\ndesign; ensure you can write simple SQL queries and outline system architecture. \\nMock interviews: Try Pramp (free mock interview platform) or interview with a friend/mentor . This\\ncan greatly boost confidence. \\nResume review communities: r/EngineeringResumes on Reddit or others – you can get feedback\\non your resume from peers. \\nProjects (Polish & Present): This month you likely won’t start new technical projects, but you might \\nrevisit an old project to polish it. For example, if one of your earlier projects lacked tests or had\\nsome bugs, fixing those shows growth. You can even do a “v2” of a project using new skills (e.g.,\\nrefactor your Month 2 ML project with proper pipelines or deploy your Month 4 CNN as an API).\\nMinor improvements can be content on your blog (“I revisited my old project with new eyes and\\nhere’s what I improved”). It demonstrates continuous improvement.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Minor improvements can be content on your blog (“I revisited my old project with new eyes and\\nhere’s what I improved”). It demonstrates continuous improvement. \\nYouTube Opportunity: Share your journey now that you have nearly completed it. A video like “How\\nI became an AI Engineer in 12 months” where you candidly discuss the roadmap, challenges, and\\nshow snippets of projects could inspire others and also serve as a self-reflection. Additionally, you\\ncould do live streams solving LeetCode problems or talking about interview prep – this shows you’re\\nserious about the job transition and might even attract leads (somebody could refer you after seeing\\nyour depth). \\nSpaced Repetition: This is where your spaced repetition habit pays off – keep cycling through all\\nthose flashcards on theory and math regularly so everything is fresh. Also, simulate Q&A: have a list\\nof likely interview questions (technical and behavioral) and practice responding out loud or in'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='those flashcards on theory and math regularly so everything is fresh. Also, simulate Q&A: have a list\\nof likely interview questions (technical and behavioral) and practice responding out loud or in\\nwriting. Use Anki for tricky algorithm tips or specific facts (like “What’s the equation for a neuron\\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n• \\n16'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='output? What’s cross-entropy?”). By now, you should also revisit any ECE core knowledge if relevant\\n– sometimes, roles value that background, so don’t neglect what you learned in your degree; be\\nready to mention how it complements your AI skills (e.g., knowledge of hardware could help\\noptimize models, etc.). Keep your mind fresh but also get enough rest – don’t burn out right before\\ninterviews.\\nMonth 12: Transition – Interviews, Contributions, and Next Steps\\nFocus: This final month, you will be actively interviewing (if things go to plan) or at least aggressively\\napplying. Meanwhile, continue sharpening skills by contributing to open-source and staying up-to-date with\\nthe latest in AI (to discuss in interviews). Also, lay the groundwork for lifelong learning, since this year is just\\nthe beginning of a career .\\nJob Applications: By now, you should apply to a range of companies – FAANG (stretch goals, but'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='the beginning of a career .\\nJob Applications: By now, you should apply to a range of companies – FAANG (stretch goals, but\\nyour strong portfolio gives you a shot!) as well as top startups especially in the AI tooling/LLM space.\\nMany startups would value your experience with LangChain, vector DBs, etc., as those are hot skills.\\nTailor each application – mention your specific experience relevant to their work. Leverage referrals if\\npossible: use LinkedIn to see if you have connections at these companies; a referral plus your project\\nlinks can get you interviews. For freelance, step up outreach: send proposals highlighting similar\\nwork you’ve done. \\nInterview Rounds: Hopefully, you land interviews. In technical rounds, draw confidently on your\\npreparation. For coding, keep practicing problems daily up to the interview day. In ML design\\nrounds, use a structured approach (clarify requirements, explain your approach clearly – you’ve'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='preparation. For coding, keep practicing problems daily up to the interview day. In ML design\\nrounds, use a structured approach (clarify requirements, explain your approach clearly – you’ve\\npracticed by explaining on YouTube, so use those skills). In behavioral rounds, tell the story of this\\nself-driven journey – it demonstrates passion, perseverance, and ability to learn fast, all highly\\nvalued. Be ready with examples of projects: e.g., “Tell me about a challenging problem you solved” –\\nyou can cite debugging your agent’s hallucinations or managing without a GPU by optimizing code,\\netc. Emphasize how you independently initiated and completed a complex roadmap – that’s akin to\\nbeing a self-driven employee. \\nOpen-Source Contribution: This is a good time to contribute to an open-source project related to\\nyour specialization (if you haven’t yet). For example, contribute a small fix or documentation update'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Open-Source Contribution: This is a good time to contribute to an open-source project related to\\nyour specialization (if you haven’t yet). For example, contribute a small fix or documentation update\\nto LangChain or Hugging Face Transformers. It signals to employers that you engage with the\\ncommunity and understand collaborative workflows. It could be as simple as improving an example\\nin LangChain’s docs or fixing a minor bug you encountered. Mention this in interviews (“I even\\ncontributed a bugfix to LangChain that got merged”) – it’s impressive. \\nContinued Learning: The field of AI moves rapidly. Identify a few key sources to stay updated: e.g., \\nDeepLearning.AI’s “The Batch” newsletter for weekly AI news, the r/MachineLearning subreddit\\nfor latest research highlights, and YouTube channels like Yannic Kilcher or Two Minute Papers for\\nresearch summaries. This habit will help you in interviews if asked about recent developments (“Have'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='for latest research highlights, and YouTube channels like Yannic Kilcher or Two Minute Papers for\\nresearch summaries. This habit will help you in interviews if asked about recent developments (“Have\\nyou heard about GPT-4’s new vision capabilities?” – you can give an informed opinion). It will also\\nserve you well on the job. \\nFreelance/SaaS angle: If by end of the year you decide to build an AI SaaS product (another stated\\ngoal), you now have the skills. This month, you could draft a business plan for a tool you built. For\\nexample, maybe your capstone agent can be turned into a SaaS for researchers or students.\\nConsider if you want to pursue that: even if you take a job, this could be a side project or a startup\\nattempt. Evaluate the market, get feedback from potential users (this itself could be a learning\\nproject – building the product mindset). \\n• \\n• \\n• \\n• \\n• \\n17'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Reflect and Plan Ahead: Take time to reflect on how far you’ve come. Identify what you loved most –\\nwas it building end-to-end projects, was it the research aspect of trying new techniques, or making\\ncontent? This can guide your next steps. If working at a big company, you’ll continue learning on the\\njob. If freelancing, you might pick a niche (LLM apps for finance, for example). If doing a startup,\\nyour learning shifts to business. In any case, set aside a little time to update your knowledge: maybe\\nplan to tackle a new advanced topic next (like reinforcement learning or AI for robotics) as a\\ncontinued growth goal. \\nCelebrate: Don’t forget to acknowledge your achievements. Completing such an intensive roadmap\\nis rare and employers will recognize the caliber of effort. Perhaps make a final YouTube video or blog\\npost wrapping up the journey and announcing your next step (whether you got a job or launching'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='is rare and employers will recognize the caliber of effort. Perhaps make a final YouTube video or blog\\npost wrapping up the journey and announcing your next step (whether you got a job or launching\\nsomething). It not only gives closure to your audience but also to you. It can mark the transition\\nfrom “learner” to professional AI Engineer. \\nYouTube/Community: In this month, your YouTube channel might start paying off: with a body of\\ncontent, you could see increased engagement. Engage with your commenters, maybe do a Q&A\\nabout “How I would learn AI in 2026” or similar – this reinforces your own knowledge and establishes\\nyou as part of the community. Being active in the community can lead to job offers or freelance gigs\\nunexpectedly (people might reach out seeing your content). \\nSpaced Repetition: Keep your flashcards routine alive lightly to stay sharp, but also realize that by\\nnow repetition is happening via real-life usage (interviews, projects). Use your spaced repetition'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='now repetition is happening via real-life usage (interviews, projects). Use your spaced repetition\\nmore for maintaining interview readiness until you land an offer . Also, use it for any new on-the-job\\nlearning that might occur if you started working. Essentially, the habit you built will continue to serve\\nyou in your career for continuous learning.\\nConclusion: By following this 12-month roadmap, Yash will have transformed from a student with basic\\nknowledge into a well-rounded AI Engineer capable of building production-grade AI systems. He will have\\na rich portfolio of projects (from simple models to an AutoGPT-like agent), hands-on experience with\\nstate-of-the-art tools (Hugging Face, LangChain, vector DBs, etc.), and a personal brand via his YouTube\\nchannel.  This  journey  emphasizes  active  learning  through  projects  and  consistent  review,  which  keeps\\nmotivation high and knowledge retained.'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='channel.  This  journey  emphasizes  active  learning  through  projects  and  consistent  review,  which  keeps\\nmotivation high and knowledge retained. \\nBy focusing on Agentic AI in the latter half, Yash is entering one of the most cutting-edge areas of AI in\\n2025,  positioning  himself  strongly  for  roles  in  AI  startups  or  innovative  teams  at  big  tech.  The\\ncombination  of  foundational  understanding  and  practical  building  experience  means  he  can  not  only\\ndesign solutions but also implement and deploy them – exactly what companies seek in a “production-\\nready” AI engineer. \\nFinally,  the  roadmap’s  emphasis  on  sharing  (GitHub,  YouTube,  blog)  ensures  Yash  gets  feedback  and\\nrecognition for his work, minimizing the risk of losing momentum. Each project built is not an end, but a\\nstepping stone to the next, creating a virtuous cycle of learning. With this approach, by the end of the year'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='stepping stone to the next, creating a virtuous cycle of learning. With this approach, by the end of the year\\nYash will be well-prepared to land a top-tier job or freelance contracts and even have the foundation to\\nlaunch his own AI-powered tools, fulfilling all the goals set out at the start.\\nSources: The roadmap recommendations are informed by industry-aligned curricula and expert insights.\\nFor example, the breakdown of foundational topics and portfolio building follows suggestions from an AI\\nDeveloper  roadmap .  Emphasis  on  LangChain,  LLMs,  and  vector  databases  reflects  current  best\\npractices for building AI agents. The strategy to “learn then build” iteratively is echoed by practitioners\\n• \\n• \\n• \\n• \\n36\\n36\\n35\\n37 38\\n36\\n18'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='on Reddit , who advise swiftly applying new skills to projects (like using LangChain with a dataset).\\nHugging Face’s course is highlighted as a best-in-class resource for mastering transformers, and short\\ncourses by DeepLearning.AI are recommended to quickly pick up prompt engineering and LangChain from\\nthe  experts .  Additionally,  tips  for  agent  design  (e.g.,  limiting  each  LLM  call  to  a  single  task,\\noptimizing  for  cost)  are  drawn  from  experienced  AI  engineers’  lessons.  By  following  this  guided\\napproach,  Yash  can  be  confident  that  he’s  learning  the  most  relevant  skills with  the  most  effective\\nmethods, as validated by the AI community and industry leaders. Good luck, and happy learning!\\nAI Developer Roadmap (2025 Edition) | by CodePicker\\n| Medium\\nhttps://medium.com/@codepicker57/ai-developer-roadmap-2025-edition-e04dddd2ed3a\\nIntroduction - Hugging Face LLM Course\\nhttps://huggingface.co/learn/llm-course/en/chapter1/1\\nNeural Networks: Zero To Hero'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='Introduction - Hugging Face LLM Course\\nhttps://huggingface.co/learn/llm-course/en/chapter1/1\\nNeural Networks: Zero To Hero\\nhttps://karpathy.ai/zero-to-hero.html\\nRoadmap to Becoming an AI Engineer in 8 to 12 Months (From Scratch). : r/learnmachinelearning\\nhttps://www.reddit.com/r/learnmachinelearning/comments/1g6d4cz/roadmap_to_becoming_an_ai_engineer_in_8_to_12/\\nBuild an Agent |  LangChain\\nhttps://python.langchain.com/docs/tutorials/agents/\\nChatGPT Prompt Engineering for Developers - DeepLearning.AI\\nhttps://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\\nLangChain for LLM Application Development - DeepLearning.AI\\nhttps://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/\\nAI Agent best practices from one year as AI Engineer : r/AI_Agents\\nhttps://www.reddit.com/r/AI_Agents/comments/1lpj771/ai_agent_best_practices_from_one_year_as_ai/\\nBuilding LLM applications for production\\nhttps://huyenchip.com/2023/04/11/llm-engineering.html\\n39\\n12'),\n",
       " Document(metadata={'producer': 'WeasyPrint 65.1', 'creator': 'ChatGPT', 'creationdate': '', 'title': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization)', 'author': 'ChatGPT Deep Research', 'source': '..\\\\data\\\\pdf\\\\12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'source_file': '12-Month Roadmap to Become a Production-Ready AI Engineer (Agentic AI Specialization).pdf', 'file_type': 'pdf'}, page_content='https://www.reddit.com/r/AI_Agents/comments/1lpj771/ai_agent_best_practices_from_one_year_as_ai/\\nBuilding LLM applications for production\\nhttps://huyenchip.com/2023/04/11/llm-engineering.html\\n39\\n12\\n20 21\\n25\\n1 2 3 4 5 9 10 11 14 16 17 18 36 37 38\\n6 12\\n7 8 13\\n15 39\\n19 28 29\\n20\\n21 22\\n23 24 25 26 27 30 31 32\\n33 34 35\\n19'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 0, 'page_label': '1', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='1 \\n \\nNews Values - Revised \\nTheodora Ivancheva \\n \\n \\n \\nIntroduction. The notion of what makes events become news has been an object of \\nconsiderable research among academics and practitioners of various backgrounds: \\nsociologists, linguists, psychologists, practicing journalists and anthropologists. The theory of \\nnews values was initially pioneered by the Norwegian scholars Johan Galtung and Mari \\nHomboe Ruge. It comprises twelve criteria that the authors claim serve as definition of \\nnewsworthiness. Since its emergence, the news values set of criteria has given rise to many a \\nhot discussions among academics and professionals. \\nThe present artice presents a succinct overview of the existing theory of news values. Apart \\nfrom the seminal work of Galtung and Juge, the conclusions of authors auch as Hardcup and \\nO’Neill, MacShane and Brighton and Foy are discussed. \\n \\nWhat is news?  In the times of globalization we are constantly exposed to messages that claim'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 0, 'page_label': '1', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='O’Neill, MacShane and Brighton and Foy are discussed. \\n \\nWhat is news?  In the times of globalization we are constantly exposed to messages that claim \\nto present us with news of any kind, source and topic. Apart from the traditional news \\nprogrammes streaming through diversified television channels and the countless number of \\nnewspapers on news stalls, our mail boxes are periodically, if not daily, filled with \\nnewsletters, updates, the latest news concerning a topic of our interest/subscription or simply \\na wayward message that promises to contain news, purely as spam.  In other words, the \\nlexical item “news” has numerous connotations depending on the context in which it appears. \\nFor instance, the utterance “Have you heard the latest news?” is open to multiple \\ninterpretations: \\n1.  two people discussing the latest breaking news on TV, national or local \\nnewspapers, or; \\n2.  the development of a news story that hit news reports some time ago;'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 0, 'page_label': '1', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='interpretations: \\n1.  two people discussing the latest breaking news on TV, national or local \\nnewspapers, or; \\n2.  the development of a news story that hit news reports some time ago; \\n3.  the latest findings concerning some scientific research;   \\n4.  two colleagues talking about the latest changes in their working place or a \\ncorporate gossip; \\n5.  spouses chatting about family issues; \\nbrought to you by COREView metadata, citation and similar papers at core.ac.uk\\nprovided by New Bulgarian University Scholar Electronic Repository'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 1, 'page_label': '2', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='2 \\n \\n6.  teenagers gossiping about a friend’s new relationship; \\n7.  elderly ladies commenting the development of the main characters’ life stories of \\ntheir favourite soap opera; \\n8.  the key question of a TV commercial where friends are sharing information about \\nthe irresistibly low interest rates of a bank. \\nThese are just a few possible interpretations and they invariably depend on the writer’s \\nawareness and experience of various contexts as well as cultural identity.  \\nIn further words, the answer to the question “What is news?” may seem more that obvious. \\nNews is everything that is new that is happening. The dictionary of Merriam Webster offers \\nthe following definitions: \\n1.  a : a report of recent events \\nb : previously unknown information  \\nc : something having a specified influence or effect  \\n2.  a : material reported in a newspaper or news periodical or on a newscast \\nb : matter that is newsworthy (see: http://www.merriam-webster.com/dictionary/news )'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 1, 'page_label': '2', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='2.  a : material reported in a newspaper or news periodical or on a newscast \\nb : matter that is newsworthy (see: http://www.merriam-webster.com/dictionary/news ) \\nThe British National Corpus (BNC) http://www.natcorp.ox.ac.uk/  enables a quick check \\nof the different contexts in which the word item “news” appears. The contexts are a collection \\nof over 100 million, wide-range written and spoken language sources, designed to represent \\nthe later part of the 20 th  century, referring both to written and spoken British English, which is \\nof paramount importance for the purposes of the present research as the examples are entirely \\nexcerpted from British online or printed newspapers.  It is also worth noting that each \\nindividual search offers 50 random solutions, i.e the solutions quoted below may differ from \\nany consecutive trial. Furthermore, the initials at the beginning of each item indicate the'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 1, 'page_label': '2', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='individual search offers 50 random solutions, i.e the solutions quoted below may differ from \\nany consecutive trial. Furthermore, the initials at the beginning of each item indicate the \\nsource reference, given here in parenthesis right after the excerpted item to ascertain the \\nreader-friendly nature of the example (see Appendix). \\nThe tables below are a summarized version of the number of general occurrances of \\nthe word “news” in different written and oral contexts. It is worth noting that these are not the \\ntotal number of utterances, which by far outnumber the number of contextual occurrences. A \\nmore detailed study of the use of the item “news” would benefit tremendously of the overall \\nfigure of utterances to exapmlify its broad usage and various semantic fields.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 2, 'page_label': '3', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='3 \\n \\nsource  \\n          \\nOnline \\nnewspaper \\nPrinted \\nnewspaper \\nFiction \\nBook \\nSpecialized \\nliterature \\nother \\noccurrances  6 6 8 7 8 \\nTable 1.  \\nTable 1  illustrates the usage of the word “news” in written corpora. The ratio between newspapers and \\nother written materials is in favour of newspapers – 12 occurrences in printed and online newspapers \\nversus 8 in fiction literature, 7 in specialized literature, and 8 in other types of printed materials like \\nnewsletters or catalogues (see Table 1).  \\nsource \\n  \\n          \\nTV Programme Radio Programme Business Meeting  \\noccurrences  1 2 2 \\nTable 2.  \\nTable 2  shows the appearance of the lexical item “news” in corpora of oral performance. The \\nratio is almost equal - two times in radio programmes and business meetings each compared \\nto just one occurrence in a television programme (see Table 2).  \\nOn balance, the lexical item news has broad applications in terms of language contexts both'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 2, 'page_label': '3', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='to just one occurrence in a television programme (see Table 2).  \\nOn balance, the lexical item news has broad applications in terms of language contexts both \\nwritten and oral. Its polysemy requires plausible limitations for the purposes of the present \\nwork. What we assume as news here is closer to what Merriam Webster’s Dictionary \\nsuggests, i.e a report of recent events and material reported in a newspaper or news periodical \\nor on a newscast  (see: http://www.merriam-webster.com/dictionary/news ). \\nAs the influx of news in our lives is uncontrollable and, thus hard to observe, we will focus \\nour attention on what is reported in media, that is to say what makes events or happenings \\nbecome news items, bearing in mind that new things happen all the time everywhere in the \\nworld and they never find their way into newspapers or onto the air in a newscast. \\nFurthermore, as the number of printed and electronic media is vast, the encuing examples'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 2, 'page_label': '3', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='world and they never find their way into newspapers or onto the air in a newscast. \\nFurthermore, as the number of printed and electronic media is vast, the encuing examples \\nhave been excerpted from the printed or electronic versions of newspapers.  \\nWhat makes a story newsworthy enough to be published or broadcast? It is news values that \\ngive journalists and editors a set of rules by which to work, plan and execute the content of a \\npublication or a broadcast. The types of media are varied. A newspaper is a publication that is \\nissued daily, weekly, bidaily, or bimonthly, and includes local and international news stories, \\nadvertisements, announcements, opinions, cartoons, sports news, television listings,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 3, 'page_label': '4', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='4 \\n \\nclassifieds and other sections. It is an important method of letting the public knows everything \\nthat is happening around the world and in their local area. Even with the advancements in \\ncomputer technology, newspapers continue to be an important aspect of everyday life.  \\nNot only are there a vast number of media types available but there are various types \\nof printed newspaper on offer as well. Newspapers generally are divided into three categories: \\nbroadsheets, the Berliner format, and tabloids. Broadsheets are believed to present high-\\nquality journalism; however, they are unsuited to reading in public transport that is why \\nseveral years ago a more manageable format was adopted, as people have no other time to \\nread newspapers but on their way to work. Thus, the newspaper format can hardly serve as a \\ncritical quality factor of the printed media of today.  The Berliner format is a blending'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 3, 'page_label': '4', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='read newspapers but on their way to work. Thus, the newspaper format can hardly serve as a \\ncritical quality factor of the printed media of today.  The Berliner format is a blending \\nbetween broadsheets and tabloids. Some broadsheet newspapers in Britain have looked to the \\nBerliner format as a portable-size format, without the typically applied negative connotations \\nto tabloids. For example, the Guardian adopted the Berliner format in 2005 right after \\ncompeting broadsheet newspapers had switched to the tabloid format. Tabloids are the \\nsmallest newspapers in terms of format as well as the least reputed ones due to their tendency \\nto present rumors, gossips, and sensational news about celebrities. The Times  was printed in \\nbroadsheet format for 219 years but since 2004 it has switched to a tabloid format, both to \\nease its readers with its user-friendly size and to appeal to a much younger audience. Almost'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 3, 'page_label': '4', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='broadsheet format for 219 years but since 2004 it has switched to a tabloid format, both to \\nease its readers with its user-friendly size and to appeal to a much younger audience. Almost \\nall Bulgarian dailies share the tabloid format and have never had a broadsheet one but the \\ndaily Dnevnik which, when initially published, was the only broadsheet daily on the market. \\nThe other broadsheet in the country is the weekly – Kapital  that carters for the public’s need \\nof political, economic and cultural analyses as well as the demand to offer and search for job \\nvacancies in the high, more sophisticated job market niche. Kapital  still shares the broadsheet \\nformat, which is inkeeping with its content and target audience. The weekly is dedicated \\nprimarily to business analyses and its audience comprises highly educated economists, CEOs \\nand the business community in Bulgaria in general.  \\nTechnological advances have allowed printed newspapers to address audiences of'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 3, 'page_label': '4', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='and the business community in Bulgaria in general.  \\nTechnological advances have allowed printed newspapers to address audiences of \\ndifferent reading habits, those who traditionally prefer to buy and read the printed copy of \\ntheir preffered paper, as well as those who are keener on making use of technologies and, \\nrespectively visit the online version of the paper(s), or users of e-book readers who can simply \\ndownload their favoured newspaper, magazine or e-book.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 4, 'page_label': '5', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='5 \\n \\nWhat is the role of the journalist?  For a layperson, the answer to this question may reach as \\nfar as to simply saying “to report or present news” or “to write articles.” However, the reality \\nis much more complex and is worth reviewing. Strange as it may seem, the features of printed \\nand electronic media are so strikingly diversified that they result in many “journalisms.” That \\ndiversity naturally differs from country to country; however, there are numerous similarities \\nthat unify journalism as a whole. With the rapid development and improvement of \\ntechnologies, every personal computer owner is enabled to disseminate information, \\nsometimes, even much wider than the official news organizations. However well organized a \\nwebsite may seem it may not necessarily offer reliable, trustworthy news. Additionally, news \\nis not a scarce commodity any more and, thus the role of the journalist has become more'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 4, 'page_label': '5', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='website may seem it may not necessarily offer reliable, trustworthy news. Additionally, news \\nis not a scarce commodity any more and, thus the role of the journalist has become more \\nimportant that it has ever been before. News items, whether breaking news, features or even \\nanalyses have to be accurate. For the purpose journalist, unlike gossipers and proponents, \\ncollect the information they need to present a story and verify its validity. Objectivity is \\nanother concern with the profession. Journalists are reasoning, thinking human beings and it \\nwould be naïve to think that what is published does not contain personal opinion. Potter states \\nthat ” By using an objective, scientific method for verifying information, journalists can report \\nstories that do not reflect their own personal views. The story itself, in other words, should be \\nimpartial and fair.” (Potter 2006:11). While opinion reflects on personal thoughts,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 4, 'page_label': '5', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='stories that do not reflect their own personal views. The story itself, in other words, should be \\nimpartial and fair.” (Potter 2006:11). While opinion reflects on personal thoughts, \\nunderstanding and believes, fairness refers to the different angles a story is presented. At the \\ntime of which the present work is being written the British jazz and soul singer Amy \\nWinehouse has been found dead in her apartment in Camden, North Lonon. Let us take, for \\ninstance, the news presentation of this news account in the Telegraph online \\n(http://www.telegraph.co.uk/ ). Five days after the news hit the headlines, the Telegraph \\ncontains an influx of items on the topic. The event is presented from several different angles. \\nFirst, it is explicable that the newspaper does not contain breking-news headlines. i.e large \\ntexts in huge fonts, as that is the fifth day after the dead of the celebrity; the event is not'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 4, 'page_label': '5', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='First, it is explicable that the newspaper does not contain breking-news headlines. i.e large \\ntexts in huge fonts, as that is the fifth day after the dead of the celebrity; the event is not \\ntreated as hard news any more, still it forms prolific follow-ups. However, the Telegraph \\nacknowledges the event in the Obituary section with a detailed bibliographical article, \\npresenting the chronological events and artistical achievements of the life of the renowned, \\nand at the same time notorious, singer. Confiremed fans are offered to watch and listen to \\nsummarized famous videos of the most popular hit tracks together with the official \\nannouncement of the discovery of the deceased read in public by a superintendant. The tone \\nof the announcemet is neutral at the start; however, it finishes with the police, as institution, \\nexpressing deep regrets and sorrow following the tragic news. The section Culture presents a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 5, 'page_label': '6', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"6 \\n \\nfull-length interview with Amy Winehouse that is claimed to be the last ever, conducted by \\nNeil McCormick, who has been the most prominent music critic for the The Telegraph since \\n1996. Concomitant events are featured, albeit short in time and span, related to the funeral \\nceremony of the singer. Here are the headlines directly copied and pasted from the online \\nTelegraph; the size of font and typeface are the original ones. If the selection of typeface and \\nfont size bring about the level of importance of news stories and events being projected on a \\nnewspapers page then the full story of the death of the British jazz and soul singer are given \\nequal prominence (see Hodson 1984:100; Ivancheva 2005:261).  \\n1.Amy Winehouse: police continue investigation into \\nmusician's death \\n2.Amy Winehouse: the final interview by Neil McCormick  \\n 3.Amy Winehouse's last public appearance \\n4. Amy Winehouse 'drunk' on stage in Belgrade \\n5. Amy Winehouse's parents visit singer's Camden home\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 5, 'page_label': '6', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"3.Amy Winehouse's last public appearance \\n4. Amy Winehouse 'drunk' on stage in Belgrade \\n5. Amy Winehouse's parents visit singer's Camden home \\n6. Amy Winehouse 'looked fine' day before death \\n7. Former collaborator Mark Ronson arrives for Amy \\nWinehouse memorial \\nThe representation of the story of Winehouse is an illustrative example of what fair \\njournalism should be, i.e “…to report all significant viewpoints in a way that is fair to those \\ninvolved and that also presents a complete and honest picture to the audience.”(  Potter  \\n2006:16).  \\nTo sum up, contemporary journalists are to perform challanging, complicated multitasking. In \\ntheir pursuit for independence from the people or organizations they write about, journalists \\nstruggle to strike a balance between an objective, fair representation deprived of explicit \\npersonal opinion. They search contrasting views and report them without taking one side or\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 5, 'page_label': '6', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='struggle to strike a balance between an objective, fair representation deprived of explicit \\npersonal opinion. They search contrasting views and report them without taking one side or \\nanother. Journalists do original reporting being able to differentiate between fact, opinion, and \\nrumour.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 6, 'page_label': '7', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='7 \\n \\nWhat is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \\nsociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \\nstudies. Stuart Hall states that:  \\nThe media do not simply and transparently  report events which are \\nnaturally newsworthy in themselves. News is the end product of a \\ncomplex process, which begins with systematic sorting and selecting \\nof events and topics according to a socially constructed set of \\ncategories.  \\n       Stuart Hall ( in Fowler1991:12) \\n  Philo goes on even further to maintain that news is not found or even gathered. It is a \\ncreation of a journalistic process, an artefact, and a commodity ( in Fowler 1991). The last \\nstatement, as discussed above, is hardly applicable in the contemporary era of mass \\ncommunication, where, with the existence of the internet, everybody can have access to \\npractically any nugget of information. Brighton and Foy are of the opinion that:'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 6, 'page_label': '7', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='communication, where, with the existence of the internet, everybody can have access to \\npractically any nugget of information. Brighton and Foy are of the opinion that: \\nIt is news values that give journalists and editors a set of rules – often \\nintangible, informal, almost unconscious elements – by which to work, \\nfrom which to plan and execute the content of a publication or a broadcast. \\nIn its purest sense everything that happens in the world is a new event, and \\nsomebody, somewhere, will have some level of interest in that occurrence. \\nBut what takes it from being new to being news? The set of values applied \\nby different media – local, regional, national and international, print, \\ntelevision, radio, internet, bulleting board – are as varied as the media \\nthemselves.  \\n    Brighton and Foy (2007:1) \\n A classical definition of what constitutes news values was developed by two Norwegian \\nsocial scientists Johan Galtung and Mari Homboe Ruge and officially published back in \\n1965.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 6, 'page_label': '7', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='A classical definition of what constitutes news values was developed by two Norwegian \\nsocial scientists Johan Galtung and Mari Homboe Ruge and officially published back in \\n1965.  \\n  The list of criteria is as follows (in Fowler 1991:13): \\n/head2right Frequency.  An event is more likely to be reported if its duration is close to the \\npublication frequency of the news medium. Because newspapers are published once a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 7, 'page_label': '8', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='8 \\n \\nday, a single event is more likely to be reported rather than a long process one. For \\ninstance, the publication of unemployment figures on a certain day is more \\nnewsworthy than the long-term phenomenon of unemployment itself. \\n/head2right Threshold.  Refers to the ‘size’ needed for an event to become newsworthy. For \\nexample, an accident involving  a hundred people is more likely to be published than \\none involving two or three people. \\n/head2right Unambiguity .  Mysterious events as well as clear ones are newsworthy if they can be \\nrelated to cultural stereotypes, where a stereotype is a socially-constructed mental \\npigeon-hole into which events and individuals can be sorted, thereby making such \\nevents and individuals comprehensible. \\n/head2right Meaningfulness  (with its two subcategories Cultural proximity and Relevance).  \\nRefers to a preoccupation with countries, societies and individuals perceived to be \\nlike oneself.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 7, 'page_label': '8', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='/head2right Meaningfulness  (with its two subcategories Cultural proximity and Relevance).  \\nRefers to a preoccupation with countries, societies and individuals perceived to be \\nlike oneself.  \\n/square4 Cultural proximity.  Relates to geographical closeness of a country. \\nCultural proximity is founded on an ideology of ethnocentrism: a \\npreoccupation with countries, societies and individuals perceived to \\nbe like oneself  (Fowler 1991). \\n/square4 Relevance. If Culture1 and Culture2 i1 are geographically far away but \\nin Culture1 it is likely to happen the same type of event, so Culture1 is \\naffected in the same way as Culture2. \\n/head2right Consonance  with its two sub criteria predictability  and demand  refer to categories of \\nevents which people either expect to happen or want to happen, e.g. Royal weddings \\nand births. \\n/head2right Unexpectedness .  An event is even more newsworthy if it happens without warning or \\nis unusual.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 7, 'page_label': '8', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='and births. \\n/head2right Unexpectedness .  An event is even more newsworthy if it happens without warning or \\nis unusual. \\n/head2right Continuity.  Once an event is defined as news, it will continue to be news even though \\nits amplitude may be less. Moreover, even ‘non-events’ which are part of the story will \\nbe covered. \\n/head2right  Composition . Refers to the balance of a paper bulletin, that is, an item will be more or \\nless newsworthy depending on what else is available for inclusion. \\n/head2right Reference to elite nations. Encodes a ‘superpowers’ ideology of the dominating status \\nof North America, Japan, Europe and Russia in world political and cultural affairs. \\n                                                             \\n1 Where Culture1 is the culture of the recipient of the information and Culture2 is the culture of the target \\ncountry.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 8, 'page_label': '9', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"9 \\n \\n/head2right Reference to elite people. Refers to media's infatuation of celebrities, e.g. Bill Clinton, \\nUS President between 1993 – 2001 more popular among ordinary people with the \\nLewinski Scandal. \\n/head2right Reference to persons (Personalisation). Whenever possible events are seen as the \\nactions of people as individuals. Personalisation varies from paper to paper being most \\nstriking in the popular press. \\n/head2right Reference to something negative.   It suggests that news take the normal for granted, \\nand so is driven to make stories out of deviant: crime, dissidence, disaster. As Fowler \\n(1991) points out, negativity is a value rather than anything more natural: there is no \\nnatural reason why disasters should be more newsworthy than triumphs.  \\nThe set of criteria can also be summarized under the following unifying headings: \\n1.  Impact : frequency, unambiguity, threshold, negativity, unexpectedness\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 8, 'page_label': '9', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='The set of criteria can also be summarized under the following unifying headings: \\n1.  Impact : frequency, unambiguity, threshold, negativity, unexpectedness \\n2.  Audience identification : personalization, meaningfulness, reference to elite nation, \\nreference to elite persons. \\n3.  Pragmatics of media coverage : consonance, continuity, composition \\n \\nJohan Galtung and Mari Ruge’s seminal work on the taxonomy of news values that make an \\nevent become news, or that serves as criteria for selection prior to publication, has been the \\ncore of a great amount of encuing scientific research elaborating on the issue of \\nnewsworthiness.  Several attempts to revise the list of criteria have been made since the \\noriginal publication appeared in the 1965 edition of the Journal of International Peace \\nStudies , entitled Structuring and Selecting News . For example, Denis MacShane 2 (quoted in \\nBrighton and Foy 2007: 8) suggested later in 1979 a new subdivision of newsworthy events'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 8, 'page_label': '9', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='Studies , entitled Structuring and Selecting News . For example, Denis MacShane 2 (quoted in \\nBrighton and Foy 2007: 8) suggested later in 1979 a new subdivision of newsworthy events \\ninto several categoris such as: \\n/head2right Conflict \\n/head2right Hardship and danger to the community \\n/head2right Unusualness (oddity, novelty) \\n/head2right Scandal \\n/head2right Individualism \\n                                                             \\n2 Denis MacShane  is a British politician, who has been theMember of Parliament (MP) for Rotherham since \\nthe 1994 by-election and served as the Minister for Europe from 2002 until 2005. From 1969 to 1977 he worked \\nas a newsreader and reported for  BBC Radio Birmingham. (http://en.wikipedia.org/wiki/Denis_MacShane )'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 9, 'page_label': '10', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='10 \\n \\nMost of the above have more to do with impact like conflict, scandal unusualness, hardship \\nand danger to community; individualism falls into the category of audience identification. \\nWhat MacShane fails to isolate as a criterion is the pragmatic news value of stories in a news \\norganization diary that bring about the balance of any meadia in question.  \\nHardcup and O’Neill argue that Galtung and Ruge’s taxonomy possesses certain problematic \\nareas and, thus the authors pose the following questions: \\n/head2right Frequency . How does this relate to stories that are not about events at all, but about \\ntrends, speculation, or even the absence of events? \\n/head2right Threshold. Isn’t this still open to subjective interpretation? Which is bigger – 20 \\ndeaths in ten road accidents or five deaths in one rail crash? \\n/head2right Unambiguity.  Is the ambiguity in the subject or the journalist’s interpretation?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 9, 'page_label': '10', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='deaths in ten road accidents or five deaths in one rail crash? \\n/head2right Unambiguity.  Is the ambiguity in the subject or the journalist’s interpretation? \\n/head2right Meaningfulness.  This is a slippery concept that changes over time and relies on \\nsubjective interpretation. \\n/head2right Unexpectedness.  How can we tell if the journalist is simply taking an unexpected \\nangle on a predictable event? \\n/head2right Consonance . How useful is this category if it is possible only to guess if and when it \\nhas applied? \\n/head2right Composition . How is it possible to know what was in the selector’s mind when \\nmaking a particular decision? \\n/head2right Elite Nations . The dearth of foreign news in UK tabloids newspapers renders this \\nrelatively infrequently identified factors; does that mean it does not apply? \\n/head2right Elite People . How useful is a category that does not distinguish between the Spice \\nGirls and the President of the USA?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 9, 'page_label': '10', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='/head2right Elite People . How useful is a category that does not distinguish between the Spice \\nGirls and the President of the USA? \\n/head2right Reference to persons . Is this intrinsic to the subject or the journalist’s technique? \\n/head2right Reference to something negative . Negative for whom? Bad news for some might be \\ngood news for others.  \\n   Hardcup and O’Neill, 2001 (in Othman and Tiung 2009 )\\n     \\nAs a result of their study Hardcup and O’Neill (in Brighton and Foy  2007: 8) present their list \\nof criteria.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 10, 'page_label': '11', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='11 \\n \\n/head2right Power elite - powerful individuals, polititians, tycoons, organisations or institutions \\n(e.g Boiko Borisov PM of Bulgaria, Donald Trump, Robert Kiyosaki, etc.); \\n/head2right Celebrity  - people who are already famous or notorious; \\n/head2right Entertainment -  sex, gay couples,  music, theatre, stories of human interest, romantic \\ndrama, intriguing photographs, etc.;   \\n/head2right Surprise  – surprising events, both positive or negative in content; \\n/head2right Bad news – conflicts, tragedies – events with overall negative connotations; \\n/head2right Good news  – rescues, cures, survivals – events with overall positive connotations; \\n/head2right Magnitude  – events whose number of people involved is of paramount importance ,or \\nwhose impact concerns a grat number of people; \\n/head2right Relevance  - events that concern specific groups of people and/or whole nations \\nrelevant to the readership;'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 10, 'page_label': '11', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='whose impact concerns a grat number of people; \\n/head2right Relevance  - events that concern specific groups of people and/or whole nations \\nrelevant to the readership; \\n/head2right Follow-ups  – news items that have already been in the news and continue to develop; \\n/head2right Media agenda  - stories that set or fit the news organisation’s own agenda. \\nHardcup and O’Neill’s classification of news values fall in three major summarized areas. \\nThe first is related to the protagonists within a strory, i.e powr elite, celebrities; the second has \\na conceptual essence, for instance – relevance. The third comprises the notion of media \\npractices – follow-ups, media agenda. \\nJohan Galtung and Mari Homboe Ruge Hardcup and O’Neill \\nFrequency  \\nThreshold Magnitude \\nUnambiguity  \\nMeaningfulness Relevance \\nConsonance  predictability demand  Entertainment \\nUnexpectedness Surprise \\nContinuity Follow-ups \\nComposition Media agenda \\nReference to elite nations  \\nReference to elite people Celebrity'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 10, 'page_label': '11', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='Consonance  predictability demand  Entertainment \\nUnexpectedness Surprise \\nContinuity Follow-ups \\nComposition Media agenda \\nReference to elite nations  \\nReference to elite people Celebrity \\nPersonalisation  \\n Power elite \\nReference to something negative  Bad news, Good news  \\nTable 3'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 11, 'page_label': '12', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='12 \\n \\nMoreover, a brief comparison of the two pairs of scholars’ research reveals a predominant \\noverlap of the news values criteria (see Table 3). Hardcup and O’Neill’s idea of “size” of an \\nevent, termed magnitude, is nothing different from Galtun and Ruge’s threshold. \\nMeaningfulness and relevance both refer to the notion of the acceptance and self-\\nidentification of a culture “preoccupied with countries, societies and individuals perceived to \\nbe like oneself,” as Fowler words it (Fowler 1991). Some might argue that a culture can be a \\nconstruct of many subcultures, which virtually is true, and one event may not be equally \\nrelevant to the whole multitude of cultures; however, that argument, to my mind, reflects on \\nthe type of media and its readership profile’s interest. Consonance and entertainment also \\nhave similar connotations. If consonance refers to peoples’ expectations or need something to'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 11, 'page_label': '12', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='the type of media and its readership profile’s interest. Consonance and entertainment also \\nhave similar connotations. If consonance refers to peoples’ expectations or need something to \\nhappen, then all types of events like, gay weddings, personal drama, organized events \\n(theathre, music concerts, etc) cater for peoples’ demand to satisfy their curiosity, need for \\nrelaxation and quench their thirst for human-interest information. Continuity and follow-ups \\nreflect the tendency for some event to fail to drop news bulletins, having already been in the \\nnews. These events are predominantly of negative nature, such as murders, natural disasters, \\nepidemics; rarely are there follow-ups of good news unless the protagonists are of royal origin \\nor non-royal one, which is the case of the marriage between the British Prince William and \\nCatherine Middelton on 29 th  April, 2011 at Westminster Abbey. As Fowler rightly defines'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 11, 'page_label': '12', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='or non-royal one, which is the case of the marriage between the British Prince William and \\nCatherine Middelton on 29 th  April, 2011 at Westminster Abbey. As Fowler rightly defines \\nsuch negative occurrences in the media as “hysteria in the Press,” especially in the printed (as \\nwell as online, it must be noted) press, giving an illustrative example of a roughly three-month \\ncontinuity of salmonella panic among the British (between late November, 1988 and early \\nMarch, 1989) (Fowler 1991: 148). Composition and media agenda imply technical media \\npractices referring to the choice of media what else is available to include on a specific day. \\nSuch choices could be also dependent on hard news as prominence is heavily dependent on \\njuxtaposed news items, especially in the printed press (see Ivancheva 2005). Reference to elite \\npeople compares to Hardcup and O’Neill’s celebrity where both teams of researchers refer to'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 11, 'page_label': '12', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='juxtaposed news items, especially in the printed press (see Ivancheva 2005). Reference to elite \\npeople compares to Hardcup and O’Neill’s celebrity where both teams of researchers refer to \\nthe notoriety of already popular people whose public behavior frequently makes newspaper \\nheadlines. Last but not least, most of the concepts of both lists totally coincide or repeat each \\nother; their difference is only a matter of synonymy. \\nStuart Hall (ibid) distinguishes between formal and ideological news values. The \\nformer are: \\n/head2right Linkage  – Has the story got any connection with previous events and \\noccurrences, or does it allow journalists to link it to any of the above?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 12, 'page_label': '13', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='13 \\n \\n/head2right  Recency  – Has the event happened lately and how much worthy is it from the \\npoin of view of the present moment? \\n/head2right Newsworthiness of event/person \\nIn their book, News Values  published in 2007 the two practitioner-academics Paul Brighton \\nand Dennis Foy attempt to present a revisited and more contemporary version of the news \\nvalues theory. The authors discuss newspaper, radio and television practices, as well as the \\ninternet news channels. They suggest seven criteria, which are: \\n/head2right Relevance  – the significance of an item to the viewer, listener, or reader.  \\n/head2right Topicality  – Is it new, current, immediately relevant?  \\n/head2right Composition  – How a news item fits with the other items that surround it. \\n/head2right Expectation  – Does the consumer expect to be told about this?  \\n/head2right Unusualness  – What sets it apart from other events, which are not reported?  \\n/head2right Worth  – Does it justify its appearance in the news?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 12, 'page_label': '13', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='/head2right Unusualness  – What sets it apart from other events, which are not reported?  \\n/head2right Worth  – Does it justify its appearance in the news?  \\n/head2right External influences – Is the content of a news item pure, or has it been \\ncorrupted by pressure from outside, such as a proprietor, an advertiser or \\npolitician?          \\n      (Brighton and Foy  2007:26) \\nThe criterion relevance corresponds to Galtung and Ruge’s term of consonance. Relevance is \\na broad notion and, as the writers claim ‘”…it is this aspect of the news values system that is \\ninstinctively deployed by professional news-gatherers, who will often claim to ‘know the \\naudience’.”(Brighton and Foy 2007). A car crash, let us say, in Durhum, UK, with one \\ncasualty will be of direct interest only to those who reside in Durhum. However, if the \\ncasualty happens to be a Bulgarian, then the car- crash accident will, most probably, become a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 12, 'page_label': '13', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='casualty will be of direct interest only to those who reside in Durhum. However, if the \\ncasualty happens to be a Bulgarian, then the car- crash accident will, most probably, become a \\nleading news item for most dailies and electronic newscasts in Bulgaria.  \\nTopicality has to do with events like anniversaries of historical events as 1 9th  February in \\nBulgaria, which commemorates either the birth or the death of the prominent Bulgarian hero – \\nVassil Levski, who idelogised a revolutionary movement to liberate Bulgaria from Ottoman \\nrule. In such cases, there are planned media agendas at work.  \\nComposition is as old criterion as that of Galtung and Ruge’s publication in 1965, \\ncorresponding to the common market law of demand and supply. A news editor will provide \\ntheir readership with what is felt to be the demand and, will respectively strive to achieve a'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 13, 'page_label': '14', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='14 \\n \\nbalanced presentation of various news items – the supply, also taking into consideration the \\nmarket competition with other media available in the respective country. \\n Anything that is likely to have an impact on the public falls in the category of expectation. A \\ndrug dealer, caught red handed selling dope to the schoolchildren in the local school; a singer \\nthat is alledgedly thought to have had a love affair with a country’s president (e.g. the \\nBulgarian singer Mariana Popova and the President of the Republic of Bulgaria - Georgi \\nParvanov); a local hospital medicals that ridiculously confirm only two final diagnosis of their  \\npatients as the hospital management has just two clinical pathways contracted with the \\nNational Health Insurance Fund; pediatritians that charge underaged patients a consumer tax; \\na bomb scare in the subway of London. All of the above examples are of information that the \\npublic expects to be told about, locally, nationally, or internationally.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 13, 'page_label': '14', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='a bomb scare in the subway of London. All of the above examples are of information that the \\npublic expects to be told about, locally, nationally, or internationally.  \\nAs far as unusualness is concerned, it is clearly exemplified by the popular journalistic quote -\\nwhen a dog bites a man that is not news, because it happens so often. But if a man bites a dog, \\nthat is news. 3 The quote self-sufficiently identifies the nature if such unexpected, sensational, \\nunplanned events and happenings that inevitably become hard news, forming large-point fonts \\nand specially typefaced headlines in the printed media, as well as the breaking news items of \\nnewscasts. It would not be an exaggeration to state that unusual events turn into hard news – \\nthe staple diet of media.  \\nThe criterion worth, to my mind, is similar to Galtung and Ruge’s ideas of threshold with the \\nsubtle difference that Brighton and Foy attribute not only to the “size” of the event, but to the'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 13, 'page_label': '14', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='The criterion worth, to my mind, is similar to Galtung and Ruge’s ideas of threshold with the \\nsubtle difference that Brighton and Foy attribute not only to the “size” of the event, but to the \\ntype of protagonists involved as well; rather its assimilation with the formers’ reference to \\nelite nations or people.  The authors discuss the newsworthy nature of the subjects whether \\nthey are popular at all to have any impact on the public’s interest and lives of people. The \\nscholars, rightly though, go on to discuss the contemporary implication of the lexical item \\n“celebrity,” which refers not only to politically involved persons but also musicians, actors, \\nactresses, and even soap opera stars.  \\nLast but not least, the writers discuss external influences as a criterion with regard to human-\\ninterest factors that might prevent an event from becoming a news item like, for example the'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 13, 'page_label': '14', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='interest factors that might prevent an event from becoming a news item like, for example the \\n                                                             \\n3 The origin of the popular quote is yet controversial. Several hypotheses exist: 1.It is said to have been coined \\nby Alfred Harmsworth, a British newspaper magnate. 2. It is attributed to Charles Anderson Dana (1819 – 1897) \\nan American journalist, author, and government official; or to 3. John B. Bogart (1848–1921),  New York \\nSun  editor. (see http://en.wikipedia.org/wiki/Man_bites_dog_(journalism))'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 14, 'page_label': '15', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='15 \\n \\nowner of a news corporation’s control over what is published/ aired or not ( see Brighton and \\nFoy 2007:164). \\n \\nConclusion.\\n  The theory of what makes events become potential news has been, as \\nsuccincltly discussed, the focus of attention to scholars of different scientific background. \\nJohan Galtung and Mari Homboe Ruge unarguably set the beginning of a critical approach to \\nmedia practices not only of high relevance to those professionally involved, but also to those \\nwho consume media products. The encuing revisions of the original taxonomy have added \\nnew shades of what news values could be at the dawn of the 21 st  centrury. The widespread \\napplication of technology and all available means of mass communication give rise to the \\napplicability of some of the original criteria. When the Norwegian scholars conducted their \\nresearch in 1965 (or, logically prior to the date of the publication of their results), the internet'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 14, 'page_label': '15', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='applicability of some of the original criteria. When the Norwegian scholars conducted their \\nresearch in 1965 (or, logically prior to the date of the publication of their results), the internet \\nwas non-existent. Hence, a criterion as frequency, in their terminology, has taken new \\nconnotations, especially with new practices of printed media to sell yesterday today’s news \\n(most newspapers are on the stalls the night before the date of their publication in Bulgartia). \\nWhat is more, the online versions of printed newspapers, being advantageous of the \\ncapabilities of technological advances, update hard news as frequently as it is felt to be \\nnecessary; and change the so called news in brief (NIB), which is said to be space fillers. \\nGiven that, composition as criterion calls for further research, albeit some authors (Hardcup \\nand O’Neill; Brighton and Foy 2007) attribute it to media agenda. In contrast, MacShane’s'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 14, 'page_label': '15', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='Given that, composition as criterion calls for further research, albeit some authors (Hardcup \\nand O’Neill; Brighton and Foy 2007) attribute it to media agenda. In contrast, MacShane’s \\nfailure to discuss such pragmatic practicalities of media coverage and focus of attention to \\nimpact and audience identification (see above) could be ascribed to his having been a \\npractitioner, rather than a scholar, thus considering such criterion as a taken-for-granted one \\namong professionals. Moreover, it is worth noting that journalists are critical-thinking \\nmembers of a sociocultural environment and, despite their professional ethics to objectively \\npresent news, they still have an opinion on events and happenings. Personal opinion can be \\nencoded in any utterance by means of special usage of the verb system of the target language \\n(e.g Active vs Passive Voice; positive vs negative connotation; modality);syntax (e.g elliptical'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 14, 'page_label': '15', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='encoded in any utterance by means of special usage of the verb system of the target language \\n(e.g Active vs Passive Voice; positive vs negative connotation; modality);syntax (e.g elliptical \\nsentences; metaphors); nominal syntagms (choice of adjectives); phonostylistical devices, etc. \\nThese phenomena possess their peculiarities as far as languages are concerned and they would \\nbe worth investigating from sociolinguistic/sociocultural point of view in futher research \\npaper work.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 15, 'page_label': '16', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='16 \\n \\nExternal influences in Brighton and Foy’terminology set another aspect of news gathering. \\nMedia ownership self-sufficiently establishes what and, more importantly, whose ideas a \\nmedium voices. Downie and Schudson, 2002 suggest a new perspective of what influences \\nmeadia choices of news presentation: \\n“…the economic foundation of the nation’s newspapers, long supported by advertising, is \\ncollapsing, and newspapers themselves, which have been the country’s (the USA here) chief \\nsource of independent reporting, are shrinking literally. Fewer journalists are reporting less \\nnews in fewer pages. ” \\n      Downie and Schudson 2002( Fenton 2011:3) \\nThe picture is almost identical in Central and Eastern Europe and the Commonwealth of \\nIndependent States: Albania, Armenia, Bosnia and Herzegovina, Bulgaria, Czech Republic, \\nEstonia, Hungary, Kyrguzstan, Latvia, Lithuania, Macedonia, Modlova, Montenegro, Poland,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 15, 'page_label': '16', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='Independent States: Albania, Armenia, Bosnia and Herzegovina, Bulgaria, Czech Republic, \\nEstonia, Hungary, Kyrguzstan, Latvia, Lithuania, Macedonia, Modlova, Montenegro, Poland, \\nRomania, Serbia, Slovakia, and Ukraine, according to an investigation conducted by the Open \\nSociety Institute Media Program (OSI 2010) (ibid).  \\nOn balance, the process of newsgathering is a complex phenomenon. The theoretical \\ntaxonomies in academic literature, on the one hand, present one possible aspect of what types \\nof events are prone to turn into news items. The human interference as a journalistic choice, \\npersonal values, stereotypes, and cultural belonging add to the picture of news selection and \\npresentation. Media ownership together with political and economic factors are other criteria \\nthat influence media contents. Audiences and readership profiles are to be taken into \\nconsideration as well. Finally yet importantly, news values are then to be viewed as qualities'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 15, 'page_label': '16', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"that influence media contents. Audiences and readership profiles are to be taken into \\nconsideration as well. Finally yet importantly, news values are then to be viewed as qualities \\nof potential reports and they are not simply features of selection but features of representation. \\nNews events, being systematically sorted and selected, are to be carefully worded, designed, \\nprojected and given prominence to on the newspaper's pages, computer and television screens.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 16, 'page_label': '17', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"17 \\n \\nBibliography \\n \\nBell, Garret 1998: Bell, Allan, Garrett, Peter. Approaches to Media Discourse. //Oxford: \\nBlackwell Publishers, 1998 \\nBranston, Stafford  1999:  Branston,Gill, Stafford, Roy. The Media Student's Book. London: \\nRoutledge,1999 \\nDijk 1985:   Dijk, Teun, Adrianus, van. Handbook of Discourse Analysis vol.2 Dimensions of \\nDiscourse, Florida: Academic Press, 1985 \\nFedler, Bender,Davenport,Drager 1999: Fedler, Fred, Bender, Jhon, Davenport, Lucinda, \\nDrager, Michalel. Reporting for the Media. Haracourt Brace & Company,1999 \\nFenton 2011:  Fenton, Natelie. Deregulation of democracy? New media, news, neoliberalism and \\nthe public interest.// Continuum: \\n 25: 1, 63 — 72, Routledge \\nFiske 1990: Fiske, John. Introduction to Communication Studies (2 nd ed). London and New York: \\nRoutledge, 1990 \\nFowler 1991: Fowler, Roger. Language in the News: Discourse and Ideology in the Press. \\nLondon: Routledge, 1991\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 16, 'page_label': '17', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"Routledge, 1990 \\nFowler 1991: Fowler, Roger. Language in the News: Discourse and Ideology in the Press. \\nLondon: Routledge, 1991 \\nGaltung, Ruge 1965:  Galtung, Johan, Ruge, Marie, Holmboe. Structure of Foreign News. Sage \\n<\\nhttp://www.blisty.cz/files/2010/07/20/galtung-structure-foreign-news-1965.pdf > (27.08.2011)  \\nHodgson 1984:  Hodgson, F. W. Modern Newspaper Practice. Oxford: Focal Press, 1984 \\nKeeble 1994:  Keeble, Richard.  The Newspapers Handbook. London and New York: Routledge, \\n1994 \\nO'Sullivan, Dutton, Rayner  1994:  O'Sullivan, Tim, Dutton, Brian, Rayner, Philip.  Studying the \\nMedia: An Introduction. London: Arnold, 1994 \\nOthman, Tiung 2009:  Othman, Siti, Suriani, Tiung.Lee,Kuok. The News Types of Two \\nCountries: A Comparative Study of News Values Quality Newspapers and Popular Newspapers in \\nMalaysia and Britain.//Sosiohumanica \\n<\\nhttp://www.sosiohumanikajpssk.com/sh_files/File/siti.lee.usim.ums.pdf > (27.08.2011)\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 16, 'page_label': '17', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='Malaysia and Britain.//Sosiohumanica \\n<\\nhttp://www.sosiohumanikajpssk.com/sh_files/File/siti.lee.usim.ums.pdf > (27.08.2011) \\nPotter 2006: Potter, Deborah., (2006) Handbook of Independent Journalism , Bureau of \\nInternational Information Programmes: U.S Department of State \\n< http://www.america.gov/media/pdf/books/journalism.pdf#popup > (27.08.2011)  \\nReah 1998:  Reah, Danuta. The Language of Newspapers. London: Routledge,1998 \\nSimpson 1993:  Simpson, Paul.  Language Ideology and Point of View. London: Routledge, 1993 \\nIvancheva 2005:   Ivancheva, Theodora. Comparative Analysis of Linguistic and Non-linguistic \\nMethods of Projecting News Values in the Dailies Trud and The Times.// New Bulgarian \\nUniversity, vol. 6. Sofia, 2005'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 17, 'page_label': '18', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='18 \\n \\n \\nWebsites: \\n \\nhttp://en.wikipedia.org/wiki/Denis_MacShane  \\nhttp://en.wikipedia.org/wiki/Man_bites_dog_(journalism) \\nhttp://www.natcorp.ox.ac.uk/  \\nhttp://www.telegraph.co.uk/'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 18, 'page_label': '19', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"19 \\n \\nAPPENDIX \\n(Here is a random selection of 50 solutions from the 14684 found). \\nA1R  3 THE STORY was that Breakfast News (BBC 1), the third relaunch of the cereal \\ntelevision which began in 1983 as Breakfast Time with Frank Bough and Selina Scott \\nchummy in jumpers, was going serious. (A1R  [Independent, electronic edition of 19891003].  \\nLondon: Newspaper Publishing plc, 1989, Arts material, pp. ??. 61 s-units, 1545 words. ) \\nA29  54  The People's Daily, the Communist party organ, published news of his death nearly \\ntwo weeks late but avoided any harsh commentary.( A29  [Independent, electronic edition of \\n19891004].  London: Newspaper Publishing plc, 1989, Gazette material, pp. ??. 133 s-units, \\n3354 words. ) \\nA2F  17  News of the Prague embassy's open door seems likely to provoke a greatly increased \\nflow of new emigrants from East Germany. (A2F  [Independent, electronic edition of \\n19891004].  London: Newspaper Publishing plc, 1989, Title material, pp. ??. 138 s-units, 3149\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 18, 'page_label': '19', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"flow of new emigrants from East Germany. (A2F  [Independent, electronic edition of \\n19891004].  London: Newspaper Publishing plc, 1989, Title material, pp. ??. 138 s-units, 3149 \\nwords. ) \\nA3D  13  Foreign News Page 10 (A3D  [Independent, electronic edition of 19891007].  London: \\nNewspaper Publishing plc, 1989, Foreign material, pp. ??. 439 s-units, 9297 words. ) \\nA8F  406  No wonder he can't bring himself to show much emotion at the news of his family's \\ndemise.( A8F  [Guardian, electronic edition of 19891123].  London: Guardian Newspapers \\nLtd, 1989, Arts material, pp. ??. 888 s-units, 18531 words. ) \\nABH  1649  The prime minister warned MPs that the Gulf war would not be ‘an easy or \\npainless business’ and readied them for ‘difficult news’to come. (ABH  The Economist.  \\nLondon: The Economist Newspaper Ltd, 1991, pp. ??. 3341 s-units, 60150 words. ) \\nAC2  1057  That afternoon the convener communicated his version of the story to the shop\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 18, 'page_label': '19', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"London: The Economist Newspaper Ltd, 1991, pp. ??. 3341 s-units, 60150 words. ) \\nAC2  1057  That afternoon the convener communicated his version of the story to the shop \\nsteward's committee and within an hour every department was buzzing with the news. (AC2  \\nMan at the sharp end.  Kilby, M. Lewes, East Sussex: The Book Guild Ltd, 1991, pp. ??. 2565 \\ns-units, 36227 words. ) \\nACG  1865  Though he sits by the gate of Shiloh, in his blindness watching the road, he is \\nnearly the last in the town to hear the news. (ACG  Lo and behold!  Dennis, Trevor. London: \\nSPCK, 1991, pp. ??. 1987 s-units, 36214 words. ) \\nAKG  none  Daily Telegraph, electronic edition of 1992-04-13: News and features. (AKG  \\n[Daily Telegraph, electronic edition of 19920413].  London: The Daily Telegraph plc, 1992, \\nSocial material, pp. ??. 34 s-units, 677 words. ) \\nAKH  919  In 1970 Hall joined the News of the World, where she was woman's editor until\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 18, 'page_label': '19', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"Social material, pp. ??. 34 s-units, 677 words. ) \\nAKH  919  In 1970 Hall joined the News of the World, where she was woman's editor until \\n1988. (AKH  [Daily Telegraph, electronic edition of 19920413].  London: The Daily \\nTelegraph plc, 1992, World affairs material, pp. ??. 963 s-units, 20012 words. (AKH  [Daily \\nTelegraph, electronic edition of 19920413].  London: The Daily Telegraph plc, 1992, World \\naffairs material, pp. ??. 963 s-units, 20012 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 19, 'page_label': '20', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"20 \\n \\nAPW  879  I did not hear the sailor's words, but Lachlan forbade me to waken Hector, he said \\nthe morning would do for the news. (APW  Quest for a babe.  Hendry, Frances Mary. \\nEdinburgh: Canongate Publishing Ltd, 1990, pp. 43-141. 3543 s-units, 37837 words. ) \\nB1R  1566  This remedy may be needed after a fright, rage, vexation, jealousy or hearing bad \\nnews. (B1R  How to use homeopathy.  Hammond, Christopher. Shaftesbury, Dorset: Element \\nBooks Ltd, 1991, pp. 1-134. 2739 s-units, 35304 words. ) \\nB2E  1373  We began to get worse and worse news from the Continent about Concentration \\nCamps, for Jews and others, that were almost unbelievably brutal. (B2E  Oh! sister I saw the \\nbells go down.  Saunders-Veness, Frances. Lewes, East Sussex: The Book Guild Ltd, 1989, \\npp. 7-73. 1596 s-units, 25384 words. ) \\nC86  1607  When Creed called, Jed was watching a news report about a vulture who'd just \\nbeen arrested on a murder charge. (C86  The five gates of hell.  Thomson, Rupert. London:\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 19, 'page_label': '20', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"C86  1607  When Creed called, Jed was watching a news report about a vulture who'd just \\nbeen arrested on a murder charge. (C86  The five gates of hell.  Thomson, Rupert. London: \\nBloomsbury Publishing Ltd, 1991, pp. 123-226. 4332 s-units, 41866 words. ) \\nCBU  603  The news of the near fatal stabbing of WPC Harrison in Liverpool has focused \\nattention again on the vulnerability of women to physical violence, particularly during their \\nworking lives. (CBU  Accountancy.  London: Institute of Chartered Accountants, 1993, pp. ??. \\n5049 s-units, 102586 words. ) \\nCGD  997  Resistance to uncomfortable news, for example a recommendation to give up one's \\nown home, is as strongly present as in earlier life.( CGD  Family work with elderly people.  \\nFroggatt, Alison. Basingstoke: Macmillan Publishers Ltd, 1990, pp. 1-107. 1936 s-units, \\n37812 words. ) \\nCGL  288  This quarterly publication, available to members of CWH is full of news updates on\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 19, 'page_label': '20', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"Froggatt, Alison. Basingstoke: Macmillan Publishers Ltd, 1990, pp. 1-107. 1936 s-units, \\n37812 words. ) \\nCGL  288  This quarterly publication, available to members of CWH is full of news updates on \\nthe aircraft of the CWH Museum along with articles of an historical nature. (CGL  FlyPast.  \\nStamford, Lincs: Key Publishing, 1992, pp. ??. 1934 s-units, 39395 words. ) \\nCH6  9210  ‘I've got some great news,’ she told her mother Barbara Cooper. (CH6  The Daily \\nMirror.  London: Mirror Group Newspapers, 1992, pp. ??. 9610 s-units, 127906 words.) \\nCH7  2499  The former Kent all-rounder was ‘disgusted’ that news of his sacking — along \\nwith batsman Andrew Brown — was announced before the club had told them.( CH7  The \\nDaily Mirror.  London: Mirror Group Newspapers, 1992, pp. ??. 5437 s-units, 84868 words. ) \\nCKB  3038  ‘Have you heard the news?’ (CKB  The raven on the water.  Taylor, Andrew. \\nLondon: Fontana Press, 1992, pp. 7-136. 3819 s-units, 39288 words.)\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 19, 'page_label': '20', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='CKB  3038  ‘Have you heard the news?’ (CKB  The raven on the water.  Taylor, Andrew. \\nLondon: Fontana Press, 1992, pp. 7-136. 3819 s-units, 39288 words.) \\nCR8  776  They were more reassured by the news that the prince was about to give a lunch, \\nwhich would be attended by his son, Prince Ranariddh, who leads FUNCINPEC, and by Chea \\nSim, the general secretary of the CPP.( CR8  The Economist.  London: The Economist \\nNewspaper Ltd, 1993, pp. ??. 3139 s-units, 57460 words. ) \\nCRA  469  FOR a writer who was put in the ‘Garbage School of Literature’ along with \\nTennessee Williams and William Faulkner by the editor of the Jackson Daily News, Eudora \\nWelty has done well for herself. (CRA  The Economist.  London: The Economist Newspaper \\nLtd, 1993, pp. ??. 3317 s-units, 58734 words. )'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 20, 'page_label': '21', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='21 \\n \\nCRC  2650  It owns 40% of Nikkei Quick, a Japanese-language on-line financial news service \\nwhose cubby-hole is the first in which company announcements are placed. (CRC  The \\nEconomist.  London: The Economist Newspaper Ltd, 1993, pp. ??. 4039 s-units, 71921 \\nwords.) \\nCRU  540  The Gay News Defence Committee organised many forms of protest, including a \\nmarch and meeting in Trafalgar Square which attracted 5,000 people. (CRU  Permission and \\nRegulation.  Newburn, T. London: Routledge & Kegan Paul plc, 1992, pp. 1-70. 1152 s-units, \\n31189 words. ) \\nCTD  49  Not such good news from one of the original players in this arena though, Mac-on-\\nRISC house Quorum Software Systems Inc, Menlo Park, California, has filed suit against \\nApple seeking to counter allegations of patent and copyright infringement made by Apple. \\n(CTD  Unigram x.  APT Data Services Ltd., 1993, pp. ??. 418 s-units, 10171 words. )'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 20, 'page_label': '21', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"Apple seeking to counter allegations of patent and copyright infringement made by Apple. \\n(CTD  Unigram x.  APT Data Services Ltd., 1993, pp. ??. 418 s-units, 10171 words. ) \\nCTE  264  Another piece of what sounds like good news is that the entire Coherent 4.0 consists \\nof six floppy disks and ‘installs in less than an hour’. (CTE  Unigram x.  APT Data Services \\nLtd., 1993, pp. ??. 331 s-units, 8060 words. ) \\nEC2  100  ’(News at Ten, 4.6.91). (EC2  ASH Supporters' News Issue No. 29.  London: Action \\non Smoking & Health, 1991, pp. ??. 375 s-units, 7001 words. ) \\nFM2  855  So that's good news. (FM2  Missprint planning meeting (Business). Recorded on 28 \\nMarch 1993 with 5 participants, totalling 15029 words, 1941 utterances (duration not \\nrecorded).  \\nPS000  17 words, 48 utterances.  \\nPS1S1  (`Wendy', female, 25, lexicographer): 8022 words, 782 utterances.  \\nPS1S2  (`Clare', female, 21, transcriber): 1937 words, 353 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 20, 'page_label': '21', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"recorded).  \\nPS000  17 words, 48 utterances.  \\nPS1S1  (`Wendy', female, 25, lexicographer): 8022 words, 782 utterances.  \\nPS1S2  (`Clare', female, 21, transcriber): 1937 words, 353 utterances.  \\nPS1S3  (`Derek', male, 24, transcriber): 3430 words, 480 utterances.  \\nPS1S4  (`David', male, 24, transcriber): 1623 words, 278 utterances. ) \\nFS0  710  Auque's news appeared to point to the fact that John was being held by an Iranian-\\nbacked group, and in March Hashemi Rafsanjani called a news conference in Tehran during \\nwhich he repeated his request that Britain should help locate the missing Iranians in Beirut if \\nit wanted Iran to help with the British hostages. (FS0  Some other rainbow.  Morrell, J and \\nMcCarthy, J. London: Transworld Publishers Ltd, 1993, pp. ??. 1974 s-units, 35288 words. ) \\nGUK  955  The news of Soeur Dosithée's holy and resigned death came on a black-edged card \\nin a black-edged envelope. (GUK  Daughters of the house.  Roberts, Michele. London: Virago\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 20, 'page_label': '21', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"GUK  955  The news of Soeur Dosithée's holy and resigned death came on a black-edged card \\nin a black-edged envelope. (GUK  Daughters of the house.  Roberts, Michele. London: Virago \\nPress Ltd, 1993, pp. 30-153. 3950 s-units, 41259 words. ) \\nGUU  1404  ‘Any news of Ivor?’ she asked gently. (GUU  Freelance death.  Taylor, Andrew. \\nLondon: Victor Gollancz Ltd, 1993, pp. 52-175. 4337 s-units, 40867 words. ) \\nH0M  543  the fucking news… (H0M  Money.  Amis, Martin. London: Penguin Group, 1985, \\npp. ??. 4072 s-units, 41518 words. ) \\nH46  277  NEWS ( H46  Bookseller.  London: J Whitaker & sons, 1993, pp. ??. 1326 s-units, \\n25503 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 21, 'page_label': '22', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"22 \\n \\nHAF  419  NEWS DIGEST ( HAF  The Sunday People.  pp. ??. 1337 s-units, 19285 words. ) \\nHAK  41  After joining Courage, he used his editing experience on in-house newspapers and \\nmagazines and branched out into video news and promotional programmes. (HAK  BAIE \\nNews for communicators in business.  Dorking: Hardman Press, 1993, pp. ??. 399 s-units, \\n8457 words. ) \\nHP4  616  Wimpey News has teamed up with Kuoni, one of the world's leading travel \\ncompanies, to offer readers the chance of visiting one of three exotic holiday destinations for \\nlittle more than the cost of a European holiday. (HP4  [Misc unpublished -- Wimpey \\nnewsletter].  u.p., n.d., pp. ??. 1680 s-units, 33791 words. ) \\nHS2  616  GOLF NEWS ( HS2  Glenpatrick News.  u.p., n.d., pp. ??. 627 s-units, 11375 words. ) \\nHSY  10  More news? (HSY  CompuAdd. The catalogue.  u.p., n.d., pp. ??. 172 s-units, 2733 \\nwords. ) \\nHU1  797  We await further news of quantitative surveys with interest. (HU1  The Embalmer.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 21, 'page_label': '22', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content='HSY  10  More news? (HSY  CompuAdd. The catalogue.  u.p., n.d., pp. ??. 172 s-units, 2733 \\nwords. ) \\nHU1  797  We await further news of quantitative surveys with interest. (HU1  The Embalmer.  \\nKnebworth: British Institute of Embalmers, 1993, pp. 3-35. 960 s-units, 18716 words. ) \\nHY5  259  When Charles Emmanuel II died, in 1675, special envoys bringing news of his \\ndeath were treated in both Paris and London as the representatives of a king: both Charles II \\nand Louis XIV wore violet mourning, the colour appropriate for a royal death. (HY5  The rise \\nof modern diplomacy 1450–1919.  Anderson, M S. Harlow: Longman Group UK Ltd, 1993, \\npp. 41-148. 1543 s-units, 44759 words. ) \\nJ1C  2344  Subject: Youth Team News (J1C  [Leeds United e-mail list].  u.p., n.d., pp. ??. 3437 \\ns-units, 40333 words. ) \\nJ1H  2665  Team news for Saturday eagerly awaited. (J1H  [Leeds United e-mail list].  u.p., \\nn.d., pp. ??. 4079 s-units, 46681 words. )'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 21, 'page_label': '22', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"s-units, 40333 words. ) \\nJ1H  2665  Team news for Saturday eagerly awaited. (J1H  [Leeds United e-mail list].  u.p., \\nn.d., pp. ??. 4079 s-units, 46681 words. ) \\nJ27  25  During his lifetime Jesus challenged the people of his time to accept the message of \\nthe ‘Good News’, or Gospel (Mark 1:15). (J27  Short courses in religious and moral \\neducation.  u.p., n.d., pp. ??. 881 s-units, 14566 words. ) \\nJ54  21  I shall definitely be at the airport to meet you and I hope to have some startling and \\nimportant news to give you in person. (J54  The divided house.  Raymond, Mary. UK: F A \\nThorpe (Publishing) Ltd, 1985, pp. 1-236. 2757 s-units, 35534 words. ) \\nK5M  10539  Meanwhile, Colin and Wendy Parry, of Great Sankey, Warrington, saw hopes \\nfor their son Tim snatched away with the news that his condition has deteriorated in the \\nintensive care unit of Liverpool's Walton neurosurgical centre. (K5M  [Scotsman].  u.p., n.d., \\nWorld affairs material, pp. ??. 12622 s-units, 261981 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 21, 'page_label': '22', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"intensive care unit of Liverpool's Walton neurosurgical centre. (K5M  [Scotsman].  u.p., n.d., \\nWorld affairs material, pp. ??. 12622 s-units, 261981 words. ) \\nKAC  8 We, the Editors of the Medau News, would like to know your views and suggestions \\non this subject and look forward to printing them in the January issue. (KAC  Medau News. \\nUK: The Medau Society, 1979, pp. ??. 207 s-units, 3505 words. )\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 22, 'page_label': '23', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"23 \\n \\nKCJ  1256  well it's, it's it's on at one o'clock, one o'clock and er it's on erm half past six \\ntonight, well I've taped it at half past six tonight and after everybody's watched the news I've, \\nI watched it after, er, you know, so, I watch it then an hour (KCJ  2 conversations recorded by \\n`James' (PS1C7) between 3 and 6 April 1992 with 2 interlocutors, totalling 13482 words, \\n1486 utterances, and 1 hour 23 minutes 47 seconds of recordings.  \\nPS1C7  (`James', male, 63, retired, DE, north-east England): 7486 words, 735 utterances.  \\nPS1C8  (`Patricia', female, 72, housewife, DE, north-east England): 2953 words, 429 \\nutterances.  \\nPS1C9  (`Margaret', female, 30, housewife, north-east England): 3043 words, 322 utterances. \\n) \\nKGH  1434  To the news we go with with Wipe Out by the Safaris. (KGH  BBC Radio \\nNottingham: radio broadcast (Leisure). Recorded on 10 November 1993 with 9 participants, \\ntotalling 16523 words, 1149 utterances, and lasting 1 hour 30 minutes.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 22, 'page_label': '23', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"Nottingham: radio broadcast (Leisure). Recorded on 10 November 1993 with 9 participants, \\ntotalling 16523 words, 1149 utterances, and lasting 1 hour 30 minutes.  \\nPS388  (`Geoff', male, radio presenter): 1667 words, 146 utterances.  \\nPS389  (`Sue', female): 605 words, 31 utterances.  \\nPS38A  (`Teresa', female, radio weather forecaster): 530 words, 35 utterances.  \\nPS38B  (male, 10+, schoolchild): 280 words, 24 utterances.  \\nPS38C  (male, 10+, schoolchild): 1021 words, 88 utterances.  \\nPS38D  (male, 10+, schoolchild): 99 words, 15 utterances.  \\nPS38E  (male, 10+, schoolchild): 208 words, 25 utterances.  \\nPS38F  (male, 10+, schoolchild): 6740 words, 508 utterances.  \\nPS38G  (`Trudy', female): 1094 words, 176 utterances. ) \\nKLV  534  So there's some good news there. (KLV  General Portfolio management meeting \\n(Business). Recorded on 7 April 1993 with 9 participants, totalling 16821 words, 834 \\nutterances (duration not recorded).  \\nPS000  4813 words, 478 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 22, 'page_label': '23', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"(Business). Recorded on 7 April 1993 with 9 participants, totalling 16821 words, 834 \\nutterances (duration not recorded).  \\nPS000  4813 words, 478 utterances.  \\nPS3SF  (`Mike', male, 40+, group manager, London): 9438 words, 189 utterances.  \\nPS3SG  (`Robert', male, 45+, team manager, Home Counties): 609 words, 31 utterances.  \\nPS3SH  (`Jackie', female, 35+, team manager, Home Counties): 622 words, 35 utterances.  \\nPS3SJ  (`Steve', male, 50+, team manager, Home Counties): 93 words, 9 utterances.  \\nPS3SK  (`Sheila', female, 45+, team manager, Home Counties): 293 words, 46 utterances.  \\nPS3SL  (`Phil', male, 45+, team manager, Home Counties): 846 words, 33 utterances.  \\nPS3SM  (`Ian', male, 45+, team manager, Home Counties): 36 words, 4 utterances.  \\nPS3SN  (female, 45+, personal assistant, Home Counties): 71 words, 9 utterances. ) \\nKRT  1876  Well, we, we as you correctly say er with the whole industry had a, had a difficult\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 22, 'page_label': '23', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS3SN  (female, 45+, personal assistant, Home Counties): 71 words, 9 utterances. ) \\nKRT  1876  Well, we, we as you correctly say er with the whole industry had a, had a difficult \\nAugust, I think the good news for Rover is that we fell less in volume terms than most of the \\ncompetition, and indeed we marginally increased our market share (KRT  Fox FM News: \\nradio programme. Recorded on [date unknown] with 292 participants, totalling 158242 words, \\n2687 utterances (duration not recorded).  \\nPS63J  (`A', male): 609 words, 18 utterances.  \\nPS63K  (`JM', female): 38152 words, 799 utterances.  \\nPS63L  (`AW', female): 2227 words, 30 utterances.  \\nPS63M  (`PC', male): 543 words, 9 utterances.  \\nPS63N  (`BC', male): 497 words, 8 utterances.  \\nPS63P  (`MT', female): 179 words, 6 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 23, 'page_label': '24', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"24 \\n \\nPS63R  (`NW', male): 372 words, 4 utterances.  \\nPS63S  (`VH', female): 97 words, 1 utterance.  \\nPS63T  (`JG', male): 415 words, 4 utterances.  \\nPS63U  (`DB', male): 615 words, 10 utterances.  \\nPS63V  (`B', male): 777 words, 27 utterances.  \\nPS63W  (`TB', male): 1029 words, 10 utterances.  \\nPS63X  (`NT', male): 576 words, 6 utterances.  \\nPS63Y  (`MN', male): 723 words, 6 utterances.  \\nPS640  (`LB', female): 3539 words, 64 utterances.  \\nPS641  (`TR', male): 199 words, 2 utterances.  \\nPS642  (`MM', female): 57 words, 1 utterance.  \\nPS643  (`PM', male): 2713 words, 48 utterances.  \\nPS644  (`SI', male): 679 words, 13 utterances.  \\nPS645  (`MP', male): 404 words, 9 utterances.  \\nPS646  (`TS', male): 77 words, 2 utterances.  \\nPS647  (`C', male): 440 words, 22 utterances.  \\nPS648  (`JP', male): 1705 words, 14 utterances.  \\nPS649  (`CS', male): 267 words, 3 utterances.  \\nPS64A  (`D', male): 348 words, 21 utterances.  \\nPS64B  (`CM', male): 310 words, 6 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 23, 'page_label': '24', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS648  (`JP', male): 1705 words, 14 utterances.  \\nPS649  (`CS', male): 267 words, 3 utterances.  \\nPS64A  (`D', male): 348 words, 21 utterances.  \\nPS64B  (`CM', male): 310 words, 6 utterances.  \\nPS64C  (`MG', female): 92 words, 1 utterance.  \\nPS64D  (`E', female): 241 words, 9 utterances.  \\nPS64E  (`F', female): 208 words, 9 utterances.  \\nPS64F  (`G', female): 42 words, 2 utterances.  \\nPS64G  (`H', female): 129 words, 8 utterances.  \\nPS64H  (`AS', male): 1243 words, 10 utterances.  \\nPS64J  (`TD', male): 66 words, 1 utterance.  \\nPS64K  (`I', female): 338 words, 5 utterances.  \\nPS64L  (`J', male): 645 words, 33 utterances.  \\nPS64M  (`MB', male): 505 words, 8 utterances.  \\nPS64N  (`BW', male): 83 words, 4 utterances.  \\nPS64P  (`CR', female): 508 words, 4 utterances.  \\nPS64R  (`BF', male): 374 words, 3 utterances.  \\nPS64S  (`K', male): 629 words, 10 utterances.  \\nPS64T  (`TM', male): 327 words, 8 utterances.  \\nPS64U  (`AR', male): 538 words, 10 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 23, 'page_label': '24', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS64R  (`BF', male): 374 words, 3 utterances.  \\nPS64S  (`K', male): 629 words, 10 utterances.  \\nPS64T  (`TM', male): 327 words, 8 utterances.  \\nPS64U  (`AR', male): 538 words, 10 utterances.  \\nPS64V  (`PR', male): 534 words, 10 utterances.  \\nPS64W  (`L', male): 665 words, 11 utterances.  \\nPS64X  (`CP', male): 593 words, 7 utterances.  \\nPS64Y  (`HH', male): 1528 words, 22 utterances.  \\nPS650  (`IP', male): 48 words, 1 utterance.  \\nPS651  (`PP', male): 350 words, 8 utterances.  \\nPS652  (`AD', female): 368 words, 17 utterances.  \\nPS653  (`TC', male): 193 words, 3 utterances.  \\nPS654  (`TA', male): 117 words, 1 utterance.  \\nPS655  (`IW', male): 505 words, 9 utterances.  \\nPS656  (`DO', male): 784 words, 5 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 24, 'page_label': '25', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"25 \\n \\nPS657  (`RP', male): 2475 words, 43 utterances.  \\nPS658  (`DG', male): 438 words, 8 utterances.  \\nPS659  (`CF', female): 74 words, 1 utterance.  \\nPS65A  (`CJ', female): 310 words, 2 utterances.  \\nPS65B  (`GM', male): 913 words, 15 utterances.  \\nPS65C  (`NS', male): 54 words, 1 utterance.  \\nPS65D  (`DM', male): 585 words, 4 utterances.  \\nPS65E  (`RG', female): 826 words, 6 utterances.  \\nPS65F  (`GO', male): 232 words, 2 utterances.  \\nPS65G  (`F', male): 372 words, 17 utterances.  \\nPS65H  (`RJ', male): 526 words, 7 utterances.  \\nPS65J  (`JB', female): 423 words, 9 utterances.  \\nPS65K  (`G', male): 907 words, 26 utterances.  \\nPS65L  (`JM', male): 1503 words, 18 utterances.  \\nPS65M  (`H', male): 583 words, 21 utterances.  \\nPS65N  (`LR', male): 130 words, 3 utterances.  \\nPS65P  (`MU', male): 14 words, 1 utterance.  \\nPS65R  (`HN', male): 368 words, 4 utterances.  \\nPS65S  (`I', male): 344 words, 19 utterances.  \\nPS65T  (`DW', female): 452 words, 3 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 24, 'page_label': '25', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS65P  (`MU', male): 14 words, 1 utterance.  \\nPS65R  (`HN', male): 368 words, 4 utterances.  \\nPS65S  (`I', male): 344 words, 19 utterances.  \\nPS65T  (`DW', female): 452 words, 3 utterances.  \\nPS65U  (`RH', male): 653 words, 6 utterances.  \\nPS65V  (`EA', male): 348 words, 9 utterances.  \\nPS65W  (`JH', male): 561 words, 4 utterances.  \\nPS65X  (`MM', male): 218 words, 3 utterances.  \\nPS65Y  (`DF', male): 349 words, 6 utterances.  \\nPS660  (`NH', male): 237 words, 3 utterances.  \\nPS661  (`IG', male): 216 words, 4 utterances.  \\nPS662  (`NC', male): 686 words, 9 utterances.  \\nPS663  (`MH', male): 342 words, 4 utterances.  \\nPS664  (`TN', male): 457 words, 8 utterances.  \\nPS665  (`CG', male): 1006 words, 16 utterances.  \\nPS666  (`LS', male): 487 words, 8 utterances.  \\nPS667  (`DH', male): 816 words, 11 utterances.  \\nPS668  (`Zippy', male): 17 words, 1 utterance.  \\nPS669  (`SJ', female): 699 words, 5 utterances.  \\nPS66A  (`A', female): 631 words, 16 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 24, 'page_label': '25', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS667  (`DH', male): 816 words, 11 utterances.  \\nPS668  (`Zippy', male): 17 words, 1 utterance.  \\nPS669  (`SJ', female): 699 words, 5 utterances.  \\nPS66A  (`A', female): 631 words, 16 utterances.  \\nPS66B  (`RR', male): 66 words, 2 utterances.  \\nPS66C  (`ML', male): 3676 words, 30 utterances.  \\nPS66D  (`AC', male): 575 words, 7 utterances.  \\nPS66E  (`JZ', female): 641 words, 3 utterances.  \\nPS66F  (`D', female): 256 words, 9 utterances.  \\nPS66G  (`RB', male): 386 words, 6 utterances.  \\nPS66H  (`DS', male): 1486 words, 15 utterances.  \\nPS66J  (`KG', male): 52 words, 1 utterance.  \\nPS66K  (`AH', female): 61 words, 1 utterance.  \\nPS66L  (`SW', male): 256 words, 5 utterances.  \\nPS66M  (`LM', male): 37 words, 1 utterance.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 25, 'page_label': '26', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"26 \\n \\nPS66N  (`RM', male): 1230 words, 11 utterances.  \\nPS66P  (`BG', female): 24 words, 1 utterance.  \\nPS66R  (`E', male): 591 words, 23 utterances.  \\nPS66S  (`CB', female): 576 words, 5 utterances.  \\nPS66T  (`AH', male): 259 words, 1 utterance.  \\nPS66U  (`BH', male): 1512 words, 10 utterances.  \\nPS66V  (`P', male): 74 words, 2 utterances.  \\nPS66W  (`AK', female): 174 words, 7 utterances.  \\nPS66X  (`Q', male): 317 words, 8 utterances.  \\nPS66Y  (`Bungle', male): 158 words, 14 utterances.  \\nPS670  (`Jeffrey', male): 5 words, 1 utterance.  \\nPS671  (`JB', male): 1436 words, 22 utterances.  \\nPS672  (`SH', male): 666 words, 6 utterances.  \\nPS673  (`SK', male): 266 words, 6 utterances.  \\nPS674  (`MS', male): 104 words, 2 utterances.  \\nPS675  (`PS', male): 925 words, 16 utterances.  \\nPS676  (`RV', female): 67 words, 3 utterances.  \\nPS677  (`AA', male): 474 words, 4 utterances.  \\nPS678  (`MH', male): 42 words, 1 utterance.  \\nPS679  (`JE', male): 307 words, 3 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 25, 'page_label': '26', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS676  (`RV', female): 67 words, 3 utterances.  \\nPS677  (`AA', male): 474 words, 4 utterances.  \\nPS678  (`MH', male): 42 words, 1 utterance.  \\nPS679  (`JE', male): 307 words, 3 utterances.  \\nPS67A  (`EL', female): 469 words, 4 utterances.  \\nPS67B  (`NY', female): 256 words, 3 utterances.  \\nPS67C  (`LJ', male): 393 words, 6 utterances.  \\nPS67D  (`IC', male): 472 words, 10 utterances.  \\nPS67E  (`JW', male): 845 words, 14 utterances.  \\nPS67F  (`NA', male): 223 words, 1 utterance.  \\nPS67G  (`PT', male): 601 words, 7 utterances.  \\nPS67H  (`MI', male): 4138 words, 53 utterances.  \\nPS67J  (`PG', male): 91 words, 1 utterance.  \\nPS67K  (`FD', male): 47 words, 1 utterance.  \\nPS67L  (`TK', male): 595 words, 8 utterances.  \\nPS67M  (`TP', male): 87 words, 1 utterance.  \\nPS67N  (`NM', male): 43 words, 1 utterance.  \\nPS67P  (`JS', male): 2060 words, 17 utterances.  \\nPS67R  (`GD', male): 418 words, 7 utterances.  \\nPS67S  (`MR', male): 1035 words, 5 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 25, 'page_label': '26', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS67N  (`NM', male): 43 words, 1 utterance.  \\nPS67P  (`JS', male): 2060 words, 17 utterances.  \\nPS67R  (`GD', male): 418 words, 7 utterances.  \\nPS67S  (`MR', male): 1035 words, 5 utterances.  \\nPS67T  (`PJ', male): 557 words, 5 utterances.  \\nPS67U  (`AT', male): 194 words, 2 utterances.  \\nPS67V  (`GW', male): 518 words, 4 utterances.  \\nPS67W  (`RG', male): 199 words, 4 utterances.  \\nPS67X  (`MJ', male): 393 words, 5 utterances.  \\nPS67Y  (`AP', male): 151 words, 3 utterances.  \\nPS680  (`PA', male): 186 words, 4 utterances.  \\nPS681  (`FJ', male): 407 words, 2 utterances.  \\nPS682  (`VB', female): 419 words, 4 utterances.  \\nPS683  (`RK', male): 366 words, 10 utterances.  \\nPS684  (`B', female): 127 words, 6 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 26, 'page_label': '27', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"27 \\n \\nPS685  (`GB', male): 181 words, 3 utterances.  \\nPS686  (`JT', female): 35 words, 1 utterance.  \\nPS687  (`JK', female): 11 words, 1 utterance.  \\nPS688  (`HC', female): 82 words, 2 utterances.  \\nPS689  (`RA', male): 213 words, 4 utterances.  \\nPS68A  (`AB', female): 89 words, 1 utterance.  \\nPS68B  (`PK', male): 3131 words, 43 utterances.  \\nPS68C  (`AG', female): 325 words, 5 utterances.  \\nPS68D  (`MW', male): 686 words, 7 utterances.  \\nPS68E  (`MH', female): 971 words, 11 utterances.  \\nPS68F  (`SP', female): 22 words, 1 utterance.  \\nPS68G  (`BJ', male): 61 words, 1 utterance.  \\nPS68H  (`BW', female): 51 words, 1 utterance.  \\nPS68J  (`PH', male): 488 words, 4 utterances.  \\nPS68K  (`WT', male): 299 words, 6 utterances.  \\nPS68L  (`KP', male): 33 words, 1 utterance.  \\nPS68M  (`PL', male): 53 words, 1 utterance.  \\nPS68N  (`CW', male): 91 words, 1 utterance.  \\nPS68P  (`MB', female): 279 words, 4 utterances.  \\nPS68R  (`KM', male): 236 words, 5 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 26, 'page_label': '27', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS68M  (`PL', male): 53 words, 1 utterance.  \\nPS68N  (`CW', male): 91 words, 1 utterance.  \\nPS68P  (`MB', female): 279 words, 4 utterances.  \\nPS68R  (`KM', male): 236 words, 5 utterances.  \\nPS68S  (`K', female): 116 words, 4 utterances.  \\nPS68T  (`SS', female): 241 words, 4 utterances.  \\nPS68U  (`AJ', male): 149 words, 8 utterances.  \\nPS68V  (`BG', male): 89 words, 2 utterances.  \\nPS68W  (`GF', male): 106 words, 4 utterances.  \\nPS68X  (`RS', male): 1256 words, 13 utterances.  \\nPS68Y  (`NH', female): 69 words, 1 utterance.  \\nPS690  (`CL', female): 455 words, 7 utterances.  \\nPS691  (`DP', male): 719 words, 7 utterances.  \\nPS692  (`JN', female): 987 words, 13 utterances.  \\nPS693  (`PB', male): 215 words, 4 utterances.  \\nPS694  (`MF', male): 74 words, 2 utterances.  \\nPS695  (`IJ', male): 142 words, 1 utterance.  \\nPS696  (`WH', male): 55 words, 1 utterance.  \\nPS697  (`AK', male): 536 words, 12 utterances.  \\nPS698  (`C', female): 134 words, 7 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 26, 'page_label': '27', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS695  (`IJ', male): 142 words, 1 utterance.  \\nPS696  (`WH', male): 55 words, 1 utterance.  \\nPS697  (`AK', male): 536 words, 12 utterances.  \\nPS698  (`C', female): 134 words, 7 utterances.  \\nPS699  (`JC', male): 110 words, 2 utterances.  \\nPS69A  (`HK', male): 74 words, 1 utterance.  \\nPS69B  (`HM', male): 65 words, 1 utterance.  \\nPS69C  (`EP', female): 649 words, 4 utterances.  \\nPS69D  (`SP', male): 217 words, 2 utterances.  \\nPS69E  (`RL', male): 272 words, 3 utterances.  \\nPS69F  (`TI', male): 47 words, 1 utterance.  \\nPS69G  (`LH', female): 522 words, 12 utterances.  \\nPS69H  (`FW', male): 365 words, 5 utterances.  \\nPS69J  (`LM', female): 132 words, 7 utterances.  \\nPS69K  (`NR', female): 360 words, 5 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 27, 'page_label': '28', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"28 \\n \\nPS69L  (`TF', female): 26 words, 2 utterances.  \\nPS69M  (`GP', female): 356 words, 3 utterances.  \\nPS69N  (`SM', female): 637 words, 10 utterances.  \\nPS69P  (`NK', male): 285 words, 6 utterances.  \\nPS69R  (`WE', male): 97 words, 1 utterance.  \\nPS69S  (`NP', female): 382 words, 3 utterances.  \\nPS69T  (`DC', male): 104 words, 1 utterance.  \\nPS69U  (`CH', female): 77 words, 1 utterance.  \\nPS69V  (`EF', male): 405 words, 4 utterances.  \\nPS69W  (`BS', male): 218 words, 3 utterances.  \\nPS69X  (`MC', female): 45 words, 1 utterance.  \\nPS69Y  (`BH', female): 807 words, 19 utterances.  \\nPS6A0  (`BY', female): 24 words, 1 utterance.  \\nPS6A1  (`CH', male): 362 words, 3 utterances.  \\nPS6A2  (`KS', male): 219 words, 2 utterances.  \\nPS6A3  (`RM', female): 51 words, 1 utterance.  \\nPS6A4  (`JJ', male): 169 words, 1 utterance.  \\nPS6A5  (`CA', female): 107 words, 4 utterances.  \\nPS6A6  (`CC', male): 207 words, 4 utterances.  \\nPS6A7  (`KC', male): 123 words, 2 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 27, 'page_label': '28', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS6A4  (`JJ', male): 169 words, 1 utterance.  \\nPS6A5  (`CA', female): 107 words, 4 utterances.  \\nPS6A6  (`CC', male): 207 words, 4 utterances.  \\nPS6A7  (`KC', male): 123 words, 2 utterances.  \\nPS6A8  (`JW', female): 231 words, 5 utterances.  \\nPS6A9  (`JMC', female): 500 words, 12 utterances.  \\nPS6AA  (`FJM', female): 117 words, 3 utterances.  \\nPS6AB  (`KK', female): 397 words, 5 utterances.  \\nPS6AC  (`BO', male): 63 words, 2 utterances.  \\nPS6AD  (`NP', male): 447 words, 5 utterances.  \\nPS6AE  (`HA', male): 40 words, 1 utterance.  \\nPS6AF  (`DW', male): 910 words, 11 utterances.  \\nPS6AG  (`JV', male): 720 words, 4 utterances.  \\nPS6AH  (`RD', female): 30 words, 1 utterance.  \\nPS6AJ  (`EC', male): 69 words, 1 utterance.  \\nPS6AK  (`WR', male): 526 words, 3 utterances.  \\nPS6AL  (`PD', male): 176 words, 2 utterances.  \\nPS6AM  (`HE', female): 129 words, 5 utterances.  \\nPS6AN  (`DV', male): 725 words, 5 utterances.  \\nPS6AP  (`PE', male): 180 words, 3 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 27, 'page_label': '28', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS6AL  (`PD', male): 176 words, 2 utterances.  \\nPS6AM  (`HE', female): 129 words, 5 utterances.  \\nPS6AN  (`DV', male): 725 words, 5 utterances.  \\nPS6AP  (`PE', male): 180 words, 3 utterances.  \\nPS6AR  (`AF', male): 555 words, 4 utterances.  \\nPS6AS  (`LH', male): 19 words, 1 utterance.  \\nPS6AT  (`LC', male): 22 words, 1 utterance.  \\nPS6AU  (`BN', male): 447 words, 4 utterances.  \\nPS6AV  (`TJ', male): 217 words, 1 utterance.  \\nPS6AW  (`WW', female): 218 words, 2 utterances.  \\nPS6AX  (`SR', male): 531 words, 11 utterances.  \\nPS6AY  (`PW', male): 271 words, 6 utterances.  \\nPS6B0  (`YO', female): 17 words, 1 utterance.  \\nPS6B1  (`FM', male): 212 words, 4 utterances.  \\nPS6B2  (`SA', female): 380 words, 11 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 28, 'page_label': '29', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"29 \\n \\nPS6B3  (`KB', male): 47 words, 1 utterance.  \\nPS6B4 (`WA', male): 32 words, 1 utterance.  \\nPS6B5  (`VB', male): 86 words, 1 utterance.  \\nPS6B6  (`AM', male): 56 words, 1 utterance.  \\nPS6B7  (`HA', female): 92 words, 1 utterance.  \\nPS6B8  (`RJ', female): 364 words, 3 utterances.  \\nPS6B9  (`TF', male): 80 words, 1 utterance.  \\nPS6BA  (`FH', female): 512 words, 4 utterances.  \\nPS6BB  (`AL', male): 171 words, 2 utterances.  \\nPS6BC  (`JL', male): 416 words, 5 utterances.  \\nPS6BD  (`BV', male): 367 words, 3 utterances.  \\nPS6BE  (`CK', female): 402 words, 5 utterances.  \\nPS6BF  (`ZW', female): 136 words, 2 utterances.  \\nPS6BG  (`AC', female): 35 words, 3 utterances.  \\nPS6BH  (`EH', female): 106 words, 1 utterance.  \\nPS6BJ  (`HT', female): 105 words, 2 utterances.  \\nPS6BK  (`JR', male): 293 words, 5 utterances.  \\nPS6BL  (`PK', female): 92 words, 2 utterances.  \\nPS6BM  (`MA', female): 320 words, 10 utterances.  \\nPS6BN  (`JG', female): 147 words, 3 utterances.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 28, 'page_label': '29', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS6BK  (`JR', male): 293 words, 5 utterances.  \\nPS6BL  (`PK', female): 92 words, 2 utterances.  \\nPS6BM  (`MA', female): 320 words, 10 utterances.  \\nPS6BN  (`JG', female): 147 words, 3 utterances.  \\nPS6BP  (`M', male): 24 words, 1 utterance.  \\nPS6BS  (`JO', male): 58 words, 2 utterances.  \\nPS6BT  (`LB', male): 282 words, 6 utterances.  \\nPS6BU  (`DD', female): 65 words, 1 utterance.  \\nPS6BV  (`AM', female): 123 words, 3 utterances.  \\nPS6BW  (`NO', male): 239 words, 3 utterances.  \\nPS6BX  (`DJ', male): 440 words, 6 utterances.  \\nPS6BY  (`N', male): 136 words, 5 utterances.  \\nPS6C0  (`EH', male): 252 words, 3 utterances.  \\nPS6C1  (`BM', male): 221 words, 5 utterances.  \\nPS6C2  (`O', male): 51 words, 5 utterances.  \\nPS6C3  (`JH', female): 194 words, 3 utterances.  \\nPS6C4  (`R', male): 176 words, 9 utterances.  \\nPS6C5  (`JS', female): 118 words, 3 utterances.  \\nPS6C6  (`AT', female): 294 words, 3 utterances.  \\nPS6C7  (`DL', male): 56 words, 1 utterance.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 28, 'page_label': '29', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"PS6C4  (`R', male): 176 words, 9 utterances.  \\nPS6C5  (`JS', female): 118 words, 3 utterances.  \\nPS6C6  (`AT', female): 294 words, 3 utterances.  \\nPS6C7  (`DL', male): 56 words, 1 utterance.  \\nPS6C8  (`KH', male): 67 words, 1 utterance.  \\nPS6C9  (`BS', female): 63 words, 1 utterance.  \\nPS6CA  (`SC', female): 275 words, 3 utterances.  \\nPS6CB  (`LT', male): 236 words, 5 utterances.  \\nPS6CC  (`DM', female): 253 words, 10 utterances.  \\nPS6CD  (`NA', female): 232 words, 3 utterances.  \\nPS6CE  (`J', female): 60 words, 4 utterances.  \\nPS6CF  (`ID', female): 355 words, 3 utterances.  \\nPS6CG  (`CB', male): 255 words, 4 utterances.  \\nPS6CH  (`RD', male): 72 words, 1 utterance.  \\nPS6CJ  (`RO', male): 109 words, 1 utterance.\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 8.56', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2011-08-30T06:57:22+00:00', 'moddate': '2011-08-30T06:57:22+00:00', 'title': 'Microsoft Word - news values revised', 'author': 'user', 'source': '..\\\\data\\\\pdf\\\\12037624.pdf', 'total_pages': 30, 'page': 29, 'page_label': '30', 'source_file': '12037624.pdf', 'file_type': 'pdf'}, page_content=\"30 \\n \\nPS6CK  (`GH', male): 30 words, 1 utterance.  \\nPS6CL  (`CM', female): 305 words, 6 utterances.  \\nPS6CM  (`LT'): 332 words, 7 utterances.  \\nKRTPS000  95 words, 1 utterance. )” \\n (see it also online for resource details: http://www.natcorp.ox.ac.uk/using/index.xml?ID=simple )\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='1\\nRetrieval-Augmented Generation for Large\\nLanguage Models: A Survey\\nYunfan Gaoa, Yun Xiongb, Xinyu Gao b, Kangxiang Jia b, Jinliu Pan b, Yuxi Bic, Yi Dai a, Jiawei Sun a, Meng\\nWangc, and Haofen Wang a,c\\naShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\\nbShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\\ncCollege of Design and Innovation, Tongji University\\nAbstract—Large Language Models (LLMs) showcase impres-\\nsive capabilities but encounter challenges like hallucination,\\noutdated knowledge, and non-transparent, untraceable reasoning\\nprocesses. Retrieval-Augmented Generation (RAG) has emerged\\nas a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the\\ngeneration, particularly for knowledge-intensive tasks, and allows\\nfor continuous knowledge updates and integration of domain-\\nspecific information. RAG synergistically merges LLMs’ intrin-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='generation, particularly for knowledge-intensive tasks, and allows\\nfor continuous knowledge updates and integration of domain-\\nspecific information. RAG synergistically merges LLMs’ intrin-\\nsic knowledge with the vast, dynamic repositories of external\\ndatabases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing\\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\\nIt meticulously scrutinizes the tripartite foundation of RAG\\nframeworks, which includes the retrieval, the generation and the\\naugmentation techniques. The paper highlights the state-of-the-\\nart technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG\\nsystems. Furthermore, this paper introduces up-to-date evalua-\\ntion framework and benchmark. At the end, this article delineates\\nthe challenges currently faced and points out prospective avenues\\nfor research and development 1.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='tion framework and benchmark. At the end, this article delineates\\nthe challenges currently faced and points out prospective avenues\\nfor research and development 1.\\nIndex Terms—Large language model, retrieval-augmented gen-\\neration, natural language processing, information retrieval\\nI. I NTRODUCTION\\nL\\nARGE language models (LLMs) have achieved remark-\\nable success, though they still face significant limitations,\\nespecially in domain-specific or knowledge-intensive tasks [1],\\nnotably producing “hallucinations” [2] when handling queries\\nbeyond their training data or requiring current information. To\\novercome challenges, Retrieval-Augmented Generation (RAG)\\nenhances LLMs by retrieving relevant document chunks from\\nexternal knowledge base through semantic similarity calcu-\\nlation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='lation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,\\nestablishing RAG as a key technology in advancing chatbots\\nand enhancing the suitability of LLMs for real-world applica-\\ntions.\\nRAG technology has rapidly developed in recent years, and\\nthe technology tree summarizing related research is shown\\nCorresponding Author.Email:haofen.wang@tongji.edu.cn\\n1Resources are available at https://github.com/Tongji-KGLLM/\\nRAG-Survey\\nin Figure 1. The development trajectory of RAG in the era\\nof large models exhibits several distinct stage characteristics.\\nInitially, RAG’s inception coincided with the rise of the\\nTransformer architecture, focusing on enhancing language\\nmodels by incorporating additional knowledge through Pre-\\nTraining Models (PTM). This early stage was characterized\\nby foundational work aimed at refining pre-training techniques'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='models by incorporating additional knowledge through Pre-\\nTraining Models (PTM). This early stage was characterized\\nby foundational work aimed at refining pre-training techniques\\n[3]–[5].The subsequent arrival of ChatGPT [6] marked a\\npivotal moment, with LLM demonstrating powerful in context\\nlearning (ICL) capabilities. RAG research shifted towards\\nproviding better information for LLMs to answer more com-\\nplex and knowledge-intensive tasks during the inference stage,\\nleading to rapid development in RAG studies. As research\\nprogressed, the enhancement of RAG was no longer limited\\nto the inference stage but began to incorporate more with LLM\\nfine-tuning techniques.\\nThe burgeoning field of RAG has experienced swift growth,\\nyet it has not been accompanied by a systematic synthesis that\\ncould clarify its broader trajectory. This survey endeavors to\\nfill this gap by mapping out the RAG process and charting\\nits evolution and anticipated future paths, with a focus on the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='could clarify its broader trajectory. This survey endeavors to\\nfill this gap by mapping out the RAG process and charting\\nits evolution and anticipated future paths, with a focus on the\\nintegration of RAG within LLMs. This paper considers both\\ntechnical paradigms and research methods, summarizing three\\nmain research paradigms from over 100 RAG studies, and\\nanalyzing key technologies in the core stages of “Retrieval,”\\n“Generation,” and “Augmentation.” On the other hand, current\\nresearch tends to focus more on methods, lacking analysis and\\nsummarization of how to evaluate RAG. This paper compre-\\nhensively reviews the downstream tasks, datasets, benchmarks,\\nand evaluation methods applicable to RAG. Overall, this\\npaper sets out to meticulously compile and categorize the\\nfoundational technical concepts, historical progression, and\\nthe spectrum of RAG methodologies and applications that\\nhave emerged post-LLMs. It is designed to equip readers and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='foundational technical concepts, historical progression, and\\nthe spectrum of RAG methodologies and applications that\\nhave emerged post-LLMs. It is designed to equip readers and\\nprofessionals with a detailed and structured understanding of\\nboth large models and RAG. It aims to illuminate the evolution\\nof retrieval augmentation techniques, assess the strengths and\\nweaknesses of various approaches in their respective contexts,\\nand speculate on upcoming trends and innovations.\\nOur contributions are as follows:\\n• In this survey, we present a thorough and systematic\\nreview of the state-of-the-art RAG methods, delineating\\nits evolution through paradigms including naive RAG,\\narXiv:2312.10997v5  [cs.CL]  27 Mar 2024'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2\\nFig. 1. Technology tree of RAG research. The stages of involving RAG mainly include pre-training, fine-tuning, and inference. With the emergence of LLMs,\\nresearch on RAG initially focused on leveraging the powerful in context learning abilities of LLMs, primarily concentrating on the inference stage. Subsequent\\nresearch has delved deeper, gradually integrating more with the fine-tuning of LLMs. Researchers have also been exploring ways to enhance language models\\nin the pre-training stage through retrieval-augmented techniques.\\nadvanced RAG, and modular RAG. This review contex-\\ntualizes the broader scope of RAG research within the\\nlandscape of LLMs.\\n• We identify and discuss the central technologies integral\\nto the RAG process, specifically focusing on the aspects\\nof “Retrieval”, “Generation” and “Augmentation”, and\\ndelve into their synergies, elucidating how these com-\\nponents intricately collaborate to form a cohesive and\\neffective RAG framework.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='of “Retrieval”, “Generation” and “Augmentation”, and\\ndelve into their synergies, elucidating how these com-\\nponents intricately collaborate to form a cohesive and\\neffective RAG framework.\\n• We have summarized the current assessment methods of\\nRAG, covering 26 tasks, nearly 50 datasets, outlining\\nthe evaluation objectives and metrics, as well as the\\ncurrent evaluation benchmarks and tools. Additionally,\\nwe anticipate future directions for RAG, emphasizing\\npotential enhancements to tackle current challenges.\\nThe paper unfolds as follows: Section II introduces the\\nmain concept and current paradigms of RAG. The following\\nthree sections explore core components—“Retrieval”, “Gen-\\neration” and “Augmentation”, respectively. Section III focuses\\non optimization methods in retrieval,including indexing, query\\nand embedding optimization. Section IV concentrates on post-\\nretrieval process and LLM fine-tuning in generation. Section V\\nanalyzes the three augmentation processes. Section VI focuses'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and embedding optimization. Section IV concentrates on post-\\nretrieval process and LLM fine-tuning in generation. Section V\\nanalyzes the three augmentation processes. Section VI focuses\\non RAG’s downstream tasks and evaluation system. Sec-\\ntion VII mainly discusses the challenges that RAG currently\\nfaces and its future development directions. At last, the paper\\nconcludes in Section VIII.\\nII. O VERVIEW OF RAG\\nA typical application of RAG is illustrated in Figure 2.\\nHere, a user poses a question to ChatGPT about a recent,\\nwidely discussed news. Given ChatGPT’s reliance on pre-\\ntraining data, it initially lacks the capacity to provide up-\\ndates on recent developments. RAG bridges this information\\ngap by sourcing and incorporating knowledge from external\\ndatabases. In this case, it gathers relevant news articles related\\nto the user’s query. These articles, combined with the original\\nquestion, form a comprehensive prompt that empowers LLMs\\nto generate a well-informed answer.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='to the user’s query. These articles, combined with the original\\nquestion, form a comprehensive prompt that empowers LLMs\\nto generate a well-informed answer.\\nThe RAG research paradigm is continuously evolving, and\\nwe categorize it into three stages: Naive RAG, Advanced\\nRAG, and Modular RAG, as showed in Figure 3. Despite\\nRAG method are cost-effective and surpass the performance\\nof the native LLM, they also exhibit several limitations.\\nThe development of Advanced RAG and Modular RAG is\\na response to these specific shortcomings in Naive RAG.\\nA. Naive RAG\\nThe Naive RAG research paradigm represents the earli-\\nest methodology, which gained prominence shortly after the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='3\\nFig. 2. A representative instance of the RAG process applied to question answering. It mainly consists of 3 steps. 1) Indexing. Documents are split into chunks,\\nencoded into vectors, and stored in a vector database. 2) Retrieval. Retrieve the Top k chunks most relevant to the question based on semantic similarity. 3)\\nGeneration. Input the original question and the retrieved chunks together into LLM to generate the final answer.\\nwidespread adoption of ChatGPT. The Naive RAG follows\\na traditional process that includes indexing, retrieval, and\\ngeneration, which is also characterized as a “Retrieve-Read”\\nframework [7].\\nIndexing starts with the cleaning and extraction of raw data\\nin diverse formats like PDF, HTML, Word, and Markdown,\\nwhich is then converted into a uniform plain text format. To\\naccommodate the context limitations of language models, text\\nis segmented into smaller, digestible chunks. Chunks are then\\nencoded into vector representations using an embedding model'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='accommodate the context limitations of language models, text\\nis segmented into smaller, digestible chunks. Chunks are then\\nencoded into vector representations using an embedding model\\nand stored in vector database. This step is crucial for enabling\\nefficient similarity searches in the subsequent retrieval phase.\\nRetrieval. Upon receipt of a user query, the RAG system\\nemploys the same encoding model utilized during the indexing\\nphase to transform the query into a vector representation.\\nIt then computes the similarity scores between the query\\nvector and the vector of chunks within the indexed corpus.\\nThe system prioritizes and retrieves the top K chunks that\\ndemonstrate the greatest similarity to the query. These chunks\\nare subsequently used as the expanded context in prompt.\\nGeneration. The posed query and selected documents are\\nsynthesized into a coherent prompt to which a large language\\nmodel is tasked with formulating a response. The model’s'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Generation. The posed query and selected documents are\\nsynthesized into a coherent prompt to which a large language\\nmodel is tasked with formulating a response. The model’s\\napproach to answering may vary depending on task-specific\\ncriteria, allowing it to either draw upon its inherent parametric\\nknowledge or restrict its responses to the information con-\\ntained within the provided documents. In cases of ongoing\\ndialogues, any existing conversational history can be integrated\\ninto the prompt, enabling the model to engage in multi-turn\\ndialogue interactions effectively.\\nHowever, Naive RAG encounters notable drawbacks:\\nRetrieval Challenges . The retrieval phase often struggles\\nwith precision and recall, leading to the selection of misaligned\\nor irrelevant chunks, and the missing of crucial information.\\nGeneration Difficulties. In generating responses, the model\\nmay face the issue of hallucination, where it produces con-\\ntent not supported by the retrieved context. This phase can'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Generation Difficulties. In generating responses, the model\\nmay face the issue of hallucination, where it produces con-\\ntent not supported by the retrieved context. This phase can\\nalso suffer from irrelevance, toxicity, or bias in the outputs,\\ndetracting from the quality and reliability of the responses.\\nAugmentation Hurdles . Integrating retrieved information\\nwith the different task can be challenging, sometimes resulting\\nin disjointed or incoherent outputs. The process may also\\nencounter redundancy when similar information is retrieved\\nfrom multiple sources, leading to repetitive responses. Deter-\\nmining the significance and relevance of various passages and\\nensuring stylistic and tonal consistency add further complexity.\\nFacing complex issues, a single retrieval based on the original\\nquery may not suffice to acquire adequate context information.\\nMoreover, there’s a concern that generation models might\\noverly rely on augmented information, leading to outputs that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='query may not suffice to acquire adequate context information.\\nMoreover, there’s a concern that generation models might\\noverly rely on augmented information, leading to outputs that\\nsimply echo retrieved content without adding insightful or\\nsynthesized information.\\nB. Advanced RAG\\nAdvanced RAG introduces specific improvements to over-\\ncome the limitations of Naive RAG. Focusing on enhancing re-\\ntrieval quality, it employs pre-retrieval and post-retrieval strate-\\ngies. To tackle the indexing issues, Advanced RAG refines\\nits indexing techniques through the use of a sliding window\\napproach, fine-grained segmentation, and the incorporation of\\nmetadata. Additionally, it incorporates several optimization\\nmethods to streamline the retrieval process [8].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='4\\nFig. 3. Comparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\\nchain-like structure. (Right) Modular RAG inherits and develops from the previous paradigm, showcasing greater flexibility overall. This is evident in the\\nintroduction of multiple specific functional modules and the replacement of existing modules. The overall process is not limited to sequential retrieval and\\ngeneration; it includes methods such as iterative and adaptive retrieval.\\nPre-retrieval process. In this stage, the primary focus is\\non optimizing the indexing structure and the original query.\\nThe goal of optimizing indexing is to enhance the quality of\\nthe content being indexed. This involves strategies: enhancing\\ndata granularity, optimizing index structures, adding metadata,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='The goal of optimizing indexing is to enhance the quality of\\nthe content being indexed. This involves strategies: enhancing\\ndata granularity, optimizing index structures, adding metadata,\\nalignment optimization, and mixed retrieval. While the goal\\nof query optimization is to make the user’s original question\\nclearer and more suitable for the retrieval task. Common\\nmethods include query rewriting query transformation, query\\nexpansion and other techniques [7], [9]–[11].\\nPost-Retrieval Process. Once relevant context is retrieved,\\nit’s crucial to integrate it effectively with the query. The main\\nmethods in post-retrieval process include rerank chunks and\\ncontext compressing. Re-ranking the retrieved information to\\nrelocate the most relevant content to the edges of the prompt is\\na key strategy. This concept has been implemented in frame-\\nworks such as LlamaIndex 2, LangChain3, and HayStack [12].\\nFeeding all relevant documents directly into LLMs can lead'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='a key strategy. This concept has been implemented in frame-\\nworks such as LlamaIndex 2, LangChain3, and HayStack [12].\\nFeeding all relevant documents directly into LLMs can lead\\nto information overload, diluting the focus on key details with\\nirrelevant content.To mitigate this, post-retrieval efforts con-\\ncentrate on selecting the essential information, emphasizing\\ncritical sections, and shortening the context to be processed.\\n2https://www.llamaindex.ai\\n3https://www.langchain.com/\\nC. Modular RAG\\nThe modular RAG architecture advances beyond the for-\\nmer two RAG paradigms, offering enhanced adaptability and\\nversatility. It incorporates diverse strategies for improving its\\ncomponents, such as adding a search module for similarity\\nsearches and refining the retriever through fine-tuning. Inno-\\nvations like restructured RAG modules [13] and rearranged\\nRAG pipelines [14] have been introduced to tackle specific\\nchallenges. The shift towards a modular RAG approach is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='vations like restructured RAG modules [13] and rearranged\\nRAG pipelines [14] have been introduced to tackle specific\\nchallenges. The shift towards a modular RAG approach is\\nbecoming prevalent, supporting both sequential processing and\\nintegrated end-to-end training across its components. Despite\\nits distinctiveness, Modular RAG builds upon the foundational\\nprinciples of Advanced and Naive RAG, illustrating a progres-\\nsion and refinement within the RAG family.\\n1) New Modules: The Modular RAG framework introduces\\nadditional specialized components to enhance retrieval and\\nprocessing capabilities. The Search module adapts to spe-\\ncific scenarios, enabling direct searches across various data\\nsources like search engines, databases, and knowledge graphs,\\nusing LLM-generated code and query languages [15]. RAG-\\nFusion addresses traditional search limitations by employing\\na multi-query strategy that expands user queries into diverse'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='using LLM-generated code and query languages [15]. RAG-\\nFusion addresses traditional search limitations by employing\\na multi-query strategy that expands user queries into diverse\\nperspectives, utilizing parallel vector searches and intelligent\\nre-ranking to uncover both explicit and transformative knowl-\\nedge [16]. The Memory module leverages the LLM’s memory\\nto guide retrieval, creating an unbounded memory pool that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='5\\naligns the text more closely with data distribution through iter-\\native self-enhancement [17], [18]. Routing in the RAG system\\nnavigates through diverse data sources, selecting the optimal\\npathway for a query, whether it involves summarization,\\nspecific database searches, or merging different information\\nstreams [19]. The Predict module aims to reduce redundancy\\nand noise by generating context directly through the LLM,\\nensuring relevance and accuracy [13]. Lastly, the Task Adapter\\nmodule tailors RAG to various downstream tasks, automating\\nprompt retrieval for zero-shot inputs and creating task-specific\\nretrievers through few-shot query generation [20], [21] .This\\ncomprehensive approach not only streamlines the retrieval pro-\\ncess but also significantly improves the quality and relevance\\nof the information retrieved, catering to a wide array of tasks\\nand queries with enhanced precision and flexibility.\\n2) New Patterns: Modular RAG offers remarkable adapt-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='of the information retrieved, catering to a wide array of tasks\\nand queries with enhanced precision and flexibility.\\n2) New Patterns: Modular RAG offers remarkable adapt-\\nability by allowing module substitution or reconfiguration\\nto address specific challenges. This goes beyond the fixed\\nstructures of Naive and Advanced RAG, characterized by a\\nsimple “Retrieve” and “Read” mechanism. Moreover, Modular\\nRAG expands this flexibility by integrating new modules or\\nadjusting interaction flow among existing ones, enhancing its\\napplicability across different tasks.\\nInnovations such as the Rewrite-Retrieve-Read [7]model\\nleverage the LLM’s capabilities to refine retrieval queries\\nthrough a rewriting module and a LM-feedback mechanism\\nto update rewriting model., improving task performance.\\nSimilarly, approaches like Generate-Read [13] replace tradi-\\ntional retrieval with LLM-generated content, while Recite-\\nRead [22] emphasizes retrieval from model weights, enhanc-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Similarly, approaches like Generate-Read [13] replace tradi-\\ntional retrieval with LLM-generated content, while Recite-\\nRead [22] emphasizes retrieval from model weights, enhanc-\\ning the model’s ability to handle knowledge-intensive tasks.\\nHybrid retrieval strategies integrate keyword, semantic, and\\nvector searches to cater to diverse queries. Additionally, em-\\nploying sub-queries and hypothetical document embeddings\\n(HyDE) [11] seeks to improve retrieval relevance by focusing\\non embedding similarities between generated answers and real\\ndocuments.\\nAdjustments in module arrangement and interaction, such\\nas the Demonstrate-Search-Predict (DSP) [23] framework\\nand the iterative Retrieve-Read-Retrieve-Read flow of ITER-\\nRETGEN [14], showcase the dynamic use of module out-\\nputs to bolster another module’s functionality, illustrating a\\nsophisticated understanding of enhancing module synergy.\\nThe flexible orchestration of Modular RAG Flow showcases'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='puts to bolster another module’s functionality, illustrating a\\nsophisticated understanding of enhancing module synergy.\\nThe flexible orchestration of Modular RAG Flow showcases\\nthe benefits of adaptive retrieval through techniques such as\\nFLARE [24] and Self-RAG [25]. This approach transcends\\nthe fixed RAG retrieval process by evaluating the necessity\\nof retrieval based on different scenarios. Another benefit of\\na flexible architecture is that the RAG system can more\\neasily integrate with other technologies (such as fine-tuning\\nor reinforcement learning) [26]. For example, this can involve\\nfine-tuning the retriever for better retrieval results, fine-tuning\\nthe generator for more personalized outputs, or engaging in\\ncollaborative fine-tuning [27].\\nD. RAG vs Fine-tuning\\nThe augmentation of LLMs has attracted considerable atten-\\ntion due to their growing prevalence. Among the optimization\\nmethods for LLMs, RAG is often compared with Fine-tuning'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='D. RAG vs Fine-tuning\\nThe augmentation of LLMs has attracted considerable atten-\\ntion due to their growing prevalence. Among the optimization\\nmethods for LLMs, RAG is often compared with Fine-tuning\\n(FT) and prompt engineering. Each method has distinct charac-\\nteristics as illustrated in Figure 4. We used a quadrant chart to\\nillustrate the differences among three methods in two dimen-\\nsions: external knowledge requirements and model adaption\\nrequirements. Prompt engineering leverages a model’s inherent\\ncapabilities with minimum necessity for external knowledge\\nand model adaption. RAG can be likened to providing a model\\nwith a tailored textbook for information retrieval, ideal for pre-\\ncise information retrieval tasks. In contrast, FT is comparable\\nto a student internalizing knowledge over time, suitable for\\nscenarios requiring replication of specific structures, styles, or\\nformats.\\nRAG excels in dynamic environments by offering real-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='to a student internalizing knowledge over time, suitable for\\nscenarios requiring replication of specific structures, styles, or\\nformats.\\nRAG excels in dynamic environments by offering real-\\ntime knowledge updates and effective utilization of external\\nknowledge sources with high interpretability. However, it\\ncomes with higher latency and ethical considerations regarding\\ndata retrieval. On the other hand, FT is more static, requiring\\nretraining for updates but enabling deep customization of the\\nmodel’s behavior and style. It demands significant compu-\\ntational resources for dataset preparation and training, and\\nwhile it can reduce hallucinations, it may face challenges with\\nunfamiliar data.\\nIn multiple evaluations of their performance on various\\nknowledge-intensive tasks across different topics, [28] re-\\nvealed that while unsupervised fine-tuning shows some im-\\nprovement, RAG consistently outperforms it, for both exist-\\ning knowledge encountered during training and entirely new'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='vealed that while unsupervised fine-tuning shows some im-\\nprovement, RAG consistently outperforms it, for both exist-\\ning knowledge encountered during training and entirely new\\nknowledge. Additionally, it was found that LLMs struggle\\nto learn new factual information through unsupervised fine-\\ntuning. The choice between RAG and FT depends on the\\nspecific needs for data dynamics, customization, and com-\\nputational capabilities in the application context. RAG and\\nFT are not mutually exclusive and can complement each\\nother, enhancing a model’s capabilities at different levels.\\nIn some instances, their combined use may lead to optimal\\nperformance. The optimization process involving RAG and FT\\nmay require multiple iterations to achieve satisfactory results.\\nIII. R ETRIEVAL\\nIn the context of RAG, it is crucial to efficiently retrieve\\nrelevant documents from the data source. There are several\\nkey issues involved, such as the retrieval source, retrieval'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='III. R ETRIEVAL\\nIn the context of RAG, it is crucial to efficiently retrieve\\nrelevant documents from the data source. There are several\\nkey issues involved, such as the retrieval source, retrieval\\ngranularity, pre-processing of the retrieval, and selection of\\nthe corresponding embedding model.\\nA. Retrieval Source\\nRAG relies on external knowledge to enhance LLMs, while\\nthe type of retrieval source and the granularity of retrieval\\nunits both affect the final generation results.\\n1) Data Structure: Initially, text is s the mainstream source\\nof retrieval. Subsequently, the retrieval source expanded to in-\\nclude semi-structured data (PDF) and structured data (Knowl-\\nedge Graph, KG) for enhancement. In addition to retrieving\\nfrom original external sources, there is also a growing trend in\\nrecent researches towards utilizing content generated by LLMs\\nthemselves for retrieval and enhancement purposes.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='6\\nTABLE I\\nSUMMARY OF RAG METHODS\\nMethod Retrieval Source Retrieval\\nData Type\\nRetrieval\\nGranularity\\nAugmentation\\nStage\\nRetrieval\\nprocess\\nCoG [29] Wikipedia Text Phrase Pre-training Iterative\\nDenseX [30] FactoidWiki Text Proposition Inference Once\\nEAR [31] Dataset-base Text Sentence Tuning Once\\nUPRISE [20] Dataset-base Text Sentence Tuning Once\\nRAST [32] Dataset-base Text Sentence Tuning Once\\nSelf-Mem [17] Dataset-base Text Sentence Tuning Iterative\\nFLARE [24] Search Engine,Wikipedia Text Sentence Tuning Adaptive\\nPGRA [33] Wikipedia Text Sentence Inference Once\\nFILCO [34] Wikipedia Text Sentence Inference Once\\nRADA [35] Dataset-base Text Sentence Inference Once\\nFilter-rerank [36] Synthesized dataset Text Sentence Inference Once\\nR-GQA [37] Dataset-base Text Sentence Pair Tuning Once\\nLLM-R [38] Dataset-base Text Sentence Pair Inference Iterative\\nTIGER [39] Dataset-base Text Item-base Pre-training Once\\nLM-Indexer [40] Dataset-base Text Item-base Tuning Once'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='LLM-R [38] Dataset-base Text Sentence Pair Inference Iterative\\nTIGER [39] Dataset-base Text Item-base Pre-training Once\\nLM-Indexer [40] Dataset-base Text Item-base Tuning Once\\nBEQUE [9] Dataset-base Text Item-base Tuning Once\\nCT-RAG [41] Synthesized dataset Text Item-base Tuning Once\\nAtlas [42] Wikipedia, Common Crawl Text Chunk Pre-training Iterative\\nRA VEN [43] Wikipedia Text Chunk Pre-training Once\\nRETRO++ [44] Pre-training Corpus Text Chunk Pre-training Iterative\\nINSTRUCTRETRO [45] Pre-training corpus Text Chunk Pre-training Iterative\\nRRR [7] Search Engine Text Chunk Tuning Once\\nRA-e2e [46] Dataset-base Text Chunk Tuning Once\\nPROMPTAGATOR [21] BEIR Text Chunk Tuning Once\\nAAR [47] MSMARCO,Wikipedia Text Chunk Tuning Once\\nRA-DIT [27] Common Crawl,Wikipedia Text Chunk Tuning Once\\nRAG-Robust [48] Wikipedia Text Chunk Tuning Once\\nRA-Long-Form [49] Dataset-base Text Chunk Tuning Once\\nCoN [50] Wikipedia Text Chunk Tuning Once\\nSelf-RAG [25] Wikipedia Text Chunk Tuning Adaptive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='RAG-Robust [48] Wikipedia Text Chunk Tuning Once\\nRA-Long-Form [49] Dataset-base Text Chunk Tuning Once\\nCoN [50] Wikipedia Text Chunk Tuning Once\\nSelf-RAG [25] Wikipedia Text Chunk Tuning Adaptive\\nBGM [26] Wikipedia Text Chunk Inference Once\\nCoQ [51] Wikipedia Text Chunk Inference Iterative\\nToken-Elimination [52] Wikipedia Text Chunk Inference Once\\nPaperQA [53] Arxiv,Online Database,PubMed Text Chunk Inference Iterative\\nNoiseRAG [54] FactoidWiki Text Chunk Inference Once\\nIAG [55] Search Engine,Wikipedia Text Chunk Inference Once\\nNoMIRACL [56] Wikipedia Text Chunk Inference Once\\nToC [57] Search Engine,Wikipedia Text Chunk Inference Recursive\\nSKR [58] Dataset-base,Wikipedia Text Chunk Inference Adaptive\\nITRG [59] Wikipedia Text Chunk Inference Iterative\\nRAG-LongContext [60] Dataset-base Text Chunk Inference Once\\nITER-RETGEN [14] Wikipedia Text Chunk Inference Iterative\\nIRCoT [61] Wikipedia Text Chunk Inference Recursive\\nLLM-Knowledge-Boundary [62] Wikipedia Text Chunk Inference Once'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='ITER-RETGEN [14] Wikipedia Text Chunk Inference Iterative\\nIRCoT [61] Wikipedia Text Chunk Inference Recursive\\nLLM-Knowledge-Boundary [62] Wikipedia Text Chunk Inference Once\\nRAPTOR [63] Dataset-base Text Chunk Inference Recursive\\nRECITE [22] LLMs Text Chunk Inference Once\\nICRALM [64] Pile,Wikipedia Text Chunk Inference Iterative\\nRetrieve-and-Sample [65] Dataset-base Text Doc Tuning Once\\nZemi [66] C4 Text Doc Tuning Once\\nCRAG [67] Arxiv Text Doc Inference Once\\n1-PAGER [68] Wikipedia Text Doc Inference Iterative\\nPRCA [69] Dataset-base Text Doc Inference Once\\nQLM-Doc-ranking [70] Dataset-base Text Doc Inference Once\\nRecomp [71] Wikipedia Text Doc Inference Once\\nDSP [23] Wikipedia Text Doc Inference Iterative\\nRePLUG [72] Pile Text Doc Inference Once\\nARM-RAG [73] Dataset-base Text Doc Inference Iterative\\nGenRead [13] LLMs Text Doc Inference Iterative\\nUniMS-RAG [74] Dataset-base Text Multi Tuning Once\\nCREA-ICL [19] Dataset-base Crosslingual,Text Sentence Inference Once'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='GenRead [13] LLMs Text Doc Inference Iterative\\nUniMS-RAG [74] Dataset-base Text Multi Tuning Once\\nCREA-ICL [19] Dataset-base Crosslingual,Text Sentence Inference Once\\nPKG [75] LLM Tabular,Text Chunk Inference Once\\nSANTA [76] Dataset-base Code,Text Item Pre-training Once\\nSURGE [77] Freebase KG Sub-Graph Tuning Once\\nMK-ToD [78] Dataset-base KG Entity Tuning Once\\nDual-Feedback-ToD [79] Dataset-base KG Entity Sequence Tuning Once\\nKnowledGPT [15] Dataset-base KG Triplet Inference Muti-time\\nFABULA [80] Dataset-base,Graph KG Entity Inference Once\\nHyKGE [81] CMeKG KG Entity Inference Once\\nKALMV [82] Wikipedia KG Triplet Inference Iterative\\nRoG [83] Freebase KG Triplet Inference Iterative\\nG-Retriever [84] Dataset-base TextGraph Sub-Graph Inference Once'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='7\\nFig. 4. RAG compared with other model optimization methods in the aspects of “External Knowledge Required” and “Model Adaption Required”. Prompt\\nEngineering requires low modifications to the model and external knowledge, focusing on harnessing the capabilities of LLMs themselves. Fine-tuning, on\\nthe other hand, involves further training the model. In the early stages of RAG (Naive RAG), there is a low demand for model modifications. As research\\nprogresses, Modular RAG has become more integrated with fine-tuning techniques.\\nUnstructured Data , such as text, is the most widely used\\nretrieval source, which are mainly gathered from corpus. For\\nopen-domain question-answering (ODQA) tasks, the primary\\nretrieval sources are Wikipedia Dump with the current major\\nversions including HotpotQA 4 (1st October , 2017), DPR5 (20\\nDecember, 2018). In addition to encyclopedic data, common\\nunstructured data includes cross-lingual text [19] and domain-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='versions including HotpotQA 4 (1st October , 2017), DPR5 (20\\nDecember, 2018). In addition to encyclopedic data, common\\nunstructured data includes cross-lingual text [19] and domain-\\nspecific data (such as medical [67]and legal domains [29]).\\nSemi-structured data. typically refers to data that contains a\\ncombination of text and table information, such as PDF. Han-\\ndling semi-structured data poses challenges for conventional\\nRAG systems due to two main reasons. Firstly, text splitting\\nprocesses may inadvertently separate tables, leading to data\\ncorruption during retrieval. Secondly, incorporating tables into\\nthe data can complicate semantic similarity searches. When\\ndealing with semi-structured data, one approach involves lever-\\naging the code capabilities of LLMs to execute Text-2-SQL\\nqueries on tables within databases, such as TableGPT [85].\\nAlternatively, tables can be transformed into text format for\\nfurther analysis using text-based methods [75]. However, both'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='queries on tables within databases, such as TableGPT [85].\\nAlternatively, tables can be transformed into text format for\\nfurther analysis using text-based methods [75]. However, both\\nof these methods are not optimal solutions, indicating substan-\\ntial research opportunities in this area.\\nStructured data , such as knowledge graphs (KGs) [86] ,\\nwhich are typically verified and can provide more precise in-\\nformation. KnowledGPT [15] generates KB search queries and\\nstores knowledge in a personalized base, enhancing the RAG\\nmodel’s knowledge richness. In response to the limitations of\\nLLMs in understanding and answering questions about textual\\ngraphs, G-Retriever [84] integrates Graph Neural Networks\\n4https://hotpotqa.github.io/wiki-readme.html\\n5https://github.com/facebookresearch/DPR\\n(GNNs), LLMs and RAG, enhancing graph comprehension\\nand question-answering capabilities through soft prompting\\nof the LLM, and employs the Prize-Collecting Steiner Tree'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='(GNNs), LLMs and RAG, enhancing graph comprehension\\nand question-answering capabilities through soft prompting\\nof the LLM, and employs the Prize-Collecting Steiner Tree\\n(PCST) optimization problem for targeted graph retrieval. On\\nthe contrary, it requires additional effort to build, validate,\\nand maintain structured databases. On the contrary, it requires\\nadditional effort to build, validate, and maintain structured\\ndatabases.\\nLLMs-Generated Content. Addressing the limitations of\\nexternal auxiliary information in RAG, some research has\\nfocused on exploiting LLMs’ internal knowledge. SKR [58]\\nclassifies questions as known or unknown, applying retrieval\\nenhancement selectively. GenRead [13] replaces the retriever\\nwith an LLM generator, finding that LLM-generated contexts\\noften contain more accurate answers due to better alignment\\nwith the pre-training objectives of causal language modeling.\\nSelfmem [17] iteratively creates an unbounded memory pool'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='often contain more accurate answers due to better alignment\\nwith the pre-training objectives of causal language modeling.\\nSelfmem [17] iteratively creates an unbounded memory pool\\nwith a retrieval-enhanced generator, using a memory selec-\\ntor to choose outputs that serve as dual problems to the\\noriginal question, thus self-enhancing the generative model.\\nThese methodologies underscore the breadth of innovative\\ndata source utilization in RAG, striving to improve model\\nperformance and task effectiveness.\\n2) Retrieval Granularity: Another important factor besides\\nthe data format of the retrieval source is the granularity of\\nthe retrieved data. Coarse-grained retrieval units theoretically\\ncan provide more relevant information for the problem, but\\nthey may also contain redundant content, which could distract\\nthe retriever and language models in downstream tasks [50],\\n[87]. On the other hand, fine-grained retrieval unit granularity'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='they may also contain redundant content, which could distract\\nthe retriever and language models in downstream tasks [50],\\n[87]. On the other hand, fine-grained retrieval unit granularity\\nincreases the burden of retrieval and does not guarantee seman-\\ntic integrity and meeting the required knowledge. Choosing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='8\\nthe appropriate retrieval granularity during inference can be\\na simple and effective strategy to improve the retrieval and\\ndownstream task performance of dense retrievers.\\nIn text, retrieval granularity ranges from fine to coarse,\\nincluding Token, Phrase, Sentence, Proposition, Chunks, Doc-\\nument. Among them, DenseX [30]proposed the concept of\\nusing propositions as retrieval units. Propositions are defined\\nas atomic expressions in the text, each encapsulating a unique\\nfactual segment and presented in a concise, self-contained nat-\\nural language format. This approach aims to enhance retrieval\\nprecision and relevance. On the Knowledge Graph (KG),\\nretrieval granularity includes Entity, Triplet, and sub-Graph.\\nThe granularity of retrieval can also be adapted to downstream\\ntasks, such as retrieving Item IDs [40]in recommendation tasks\\nand Sentence pairs [38]. Detailed information is illustrated in\\nTable I.\\nB. Indexing Optimization\\nIn the Indexing phase, documents will be processed, seg-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and Sentence pairs [38]. Detailed information is illustrated in\\nTable I.\\nB. Indexing Optimization\\nIn the Indexing phase, documents will be processed, seg-\\nmented, and transformed into Embeddings to be stored in a\\nvector database. The quality of index construction determines\\nwhether the correct context can be obtained in the retrieval\\nphase.\\n1) Chunking Strategy: The most common method is to split\\nthe document into chunks on a fixed number of tokens (e.g.,\\n100, 256, 512) [88]. Larger chunks can capture more context,\\nbut they also generate more noise, requiring longer processing\\ntime and higher costs. While smaller chunks may not fully\\nconvey the necessary context, they do have less noise. How-\\never, chunks leads to truncation within sentences, prompting\\nthe optimization of a recursive splits and sliding window meth-\\nods, enabling layered retrieval by merging globally related\\ninformation across multiple retrieval processes [89]. Never-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='the optimization of a recursive splits and sliding window meth-\\nods, enabling layered retrieval by merging globally related\\ninformation across multiple retrieval processes [89]. Never-\\ntheless, these approaches still cannot strike a balance between\\nsemantic completeness and context length. Therefore, methods\\nlike Small2Big have been proposed, where sentences (small)\\nare used as the retrieval unit, and the preceding and following\\nsentences are provided as (big) context to LLMs [90].\\n2) Metadata Attachments: Chunks can be enriched with\\nmetadata information such as page number, file name, au-\\nthor,category timestamp. Subsequently, retrieval can be filtered\\nbased on this metadata, limiting the scope of the retrieval.\\nAssigning different weights to document timestamps during\\nretrieval can achieve time-aware RAG, ensuring the freshness\\nof knowledge and avoiding outdated information.\\nIn addition to extracting metadata from the original doc-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='retrieval can achieve time-aware RAG, ensuring the freshness\\nof knowledge and avoiding outdated information.\\nIn addition to extracting metadata from the original doc-\\numents, metadata can also be artificially constructed. For\\nexample, adding summaries of paragraph, as well as intro-\\nducing hypothetical questions. This method is also known as\\nReverse HyDE. Specifically, using LLM to generate questions\\nthat can be answered by the document, then calculating the\\nsimilarity between the original question and the hypothetical\\nquestion during retrieval to reduce the semantic gap between\\nthe question and the answer.\\n3) Structural Index: One effective method for enhancing\\ninformation retrieval is to establish a hierarchical structure for\\nthe documents. By constructing In structure, RAG system can\\nexpedite the retrieval and processing of pertinent data.\\nHierarchical index structure . File are arranged in parent-\\nchild relationships, with chunks linked to them. Data sum-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='expedite the retrieval and processing of pertinent data.\\nHierarchical index structure . File are arranged in parent-\\nchild relationships, with chunks linked to them. Data sum-\\nmaries are stored at each node, aiding in the swift traversal\\nof data and assisting the RAG system in determining which\\nchunks to extract. This approach can also mitigate the illusion\\ncaused by block extraction issues.\\nKnowledge Graph index . Utilize KG in constructing the\\nhierarchical structure of documents contributes to maintaining\\nconsistency. It delineates the connections between different\\nconcepts and entities, markedly reducing the potential for\\nillusions. Another advantage is the transformation of the\\ninformation retrieval process into instructions that LLM can\\ncomprehend, thereby enhancing the accuracy of knowledge\\nretrieval and enabling LLM to generate contextually coherent\\nresponses, thus improving the overall efficiency of the RAG\\nsystem. To capture the logical relationship between document'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='retrieval and enabling LLM to generate contextually coherent\\nresponses, thus improving the overall efficiency of the RAG\\nsystem. To capture the logical relationship between document\\ncontent and structure, KGP [91] proposed a method of building\\nan index between multiple documents using KG. This KG\\nconsists of nodes (representing paragraphs or structures in the\\ndocuments, such as pages and tables) and edges (indicating\\nsemantic/lexical similarity between paragraphs or relationships\\nwithin the document structure), effectively addressing knowl-\\nedge retrieval and reasoning problems in a multi-document\\nenvironment.\\nC. Query Optimization\\nOne of the primary challenges with Naive RAG is its\\ndirect reliance on the user’s original query as the basis for\\nretrieval. Formulating a precise and clear question is difficult,\\nand imprudent queries result in subpar retrieval effectiveness.\\nSometimes, the question itself is complex, and the language'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='retrieval. Formulating a precise and clear question is difficult,\\nand imprudent queries result in subpar retrieval effectiveness.\\nSometimes, the question itself is complex, and the language\\nis not well-organized. Another difficulty lies in language\\ncomplexity ambiguity. Language models often struggle when\\ndealing with specialized vocabulary or ambiguous abbrevi-\\nations with multiple meanings. For instance, they may not\\ndiscern whether “LLM” refers to large language model or a\\nMaster of Laws in a legal context.\\n1) Query Expansion: Expanding a single query into mul-\\ntiple queries enriches the content of the query, providing\\nfurther context to address any lack of specific nuances, thereby\\nensuring the optimal relevance of the generated answers.\\nMulti-Query. By employing prompt engineering to expand\\nqueries via LLMs, these queries can then be executed in\\nparallel. The expansion of queries is not random, but rather\\nmeticulously designed.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Multi-Query. By employing prompt engineering to expand\\nqueries via LLMs, these queries can then be executed in\\nparallel. The expansion of queries is not random, but rather\\nmeticulously designed.\\nSub-Query. The process of sub-question planning represents\\nthe generation of the necessary sub-questions to contextualize\\nand fully answer the original question when combined. This\\nprocess of adding relevant context is, in principle, similar\\nto query expansion. Specifically, a complex question can be\\ndecomposed into a series of simpler sub-questions using the\\nleast-to-most prompting method [92].\\nChain-of-Verification(CoVe). The expanded queries undergo\\nvalidation by LLM to achieve the effect of reducing halluci-\\nnations. Validated expanded queries typically exhibit higher\\nreliability [93].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='9\\n2) Query Transformation: The core concept is to retrieve\\nchunks based on a transformed query instead of the user’s\\noriginal query.\\nQuery Rewrite.The original queries are not always optimal\\nfor LLM retrieval, especially in real-world scenarios. There-\\nfore, we can prompt LLM to rewrite the queries. In addition to\\nusing LLM for query rewriting, specialized smaller language\\nmodels, such as RRR (Rewrite-retrieve-read) [7]. The imple-\\nmentation of the query rewrite method in the Taobao, known\\nas BEQUE [9] has notably enhanced recall effectiveness for\\nlong-tail queries, resulting in a rise in GMV .\\nAnother query transformation method is to use prompt\\nengineering to let LLM generate a query based on the original\\nquery for subsequent retrieval. HyDE [11] construct hypothet-\\nical documents (assumed answers to the original query). It\\nfocuses on embedding similarity from answer to answer rather\\nthan seeking embedding similarity for the problem or query.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='ical documents (assumed answers to the original query). It\\nfocuses on embedding similarity from answer to answer rather\\nthan seeking embedding similarity for the problem or query.\\nUsing the Step-back Prompting method [10], the original\\nquery is abstracted to generate a high-level concept question\\n(step-back question). In the RAG system, both the step-back\\nquestion and the original query are used for retrieval, and both\\nthe results are utilized as the basis for language model answer\\ngeneration.\\n3) Query Routing: Based on varying queries, routing to\\ndistinct RAG pipeline,which is suitable for a versatile RAG\\nsystem designed to accommodate diverse scenarios.\\nMetadata Router/ Filter . The first step involves extracting\\nkeywords (entity) from the query, followed by filtering based\\non the keywords and metadata within the chunks to narrow\\ndown the search scope.\\nSemantic Router is another method of routing involves\\nleveraging the semantic information of the query. Specific'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='on the keywords and metadata within the chunks to narrow\\ndown the search scope.\\nSemantic Router is another method of routing involves\\nleveraging the semantic information of the query. Specific\\napprach see Semantic Router 6. Certainly, a hybrid routing\\napproach can also be employed, combining both semantic and\\nmetadata-based methods for enhanced query routing.\\nD. Embedding\\nIn RAG, retrieval is achieved by calculating the similarity\\n(e.g. cosine similarity) between the embeddings of the ques-\\ntion and document chunks, where the semantic representation\\ncapability of embedding models plays a key role. This mainly\\nincludes a sparse encoder (BM25) and a dense retriever (BERT\\narchitecture Pre-training language models). Recent research\\nhas introduced prominent embedding models such as AngIE,\\nV oyage, BGE,etc [94]–[96], which are benefit from multi-task\\ninstruct tuning. Hugging Face’s MTEB leaderboard 7 evaluates\\nembedding models across 8 tasks, covering 58 datasests. Ad-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='V oyage, BGE,etc [94]–[96], which are benefit from multi-task\\ninstruct tuning. Hugging Face’s MTEB leaderboard 7 evaluates\\nembedding models across 8 tasks, covering 58 datasests. Ad-\\nditionally, C-MTEB focuses on Chinese capability, covering\\n6 tasks and 35 datasets. There is no one-size-fits-all answer\\nto “which embedding model to use.” However, some specific\\nmodels are better suited for particular use cases.\\n1) Mix/hybrid Retrieval : Sparse and dense embedding\\napproaches capture different relevance features and can ben-\\nefit from each other by leveraging complementary relevance\\ninformation. For instance, sparse retrieval models can be used\\n6https://github.com/aurelio-labs/semantic-router\\n7https://huggingface.co/spaces/mteb/leaderboard\\nto provide initial search results for training dense retrieval\\nmodels. Additionally, pre-training language models (PLMs)\\ncan be utilized to learn term weights to enhance sparse\\nretrieval. Specifically, it also demonstrates that sparse retrieval'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='models. Additionally, pre-training language models (PLMs)\\ncan be utilized to learn term weights to enhance sparse\\nretrieval. Specifically, it also demonstrates that sparse retrieval\\nmodels can enhance the zero-shot retrieval capability of dense\\nretrieval models and assist dense retrievers in handling queries\\ncontaining rare entities, thereby improving robustness.\\n2) Fine-tuning Embedding Model: In instances where the\\ncontext significantly deviates from pre-training corpus, partic-\\nularly within highly specialized disciplines such as healthcare,\\nlegal practice, and other sectors replete with proprietary jargon,\\nfine-tuning the embedding model on your own domain dataset\\nbecomes essential to mitigate such discrepancies.\\nIn addition to supplementing domain knowledge, another\\npurpose of fine-tuning is to align the retriever and generator,\\nfor example, using the results of LLM as the supervision signal\\nfor fine-tuning, known as LSR (LM-supervised Retriever).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='purpose of fine-tuning is to align the retriever and generator,\\nfor example, using the results of LLM as the supervision signal\\nfor fine-tuning, known as LSR (LM-supervised Retriever).\\nPROMPTAGATOR [21] utilizes the LLM as a few-shot query\\ngenerator to create task-specific retrievers, addressing chal-\\nlenges in supervised fine-tuning, particularly in data-scarce\\ndomains. Another approach, LLM-Embedder [97], exploits\\nLLMs to generate reward signals across multiple downstream\\ntasks. The retriever is fine-tuned with two types of supervised\\nsignals: hard labels for the dataset and soft rewards from\\nthe LLMs. This dual-signal approach fosters a more effective\\nfine-tuning process, tailoring the embedding model to diverse\\ndownstream applications. REPLUG [72] utilizes a retriever\\nand an LLM to calculate the probability distributions of the\\nretrieved documents and then performs supervised training\\nby computing the KL divergence. This straightforward and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and an LLM to calculate the probability distributions of the\\nretrieved documents and then performs supervised training\\nby computing the KL divergence. This straightforward and\\neffective training method enhances the performance of the\\nretrieval model by using an LM as the supervisory signal,\\neliminating the need for specific cross-attention mechanisms.\\nMoreover, inspired by RLHF (Reinforcement Learning from\\nHuman Feedback), utilizing LM-based feedback to reinforce\\nthe retriever through reinforcement learning.\\nE. Adapter\\nFine-tuning models may present challenges, such as in-\\ntegrating functionality through an API or addressing con-\\nstraints arising from limited local computational resources.\\nConsequently, some approaches opt to incorporate an external\\nadapter to aid in alignment.\\nTo optimize the multi-task capabilities of LLM, UP-\\nRISE [20] trained a lightweight prompt retriever that can\\nautomatically retrieve prompts from a pre-built prompt pool'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='adapter to aid in alignment.\\nTo optimize the multi-task capabilities of LLM, UP-\\nRISE [20] trained a lightweight prompt retriever that can\\nautomatically retrieve prompts from a pre-built prompt pool\\nthat are suitable for a given zero-shot task input. AAR\\n(Augmentation-Adapted Retriver) [47] introduces a universal\\nadapter designed to accommodate multiple downstream tasks.\\nWhile PRCA [69] add a pluggable reward-driven contextual\\nadapter to enhance performance on specific tasks. BGM [26]\\nkeeps the retriever and LLM fixed,and trains a bridge Seq2Seq\\nmodel in between. The bridge model aims to transform the\\nretrieved information into a format that LLMs can work with\\neffectively, allowing it to not only rerank but also dynami-\\ncally select passages for each query, and potentially employ\\nmore advanced strategies like repetition. Furthermore, PKG'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='10\\nintroduces an innovative method for integrating knowledge\\ninto white-box models via directive fine-tuning [75]. In this\\napproach, the retriever module is directly substituted to gen-\\nerate relevant documents according to a query. This method\\nassists in addressing the difficulties encountered during the\\nfine-tuning process and enhances model performance.\\nIV. G ENERATION\\nAfter retrieval, it is not a good practice to directly input all\\nthe retrieved information to the LLM for answering questions.\\nFollowing will introduce adjustments from two perspectives:\\nadjusting the retrieved content and adjusting the LLM.\\nA. Context Curation\\nRedundant information can interfere with the final gener-\\nation of LLM, and overly long contexts can also lead LLM\\nto the “Lost in the middle” problem [98]. Like humans, LLM\\ntends to only focus on the beginning and end of long texts,\\nwhile forgetting the middle portion. Therefore, in the RAG\\nsystem, we typically need to further process the retrieved\\ncontent.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='tends to only focus on the beginning and end of long texts,\\nwhile forgetting the middle portion. Therefore, in the RAG\\nsystem, we typically need to further process the retrieved\\ncontent.\\n1) Reranking: Reranking fundamentally reorders document\\nchunks to highlight the most pertinent results first, effectively\\nreducing the overall document pool, severing a dual purpose\\nin information retrieval, acting as both an enhancer and a\\nfilter, delivering refined inputs for more precise language\\nmodel processing [70]. Reranking can be performed using\\nrule-based methods that depend on predefined metrics like\\nDiversity, Relevance, and MRR, or model-based approaches\\nlike Encoder-Decoder models from the BERT series (e.g.,\\nSpanBERT), specialized reranking models such as Cohere\\nrerank or bge-raranker-large, and general large language mod-\\nels like GPT [12], [99].\\n2) Context Selection/Compression: A common misconcep-\\ntion in the RAG process is the belief that retrieving as many'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='els like GPT [12], [99].\\n2) Context Selection/Compression: A common misconcep-\\ntion in the RAG process is the belief that retrieving as many\\nrelevant documents as possible and concatenating them to form\\na lengthy retrieval prompt is beneficial. However, excessive\\ncontext can introduce more noise, diminishing the LLM’s\\nperception of key information .\\n(Long) LLMLingua [100], [101] utilize small language\\nmodels (SLMs) such as GPT-2 Small or LLaMA-7B, to\\ndetect and remove unimportant tokens, transforming it into\\na form that is challenging for humans to comprehend but\\nwell understood by LLMs. This approach presents a direct\\nand practical method for prompt compression, eliminating the\\nneed for additional training of LLMs while balancing language\\nintegrity and compression ratio. PRCA tackled this issue by\\ntraining an information extractor [69]. Similarly, RECOMP\\nadopts a comparable approach by training an information\\ncondenser using contrastive learning [71]. Each training data'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='training an information extractor [69]. Similarly, RECOMP\\nadopts a comparable approach by training an information\\ncondenser using contrastive learning [71]. Each training data\\npoint consists of one positive sample and five negative sam-\\nples, and the encoder undergoes training using contrastive loss\\nthroughout this process [102] .\\nIn addition to compressing the context, reducing the num-\\nber of documents aslo helps improve the accuracy of the\\nmodel’s answers. Ma et al. [103] propose the “Filter-Reranker”\\nparadigm, which combines the strengths of LLMs and SLMs.\\nIn this paradigm, SLMs serve as filters, while LLMs function\\nas reordering agents. The research shows that instructing\\nLLMs to rearrange challenging samples identified by SLMs\\nleads to significant improvements in various Information\\nExtraction (IE) tasks. Another straightforward and effective\\napproach involves having the LLM evaluate the retrieved\\ncontent before generating the final answer. This allows the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Extraction (IE) tasks. Another straightforward and effective\\napproach involves having the LLM evaluate the retrieved\\ncontent before generating the final answer. This allows the\\nLLM to filter out documents with poor relevance through LLM\\ncritique. For instance, in Chatlaw [104], the LLM is prompted\\nto self-suggestion on the referenced legal provisions to assess\\ntheir relevance.\\nB. LLM Fine-tuning\\nTargeted fine-tuning based on the scenario and data char-\\nacteristics on LLMs can yield better results. This is also one\\nof the greatest advantages of using on-premise LLMs. When\\nLLMs lack data in a specific domain, additional knowledge can\\nbe provided to the LLM through fine-tuning. Huggingface’s\\nfine-tuning data can also be used as an initial step.\\nAnother benefit of fine-tuning is the ability to adjust the\\nmodel’s input and output. For example, it can enable LLM to\\nadapt to specific data formats and generate responses in a par-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Another benefit of fine-tuning is the ability to adjust the\\nmodel’s input and output. For example, it can enable LLM to\\nadapt to specific data formats and generate responses in a par-\\nticular style as instructed [37]. For retrieval tasks that engage\\nwith structured data, the SANTA framework [76] implements\\na tripartite training regimen to effectively encapsulate both\\nstructural and semantic nuances. The initial phase focuses on\\nthe retriever, where contrastive learning is harnessed to refine\\nthe query and document embeddings.\\nAligning LLM outputs with human or retriever preferences\\nthrough reinforcement learning is a potential approach. For\\ninstance, manually annotating the final generated answers\\nand then providing feedback through reinforcement learning.\\nIn addition to aligning with human preferences, it is also\\npossible to align with the preferences of fine-tuned models\\nand retrievers [79]. When circumstances prevent access to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='In addition to aligning with human preferences, it is also\\npossible to align with the preferences of fine-tuned models\\nand retrievers [79]. When circumstances prevent access to\\npowerful proprietary models or larger parameter open-source\\nmodels, a simple and effective method is to distill the more\\npowerful models(e.g. GPT-4). Fine-tuning of LLM can also\\nbe coordinated with fine-tuning of the retriever to align pref-\\nerences. A typical approach, such as RA-DIT [27], aligns the\\nscoring functions between Retriever and Generator using KL\\ndivergence.\\nV. A UGMENTATION PROCESS IN RAG\\nIn the domain of RAG, the standard practice often involves\\na singular (once) retrieval step followed by generation, which\\ncan lead to inefficiencies and sometimes is typically insuffi-\\ncient for complex problems demanding multi-step reasoning,\\nas it provides a limited scope of information [105]. Many\\nstudies have optimized the retrieval process in response to this\\nissue, and we have summarised them in Figure 5.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='as it provides a limited scope of information [105]. Many\\nstudies have optimized the retrieval process in response to this\\nissue, and we have summarised them in Figure 5.\\nA. Iterative Retrieval\\nIterative retrieval is a process where the knowledge base\\nis repeatedly searched based on the initial query and the text\\ngenerated so far, providing a more comprehensive knowledge'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='11\\nFig. 5. In addition to the most common once retrieval, RAG also includes three types of retrieval augmentation processes. (left) Iterative retrieval involves\\nalternating between retrieval and generation, allowing for richer and more targeted context from the knowledge base at each step. (Middle) Recursive retrieval\\ninvolves gradually refining the user query and breaking down the problem into sub-problems, then continuously solving complex problems through retrieval\\nand generation. (Right) Adaptive retrieval focuses on enabling the RAG system to autonomously determine whether external knowledge retrieval is necessary\\nand when to stop retrieval and generation, often utilizing LLM-generated special tokens for control.\\nbase for LLMs. This approach has been shown to enhance\\nthe robustness of subsequent answer generation by offering\\nadditional contextual references through multiple retrieval\\niterations. However, it may be affected by semantic discon-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='the robustness of subsequent answer generation by offering\\nadditional contextual references through multiple retrieval\\niterations. However, it may be affected by semantic discon-\\ntinuity and the accumulation of irrelevant information. ITER-\\nRETGEN [14] employs a synergistic approach that lever-\\nages “retrieval-enhanced generation” alongside “generation-\\nenhanced retrieval” for tasks that necessitate the reproduction\\nof specific information. The model harnesses the content\\nrequired to address the input task as a contextual basis for\\nretrieving pertinent knowledge, which in turn facilitates the\\ngeneration of improved responses in subsequent iterations.\\nB. Recursive Retrieval\\nRecursive retrieval is often used in information retrieval and\\nNLP to improve the depth and relevance of search results.\\nThe process involves iteratively refining search queries based\\non the results obtained from previous searches. Recursive\\nRetrieval aims to enhance the search experience by gradu-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='The process involves iteratively refining search queries based\\non the results obtained from previous searches. Recursive\\nRetrieval aims to enhance the search experience by gradu-\\nally converging on the most pertinent information through a\\nfeedback loop. IRCoT [61] uses chain-of-thought to guide\\nthe retrieval process and refines the CoT with the obtained\\nretrieval results. ToC [57] creates a clarification tree that\\nsystematically optimizes the ambiguous parts in the Query. It\\ncan be particularly useful in complex search scenarios where\\nthe user’s needs are not entirely clear from the outset or where\\nthe information sought is highly specialized or nuanced. The\\nrecursive nature of the process allows for continuous learning\\nand adaptation to the user’s requirements, often resulting in\\nimproved satisfaction with the search outcomes.\\nTo address specific data scenarios, recursive retrieval and\\nmulti-hop retrieval techniques are utilized together. Recursive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='improved satisfaction with the search outcomes.\\nTo address specific data scenarios, recursive retrieval and\\nmulti-hop retrieval techniques are utilized together. Recursive\\nretrieval involves a structured index to process and retrieve\\ndata in a hierarchical manner, which may include summarizing\\nsections of a document or lengthy PDF before performing a\\nretrieval based on this summary. Subsequently, a secondary\\nretrieval within the document refines the search, embodying\\nthe recursive nature of the process. In contrast, multi-hop\\nretrieval is designed to delve deeper into graph-structured data\\nsources, extracting interconnected information [106].\\nC. Adaptive Retrieval\\nAdaptive retrieval methods, exemplified by Flare [24] and\\nSelf-RAG [25], refine the RAG framework by enabling LLMs\\nto actively determine the optimal moments and content for\\nretrieval, thus enhancing the efficiency and relevance of the\\ninformation sourced.\\nThese methods are part of a broader trend wherein'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='to actively determine the optimal moments and content for\\nretrieval, thus enhancing the efficiency and relevance of the\\ninformation sourced.\\nThese methods are part of a broader trend wherein\\nLLMs employ active judgment in their operations, as seen\\nin model agents like AutoGPT, Toolformer, and Graph-\\nToolformer [107]–[109]. Graph-Toolformer, for instance, di-\\nvides its retrieval process into distinct steps where LLMs\\nproactively use retrievers, apply Self-Ask techniques, and em-\\nploy few-shot prompts to initiate search queries. This proactive\\nstance allows LLMs to decide when to search for necessary\\ninformation, akin to how an agent utilizes tools.\\nWebGPT [110] integrates a reinforcement learning frame-\\nwork to train the GPT-3 model in autonomously using a\\nsearch engine during text generation. It navigates this process\\nusing special tokens that facilitate actions such as search\\nengine queries, browsing results, and citing references, thereby'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='search engine during text generation. It navigates this process\\nusing special tokens that facilitate actions such as search\\nengine queries, browsing results, and citing references, thereby\\nexpanding GPT-3’s capabilities through the use of external\\nsearch engines. Flare automates timing retrieval by monitoring\\nthe confidence of the generation process, as indicated by the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='12\\nprobability of generated terms [24]. When the probability falls\\nbelow a certain threshold would activates the retrieval system\\nto collect relevant information, thus optimizing the retrieval\\ncycle. Self-RAG [25] introduces “reflection tokens” that allow\\nthe model to introspect its outputs. These tokens come in\\ntwo varieties: “retrieve” and “critic”. The model autonomously\\ndecides when to activate retrieval, or alternatively, a predefined\\nthreshold may trigger the process. During retrieval, the gen-\\nerator conducts a fragment-level beam search across multiple\\nparagraphs to derive the most coherent sequence. Critic scores\\nare used to update the subdivision scores, with the flexibility\\nto adjust these weights during inference, tailoring the model’s\\nbehavior. Self-RAG’s design obviates the need for additional\\nclassifiers or reliance on Natural Language Inference (NLI)\\nmodels, thus streamlining the decision-making process for\\nwhen to engage retrieval mechanisms and improving the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='classifiers or reliance on Natural Language Inference (NLI)\\nmodels, thus streamlining the decision-making process for\\nwhen to engage retrieval mechanisms and improving the\\nmodel’s autonomous judgment capabilities in generating ac-\\ncurate responses.\\nVI. T ASK AND EVALUATION\\nThe rapid advancement and growing adoption of RAG\\nin the field of NLP have propelled the evaluation of RAG\\nmodels to the forefront of research in the LLMs community.\\nThe primary objective of this evaluation is to comprehend\\nand optimize the performance of RAG models across diverse\\napplication scenarios.This chapter will mainly introduce the\\nmain downstream tasks of RAG, datasets, and how to evaluate\\nRAG systems.\\nA. Downstream Task\\nThe core task of RAG remains Question Answering (QA),\\nincluding traditional single-hop/multi-hop QA, multiple-\\nchoice, domain-specific QA as well as long-form scenarios\\nsuitable for RAG. In addition to QA, RAG is continuously\\nbeing expanded into multiple downstream tasks, such as Infor-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='choice, domain-specific QA as well as long-form scenarios\\nsuitable for RAG. In addition to QA, RAG is continuously\\nbeing expanded into multiple downstream tasks, such as Infor-\\nmation Extraction (IE), dialogue generation, code search, etc.\\nThe main downstream tasks of RAG and their corresponding\\ndatasets are summarized in Table II.\\nB. Evaluation Target\\nHistorically, RAG models assessments have centered on\\ntheir execution in specific downstream tasks. These evaluations\\nemploy established metrics suitable to the tasks at hand. For\\ninstance, question answering evaluations might rely on EM\\nand F1 scores [7], [45], [59], [72], whereas fact-checking\\ntasks often hinge on Accuracy as the primary metric [4],\\n[14], [42]. BLEU and ROUGE metrics are also commonly\\nused to evaluate answer quality [26], [32], [52], [78]. Tools\\nlike RALLE, designed for the automatic evaluation of RAG\\napplications, similarly base their assessments on these task-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='used to evaluate answer quality [26], [32], [52], [78]. Tools\\nlike RALLE, designed for the automatic evaluation of RAG\\napplications, similarly base their assessments on these task-\\nspecific metrics [160]. Despite this, there is a notable paucity\\nof research dedicated to evaluating the distinct characteristics\\nof RAG models.The main evaluation objectives include:\\nRetrieval Quality. Evaluating the retrieval quality is crucial\\nfor determining the effectiveness of the context sourced by\\nthe retriever component. Standard metrics from the domains\\nof search engines, recommendation systems, and information\\nretrieval systems are employed to measure the performance of\\nthe RAG retrieval module. Metrics such as Hit Rate, MRR, and\\nNDCG are commonly utilized for this purpose [161], [162].\\nGeneration Quality . The assessment of generation quality\\ncenters on the generator’s capacity to synthesize coherent and\\nrelevant answers from the retrieved context. This evaluation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Generation Quality . The assessment of generation quality\\ncenters on the generator’s capacity to synthesize coherent and\\nrelevant answers from the retrieved context. This evaluation\\ncan be categorized based on the content’s objectives: unlabeled\\nand labeled content. For unlabeled content, the evaluation\\nencompasses the faithfulness, relevance, and non-harmfulness\\nof the generated answers. In contrast, for labeled content,\\nthe focus is on the accuracy of the information produced by\\nthe model [161]. Additionally, both retrieval and generation\\nquality assessments can be conducted through manual or\\nautomatic evaluation methods [29], [161], [163].\\nC. Evaluation Aspects\\nContemporary evaluation practices of RAG models empha-\\nsize three primary quality scores and four essential abilities,\\nwhich collectively inform the evaluation of the two principal\\ntargets of the RAG model: retrieval and generation.\\n1) Quality Scores: Quality scores include context rele-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='which collectively inform the evaluation of the two principal\\ntargets of the RAG model: retrieval and generation.\\n1) Quality Scores: Quality scores include context rele-\\nvance, answer faithfulness, and answer relevance. These qual-\\nity scores evaluate the efficiency of the RAG model from\\ndifferent perspectives in the process of information retrieval\\nand generation [164]–[166].\\nContext Relevance evaluates the precision and specificity\\nof the retrieved context, ensuring relevance and minimizing\\nprocessing costs associated with extraneous content.\\nAnswer Faithfulness ensures that the generated answers\\nremain true to the retrieved context, maintaining consistency\\nand avoiding contradictions.\\nAnswer Relevance requires that the generated answers are\\ndirectly pertinent to the posed questions, effectively addressing\\nthe core inquiry.\\n2) Required Abilities: RAG evaluation also encompasses\\nfour abilities indicative of its adaptability and efficiency:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='the core inquiry.\\n2) Required Abilities: RAG evaluation also encompasses\\nfour abilities indicative of its adaptability and efficiency:\\nnoise robustness, negative rejection, information integration,\\nand counterfactual robustness [167], [168]. These abilities are\\ncritical for the model’s performance under various challenges\\nand complex scenarios, impacting the quality scores.\\nNoise Robustness appraises the model’s capability to man-\\nage noise documents that are question-related but lack sub-\\nstantive information.\\nNegative Rejection assesses the model’s discernment in\\nrefraining from responding when the retrieved documents do\\nnot contain the necessary knowledge to answer a question.\\nInformation Integration evaluates the model’s proficiency in\\nsynthesizing information from multiple documents to address\\ncomplex questions.\\nCounterfactual Robustness tests the model’s ability to rec-\\nognize and disregard known inaccuracies within documents,\\neven when instructed about potential misinformation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='complex questions.\\nCounterfactual Robustness tests the model’s ability to rec-\\nognize and disregard known inaccuracies within documents,\\neven when instructed about potential misinformation.\\nContext relevance and noise robustness are important for\\nevaluating the quality of retrieval, while answer faithfulness,\\nanswer relevance, negative rejection, information integration,\\nand counterfactual robustness are important for evaluating the\\nquality of generation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 12, 'page_label': '13', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='13\\nTABLE II\\nDOWNSTREAM TASKS AND DATASETS OF RAG\\nTask Sub Task Dataset Method\\nQA Single-hop Natural Qustion(NQ) [111]\\n[26], [30], [34], [42], [45], [50], [52], [59], [64], [82]\\n[3], [4], [22], [27], [40], [43], [54], [62], [71], [112]\\n[20], [44], [72]\\nTriviaQA(TQA) [113]\\n[13], [30], [34], [45], [50], [64]\\n[4], [27], [59], [62], [112]\\n[22], [25], [43], [44], [71], [72]\\nSQuAD [114] [20], [23], [30], [32], [45], [69], [112]\\nWeb Questions(WebQ) [115] [3], [4], [13], [30], [50], [68]\\nPopQA [116] [7], [25], [67]\\nMS MARCO [117] [4], [40], [52]\\nMulti-hop HotpotQA [118] [23], [26], [31], [34], [47], [51], [61], [82]\\n[7], [14], [22], [27], [59], [62], [69], [71], [91]\\n2WikiMultiHopQA [119] [14], [24], [48], [59], [61], [91]\\nMuSiQue [120] [14], [51], [61], [91]\\nLong-form QA ELI5 [121] [27], [34], [43], [49], [51]\\nNarrativeQA(NQA) [122] [45], [60], [63], [123]\\nASQA [124] [24], [57]\\nQMSum(QM) [125] [60], [123]\\nDomain QA Qasper [126] [60], [63]\\nCOVID-QA [127] [35], [46]'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 12, 'page_label': '13', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='NarrativeQA(NQA) [122] [45], [60], [63], [123]\\nASQA [124] [24], [57]\\nQMSum(QM) [125] [60], [123]\\nDomain QA Qasper [126] [60], [63]\\nCOVID-QA [127] [35], [46]\\nCMB [128],MMCU Medical [129] [81]\\nMulti-Choice QA QuALITY [130] [60], [63]\\nARC [131] [25], [67]\\nCommonsenseQA [132] [58], [66]\\nGraph QA GraphQA [84] [84]\\nDialog Dialog Generation Wizard of Wikipedia (WoW) [133] [13], [27], [34], [42]\\nPersonal Dialog KBP [134] [74], [135]\\nDuleMon [136] [74]\\nTask-oriented Dialog CamRest [137] [78], [79]\\nRecommendation Amazon(Toys,Sport,Beauty) [138] [39], [40]\\nIE Event Argument Extraction WikiEvent [139] [13], [27], [37], [42]\\nRAMS [140] [36], [37]\\nRelation Extraction T-REx [141],ZsRE [142] [27], [51]\\nReasoning Commonsense Reasoning HellaSwag [143] [20], [66]\\nCoT Reasoning CoT Reasoning [144] [27]\\nComplex Reasoning CSQA [145] [55]\\nOthers Language Understanding MMLU [146] [7], [27], [28], [42], [43], [47], [72]\\nLanguage Modeling WikiText-103 [147] [5], [29], [64], [71]'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 12, 'page_label': '13', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Complex Reasoning CSQA [145] [55]\\nOthers Language Understanding MMLU [146] [7], [27], [28], [42], [43], [47], [72]\\nLanguage Modeling WikiText-103 [147] [5], [29], [64], [71]\\nStrategyQA [148] [14], [24], [48], [51], [55], [58]\\nFact Checking/Verification FEVER [149] [4], [13], [27], [34], [42], [50]\\nPubHealth [150] [25], [67]\\nText Generation Biography [151] [67]\\nText Summarization WikiASP [152] [24]\\nXSum [153] [17]\\nText Classification VioLens [154] [19]\\nTREC [155] [33]\\nSentiment SST-2 [156] [20], [33], [38]\\nCode Search CodeSearchNet [157] [76]\\nRobustness Evaluation NoMIRACL [56] [56]\\nMath GSM8K [158] [73]\\nMachine Translation JRC-Acquis [159] [17]'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='14\\nTABLE III\\nSUMMARY OF METRICS APPLICABLE FOR EVALUATION ASPECTS OF RAG\\nContext\\nRelevance Faithfulness Answer\\nRelevance\\nNoise\\nRobustness\\nNegative\\nRejection\\nInformation\\nIntegration\\nCounterfactual\\nRobustness\\nAccuracy ✓ ✓ ✓ ✓ ✓ ✓ ✓\\nEM ✓\\nRecall ✓\\nPrecision ✓ ✓\\nR-Rate ✓\\nCosine Similarity ✓\\nHit Rate ✓\\nMRR ✓\\nNDCG ✓\\nBLEU ✓ ✓ ✓\\nROUGE/ROUGE-L ✓ ✓ ✓\\nThe specific metrics for each evaluation aspect are sum-\\nmarized in Table III. It is essential to recognize that these\\nmetrics, derived from related work, are traditional measures\\nand do not yet represent a mature or standardized approach for\\nquantifying RAG evaluation aspects. Custom metrics tailored\\nto the nuances of RAG models, though not included here, have\\nalso been developed in some evaluation studies.\\nD. Evaluation Benchmarks and Tools\\nA series of benchmark tests and tools have been proposed\\nto facilitate the evaluation of RAG.These instruments furnish\\nquantitative metrics that not only gauge RAG model perfor-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='A series of benchmark tests and tools have been proposed\\nto facilitate the evaluation of RAG.These instruments furnish\\nquantitative metrics that not only gauge RAG model perfor-\\nmance but also enhance comprehension of the model’s capabil-\\nities across various evaluation aspects. Prominent benchmarks\\nsuch as RGB, RECALL and CRUD [167]–[169] focus on\\nappraising the essential abilities of RAG models. Concur-\\nrently, state-of-the-art automated tools like RAGAS [164],\\nARES [165], and TruLens 8 employ LLMs to adjudicate the\\nquality scores. These tools and benchmarks collectively form\\na robust framework for the systematic evaluation of RAG\\nmodels, as summarized in Table IV.\\nVII. D ISCUSSION AND FUTURE PROSPECTS\\nDespite the considerable progress in RAG technology, sev-\\neral challenges persist that warrant in-depth research.This\\nchapter will mainly introduce the current challenges and future\\nresearch directions faced by RAG.\\nA. RAG vs Long Context'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='eral challenges persist that warrant in-depth research.This\\nchapter will mainly introduce the current challenges and future\\nresearch directions faced by RAG.\\nA. RAG vs Long Context\\nWith the deepening of related research, the context of LLMs\\nis continuously expanding [170]–[172]. Presently, LLMs can\\neffortlessly manage contexts exceeding 200,000 tokens 9. This\\ncapability signifies that long-document question answering,\\npreviously reliant on RAG, can now incorporate the entire\\ndocument directly into the prompt. This has also sparked\\ndiscussions on whether RAG is still necessary when LLMs\\n8https://www.trulens.org/trulens eval/core concepts rag triad/\\n9https://kimi.moonshot.cn\\nare not constrained by context. In fact, RAG still plays an\\nirreplaceable role. On one hand, providing LLMs with a\\nlarge amount of context at once will significantly impact its\\ninference speed, while chunked retrieval and on-demand input\\ncan significantly improve operational efficiency. On the other'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='large amount of context at once will significantly impact its\\ninference speed, while chunked retrieval and on-demand input\\ncan significantly improve operational efficiency. On the other\\nhand, RAG-based generation can quickly locate the original\\nreferences for LLMs to help users verify the generated an-\\nswers. The entire retrieval and reasoning process is observable,\\nwhile generation solely relying on long context remains a\\nblack box. Conversely, the expansion of context provides new\\nopportunities for the development of RAG, enabling it to\\naddress more complex problems and integrative or summary\\nquestions that require reading a large amount of material to\\nanswer [49]. Developing new RAG methods in the context of\\nsuper-long contexts is one of the future research trends.\\nB. RAG Robustness\\nThe presence of noise or contradictory information during\\nretrieval can detrimentally affect RAG’s output quality. This\\nsituation is figuratively referred to as “Misinformation can'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='B. RAG Robustness\\nThe presence of noise or contradictory information during\\nretrieval can detrimentally affect RAG’s output quality. This\\nsituation is figuratively referred to as “Misinformation can\\nbe worse than no information at all”. Improving RAG’s\\nresistance to such adversarial or counterfactual inputs is gain-\\ning research momentum and has become a key performance\\nmetric [48], [50], [82]. Cuconasu et al. [54] analyze which\\ntype of documents should be retrieved, evaluate the relevance\\nof the documents to the prompt, their position, and the\\nnumber included in the context. The research findings reveal\\nthat including irrelevant documents can unexpectedly increase\\naccuracy by over 30%, contradicting the initial assumption\\nof reduced quality. These results underscore the importance\\nof developing specialized strategies to integrate retrieval with\\nlanguage generation models, highlighting the need for further\\nresearch and exploration into the robustness of RAG.\\nC. Hybrid Approaches'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='language generation models, highlighting the need for further\\nresearch and exploration into the robustness of RAG.\\nC. Hybrid Approaches\\nCombining RAG with fine-tuning is emerging as a leading\\nstrategy. Determining the optimal integration of RAG and\\nfine-tuning whether sequential, alternating, or through end-to-\\nend joint training—and how to harness both parameterized'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='15\\nTABLE IV\\nSUMMARY OF EVALUATION FRAMEWORKS\\nEvaluation Framework Evaluation Targets Evaluation Aspects Quantitative Metrics\\nRGB† Retrieval Quality\\nGeneration Quality\\nNoise Robustness\\nNegative Rejection\\nInformation Integration\\nCounterfactual Robustness\\nAccuracy\\nEM\\nAccuracy\\nAccuracy\\nRECALL† Generation Quality Counterfactual Robustness R-Rate (Reappearance Rate)\\nRAGAS‡ Retrieval Quality\\nGeneration Quality\\nContext Relevance\\nFaithfulness\\nAnswer Relevance\\n*\\n*\\nCosine Similarity\\nARES‡ Retrieval Quality\\nGeneration Quality\\nContext Relevance\\nFaithfulness\\nAnswer Relevance\\nAccuracy\\nAccuracy\\nAccuracy\\nTruLens‡ Retrieval Quality\\nGeneration Quality\\nContext Relevance\\nFaithfulness\\nAnswer Relevance\\n*\\n*\\n*\\nCRUD† Retrieval Quality\\nGeneration Quality\\nCreative Generation\\nKnowledge-intensive QA\\nError Correction\\nSummarization\\nBLEU\\nROUGE-L\\nBertScore\\nRAGQuestEval\\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='Error Correction\\nSummarization\\nBLEU\\nROUGE-L\\nBertScore\\nRAGQuestEval\\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional\\nmetrics. Readers are encouraged to consult pertinent literature for the specific quantification formulas associated with these\\nmetrics, as required.\\nand non-parameterized advantages are areas ripe for explo-\\nration [27]. Another trend is to introduce SLMs with specific\\nfunctionalities into RAG and fine-tuned by the results of RAG\\nsystem. For example, CRAG [67] trains a lightweight retrieval\\nevaluator to assess the overall quality of the retrieved docu-\\nments for a query and triggers different knowledge retrieval\\nactions based on confidence levels.\\nD. Scaling laws of RAG\\nEnd-to-end RAG models and pre-trained models based\\non RAG are still one of the focuses of current re-\\nsearchers [173].The parameters of these models are one of\\nthe key factors.While scaling laws [174] are established for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='on RAG are still one of the focuses of current re-\\nsearchers [173].The parameters of these models are one of\\nthe key factors.While scaling laws [174] are established for\\nLLMs, their applicability to RAG remains uncertain. Initial\\nstudies like RETRO++ [44] have begun to address this, yet the\\nparameter count in RAG models still lags behind that of LLMs.\\nThe possibility of an Inverse Scaling Law 10, where smaller\\nmodels outperform larger ones, is particularly intriguing and\\nmerits further investigation.\\nE. Production-Ready RAG\\nRAG’s practicality and alignment with engineering require-\\nments have facilitated its adoption. However, enhancing re-\\ntrieval efficiency, improving document recall in large knowl-\\nedge bases, and ensuring data security—such as preventing\\n10https://github.com/inverse-scaling/prize\\ninadvertent disclosure of document sources or metadata by\\nLLMs—are critical engineering challenges that remain to be\\naddressed [175].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='10https://github.com/inverse-scaling/prize\\ninadvertent disclosure of document sources or metadata by\\nLLMs—are critical engineering challenges that remain to be\\naddressed [175].\\nThe development of the RAG ecosystem is greatly impacted\\nby the progression of its technical stack. Key tools like\\nLangChain and LLamaIndex have quickly gained popularity\\nwith the emergence of ChatGPT, providing extensive RAG-\\nrelated APIs and becoming essential in the realm of LLMs.The\\nemerging technology stack, while not as rich in features as\\nLangChain and LLamaIndex, stands out through its specialized\\nproducts. For example, Flowise AI prioritizes a low-code\\napproach, allowing users to deploy AI applications, including\\nRAG, through a user-friendly drag-and-drop interface. Other\\ntechnologies like HayStack, Meltano, and Cohere Coral are\\nalso gaining attention for their unique contributions to the field.\\nIn addition to AI-focused vendors, traditional software and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='technologies like HayStack, Meltano, and Cohere Coral are\\nalso gaining attention for their unique contributions to the field.\\nIn addition to AI-focused vendors, traditional software and\\ncloud service providers are expanding their offerings to include\\nRAG-centric services. Weaviate’s Verba 11 is designed for\\npersonal assistant applications, while Amazon’s Kendra 12\\noffers intelligent enterprise search services, enabling users to\\nbrowse various content repositories using built-in connectors.\\nIn the development of RAG technology, there is a clear\\ntrend towards different specialization directions, such as: 1)\\nCustomization - tailoring RAG to meet specific requirements.\\n2) Simplification - making RAG easier to use to reduce the\\n11https://github.com/weaviate/Verba\\n12https://aws.amazon.com/cn/kendra/'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='16\\nFig. 6. Summary of RAG ecosystem\\ninitial learning curve. 3) Specialization - optimizing RAG to\\nbetter serve production environments.\\nThe mutual growth of RAG models and their technology\\nstacks is evident; technological advancements continuously\\nestablish new standards for existing infrastructure. In turn,\\nenhancements to the technology stack drive the development\\nof RAG capabilities. RAG toolkits are converging into a\\nfoundational technology stack, laying the groundwork for\\nadvanced enterprise applications. However, a fully integrated,\\ncomprehensive platform concept is still in the future, requiring\\nfurther innovation and development.\\nF . Multi-modal RAG\\nRAG has transcended its initial text-based question-\\nanswering confines, embracing a diverse array of modal data.\\nThis expansion has spawned innovative multimodal models\\nthat integrate RAG concepts across various domains:\\nImage. RA-CM3 [176] stands as a pioneering multimodal\\nmodel of both retrieving and generating text and images.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='that integrate RAG concepts across various domains:\\nImage. RA-CM3 [176] stands as a pioneering multimodal\\nmodel of both retrieving and generating text and images.\\nBLIP-2 [177] leverages frozen image encoders alongside\\nLLMs for efficient visual language pre-training, enabling zero-\\nshot image-to-text conversions. The “Visualize Before You\\nWrite” method [178] employs image generation to steer the\\nLM’s text generation, showing promise in open-ended text\\ngeneration tasks.\\nAudio and Video . The GSS method retrieves and stitches\\ntogether audio clips to convert machine-translated data into\\nspeech-translated data [179]. UEOP marks a significant ad-\\nvancement in end-to-end automatic speech recognition by\\nincorporating external, offline strategies for voice-to-text con-\\nversion [180]. Additionally, KNN-based attention fusion lever-\\nages audio embeddings and semantically related text embed-\\ndings to refine ASR, thereby accelerating domain adaptation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='version [180]. Additionally, KNN-based attention fusion lever-\\nages audio embeddings and semantically related text embed-\\ndings to refine ASR, thereby accelerating domain adaptation.\\nVid2Seq augments language models with specialized temporal\\nmarkers, facilitating the prediction of event boundaries and\\ntextual descriptions within a unified output sequence [181].\\nCode. RBPS [182] excels in small-scale learning tasks by\\nretrieving code examples that align with developers’ objectives\\nthrough encoding and frequency analysis. This approach has\\ndemonstrated efficacy in tasks such as test assertion genera-\\ntion and program repair. For structured knowledge, the CoK\\nmethod [106] first extracts facts pertinent to the input query\\nfrom a knowledge graph, then integrates these facts as hints\\nwithin the input, enhancing performance in knowledge graph\\nquestion-answering tasks.\\nVIII. C ONCLUSION\\nThe summary of this paper, as depicted in Figure 6, empha-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='within the input, enhancing performance in knowledge graph\\nquestion-answering tasks.\\nVIII. C ONCLUSION\\nThe summary of this paper, as depicted in Figure 6, empha-\\nsizes RAG’s significant advancement in enhancing the capa-\\nbilities of LLMs by integrating parameterized knowledge from\\nlanguage models with extensive non-parameterized data from\\nexternal knowledge bases. The survey showcases the evolution\\nof RAG technologies and their application on many different\\ntasks. The analysis outlines three developmental paradigms\\nwithin the RAG framework: Naive, Advanced, and Modu-\\nlar RAG, each representing a progressive enhancement over\\nits predecessors. RAG’s technical integration with other AI\\nmethodologies, such as fine-tuning and reinforcement learning,\\nhas further expanded its capabilities. Despite the progress in\\nRAG technology, there are research opportunities to improve\\nits robustness and its ability to handle extended contexts.\\nRAG’s application scope is expanding into multimodal do-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='RAG technology, there are research opportunities to improve\\nits robustness and its ability to handle extended contexts.\\nRAG’s application scope is expanding into multimodal do-\\nmains, adapting its principles to interpret and process diverse\\ndata forms like images, videos, and code. This expansion high-\\nlights RAG’s significant practical implications for AI deploy-\\nment, attracting interest from academic and industrial sectors.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='17\\nThe growing ecosystem of RAG is evidenced by the rise in\\nRAG-centric AI applications and the continuous development\\nof supportive tools. As RAG’s application landscape broadens,\\nthere is a need to refine evaluation methodologies to keep\\npace with its evolution. Ensuring accurate and representative\\nperformance assessments is crucial for fully capturing RAG’s\\ncontributions to the AI research and development community.\\nREFERENCES\\n[1] N. Kandpal, H. Deng, A. Roberts, E. Wallace, and C. Raffel, “Large\\nlanguage models struggle to learn long-tail knowledge,” in Interna-\\ntional Conference on Machine Learning . PMLR, 2023, pp. 15 696–\\n15 707.\\n[2] Y . Zhang, Y . Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao,\\nY . Zhang, Y . Chenet al., “Siren’s song in the ai ocean: A survey on hal-\\nlucination in large language models,” arXiv preprint arXiv:2309.01219,\\n2023.\\n[3] D. Arora, A. Kini, S. R. Chowdhury, N. Natarajan, G. Sinha, and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='lucination in large language models,” arXiv preprint arXiv:2309.01219,\\n2023.\\n[3] D. Arora, A. Kini, S. R. Chowdhury, N. Natarajan, G. Sinha, and\\nA. Sharma, “Gar-meets-rag paradigm for zero-shot information re-\\ntrieval,” arXiv preprint arXiv:2310.20158 , 2023.\\n[4] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal,\\nH. K ¨uttler, M. Lewis, W.-t. Yih, T. Rockt ¨aschel et al. , “Retrieval-\\naugmented generation for knowledge-intensive nlp tasks,” Advances in\\nNeural Information Processing Systems, vol. 33, pp. 9459–9474, 2020.\\n[5] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Milli-\\ncan, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clarket al.,\\n“Improving language models by retrieving from trillions of tokens,”\\nin International conference on machine learning . PMLR, 2022, pp.\\n2206–2240.\\n[6] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,\\nC. Zhang, S. Agarwal, K. Slama, A. Ray et al. , “Training language'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2206–2240.\\n[6] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,\\nC. Zhang, S. Agarwal, K. Slama, A. Ray et al. , “Training language\\nmodels to follow instructions with human feedback,” Advances in\\nneural information processing systems , vol. 35, pp. 27 730–27 744,\\n2022.\\n[7] X. Ma, Y . Gong, P. He, H. Zhao, and N. Duan, “Query rewrit-\\ning for retrieval-augmented large language models,” arXiv preprint\\narXiv:2305.14283, 2023.\\n[8] I. ILIN, “Advanced rag techniques: an il-\\nlustrated overview,” https://pub.towardsai.net/\\nadvanced-rag-techniques-an-illustrated-overview-04d193d8fec6,\\n2023.\\n[9] W. Peng, G. Li, Y . Jiang, Z. Wang, D. Ou, X. Zeng, E. Chen et al. ,\\n“Large language model based long-tail query rewriting in taobao\\nsearch,” arXiv preprint arXiv:2311.03758 , 2023.\\n[10] H. S. Zheng, S. Mishra, X. Chen, H.-T. Cheng, E. H. Chi, Q. V . Le,\\nand D. Zhou, “Take a step back: Evoking reasoning via abstraction in\\nlarge language models,” arXiv preprint arXiv:2310.06117 , 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and D. Zhou, “Take a step back: Evoking reasoning via abstraction in\\nlarge language models,” arXiv preprint arXiv:2310.06117 , 2023.\\n[11] L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense retrieval\\nwithout relevance labels,” arXiv preprint arXiv:2212.10496 , 2022.\\n[12] V . Blagojevi, “Enhancing rag pipelines in haystack: Introducing diver-\\nsityranker and lostinthemiddleranker,” https://towardsdatascience.com/\\nenhancing-rag-pipelines-in-haystack-45f14e2bc9f5, 2023.\\n[13] W. Yu, D. Iter, S. Wang, Y . Xu, M. Ju, S. Sanyal, C. Zhu, M. Zeng,\\nand M. Jiang, “Generate rather than retrieve: Large language models\\nare strong context generators,” arXiv preprint arXiv:2209.10063, 2022.\\n[14] Z. Shao, Y . Gong, Y . Shen, M. Huang, N. Duan, and W. Chen,\\n“Enhancing retrieval-augmented large language models with iterative\\nretrieval-generation synergy,” arXiv preprint arXiv:2305.15294 , 2023.\\n[15] X. Wang, Q. Yang, Y . Qiu, J. Liang, Q. He, Z. Gu, Y . Xiao,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='retrieval-generation synergy,” arXiv preprint arXiv:2305.15294 , 2023.\\n[15] X. Wang, Q. Yang, Y . Qiu, J. Liang, Q. He, Z. Gu, Y . Xiao,\\nand W. Wang, “Knowledgpt: Enhancing large language models with\\nretrieval and storage access on knowledge bases,” arXiv preprint\\narXiv:2308.11761, 2023.\\n[16] A. H. Raudaschl, “Forget rag, the future\\nis rag-fusion,” https://towardsdatascience.com/\\nforget-rag-the-future-is-rag-fusion-1147298d8ad1, 2023.\\n[17] X. Cheng, D. Luo, X. Chen, L. Liu, D. Zhao, and R. Yan, “Lift\\nyourself up: Retrieval-augmented text generation with self memory,”\\narXiv preprint arXiv:2305.02437 , 2023.\\n[18] S. Wang, Y . Xu, Y . Fang, Y . Liu, S. Sun, R. Xu, C. Zhu, and\\nM. Zeng, “Training data is more valuable than you think: A simple\\nand effective method by retrieving from training data,” arXiv preprint\\narXiv:2203.08773, 2022.\\n[19] X. Li, E. Nie, and S. Liang, “From classification to generation:\\nInsights into crosslingual retrieval augmented icl,” arXiv preprint'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='arXiv:2203.08773, 2022.\\n[19] X. Li, E. Nie, and S. Liang, “From classification to generation:\\nInsights into crosslingual retrieval augmented icl,” arXiv preprint\\narXiv:2311.06595, 2023.\\n[20] D. Cheng, S. Huang, J. Bi, Y . Zhan, J. Liu, Y . Wang, H. Sun,\\nF. Wei, D. Deng, and Q. Zhang, “Uprise: Universal prompt retrieval\\nfor improving zero-shot evaluation,” arXiv preprint arXiv:2303.08518,\\n2023.\\n[21] Z. Dai, V . Y . Zhao, J. Ma, Y . Luan, J. Ni, J. Lu, A. Bakalov, K. Guu,\\nK. B. Hall, and M.-W. Chang, “Promptagator: Few-shot dense retrieval\\nfrom 8 examples,” arXiv preprint arXiv:2209.11755 , 2022.\\n[22] Z. Sun, X. Wang, Y . Tay, Y . Yang, and D. Zhou, “Recitation-augmented\\nlanguage models,” arXiv preprint arXiv:2210.01296 , 2022.\\n[23] O. Khattab, K. Santhanam, X. L. Li, D. Hall, P. Liang, C. Potts,\\nand M. Zaharia, “Demonstrate-search-predict: Composing retrieval\\nand language models for knowledge-intensive nlp,” arXiv preprint\\narXiv:2212.14024, 2022.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and M. Zaharia, “Demonstrate-search-predict: Composing retrieval\\nand language models for knowledge-intensive nlp,” arXiv preprint\\narXiv:2212.14024, 2022.\\n[24] Z. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y . Yang,\\nJ. Callan, and G. Neubig, “Active retrieval augmented generation,”\\narXiv preprint arXiv:2305.06983 , 2023.\\n[25] A. Asai, Z. Wu, Y . Wang, A. Sil, and H. Hajishirzi, “Self-rag:\\nLearning to retrieve, generate, and critique through self-reflection,”\\narXiv preprint arXiv:2310.11511 , 2023.\\n[26] Z. Ke, W. Kong, C. Li, M. Zhang, Q. Mei, and M. Bendersky,\\n“Bridging the preference gap between retrievers and llms,” arXiv\\npreprint arXiv:2401.06954, 2024.\\n[27] X. V . Lin, X. Chen, M. Chen, W. Shi, M. Lomeli, R. James, P. Ro-\\ndriguez, J. Kahn, G. Szilvasy, M. Lewis et al. , “Ra-dit: Retrieval-\\naugmented dual instruction tuning,” arXiv preprint arXiv:2310.01352 ,\\n2023.\\n[28] O. Ovadia, M. Brief, M. Mishaeli, and O. Elisha, “Fine-tuning or'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='augmented dual instruction tuning,” arXiv preprint arXiv:2310.01352 ,\\n2023.\\n[28] O. Ovadia, M. Brief, M. Mishaeli, and O. Elisha, “Fine-tuning or\\nretrieval? comparing knowledge injection in llms,” arXiv preprint\\narXiv:2312.05934, 2023.\\n[29] T. Lan, D. Cai, Y . Wang, H. Huang, and X.-L. Mao, “Copy is all\\nyou need,” in The Eleventh International Conference on Learning\\nRepresentations, 2022.\\n[30] T. Chen, H. Wang, S. Chen, W. Yu, K. Ma, X. Zhao, D. Yu, and\\nH. Zhang, “Dense x retrieval: What retrieval granularity should we\\nuse?” arXiv preprint arXiv:2312.06648 , 2023.\\n[31] F. Luo and M. Surdeanu, “Divide & conquer for entailment-aware\\nmulti-hop evidence retrieval,” arXiv preprint arXiv:2311.02616 , 2023.\\n[32] Q. Gou, Z. Xia, B. Yu, H. Yu, F. Huang, Y . Li, and N. Cam-Tu,\\n“Diversify question generation with retrieval-augmented style transfer,”\\narXiv preprint arXiv:2310.14503 , 2023.\\n[33] Z. Guo, S. Cheng, Y . Wang, P. Li, and Y . Liu, “Prompt-guided re-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='“Diversify question generation with retrieval-augmented style transfer,”\\narXiv preprint arXiv:2310.14503 , 2023.\\n[33] Z. Guo, S. Cheng, Y . Wang, P. Li, and Y . Liu, “Prompt-guided re-\\ntrieval augmentation for non-knowledge-intensive tasks,”arXiv preprint\\narXiv:2305.17653, 2023.\\n[34] Z. Wang, J. Araki, Z. Jiang, M. R. Parvez, and G. Neubig, “Learning\\nto filter context for retrieval-augmented generation,” arXiv preprint\\narXiv:2311.08377, 2023.\\n[35] M. Seo, J. Baek, J. Thorne, and S. J. Hwang, “Retrieval-augmented\\ndata augmentation for low-resource domain tasks,” arXiv preprint\\narXiv:2402.13482, 2024.\\n[36] Y . Ma, Y . Cao, Y . Hong, and A. Sun, “Large language model is not\\na good few-shot information extractor, but a good reranker for hard\\nsamples!” arXiv preprint arXiv:2303.08559 , 2023.\\n[37] X. Du and H. Ji, “Retrieval-augmented generative question answering\\nfor event argument extraction,” arXiv preprint arXiv:2211.07067, 2022.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='samples!” arXiv preprint arXiv:2303.08559 , 2023.\\n[37] X. Du and H. Ji, “Retrieval-augmented generative question answering\\nfor event argument extraction,” arXiv preprint arXiv:2211.07067, 2022.\\n[38] L. Wang, N. Yang, and F. Wei, “Learning to retrieve in-context\\nexamples for large language models,”arXiv preprint arXiv:2307.07164,\\n2023.\\n[39] S. Rajput, N. Mehta, A. Singh, R. H. Keshavan, T. Vu, L. Heldt,\\nL. Hong, Y . Tay, V . Q. Tran, J. Samostet al., “Recommender systems\\nwith generative retrieval,” arXiv preprint arXiv:2305.05065 , 2023.\\n[40] B. Jin, H. Zeng, G. Wang, X. Chen, T. Wei, R. Li, Z. Wang, Z. Li,\\nY . Li, H. Lu et al. , “Language models as semantic indexers,” arXiv\\npreprint arXiv:2310.07815, 2023.\\n[41] R. Anantha, T. Bethi, D. V odianik, and S. Chappidi, “Context tuning\\nfor retrieval augmented generation,” arXiv preprint arXiv:2312.05708 ,\\n2023.\\n[42] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='for retrieval augmented generation,” arXiv preprint arXiv:2312.05708 ,\\n2023.\\n[42] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick,\\nJ. Dwivedi-Yu, A. Joulin, S. Riedel, and E. Grave, “Few-shot\\nlearning with retrieval augmented language models,” arXiv preprint\\narXiv:2208.03299, 2022.\\n[43] J. Huang, W. Ping, P. Xu, M. Shoeybi, K. C.-C. Chang, and B. Catan-\\nzaro, “Raven: In-context learning with retrieval augmented encoder-\\ndecoder language models,” arXiv preprint arXiv:2308.07922 , 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='18\\n[44] B. Wang, W. Ping, P. Xu, L. McAfee, Z. Liu, M. Shoeybi, Y . Dong,\\nO. Kuchaiev, B. Li, C. Xiao et al. , “Shall we pretrain autoregressive\\nlanguage models with retrieval? a comprehensive study,”arXiv preprint\\narXiv:2304.06762, 2023.\\n[45] B. Wang, W. Ping, L. McAfee, P. Xu, B. Li, M. Shoeybi, and B. Catan-\\nzaro, “Instructretro: Instruction tuning post retrieval-augmented pre-\\ntraining,” arXiv preprint arXiv:2310.07713 , 2023.\\n[46] S. Siriwardhana, R. Weerasekera, E. Wen, T. Kaluarachchi, R. Rana,\\nand S. Nanayakkara, “Improving the domain adaptation of retrieval\\naugmented generation (rag) models for open domain question answer-\\ning,” Transactions of the Association for Computational Linguistics ,\\nvol. 11, pp. 1–17, 2023.\\n[47] Z. Yu, C. Xiong, S. Yu, and Z. Liu, “Augmentation-adapted retriever\\nimproves generalization of language models as generic plug-in,” arXiv\\npreprint arXiv:2305.17331, 2023.\\n[48] O. Yoran, T. Wolfson, O. Ram, and J. Berant, “Making retrieval-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='improves generalization of language models as generic plug-in,” arXiv\\npreprint arXiv:2305.17331, 2023.\\n[48] O. Yoran, T. Wolfson, O. Ram, and J. Berant, “Making retrieval-\\naugmented language models robust to irrelevant context,” arXiv\\npreprint arXiv:2310.01558, 2023.\\n[49] H.-T. Chen, F. Xu, S. A. Arora, and E. Choi, “Understanding re-\\ntrieval augmentation for long-form question answering,” arXiv preprint\\narXiv:2310.12150, 2023.\\n[50] W. Yu, H. Zhang, X. Pan, K. Ma, H. Wang, and D. Yu, “Chain-of-note:\\nEnhancing robustness in retrieval-augmented language models,” arXiv\\npreprint arXiv:2311.09210, 2023.\\n[51] S. Xu, L. Pang, H. Shen, X. Cheng, and T.-S. Chua, “Search-in-the-\\nchain: Towards accurate, credible and traceable large language models\\nfor knowledgeintensive tasks,” CoRR, vol. abs/2304.14732 , 2023.\\n[52] M. Berchansky, P. Izsak, A. Caciularu, I. Dagan, and M. Wasserblat,\\n“Optimizing retrieval-augmented reader models via token elimination,”\\narXiv preprint arXiv:2310.13682 , 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='[52] M. Berchansky, P. Izsak, A. Caciularu, I. Dagan, and M. Wasserblat,\\n“Optimizing retrieval-augmented reader models via token elimination,”\\narXiv preprint arXiv:2310.13682 , 2023.\\n[53] J. L ´ala, O. O’Donoghue, A. Shtedritski, S. Cox, S. G. Rodriques,\\nand A. D. White, “Paperqa: Retrieval-augmented generative agent for\\nscientific research,” arXiv preprint arXiv:2312.07559 , 2023.\\n[54] F. Cuconasu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano,\\nY . Maarek, N. Tonellotto, and F. Silvestri, “The power of noise:\\nRedefining retrieval for rag systems,” arXiv preprint arXiv:2401.14887,\\n2024.\\n[55] Z. Zhang, X. Zhang, Y . Ren, S. Shi, M. Han, Y . Wu, R. Lai, and\\nZ. Cao, “Iag: Induction-augmented generation framework for answer-\\ning reasoning questions,” in Proceedings of the 2023 Conference on\\nEmpirical Methods in Natural Language Processing , 2023, pp. 1–14.\\n[56] N. Thakur, L. Bonifacio, X. Zhang, O. Ogundepo, E. Kamalloo,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='ing reasoning questions,” in Proceedings of the 2023 Conference on\\nEmpirical Methods in Natural Language Processing , 2023, pp. 1–14.\\n[56] N. Thakur, L. Bonifacio, X. Zhang, O. Ogundepo, E. Kamalloo,\\nD. Alfonso-Hermelo, X. Li, Q. Liu, B. Chen, M. Rezagholizadeh et al.,\\n“Nomiracl: Knowing when you don’t know for robust multilingual\\nretrieval-augmented generation,” arXiv preprint arXiv:2312.11361 ,\\n2023.\\n[57] G. Kim, S. Kim, B. Jeon, J. Park, and J. Kang, “Tree of clarifica-\\ntions: Answering ambiguous questions with retrieval-augmented large\\nlanguage models,” arXiv preprint arXiv:2310.14696 , 2023.\\n[58] Y . Wang, P. Li, M. Sun, and Y . Liu, “Self-knowledge guided\\nretrieval augmentation for large language models,” arXiv preprint\\narXiv:2310.05002, 2023.\\n[59] Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin, “Retrieval-\\ngeneration synergy augmented large language models,” arXiv preprint\\narXiv:2310.05149, 2023.\\n[60] P. Xu, W. Ping, X. Wu, L. McAfee, C. Zhu, Z. Liu, S. Subramanian,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='generation synergy augmented large language models,” arXiv preprint\\narXiv:2310.05149, 2023.\\n[60] P. Xu, W. Ping, X. Wu, L. McAfee, C. Zhu, Z. Liu, S. Subramanian,\\nE. Bakhturina, M. Shoeybi, and B. Catanzaro, “Retrieval meets long\\ncontext large language models,” arXiv preprint arXiv:2310.03025 ,\\n2023.\\n[61] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Interleav-\\ning retrieval with chain-of-thought reasoning for knowledge-intensive\\nmulti-step questions,” arXiv preprint arXiv:2212.10509 , 2022.\\n[62] R. Ren, Y . Wang, Y . Qu, W. X. Zhao, J. Liu, H. Tian, H. Wu, J.-\\nR. Wen, and H. Wang, “Investigating the factual knowledge boundary\\nof large language models with retrieval augmentation,” arXiv preprint\\narXiv:2307.11019, 2023.\\n[63] P. Sarthi, S. Abdullah, A. Tuli, S. Khanna, A. Goldie, and C. D.\\nManning, “Raptor: Recursive abstractive processing for tree-organized\\nretrieval,” arXiv preprint arXiv:2401.18059 , 2024.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='[63] P. Sarthi, S. Abdullah, A. Tuli, S. Khanna, A. Goldie, and C. D.\\nManning, “Raptor: Recursive abstractive processing for tree-organized\\nretrieval,” arXiv preprint arXiv:2401.18059 , 2024.\\n[64] O. Ram, Y . Levine, I. Dalmedigos, D. Muhlgay, A. Shashua, K. Leyton-\\nBrown, and Y . Shoham, “In-context retrieval-augmented language\\nmodels,” arXiv preprint arXiv:2302.00083 , 2023.\\n[65] Y . Ren, Y . Cao, P. Guo, F. Fang, W. Ma, and Z. Lin, “Retrieve-and-\\nsample: Document-level event argument extraction via hybrid retrieval\\naugmentation,” in Proceedings of the 61st Annual Meeting of the\\nAssociation for Computational Linguistics (Volume 1: Long Papers) ,\\n2023, pp. 293–306.\\n[66] Z. Wang, X. Pan, D. Yu, D. Yu, J. Chen, and H. Ji, “Zemi: Learning\\nzero-shot semi-parametric language models from multiple tasks,” arXiv\\npreprint arXiv:2210.00185, 2022.\\n[67] S.-Q. Yan, J.-C. Gu, Y . Zhu, and Z.-H. Ling, “Corrective retrieval\\naugmented generation,” arXiv preprint arXiv:2401.15884 , 2024.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='preprint arXiv:2210.00185, 2022.\\n[67] S.-Q. Yan, J.-C. Gu, Y . Zhu, and Z.-H. Ling, “Corrective retrieval\\naugmented generation,” arXiv preprint arXiv:2401.15884 , 2024.\\n[68] P. Jain, L. B. Soares, and T. Kwiatkowski, “1-pager: One pass answer\\ngeneration and evidence retrieval,” arXiv preprint arXiv:2310.16568 ,\\n2023.\\n[69] H. Yang, Z. Li, Y . Zhang, J. Wang, N. Cheng, M. Li, and J. Xiao, “Prca:\\nFitting black-box large language models for retrieval question answer-\\ning via pluggable reward-driven contextual adapter,” arXiv preprint\\narXiv:2310.18347, 2023.\\n[70] S. Zhuang, B. Liu, B. Koopman, and G. Zuccon, “Open-source large\\nlanguage models are strong zero-shot query likelihood models for\\ndocument ranking,” arXiv preprint arXiv:2310.13243 , 2023.\\n[71] F. Xu, W. Shi, and E. Choi, “Recomp: Improving retrieval-augmented\\nlms with compression and selective augmentation,” arXiv preprint\\narXiv:2310.04408, 2023.\\n[72] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettle-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='lms with compression and selective augmentation,” arXiv preprint\\narXiv:2310.04408, 2023.\\n[72] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettle-\\nmoyer, and W.-t. Yih, “Replug: Retrieval-augmented black-box lan-\\nguage models,” arXiv preprint arXiv:2301.12652 , 2023.\\n[73] E. Melz, “Enhancing llm intelligence with arm-rag: Auxiliary ra-\\ntionale memory for retrieval augmented generation,” arXiv preprint\\narXiv:2311.04177, 2023.\\n[74] H. Wang, W. Huang, Y . Deng, R. Wang, Z. Wang, Y . Wang, F. Mi,\\nJ. Z. Pan, and K.-F. Wong, “Unims-rag: A unified multi-source\\nretrieval-augmented generation for personalized dialogue systems,”\\narXiv preprint arXiv:2401.13256 , 2024.\\n[75] Z. Luo, C. Xu, P. Zhao, X. Geng, C. Tao, J. Ma, Q. Lin, and D. Jiang,\\n“Augmented large language models with parametric knowledge guid-\\ning,” arXiv preprint arXiv:2305.04757 , 2023.\\n[76] X. Li, Z. Liu, C. Xiong, S. Yu, Y . Gu, Z. Liu, and G. Yu, “Structure-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='“Augmented large language models with parametric knowledge guid-\\ning,” arXiv preprint arXiv:2305.04757 , 2023.\\n[76] X. Li, Z. Liu, C. Xiong, S. Yu, Y . Gu, Z. Liu, and G. Yu, “Structure-\\naware language model pretraining improves dense retrieval on struc-\\ntured data,” arXiv preprint arXiv:2305.19912 , 2023.\\n[77] M. Kang, J. M. Kwak, J. Baek, and S. J. Hwang, “Knowledge\\ngraph-augmented language models for knowledge-grounded dialogue\\ngeneration,” arXiv preprint arXiv:2305.18846 , 2023.\\n[78] W. Shen, Y . Gao, C. Huang, F. Wan, X. Quan, and W. Bi, “Retrieval-\\ngeneration alignment for end-to-end task-oriented dialogue system,”\\narXiv preprint arXiv:2310.08877 , 2023.\\n[79] T. Shi, L. Li, Z. Lin, T. Yang, X. Quan, and Q. Wang, “Dual-feedback\\nknowledge retrieval for task-oriented dialogue systems,” arXiv preprint\\narXiv:2310.14528, 2023.\\n[80] P. Ranade and A. Joshi, “Fabula: Intelligence report generation\\nusing retrieval-augmented narrative construction,” arXiv preprint\\narXiv:2310.13848, 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='arXiv:2310.14528, 2023.\\n[80] P. Ranade and A. Joshi, “Fabula: Intelligence report generation\\nusing retrieval-augmented narrative construction,” arXiv preprint\\narXiv:2310.13848, 2023.\\n[81] X. Jiang, R. Zhang, Y . Xu, R. Qiu, Y . Fang, Z. Wang, J. Tang,\\nH. Ding, X. Chu, J. Zhao et al. , “Think and retrieval: A hypothesis\\nknowledge graph enhanced medical large language models,” arXiv\\npreprint arXiv:2312.15883, 2023.\\n[82] J. Baek, S. Jeong, M. Kang, J. C. Park, and S. J. Hwang,\\n“Knowledge-augmented language model verification,” arXiv preprint\\narXiv:2310.12836, 2023.\\n[83] L. Luo, Y .-F. Li, G. Haffari, and S. Pan, “Reasoning on graphs: Faithful\\nand interpretable large language model reasoning,” arXiv preprint\\narXiv:2310.01061, 2023.\\n[84] X. He, Y . Tian, Y . Sun, N. V . Chawla, T. Laurent, Y . LeCun,\\nX. Bresson, and B. Hooi, “G-retriever: Retrieval-augmented generation\\nfor textual graph understanding and question answering,”arXiv preprint\\narXiv:2402.07630, 2024.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='X. Bresson, and B. Hooi, “G-retriever: Retrieval-augmented generation\\nfor textual graph understanding and question answering,”arXiv preprint\\narXiv:2402.07630, 2024.\\n[85] L. Zha, J. Zhou, L. Li, R. Wang, Q. Huang, S. Yang, J. Yuan, C. Su,\\nX. Li, A. Su et al., “Tablegpt: Towards unifying tables, nature language\\nand commands into one gpt,” arXiv preprint arXiv:2307.08674 , 2023.\\n[86] M. Gaur, K. Gunaratna, V . Srinivasan, and H. Jin, “Iseeq: Information\\nseeking question generation using dynamic meta-information retrieval\\nand knowledge graphs,” in Proceedings of the AAAI Conference on\\nArtificial Intelligence, vol. 36, no. 10, 2022, pp. 10 672–10 680.\\n[87] F. Shi, X. Chen, K. Misra, N. Scales, D. Dohan, E. H. Chi, N. Sch ¨arli,\\nand D. Zhou, “Large language models can be easily distracted by\\nirrelevant context,” in International Conference on Machine Learning .\\nPMLR, 2023, pp. 31 210–31 227.\\n[88] R. Teja, “Evaluating the ideal chunk size for a rag'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='irrelevant context,” in International Conference on Machine Learning .\\nPMLR, 2023, pp. 31 210–31 227.\\n[88] R. Teja, “Evaluating the ideal chunk size for a rag\\nsystem using llamaindex,” https://www.llamaindex.ai/blog/\\nevaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5,\\n2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='19\\n[89] Langchain, “Recursively split by character,” https://python.langchain.\\ncom/docs/modules/data connection/document transformers/recursive\\ntext splitter, 2023.\\n[90] S. Yang, “Advanced rag 01: Small-to-\\nbig retrieval,” https://towardsdatascience.com/\\nadvanced-rag-01-small-to-big-retrieval-172181b396d4, 2023.\\n[91] Y . Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and T. Derr,\\n“Knowledge graph prompting for multi-document question answering,”\\narXiv preprint arXiv:2308.11730 , 2023.\\n[92] D. Zhou, N. Sch ¨arli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schu-\\nurmans, C. Cui, O. Bousquet, Q. Le et al., “Least-to-most prompting\\nenables complex reasoning in large language models,” arXiv preprint\\narXiv:2205.10625, 2022.\\n[93] S. Dhuliawala, M. Komeili, J. Xu, R. Raileanu, X. Li, A. Celikyilmaz,\\nand J. Weston, “Chain-of-verification reduces hallucination in large\\nlanguage models,” arXiv preprint arXiv:2309.11495 , 2023.\\n[94] X. Li and J. Li, “Angle-optimized text embeddings,” arXiv preprint'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and J. Weston, “Chain-of-verification reduces hallucination in large\\nlanguage models,” arXiv preprint arXiv:2309.11495 , 2023.\\n[94] X. Li and J. Li, “Angle-optimized text embeddings,” arXiv preprint\\narXiv:2309.12871, 2023.\\n[95] V oyageAI, “V oyage’s embedding models,” https://docs.voyageai.com/\\nembeddings/, 2023.\\n[96] BAAI, “Flagembedding,” https://github.com/FlagOpen/\\nFlagEmbedding, 2023.\\n[97] P. Zhang, S. Xiao, Z. Liu, Z. Dou, and J.-Y . Nie, “Retrieve anything\\nto augment large language models,” arXiv preprint arXiv:2310.07554 ,\\n2023.\\n[98] N. F. Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilacqua, F. Petroni,\\nand P. Liang, “Lost in the middle: How language models use long\\ncontexts,” arXiv preprint arXiv:2307.03172 , 2023.\\n[99] Y . Gao, T. Sheng, Y . Xiang, Y . Xiong, H. Wang, and J. Zhang, “Chat-\\nrec: Towards interactive and explainable llms-augmented recommender\\nsystem,” arXiv preprint arXiv:2303.14524 , 2023.\\n[100] N. Anderson, C. Wilson, and S. D. Richardson, “Lingua: Addressing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='rec: Towards interactive and explainable llms-augmented recommender\\nsystem,” arXiv preprint arXiv:2303.14524 , 2023.\\n[100] N. Anderson, C. Wilson, and S. D. Richardson, “Lingua: Addressing\\nscenarios for live interpretation and automatic dubbing,” inProceedings\\nof the 15th Biennial Conference of the Association for Machine\\nTranslation in the Americas (Volume 2: Users and Providers Track\\nand Government Track) , J. Campbell, S. Larocca, J. Marciano,\\nK. Savenkov, and A. Yanishevsky, Eds. Orlando, USA: Association\\nfor Machine Translation in the Americas, Sep. 2022, pp. 202–209.\\n[Online]. Available: https://aclanthology.org/2022.amta-upg.14\\n[101] H. Jiang, Q. Wu, X. Luo, D. Li, C.-Y . Lin, Y . Yang, and L. Qiu,\\n“Longllmlingua: Accelerating and enhancing llms in long context\\nscenarios via prompt compression,” arXiv preprint arXiv:2310.06839 ,\\n2023.\\n[102] V . Karpukhin, B. O ˘guz, S. Min, P. Lewis, L. Wu, S. Edunov, D. Chen,\\nand W.-t. Yih, “Dense passage retrieval for open-domain question'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2023.\\n[102] V . Karpukhin, B. O ˘guz, S. Min, P. Lewis, L. Wu, S. Edunov, D. Chen,\\nand W.-t. Yih, “Dense passage retrieval for open-domain question\\nanswering,” arXiv preprint arXiv:2004.04906 , 2020.\\n[103] Y . Ma, Y . Cao, Y . Hong, and A. Sun, “Large language model is\\nnot a good few-shot information extractor, but a good reranker for\\nhard samples!” ArXiv, vol. abs/2303.08559, 2023. [Online]. Available:\\nhttps://api.semanticscholar.org/CorpusID:257532405\\n[104] J. Cui, Z. Li, Y . Yan, B. Chen, and L. Yuan, “Chatlaw: Open-source\\nlegal large language model with integrated external knowledge bases,”\\narXiv preprint arXiv:2306.16092 , 2023.\\n[105] O. Yoran, T. Wolfson, O. Ram, and J. Berant, “Making retrieval-\\naugmented language models robust to irrelevant context,” arXiv\\npreprint arXiv:2310.01558, 2023.\\n[106] X. Li, R. Zhao, Y . K. Chia, B. Ding, L. Bing, S. Joty, and S. Poria,\\n“Chain of knowledge: A framework for grounding large language mod-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='preprint arXiv:2310.01558, 2023.\\n[106] X. Li, R. Zhao, Y . K. Chia, B. Ding, L. Bing, S. Joty, and S. Poria,\\n“Chain of knowledge: A framework for grounding large language mod-\\nels with structured knowledge bases,”arXiv preprint arXiv:2305.13269,\\n2023.\\n[107] H. Yang, S. Yue, and Y . He, “Auto-gpt for online decision\\nmaking: Benchmarks and additional opinions,” arXiv preprint\\narXiv:2306.02224, 2023.\\n[108] T. Schick, J. Dwivedi-Yu, R. Dess `ı, R. Raileanu, M. Lomeli, L. Zettle-\\nmoyer, N. Cancedda, and T. Scialom, “Toolformer: Language models\\ncan teach themselves to use tools,” arXiv preprint arXiv:2302.04761 ,\\n2023.\\n[109] J. Zhang, “Graph-toolformer: To empower llms with graph rea-\\nsoning ability via prompt augmented by chatgpt,” arXiv preprint\\narXiv:2304.11116, 2023.\\n[110] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim,\\nC. Hesse, S. Jain, V . Kosaraju, W. Saunders et al., “Webgpt: Browser-\\nassisted question-answering with human feedback,” arXiv preprint'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='C. Hesse, S. Jain, V . Kosaraju, W. Saunders et al., “Webgpt: Browser-\\nassisted question-answering with human feedback,” arXiv preprint\\narXiv:2112.09332, 2021.\\n[111] T. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. Parikh,\\nC. Alberti, D. Epstein, I. Polosukhin, J. Devlin, K. Lee et al., “Natural\\nquestions: a benchmark for question answering research,” Transactions\\nof the Association for Computational Linguistics , vol. 7, pp. 453–466,\\n2019.\\n[112] Y . Liu, S. Yavuz, R. Meng, M. Moorthy, S. Joty, C. Xiong, and Y . Zhou,\\n“Exploring the integration strategies of retriever and large language\\nmodels,” arXiv preprint arXiv:2308.12574 , 2023.\\n[113] M. Joshi, E. Choi, D. S. Weld, and L. Zettlemoyer, “Triviaqa: A large\\nscale distantly supervised challenge dataset for reading comprehen-\\nsion,” arXiv preprint arXiv:1705.03551 , 2017.\\n[114] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, “Squad: 100,000+\\nquestions for machine comprehension of text,” arXiv preprint\\narXiv:1606.05250, 2016.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='[114] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, “Squad: 100,000+\\nquestions for machine comprehension of text,” arXiv preprint\\narXiv:1606.05250, 2016.\\n[115] J. Berant, A. Chou, R. Frostig, and P. Liang, “Semantic parsing on\\nfreebase from question-answer pairs,” in Proceedings of the 2013\\nconference on empirical methods in natural language processing, 2013,\\npp. 1533–1544.\\n[116] A. Mallen, A. Asai, V . Zhong, R. Das, H. Hajishirzi, and D. Khashabi,\\n“When not to trust language models: Investigating effectiveness and\\nlimitations of parametric and non-parametric memories,” arXiv preprint\\narXiv:2212.10511, 2022.\\n[117] T. Nguyen, M. Rosenberg, X. Song, J. Gao, S. Tiwary, R. Majumder,\\nand L. Deng, “Ms marco: A human-generated machine reading com-\\nprehension dataset,” 2016.\\n[118] Z. Yang, P. Qi, S. Zhang, Y . Bengio, W. W. Cohen, R. Salakhutdi-\\nnov, and C. D. Manning, “Hotpotqa: A dataset for diverse, explain-\\nable multi-hop question answering,” arXiv preprint arXiv:1809.09600,\\n2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='nov, and C. D. Manning, “Hotpotqa: A dataset for diverse, explain-\\nable multi-hop question answering,” arXiv preprint arXiv:1809.09600,\\n2018.\\n[119] X. Ho, A.-K. D. Nguyen, S. Sugawara, and A. Aizawa, “Constructing a\\nmulti-hop qa dataset for comprehensive evaluation of reasoning steps,”\\narXiv preprint arXiv:2011.01060 , 2020.\\n[120] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Musique:\\nMultihop questions via single-hop question composition,” Transactions\\nof the Association for Computational Linguistics , vol. 10, pp. 539–554,\\n2022.\\n[121] A. Fan, Y . Jernite, E. Perez, D. Grangier, J. Weston, and M. Auli, “Eli5:\\nLong form question answering,” arXiv preprint arXiv:1907.09190 ,\\n2019.\\n[122] T. Ko ˇcisk`y, J. Schwarz, P. Blunsom, C. Dyer, K. M. Hermann, G. Melis,\\nand E. Grefenstette, “The narrativeqa reading comprehension chal-\\nlenge,” Transactions of the Association for Computational Linguistics ,\\nvol. 6, pp. 317–328, 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='and E. Grefenstette, “The narrativeqa reading comprehension chal-\\nlenge,” Transactions of the Association for Computational Linguistics ,\\nvol. 6, pp. 317–328, 2018.\\n[123] K.-H. Lee, X. Chen, H. Furuta, J. Canny, and I. Fischer, “A human-\\ninspired reading agent with gist memory of very long contexts,” arXiv\\npreprint arXiv:2402.09727, 2024.\\n[124] I. Stelmakh, Y . Luan, B. Dhingra, and M.-W. Chang, “Asqa: Factoid\\nquestions meet long-form answers,” arXiv preprint arXiv:2204.06092 ,\\n2022.\\n[125] M. Zhong, D. Yin, T. Yu, A. Zaidi, M. Mutuma, R. Jha, A. H.\\nAwadallah, A. Celikyilmaz, Y . Liu, X. Qiu et al. , “Qmsum: A new\\nbenchmark for query-based multi-domain meeting summarization,”\\narXiv preprint arXiv:2104.05938 , 2021.\\n[126] P. Dasigi, K. Lo, I. Beltagy, A. Cohan, N. A. Smith, and M. Gardner,\\n“A dataset of information-seeking questions and answers anchored in\\nresearch papers,” arXiv preprint arXiv:2105.03011 , 2021.\\n[127] T. M ¨oller, A. Reina, R. Jayakumar, and M. Pietsch, “Covid-qa: A'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='“A dataset of information-seeking questions and answers anchored in\\nresearch papers,” arXiv preprint arXiv:2105.03011 , 2021.\\n[127] T. M ¨oller, A. Reina, R. Jayakumar, and M. Pietsch, “Covid-qa: A\\nquestion answering dataset for covid-19,” in ACL 2020 Workshop on\\nNatural Language Processing for COVID-19 (NLP-COVID) , 2020.\\n[128] X. Wang, G. H. Chen, D. Song, Z. Zhang, Z. Chen, Q. Xiao, F. Jiang,\\nJ. Li, X. Wan, B. Wang et al. , “Cmb: A comprehensive medical\\nbenchmark in chinese,” arXiv preprint arXiv:2308.08833 , 2023.\\n[129] H. Zeng, “Measuring massive multitask chinese understanding,” arXiv\\npreprint arXiv:2304.12986, 2023.\\n[130] R. Y . Pang, A. Parrish, N. Joshi, N. Nangia, J. Phang, A. Chen, V . Pad-\\nmakumar, J. Ma, J. Thompson, H. He et al. , “Quality: Question an-\\nswering with long input texts, yes!” arXiv preprint arXiv:2112.08608 ,\\n2021.\\n[131] P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick,\\nand O. Tafjord, “Think you have solved question answering? try arc,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2021.\\n[131] P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick,\\nand O. Tafjord, “Think you have solved question answering? try arc,\\nthe ai2 reasoning challenge,” arXiv preprint arXiv:1803.05457 , 2018.\\n[132] A. Talmor, J. Herzig, N. Lourie, and J. Berant, “Commonsenseqa:\\nA question answering challenge targeting commonsense knowledge,”\\narXiv preprint arXiv:1811.00937 , 2018.\\n[133] E. Dinan, S. Roller, K. Shuster, A. Fan, M. Auli, and J. Weston,\\n“Wizard of wikipedia: Knowledge-powered conversational agents,”\\narXiv preprint arXiv:1811.01241 , 2018.\\n[134] H. Wang, M. Hu, Y . Deng, R. Wang, F. Mi, W. Wang, Y . Wang, W.-\\nC. Kwan, I. King, and K.-F. Wong, “Large language models as source'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='20\\nplanner for personalized knowledge-grounded dialogue,” arXiv preprint\\narXiv:2310.08840, 2023.\\n[135] ——, “Large language models as source planner for personal-\\nized knowledge-grounded dialogue,” arXiv preprint arXiv:2310.08840,\\n2023.\\n[136] X. Xu, Z. Gou, W. Wu, Z.-Y . Niu, H. Wu, H. Wang, and S. Wang,\\n“Long time no see! open-domain conversation with long-term persona\\nmemory,” arXiv preprint arXiv:2203.05797 , 2022.\\n[137] T.-H. Wen, M. Gasic, N. Mrksic, L. M. Rojas-Barahona, P.-H.\\nSu, S. Ultes, D. Vandyke, and S. Young, “Conditional generation\\nand snapshot learning in neural dialogue systems,” arXiv preprint\\narXiv:1606.03352, 2016.\\n[138] R. He and J. McAuley, “Ups and downs: Modeling the visual evolution\\nof fashion trends with one-class collaborative filtering,” in proceedings\\nof the 25th international conference on world wide web , 2016, pp.\\n507–517.\\n[139] S. Li, H. Ji, and J. Han, “Document-level event argument extraction'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='of the 25th international conference on world wide web , 2016, pp.\\n507–517.\\n[139] S. Li, H. Ji, and J. Han, “Document-level event argument extraction\\nby conditional generation,” arXiv preprint arXiv:2104.05919 , 2021.\\n[140] S. Ebner, P. Xia, R. Culkin, K. Rawlins, and B. Van Durme, “Multi-\\nsentence argument linking,” arXiv preprint arXiv:1911.03766 , 2019.\\n[141] H. Elsahar, P. V ougiouklis, A. Remaci, C. Gravier, J. Hare, F. Laforest,\\nand E. Simperl, “T-rex: A large scale alignment of natural language\\nwith knowledge base triples,” in Proceedings of the Eleventh Inter-\\nnational Conference on Language Resources and Evaluation (LREC\\n2018), 2018.\\n[142] O. Levy, M. Seo, E. Choi, and L. Zettlemoyer, “Zero-shot relation ex-\\ntraction via reading comprehension,” arXiv preprint arXiv:1706.04115,\\n2017.\\n[143] R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, “Hel-\\nlaswag: Can a machine really finish your sentence?” arXiv preprint\\narXiv:1905.07830, 2019.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2017.\\n[143] R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi, “Hel-\\nlaswag: Can a machine really finish your sentence?” arXiv preprint\\narXiv:1905.07830, 2019.\\n[144] S. Kim, S. J. Joo, D. Kim, J. Jang, S. Ye, J. Shin, and M. Seo,\\n“The cot collection: Improving zero-shot and few-shot learning of\\nlanguage models via chain-of-thought fine-tuning,” arXiv preprint\\narXiv:2305.14045, 2023.\\n[145] A. Saha, V . Pahuja, M. Khapra, K. Sankaranarayanan, and S. Chandar,\\n“Complex sequential question answering: Towards learning to converse\\nover linked question answer pairs with a knowledge graph,” inProceed-\\nings of the AAAI conference on artificial intelligence , vol. 32, no. 1,\\n2018.\\n[146] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and\\nJ. Steinhardt, “Measuring massive multitask language understanding,”\\narXiv preprint arXiv:2009.03300 , 2020.\\n[147] S. Merity, C. Xiong, J. Bradbury, and R. Socher, “Pointer sentinel'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='J. Steinhardt, “Measuring massive multitask language understanding,”\\narXiv preprint arXiv:2009.03300 , 2020.\\n[147] S. Merity, C. Xiong, J. Bradbury, and R. Socher, “Pointer sentinel\\nmixture models,” arXiv preprint arXiv:1609.07843 , 2016.\\n[148] M. Geva, D. Khashabi, E. Segal, T. Khot, D. Roth, and J. Berant,\\n“Did aristotle use a laptop? a question answering benchmark with\\nimplicit reasoning strategies,” Transactions of the Association for\\nComputational Linguistics, vol. 9, pp. 346–361, 2021.\\n[149] J. Thorne, A. Vlachos, C. Christodoulopoulos, and A. Mittal, “Fever: a\\nlarge-scale dataset for fact extraction and verification,” arXiv preprint\\narXiv:1803.05355, 2018.\\n[150] N. Kotonya and F. Toni, “Explainable automated fact-checking for\\npublic health claims,” arXiv preprint arXiv:2010.09926 , 2020.\\n[151] R. Lebret, D. Grangier, and M. Auli, “Neural text generation from\\nstructured data with application to the biography domain,” arXiv\\npreprint arXiv:1603.07771, 2016.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='[151] R. Lebret, D. Grangier, and M. Auli, “Neural text generation from\\nstructured data with application to the biography domain,” arXiv\\npreprint arXiv:1603.07771, 2016.\\n[152] H. Hayashi, P. Budania, P. Wang, C. Ackerson, R. Neervannan,\\nand G. Neubig, “Wikiasp: A dataset for multi-domain aspect-based\\nsummarization,” Transactions of the Association for Computational\\nLinguistics, vol. 9, pp. 211–225, 2021.\\n[153] S. Narayan, S. B. Cohen, and M. Lapata, “Don’t give me the details,\\njust the summary! topic-aware convolutional neural networks for ex-\\ntreme summarization,” arXiv preprint arXiv:1808.08745 , 2018.\\n[154] S. Saha, J. A. Junaed, M. Saleki, A. S. Sharma, M. R. Rifat, M. Rahouti,\\nS. I. Ahmed, N. Mohammed, and M. R. Amin, “Vio-lens: A novel\\ndataset of annotated social network posts leading to different forms\\nof communal violence and its evaluation,” in Proceedings of the First\\nWorkshop on Bangla Language Processing (BLP-2023), 2023, pp. 72–\\n84.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='of communal violence and its evaluation,” in Proceedings of the First\\nWorkshop on Bangla Language Processing (BLP-2023), 2023, pp. 72–\\n84.\\n[155] X. Li and D. Roth, “Learning question classifiers,” in COLING 2002:\\nThe 19th International Conference on Computational Linguistics, 2002.\\n[156] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Y . Ng,\\nand C. Potts, “Recursive deep models for semantic compositionality\\nover a sentiment treebank,” in Proceedings of the 2013 conference on\\nempirical methods in natural language processing , 2013, pp. 1631–\\n1642.\\n[157] H. Husain, H.-H. Wu, T. Gazit, M. Allamanis, and M. Brockschmidt,\\n“Codesearchnet challenge: Evaluating the state of semantic code\\nsearch,” arXiv preprint arXiv:1909.09436 , 2019.\\n[158] K. Cobbe, V . Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser,\\nM. Plappert, J. Tworek, J. Hilton, R. Nakano et al., “Training verifiers\\nto solve math word problems,” arXiv preprint arXiv:2110.14168, 2021.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='M. Plappert, J. Tworek, J. Hilton, R. Nakano et al., “Training verifiers\\nto solve math word problems,” arXiv preprint arXiv:2110.14168, 2021.\\n[159] R. Steinberger, B. Pouliquen, A. Widiger, C. Ignat, T. Erjavec, D. Tufis,\\nand D. Varga, “The jrc-acquis: A multilingual aligned parallel corpus\\nwith 20+ languages,” arXiv preprint cs/0609058 , 2006.\\n[160] Y . Hoshi, D. Miyashita, Y . Ng, K. Tatsuno, Y . Morioka, O. Torii,\\nand J. Deguchi, “Ralle: A framework for developing and eval-\\nuating retrieval-augmented large language models,” arXiv preprint\\narXiv:2308.10633, 2023.\\n[161] J. Liu, “Building production-ready rag applications,” https://www.ai.\\nengineer/summit/schedule/building-production-ready-rag-applications,\\n2023.\\n[162] I. Nguyen, “Evaluating rag part i: How to evaluate document retrieval,”\\nhttps://www.deepset.ai/blog/rag-evaluation-retrieval, 2023.\\n[163] Q. Leng, K. Uhlenhuth, and A. Polyzotis, “Best practices for\\nllm evaluation of rag applications,” https://www.databricks.com/blog/'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='https://www.deepset.ai/blog/rag-evaluation-retrieval, 2023.\\n[163] Q. Leng, K. Uhlenhuth, and A. Polyzotis, “Best practices for\\nllm evaluation of rag applications,” https://www.databricks.com/blog/\\nLLM-auto-eval-best-practices-RAG, 2023.\\n[164] S. Es, J. James, L. Espinosa-Anke, and S. Schockaert, “Ragas: Au-\\ntomated evaluation of retrieval augmented generation,” arXiv preprint\\narXiv:2309.15217, 2023.\\n[165] J. Saad-Falcon, O. Khattab, C. Potts, and M. Zaharia, “Ares: An\\nautomated evaluation framework for retrieval-augmented generation\\nsystems,” arXiv preprint arXiv:2311.09476 , 2023.\\n[166] C. Jarvis and J. Allard, “A survey of techniques for\\nmaximizing llm performance,” https://community.openai.\\ncom/t/openai-dev-day-2023-breakout-sessions/505213#\\na-survey-of-techniques-for-maximizing-llm-performance-2, 2023.\\n[167] J. Chen, H. Lin, X. Han, and L. Sun, “Benchmarking large lan-\\nguage models in retrieval-augmented generation,” arXiv preprint\\narXiv:2309.01431, 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='[167] J. Chen, H. Lin, X. Han, and L. Sun, “Benchmarking large lan-\\nguage models in retrieval-augmented generation,” arXiv preprint\\narXiv:2309.01431, 2023.\\n[168] Y . Liu, L. Huang, S. Li, S. Chen, H. Zhou, F. Meng, J. Zhou, and\\nX. Sun, “Recall: A benchmark for llms robustness against external\\ncounterfactual knowledge,” arXiv preprint arXiv:2311.08147 , 2023.\\n[169] Y . Lyu, Z. Li, S. Niu, F. Xiong, B. Tang, W. Wang, H. Wu, H. Liu,\\nT. Xu, and E. Chen, “Crud-rag: A comprehensive chinese benchmark\\nfor retrieval-augmented generation of large language models,” arXiv\\npreprint arXiv:2401.17043, 2024.\\n[170] P. Xu, W. Ping, X. Wu, L. McAfee, C. Zhu, Z. Liu, S. Subramanian,\\nE. Bakhturina, M. Shoeybi, and B. Catanzaro, “Retrieval meets long\\ncontext large language models,” arXiv preprint arXiv:2310.03025 ,\\n2023.\\n[171] C. Packer, V . Fang, S. G. Patil, K. Lin, S. Wooders, and J. E. Gon-\\nzalez, “Memgpt: Towards llms as operating systems,” arXiv preprint\\narXiv:2310.08560, 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='2023.\\n[171] C. Packer, V . Fang, S. G. Patil, K. Lin, S. Wooders, and J. E. Gon-\\nzalez, “Memgpt: Towards llms as operating systems,” arXiv preprint\\narXiv:2310.08560, 2023.\\n[172] G. Xiao, Y . Tian, B. Chen, S. Han, and M. Lewis, “Efficient\\nstreaming language models with attention sinks,” arXiv preprint\\narXiv:2309.17453, 2023.\\n[173] T. Zhang, S. G. Patil, N. Jain, S. Shen, M. Zaharia, I. Stoica, and J. E.\\nGonzalez, “Raft: Adapting language model to domain specific rag,”\\narXiv preprint arXiv:2403.10131 , 2024.\\n[174] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess,\\nR. Child, S. Gray, A. Radford, J. Wu, and D. Amodei, “Scaling laws\\nfor neural language models,” arXiv preprint arXiv:2001.08361 , 2020.\\n[175] U. Alon, F. Xu, J. He, S. Sengupta, D. Roth, and G. Neubig, “Neuro-\\nsymbolic language modeling with automaton-augmented retrieval,” in\\nInternational Conference on Machine Learning . PMLR, 2022, pp.\\n468–485.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='symbolic language modeling with automaton-augmented retrieval,” in\\nInternational Conference on Machine Learning . PMLR, 2022, pp.\\n468–485.\\n[176] M. Yasunaga, A. Aghajanyan, W. Shi, R. James, J. Leskovec, P. Liang,\\nM. Lewis, L. Zettlemoyer, and W.-t. Yih, “Retrieval-augmented multi-\\nmodal language modeling,” arXiv preprint arXiv:2211.12561 , 2022.\\n[177] J. Li, D. Li, S. Savarese, and S. Hoi, “Blip-2: Bootstrapping language-\\nimage pre-training with frozen image encoders and large language\\nmodels,” arXiv preprint arXiv:2301.12597 , 2023.\\n[178] W. Zhu, A. Yan, Y . Lu, W. Xu, X. E. Wang, M. Eckstein, and W. Y .\\nWang, “Visualize before you write: Imagination-guided open-ended\\ntext generation,” arXiv preprint arXiv:2210.03765 , 2022.\\n[179] J. Zhao, G. Haffar, and E. Shareghi, “Generating synthetic speech from\\nspokenvocab for speech translation,” arXiv preprint arXiv:2210.08174,\\n2022.\\n[180] D. M. Chan, S. Ghosh, A. Rastrow, and B. Hoffmeister, “Using external'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='spokenvocab for speech translation,” arXiv preprint arXiv:2210.08174,\\n2022.\\n[180] D. M. Chan, S. Ghosh, A. Rastrow, and B. Hoffmeister, “Using external\\noff-policy speech-to-text mappings in contextual end-to-end automated\\nspeech recognition,” arXiv preprint arXiv:2301.02736 , 2023.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\RAG_Research_Paper_arkiv.pdf', 'total_pages': 21, 'page': 20, 'page_label': '21', 'source_file': 'RAG_Research_Paper_arkiv.pdf', 'file_type': 'pdf'}, page_content='21\\n[181] A. Yang, A. Nagrani, P. H. Seo, A. Miech, J. Pont-Tuset, I. Laptev,\\nJ. Sivic, and C. Schmid, “Vid2seq: Large-scale pretraining of a visual\\nlanguage model for dense video captioning,” in Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition ,\\n2023, pp. 10 714–10 726.\\n[182] N. Nashid, M. Sintaha, and A. Mesbah, “Retrieval-based prompt\\nselection for code-related few-shot learning,” in 2023 IEEE/ACM 45th\\nInternational Conference on Software Engineering (ICSE) , 2023, pp.\\n2450–2462.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.27', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T16:40:31+00:00', 'author': '', 'keywords': '', 'moddate': '2025-09-21T16:40:31+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.27 (TeX Live 2025) kpathsea version 6.4.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Resume_Latest.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Resume_Latest.pdf', 'file_type': 'pdf'}, page_content='Yash Kumar\\n+919471694118 — yashcoder9187@gmail.com — linkedin.com/in/yashcoder2403 — github.com/Anonymus-Coder2403\\nBegusarai, India\\nSummary\\nApplied AI/Full-Stack engineer building LLM features end-to-end: data refinement to model-ready signals, LangChain/FastAPI APIs, and\\nNext.js/React frontends. Experience in SQL/NoSQL schema design, ETL with Python + SQL, vector search (Pinecone/FAISS)\\nSkills and Interests\\nLanguages:Python, Java, C/C++, JavaScript, TypeScript, SQL\\nAI/LLMs:LangChain, Prompt Engineering, Hugging Face, OpenAI API, Retrieval/Embeddings, Guardrails\\nDevelopment:React.js, Next.js, Tailwind; dashboards and real-time UX, FastAPI, REST, Auth (JWT/RBAC), Webhooks, Caching\\nData:Schema design (PostgreSQL, MongoDB), Vector DBs (Pinecone, Chroma/FAISS), ETL with Python+SQL\\nML Ops/Eval:Offline test sets, prompt/testing harnesses, CI on data/code\\nTools:Git, Docker, GitHub Actions, Power BI, Postman\\nExperience\\nData Analyst Intern Jan 2025 – Mar 2025\\nPawzz Foundation (Remote)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.27', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T16:40:31+00:00', 'author': '', 'keywords': '', 'moddate': '2025-09-21T16:40:31+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.27 (TeX Live 2025) kpathsea version 6.4.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Resume_Latest.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Resume_Latest.pdf', 'file_type': 'pdf'}, page_content='Tools:Git, Docker, GitHub Actions, Power BI, Postman\\nExperience\\nData Analyst Intern Jan 2025 – Mar 2025\\nPawzz Foundation (Remote)\\n–Built interactive Power BI dashboards on donor funnels; improved reporting speed by 35%.\\n–Designed lightweight SQL tables/views and Python transforms to turn raw donations & events into model-ready signals.\\n–Automated extract-clean-load jobs (Python+SQL); reduced weekly manual effort significantly.\\n–Ran small offline experiments for trend prediction; shared insights with ops to iterate on campaigns.\\nGrowth Intern May 2023 – Jul 2023\\nFact App (Remote)\\n–Instrumented event tracking and REST endpoints (JavaScript + FastAPI) to unlock funnel/retention analytics.\\n–Optimized backend handlers and queries; reduced API latency under peak usage.\\n–Built weekly growth reports (SQL + automation) and ran quick A/B style experiments, contributing to +15% retention.\\n–Partnered with product to close the loop between metrics and feature iterations.\\nProjects'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.27', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T16:40:31+00:00', 'author': '', 'keywords': '', 'moddate': '2025-09-21T16:40:31+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.27 (TeX Live 2025) kpathsea version 6.4.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Resume_Latest.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Resume_Latest.pdf', 'file_type': 'pdf'}, page_content='–Partnered with product to close the loop between metrics and feature iterations.\\nProjects\\nCareer Compass— Next.js, LangChain, FastAPI\\n–AI career assistant with resume scoring, job matching, and learning roadmaps; Next.js frontend + FastAPI services.\\n–Authored LangChain chains for retrieval & scoring; defined SQL/NoSQL fields to persist user/job signals.\\n–Built a small evaluation harness (sample resumes/jobs) to track recommendation quality (e.g., precision@k).\\nCyber Sentinel— Next.js, FastAPI, Hugging Face, MongoDB\\n–Engineered AI phishing/URL detection using Hugging Face transformers; created a labeled test set to measure 90%+ accuracy.\\n–Implemented FastAPI with JWT/RBAC and a MongoDB schema for scalable alert/log storage; webhook endpoints for actions.\\n–Responsive Next.js dashboard for real-time incidents; tight loop between detections, review, and follow-up.\\nSecure Sentinel Spark— React, Prompt Engineering 2025'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.27', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T16:40:31+00:00', 'author': '', 'keywords': '', 'moddate': '2025-09-21T16:40:31+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.27 (TeX Live 2025) kpathsea version 6.4.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Resume_Latest.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Resume_Latest.pdf', 'file_type': 'pdf'}, page_content='–Responsive Next.js dashboard for real-time incidents; tight loop between detections, review, and follow-up.\\nSecure Sentinel Spark— React, Prompt Engineering 2025\\n–Prototype of a phishing workflow using prompt engineering to simulate pipeline logic end-to-end.\\n–Built an interactive React dashboard for classification, reviewer feedback, and iteration on prompts.\\n–Used small curated examples to evaluate prompt changes before demo deployments.\\nAchievements\\n1st Prize Aug 2025\\nQubit Quest 2025, IIIT Delhi\\n–Won 1st place at national hackathon (ESYA’25) for AI-powered quantum solution.\\nFinalist Sept 2025\\nHackShastra 2025\\n–Advanced to Round 2 among 200+ teams nationwide.\\nEducation\\nB.Tech in Electronics & Communication Engineering 2022 – 2026\\nGuru Ghasidas Vishwavidyalaya CGPA: 8.0 / 10.0\\nCertifications\\n–Generative AI with Google Cloud (May 2025)\\n–Large Language Models with Google Cloud (May 2025)\\n–AWS Solutions Architect (Forage) (Jun 2025)\\n–Deep Learning Specialization — Coursera (Ongoing)'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 0, 'page_label': '1', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"As an expert who's witnessed the evolution of AI from its early days, I'm excited to guide you\\nthrough what I consider the most comprehensive and practical learning path to becoming an AI\\nEngineer. This roadmap is designed specifically for complete beginners and will transform you\\ninto a capable AI practitioner ready to build modern, cutting-edge AI systems.\\nWhy This Matters: AI isn't just about code—it's fundamentally mathematical. Understanding the\\nmath gives you superpowers to debug, optimize, and innovate beyond just following tutorials.\\nLinear Algebra\\nCalculus\\nStatistics & Probability\\nThe Ultimate AI Engineering Learning Roadmap:\\nFrom Zero to Hero \\x002025\\x00\\nPhase 1\\x00 Foundation Building \\x00Months 1\\x002\\x00\\nMathematical Prerequisites\\n\\x001\\x00\\n\\x002\\x00\\nVector operations: The backbone of neural networks\\nMatrix multiplication: How data flows through networks\\nEigenvalues/eigenvectors: Critical for understanding transformations\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 0, 'page_label': '1', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x001\\x00\\n\\x002\\x00\\nVector operations: The backbone of neural networks\\nMatrix multiplication: How data flows through networks\\nEigenvalues/eigenvectors: Critical for understanding transformations\\nResource: Khan Academy Linear Algebra + 3Blue1Brown\\'s \"Essence of Linear Algebra\"\\x003\\x00\\n\\x004\\x00\\nDerivatives: How neural networks learn through gradients\\nChain rule: The mathematical foundation of backpropagation\\nPartial derivatives: Essential for optimization\\nResource: Paul\\'s Online Math Notes + 3Blue1Brown\\'s \"Essence of Calculus\"\\nProbability distributions: Understanding uncertainty in AI\\nBayes\\' theorem: Foundation of probabilistic reasoning\\nStatistical inference: Model evaluation and validation\\nResource: Think Stats (free book) + Khan Academy Statistics'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Python Mastery\\nJupyter Notebooks\\nAndrew Ng's Machine Learning Specialization \\x00Coursera)\\nHands-on Practice\\nSupervised Learning\\nProgramming Fundamentals\\nData structures: Lists, dictionaries, sets—the building blocks\\nNumPy: Mathematical operations on arrays\\nPandas: Data manipulation and analysis\\nMatplotlib/Seaborn: Data visualization\\nResource: Automate the Boring Stuff with Python (free) + Python Crash Course\\x005\\x00\\nInteractive development environment\\nEssential for experimentation and learning\\nResource: Jupyter documentation + DataCamp's Jupyter tutorial\\nPhase 2\\x00 Machine Learning Mastery \\x00Months 3\\x004\\x00\\nCore Machine Learning\\n\\x006\\x00\\x007\\x00\\nWhy it's exceptional: Ng breaks down complex concepts with mathematical rigor but\\npractical clarity\\nMost valuable sections:\\nGradient descent visualization and intuition\\nBias-variance tradeoff explanations\\nRegularization techniques\\nModel evaluation strategies\\nTime investment: 3 months, 5\\x0010 hours/week\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Gradient descent visualization and intuition\\nBias-variance tradeoff explanations\\nRegularization techniques\\nModel evaluation strategies\\nTime investment: 3 months, 5\\x0010 hours/week\\nKey outcome: You'll understand WHY algorithms work, not just HOW to use them\\x008\\x00\\nKaggle Learn Courses: Free micro-courses on ML fundamentals\\nMost valuable: Intro to Machine Learning + Intermediate Machine Learning\\nProjects: Start with Titanic, House Prices, then progress to harder competitions\\nEssential Algorithms Deep Dive\\nLinear/Logistic Regression\\nDecision Trees and Random Forests\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 2, 'page_label': '3', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Unsupervised Learning\\nModel Evaluation\\nAndrej Karpathy\\'s \"Neural Networks: Zero to Hero\"\\n3Blue1Brown Neural Network Series\\nAndrew Ng\\'s Deep Learning Specialization\\nSupport Vector Machines\\nk-Nearest Neighbors\\nk-Means Clustering\\nPrincipal Component Analysis \\x00PCA\\x00\\nAnomaly Detection\\nCross-validation techniques\\nPrecision, recall, F1-score\\nROC curves and AUC\\nResource: scikit-learn documentation + hands-on practice\\x002\\x00\\nPhase 3\\x00 Deep Learning Revolution \\x00Months 5\\x006\\x00\\nNeural Networks from First Principles\\n\\x009\\x00\\x0010\\x00\\x0011\\x00\\nWhy it\\'s invaluable: Learn by building everything from scratch in code\\nMost critical sections:\\nMicrograd: Build an autograd engine (understand backpropagation deeply)\\nBuilding GPT from scratch: Modern transformer implementation\\nPyTorch internals: How frameworks actually work\\nUnique value: Unlike other courses, this shows you the \"magic\" behind the frameworks\\x0012\\x00\\n\\x0013\\x00\\x0014\\x00\\x003\\x00\\nWhy it\\'s essential: Visual intuition for mathematical concepts\\nMost valuable videos:'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 2, 'page_label': '3', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Unique value: Unlike other courses, this shows you the \"magic\" behind the frameworks\\x0012\\x00\\n\\x0013\\x00\\x0014\\x00\\x003\\x00\\nWhy it\\'s essential: Visual intuition for mathematical concepts\\nMost valuable videos:\\n\"But what is a neural network?\"—conceptual foundation\\n\"Gradient descent\"—optimization visualization\\n\"Backpropagation\"—the learning algorithm\\nKey benefit: You\\'ll develop intuitive understanding alongside mathematical rigor\\n\\x007\\x00\\x006\\x00\\nCourse 1: Neural Networks and Deep Learning\\nCourse 2: Improving Deep Neural Networks (regularization, optimization)\\nCourse 3: Structuring Machine Learning Projects\\nCourse 4: Convolutional Neural Networks'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 3, 'page_label': '4', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Stanford CS231n: Convolutional Neural Networks\\nFast.ai Practical Deep Learning for Coders\\nHugging Face Course\\nAttention Mechanisms & Transformers\\nCourse 5: Sequence Models\\nWhy it works: Systematic progression from basics to advanced topics\\x008\\x00\\nComputer Vision Mastery\\n\\x0015\\x00\\x0016\\x00\\x0017\\x00\\nWhy it's legendary: Gold standard for computer vision education\\nMost valuable lectures:\\nCNN architectures \\x00AlexNet, VGGNet, ResNet)\\nTransfer learning and fine-tuning\\nObject detection and segmentation\\nAssignments: Build CNNs from scratch, implement backpropagation\\nCareer impact: Many top AI engineers cite this course as transformative\\x0015\\x00\\nPractical Implementation\\n\\x0018\\x00\\x0019\\x00\\x0020\\x00\\x0021\\x00\\nWhy it's revolutionary: Top-down approach—build real applications first\\nMost valuable aspects:\\nDeploy a working model by lesson 2\\nTransfer learning techniques\\nData augmentation strategies\\nProduction deployment methods\\nPhilosophy: Learn by doing, theory follows practice\\x0020\\x00\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 3, 'page_label': '4', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Deploy a working model by lesson 2\\nTransfer learning techniques\\nData augmentation strategies\\nProduction deployment methods\\nPhilosophy: Learn by doing, theory follows practice\\x0020\\x00\\nOutcome: You'll be building and deploying real AI applications quickly\\nPhase 4\\x00 Modern AI Systems \\x00Months 7\\x008\\x00\\nLarge Language Models & NLP\\n\\x0022\\x00\\x0023\\x00\\x0024\\x00\\x0025\\x00\\nWhy it's crucial: Industry-standard library for NLP\\nMost valuable sections:\\nChapters 1\\x004: Transformer architecture deep dive\\nChapters 5\\x008: Fine-tuning and tokenization\\nChapters 9\\x0012: Advanced LLM techniques\\nPractical value: You'll learn to work with GPT, BERT, T5, and other SOTA models\\x0022\\x00\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 4, 'page_label': '5', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Building RAG Applications\\nAdvanced RAG Techniques\\nModel Deployment & Monitoring\\nScaling AI Systems\\nComputer Vision Advanced Topics\\n\"Attention Is All You Need\" paper: The foundational research\\nIllustrated Transformer blog post: Visual explanation\\nImplementation: Build a transformer from scratch (following Karpathy\\'s tutorial)\\nGenerative AI & RAG Systems\\n\\x001\\x00\\nLangChain documentation: Framework for LLM applications\\nVector databases: Pinecone, Chroma, Weaviate\\nEmbedding models: OpenAI, Sentence-BERT, instructor-xl\\nReal projects: Build document Q&A, code assistant, research tool\\nAgentic RAG: Multi-step reasoning and tool use\\nRAG optimization: Chunking strategies, retrieval improvement\\nProduction deployment: FastAPI, Docker, cloud platforms\\nPhase 5\\x00 Advanced AI Engineering \\x00Months 9\\x0012\\x00\\nMLOps & Production Systems\\nDocker containerization: Reproducible environments\\nAPI development: FastAPI, Flask\\nCloud platforms: AWS SageMaker, Google Cloud AI, Azure ML'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 4, 'page_label': '5', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='MLOps & Production Systems\\nDocker containerization: Reproducible environments\\nAPI development: FastAPI, Flask\\nCloud platforms: AWS SageMaker, Google Cloud AI, Azure ML\\nModel monitoring: Data drift, performance degradation\\nCI/CD for ML: GitHub Actions, model versioning\\nDistributed training: Multi-GPU, multi-node\\nModel optimization: Quantization, pruning, distillation\\nInference optimization: TensorRT, ONNX, TorchScript\\nResource: MLOps Specialization (DeepLearning.AI)\\nSpecialized Domains\\nObject detection: YOLO, R\\x00CNN family\\nSegmentation: U\\x00Net, Mask R\\x00CNN'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Reinforcement Learning\\nAndrew Ng's Courses (DeepLearning.AI)\\nAndrej Karpathy's Neural Networks: Zero to Hero\\nFast.ai Practical Deep Learning\\nStanford CS231n\\nHugging Face Course\\nGenerative models: GANs, Diffusion models\\nResource: CS231n advanced lectures + papers\\nOpenAI Gymnasium: RL environments\\nDeep Q\\x00Networks \\x00DQN\\x00: Value-based methods\\nPolicy gradients: Actor-critic methods\\nResource: Spinning Up in Deep RL \\x00OpenAI\\x00\\nCritical Learning Resources & Their Value\\nTier 1\\x00 Absolutely Essential\\n\\x006\\x00\\x008\\x00\\nValue: Systematic, rigorous, practical\\nBest for: Building strong fundamentals\\nInvestment: $49/month, worth every penny\\nCareer impact: 9/10\\n\\x0010\\x00\\x009\\x00\\nValue: Unparalleled depth and clarity\\nBest for: Understanding how things actually work\\nInvestment: Free on YouTube\\nCareer impact: 10/10\\n\\x0021\\x00\\x0018\\x00\\nValue: Rapid practical skills development\\nBest for: Building real applications quickly\\nInvestment: Free\\nCareer impact: 9/10\\nTier 2\\x00 Highly Valuable\\n\\x0017\\x00\\x0015\\x00\\nValue: Academic rigor meets practical application\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Best for: Building real applications quickly\\nInvestment: Free\\nCareer impact: 9/10\\nTier 2\\x00 Highly Valuable\\n\\x0017\\x00\\x0015\\x00\\nValue: Academic rigor meets practical application\\nBest for: Computer vision specialization\\nInvestment: Free (auditing), challenging time commitment\\nCareer impact: 8/10\\n\\x0022\\x00'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 6, 'page_label': '7', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='3Blue1Brown Visual Series\\nGoogle AI Course \\x00Coursera)\\nIBM AI Foundations\\nValue: Industry-standard NLP skills\\nBest for: Modern NLP applications\\nInvestment: Free\\nCareer impact: 8/10\\n\\x0013\\x00\\x003\\x00\\nValue: Intuitive mathematical understanding\\nBest for: Building deep conceptual knowledge\\nInvestment: Free on YouTube\\nCareer impact: 7/10\\nTier 3\\x00 Supplementary\\n\\x0026\\x00\\nValue: Broad overview, less depth\\nBest for: Business understanding of AI\\nCareer impact: 6/10\\n\\x0027\\x00\\nValue: Beginner-friendly introduction\\nBest for: Absolute beginners\\nCareer impact: 5/10\\nHands-On Project Progression\\nMonths 1\\x002\\x00 Foundation Projects\\n\\x00\\x00\\x00Data Analysis Portfolio: Analyze 3 different datasets with pandas/matplotlib\\n\\x00\\x00\\x00Web Scraping Bot: Extract and analyze web data\\n\\x00\\x00\\x00Statistical Analysis: A/B testing, hypothesis testing\\nMonths 3\\x004\\x00 Machine Learning Projects\\n\\x00\\x00\\x00Prediction Model: House price prediction with feature engineering\\n\\x00\\x00\\x00Classification System: Customer churn prediction\\n\\x00\\x00\\x00Clustering Analysis: Customer segmentation'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 6, 'page_label': '7', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x00\\x00\\x00Prediction Model: House price prediction with feature engineering\\n\\x00\\x00\\x00Classification System: Customer churn prediction\\n\\x00\\x00\\x00Clustering Analysis: Customer segmentation\\n\\x00\\x00\\x00End-to-end ML Pipeline: Data →  Model →  Deployment'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 7, 'page_label': '8', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Months 5\\x006\\x00 Deep Learning Applications\\n\\x00\\x00\\x00Image Classifier: Custom CNN for your domain of interest\\n\\x00\\x00\\x00Text Sentiment Analyzer: RNN/LSTM for sentiment analysis\\n\\x00\\x00\\x00Recommender System: Collaborative filtering with neural networks\\n\\x00\\x00\\x00Transfer Learning Project: Fine-tune pre-trained models\\nMonths 7\\x008\\x00 Modern AI Systems\\n\\x00\\x00\\x00RAG Chatbot: Document Q&A system with vector database\\n\\x00\\x00\\x00Code Assistant: LLM-powered programming helper\\n\\x00\\x00\\x00Multi-modal Application: Text + image processing\\n\\x00\\x00\\x00API Service: Deploy models as production APIs\\nMonths 9\\x0012\\x00 Advanced Projects\\n\\x00\\x00\\x00Distributed Training: Scale model training across multiple GPUs\\n\\x00\\x00\\x00Model Optimization: Quantize and optimize for mobile/edge\\n\\x00\\x00\\x00MLOps Pipeline: Complete CI/CD for ML models\\n\\x00\\x00\\x00Research Project: Implement and improve a recent paper\\nLearning Strategy & Best Practices\\nThe 80/20 Approach\\n80% hands-on coding: Build, experiment, break things\\n20% theory: Understand the \"why\" behind the \"how\"'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 7, 'page_label': '8', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='Learning Strategy & Best Practices\\nThe 80/20 Approach\\n80% hands-on coding: Build, experiment, break things\\n20% theory: Understand the \"why\" behind the \"how\"\\nActive learning: Don\\'t just watch videos—implement everything\\nCommunity & Networking\\nDiscord communities: Join course-specific Discord servers\\nGitHub contributions: Build a strong portfolio of projects\\nKaggle competitions: Practice on real datasets\\nTwitter/LinkedIn: Follow AI researchers and practitioners\\nLocal meetups: Connect with other learners\\nCommon Pitfalls to Avoid\\n\\x00\\x00\\x00Tutorial Hell: Don\\'t just consume content—create projects\\n\\x00\\x00\\x00Perfectionism: Start building before you feel \"ready\"\\n\\x00\\x00\\x00Skipping Math: Mathematical understanding accelerates learning'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 8, 'page_label': '9', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"The AI field moves incredibly fast, but these fundamentals will serve you for decades. Focus on\\ndepth over breadth, build constantly, and remember that every expert was once a beginner. The\\ntools and frameworks will change, but the mathematical foundations and problem-solving\\napproaches you learn here will make you adaptable to any future AI development.\\nThis roadmap has been battle-tested by thousands of successful AI engineers. Trust the\\nprocess, stay consistent, and you'll be amazed at what you can build in just one year. The AI\\n\\x00\\x00\\x00Isolation: Learn with others, ask questions, share progress\\n\\x00\\x00\\x00Following Trends: Focus on fundamentals over flashy new techniques\\nTimeline & Milestones\\nMonth 3 Milestone: Machine Learning Practitioner\\nBuild and deploy a simple ML model\\nUnderstand bias-variance tradeoff\\nKnow when to use different algorithms\\nMonth 6 Milestone: Deep Learning Engineer\\nImplement neural networks from scratch\\nBuild computer vision applications\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 8, 'page_label': '9', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"Understand bias-variance tradeoff\\nKnow when to use different algorithms\\nMonth 6 Milestone: Deep Learning Engineer\\nImplement neural networks from scratch\\nBuild computer vision applications\\nUnderstand modern architectures \\x00CNNs, RNNs, Transformers)\\nMonth 9 Milestone: AI Application Developer\\nBuild LLM-powered applications\\nWork with vector databases and RAG systems\\nDeploy models to production\\nMonth 12 Milestone: Senior AI Engineer\\nDesign end-to-end AI systems\\nOptimize models for production\\nContribute to open source projects\\nReady for senior AI engineering roles\\nYour Next Steps\\n\\x00\\x00\\x00Week 1: Set up your development environment \\x00Python, Jupyter, Git)\\n\\x00\\x00\\x00Week 2: Start Andrew Ng's Machine Learning Course\\n\\x00\\x00\\x00Week 3: Begin your first project while following the course\\n\\x00\\x00\\x00Week 4: Join relevant Discord communities and start networking\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content=\"revolution is just beginning, and there's never been a better time to join it.\\n⁂\\n\\x00\\x00\\x00https://github.com/krishnaik06/Complete-RoadMap-To-Learn-AI\\n\\x00\\x00\\x00https://www.geeksforgeeks.org/blogs/machine-learning-roadmap/\\n\\x00\\x00\\x00https://www.3blue1brown.com/lessons/neural-networks\\n\\x00\\x00\\x00https://www.3blue1brown.com/topics/neural-networks\\n\\x00\\x00\\x00https://github.com/aadi1011/AI\\x00ML\\x00Roadmap-from-scratch\\n\\x00\\x00\\x00https://www.coursera.org/specializations/deep-learning\\n\\x00\\x00\\x00https://www.coursera.org/courses?query=machine+learning+andrew+ng\\n\\x00\\x00\\x00https://www.learndatasci.com/best-artificial-intelligence-ai-courses/\\n\\x00\\x00\\x00https://karpathy.ai/zero-to-hero.html\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=VMj-3S1tku0\\n\\x00\\x00\\x00\\x00https://briansigafoos.com/neural-networks-karpathy/\\n\\x00\\x00\\x00\\x00https://www.linkedin.com/posts/sumanth077_neural-networks-zero-to-hero-by-andrej-karpathy-activit\\ny-7366011507102400512-dg3x\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=aircAruvnKk&vl=en\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=IHZwWFHWa-w\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='y-7366011507102400512-dg3x\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=aircAruvnKk&vl=en\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=IHZwWFHWa-w\\n\\x00\\x00\\x00\\x00https://www.machinelearningmastery.com/stanford-convolutional-neural-networks-for-visual-recogniti\\non-course-review/\\n\\x00\\x00\\x00\\x00https://cs231n.stanford.edu/slides/2025/lecture_1_part_2.pdf\\n\\x00\\x00\\x00\\x00https://cs231n.github.io\\n\\x00\\x00\\x00\\x00https://www.fast.ai/posts/2022\\x0007\\x0021-dl-coders-22.html\\n\\x00\\x00\\x00\\x00https://towardsai.net/p/l/7-lessons-from-fast-ai-deep-learning-course\\n\\x00\\x00\\x00\\x00https://www.machinelearningmastery.com/practical-deep-learning-for-coders-review/\\n\\x00\\x00\\x00\\x00https://course.fast.ai\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/chapter1/1\\n\\x00\\x00\\x00\\x00https://wandb.ai/int_pb/huggingface/reports/An-Introduction-To-HuggingFace-Transformers-for-NLP\\x00-\\nVmlldzoyOTgzMjI5\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/5\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/4\\n\\x00\\x00\\x00\\x00https://www.digitalocean.com/resources/articles/ai-courses\\n\\x00\\x00\\x00\\x00https://zapier.com/blog/best-ai-courses/'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/4\\n\\x00\\x00\\x00\\x00https://www.digitalocean.com/resources/articles/ai-courses\\n\\x00\\x00\\x00\\x00https://zapier.com/blog/best-ai-courses/\\n\\x00\\x00\\x00\\x00https://www.geeksforgeeks.org/blogs/deep-learning-roadmap/\\n\\x00\\x00\\x00\\x00https://www.v7labs.com/blog/deep-learning-guide\\n\\x00\\x00\\x00\\x00https://www.coursera.org/courses?query=artificial+intelligence\\n\\x00\\x00\\x00\\x00https://magnimindacademy.com/blog/deep-learning-structure-guide-for-beginners/\\n\\x00\\x00\\x00\\x00https://roadmap.sh/ai-engineer\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=PUlSon0DIus'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 10, 'page_label': '11', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x00\\x00\\x00\\x00https://cognitiveclass.ai/learn/deep-learning\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=7IgVGSaQPaw\\n\\x00\\x00\\x00\\x00https://grow.google/ai/\\n\\x00\\x00\\x00\\x00https://www.kaggle.com/learn/intro-to-deep-learning\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/learnmachinelearning/comments/1lbs4qi/a_clear_roadmap_to_complete_learni\\nng_aiml_by_the/\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/learnmachinelearning/comments/1j5trra/best_resources_to_learn_pytorch_in_2\\n025/\\n\\x00\\x00\\x00\\x00https://www.geeksforgeeks.org/deep-learning/introduction-deep-learning/\\n\\x00\\x00\\x00\\x00https://www.aimlengineer.io/p/breaking-into-aiml-in-2025-a-step\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/learnmachinelearning/comments/w4\\x00626/the_new_version_of_fastais_practic\\nal_deep/\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/3\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/ai-for-everyone/\\n\\x00\\x00\\x00\\x00https://course.fast.ai/Resources/testimonials.html\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/2'),\n",
       " Document(metadata={'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-09-18T06:57:33+00:00', 'moddate': '2025-09-18T06:57:33+00:00', 'source': '..\\\\data\\\\pdf\\\\__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'total_pages': 11, 'page': 10, 'page_label': '11', 'source_file': '__The_Ultimate_AI_Engineering_Learning_Roadmap__Fr[1].pdf', 'file_type': 'pdf'}, page_content='\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/ai-for-everyone/\\n\\x00\\x00\\x00\\x00https://course.fast.ai/Resources/testimonials.html\\n\\x00\\x00\\x00\\x00https://huggingface.co/learn/llm-course/en/chapter1/2\\n\\x00\\x00\\x00\\x00https://www.deeplearning.ai/courses/generative-ai-for-everyone/\\n\\x00\\x00\\x00\\x00https://news.ycombinator.com/item?id=32186647\\n\\x00\\x00\\x00\\x00https://www.reddit.com/r/deeplearning/comments/1dqkqhd/does_andrej_karpathys_neural_networks_z\\nero_to/\\n\\x00\\x00\\x00\\x00https://cs231n.stanford.edu\\n\\x00\\x00\\x00\\x00https://www.youtube.com/watch?v=2fq9wYslV0A\\n\\x00\\x00\\x00\\x00https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB\\x003pi\\n\\x00\\x00\\x00\\x00https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ\\n\\x00\\x00\\x00\\x00https://cs231n.stanford.edu/project.html\\n\\x00\\x00\\x00\\x00https://www.youtube.com/c/3blue1brown\\n\\x00\\x00\\x00\\x00http://karpathy.github.io/neuralnets/\\n\\x00\\x00\\x00\\x00https://www.youtube.com/playlist?list=PLoROMvodv4rOmsNzYBMe0gJY2XS8AQg16')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b34ab0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 359 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (359, 384)\n",
      "Adding 359 documents to vector store...\n",
      "Successfully added 359 documents to vector store\n",
      "Total documents in collection: 2776\n"
     ]
    }
   ],
   "source": [
    "### convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "\n",
    "##Generate the embeddings\n",
    "\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "##Store in the vector database\n",
    "\n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3d809",
   "metadata": {},
   "source": [
    "### retriever pipeline from vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "977e3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "\n",
    "         # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95223493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What are news values'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_80158d1d_112',\n",
       "  'content': '7 \\n \\nWhat is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \\nsociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \\nstudies. Stuart Hall states that:  \\nThe media do not simply and transparently  report events which are \\nnaturally newsworthy in themselves. News is the end product of a \\ncomplex process, which begins with systematic sorting and selecting \\nof events and topics according to a socially constructed set of \\ncategories.  \\n       Stuart Hall ( in Fowler1991:12) \\n  Philo goes on even further to maintain that news is not found or even gathered. It is a \\ncreation of a journalistic process, an artefact, and a commodity ( in Fowler 1991). The last \\nstatement, as discussed above, is hardly applicable in the contemporary era of mass \\ncommunication, where, with the existence of the internet, everybody can have access to \\npractically any nugget of information. Brighton and Foy are of the opinion that:',\n",
       "  'metadata': {'source_file': '12037624.pdf',\n",
       "   'total_pages': 30,\n",
       "   'creator': 'PScript5.dll Version 5.2',\n",
       "   'page_label': '7',\n",
       "   'producer': 'GPL Ghostscript 8.56',\n",
       "   'page': 6,\n",
       "   'title': 'Microsoft Word - news values revised',\n",
       "   'creationdate': '2011-08-30T06:57:22+00:00',\n",
       "   'file_type': 'pdf',\n",
       "   'content_length': 992,\n",
       "   'doc_index': 112,\n",
       "   'moddate': '2011-08-30T06:57:22+00:00',\n",
       "   'author': 'user',\n",
       "   'source': '..\\\\data\\\\pdf\\\\12037624.pdf'},\n",
       "  'similarity_score': 0.5879889130592346,\n",
       "  'distance': 0.4120110869407654,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_aa83a9e0_112',\n",
       "  'content': '7 \\n \\nWhat is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \\nsociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \\nstudies. Stuart Hall states that:  \\nThe media do not simply and transparently  report events which are \\nnaturally newsworthy in themselves. News is the end product of a \\ncomplex process, which begins with systematic sorting and selecting \\nof events and topics according to a socially constructed set of \\ncategories.  \\n       Stuart Hall ( in Fowler1991:12) \\n  Philo goes on even further to maintain that news is not found or even gathered. It is a \\ncreation of a journalistic process, an artefact, and a commodity ( in Fowler 1991). The last \\nstatement, as discussed above, is hardly applicable in the contemporary era of mass \\ncommunication, where, with the existence of the internet, everybody can have access to \\npractically any nugget of information. Brighton and Foy are of the opinion that:',\n",
       "  'metadata': {'title': 'Microsoft Word - news values revised',\n",
       "   'creator': 'PScript5.dll Version 5.2',\n",
       "   'doc_index': 112,\n",
       "   'creationdate': '2011-08-30T06:57:22+00:00',\n",
       "   'source_file': '12037624.pdf',\n",
       "   'source': '..\\\\data\\\\pdf\\\\12037624.pdf',\n",
       "   'total_pages': 30,\n",
       "   'file_type': 'pdf',\n",
       "   'moddate': '2011-08-30T06:57:22+00:00',\n",
       "   'page_label': '7',\n",
       "   'page': 6,\n",
       "   'content_length': 992,\n",
       "   'author': 'user',\n",
       "   'producer': 'GPL Ghostscript 8.56'},\n",
       "  'similarity_score': 0.5879889130592346,\n",
       "  'distance': 0.4120110869407654,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_ba3a927a_112',\n",
       "  'content': '7 \\n \\nWhat is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \\nsociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \\nstudies. Stuart Hall states that:  \\nThe media do not simply and transparently  report events which are \\nnaturally newsworthy in themselves. News is the end product of a \\ncomplex process, which begins with systematic sorting and selecting \\nof events and topics according to a socially constructed set of \\ncategories.  \\n       Stuart Hall ( in Fowler1991:12) \\n  Philo goes on even further to maintain that news is not found or even gathered. It is a \\ncreation of a journalistic process, an artefact, and a commodity ( in Fowler 1991). The last \\nstatement, as discussed above, is hardly applicable in the contemporary era of mass \\ncommunication, where, with the existence of the internet, everybody can have access to \\npractically any nugget of information. Brighton and Foy are of the opinion that:',\n",
       "  'metadata': {'title': 'Microsoft Word - news values revised',\n",
       "   'page': 6,\n",
       "   'creationdate': '2011-08-30T06:57:22+00:00',\n",
       "   'creator': 'PScript5.dll Version 5.2',\n",
       "   'producer': 'GPL Ghostscript 8.56',\n",
       "   'source': '..\\\\data\\\\pdf\\\\12037624.pdf',\n",
       "   'page_label': '7',\n",
       "   'doc_index': 112,\n",
       "   'total_pages': 30,\n",
       "   'moddate': '2011-08-30T06:57:22+00:00',\n",
       "   'author': 'user',\n",
       "   'source_file': '12037624.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'content_length': 992},\n",
       "  'similarity_score': 0.5879889130592346,\n",
       "  'distance': 0.4120110869407654,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_c75ce9f7_112',\n",
       "  'content': '7 \\n \\nWhat is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \\nsociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \\nstudies. Stuart Hall states that:  \\nThe media do not simply and transparently  report events which are \\nnaturally newsworthy in themselves. News is the end product of a \\ncomplex process, which begins with systematic sorting and selecting \\nof events and topics according to a socially constructed set of \\ncategories.  \\n       Stuart Hall ( in Fowler1991:12) \\n  Philo goes on even further to maintain that news is not found or even gathered. It is a \\ncreation of a journalistic process, an artefact, and a commodity ( in Fowler 1991). The last \\nstatement, as discussed above, is hardly applicable in the contemporary era of mass \\ncommunication, where, with the existence of the internet, everybody can have access to \\npractically any nugget of information. Brighton and Foy are of the opinion that:',\n",
       "  'metadata': {'page_label': '7',\n",
       "   'author': 'user',\n",
       "   'creator': 'PScript5.dll Version 5.2',\n",
       "   'creationdate': '2011-08-30T06:57:22+00:00',\n",
       "   'total_pages': 30,\n",
       "   'source_file': '12037624.pdf',\n",
       "   'source': '..\\\\data\\\\pdf\\\\12037624.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'page': 6,\n",
       "   'content_length': 992,\n",
       "   'producer': 'GPL Ghostscript 8.56',\n",
       "   'moddate': '2011-08-30T06:57:22+00:00',\n",
       "   'title': 'Microsoft Word - news values revised',\n",
       "   'doc_index': 112},\n",
       "  'similarity_score': 0.5879889130592346,\n",
       "  'distance': 0.4120110869407654,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_619b1ef0_112',\n",
       "  'content': '7 \\n \\nWhat is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \\nsociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \\nstudies. Stuart Hall states that:  \\nThe media do not simply and transparently  report events which are \\nnaturally newsworthy in themselves. News is the end product of a \\ncomplex process, which begins with systematic sorting and selecting \\nof events and topics according to a socially constructed set of \\ncategories.  \\n       Stuart Hall ( in Fowler1991:12) \\n  Philo goes on even further to maintain that news is not found or even gathered. It is a \\ncreation of a journalistic process, an artefact, and a commodity ( in Fowler 1991). The last \\nstatement, as discussed above, is hardly applicable in the contemporary era of mass \\ncommunication, where, with the existence of the internet, everybody can have access to \\npractically any nugget of information. Brighton and Foy are of the opinion that:',\n",
       "  'metadata': {'doc_index': 112,\n",
       "   'title': 'Microsoft Word - news values revised',\n",
       "   'total_pages': 30,\n",
       "   'creationdate': '2011-08-30T06:57:22+00:00',\n",
       "   'page_label': '7',\n",
       "   'source': '..\\\\data\\\\pdf\\\\12037624.pdf',\n",
       "   'source_file': '12037624.pdf',\n",
       "   'creator': 'PScript5.dll Version 5.2',\n",
       "   'moddate': '2011-08-30T06:57:22+00:00',\n",
       "   'producer': 'GPL Ghostscript 8.56',\n",
       "   'content_length': 992,\n",
       "   'author': 'user',\n",
       "   'page': 6,\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': 0.5879889130592346,\n",
       "  'distance': 0.4120110869407654,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"What are news values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wkmej6glqk",
   "metadata": {},
   "source": [
    "### RAG with Gemini LLM - Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "t4h3ti37z9m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GeminiLLM initialized with gemini-2.5-flash\n",
      "   Temperature: 0.1, Max tokens: 500\n"
     ]
    }
   ],
   "source": [
    "class GeminiLLM:\n",
    "    \"\"\"Wrapper for Google Gemini 2.5 Flash API optimized for RAG\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str = \"gemini-2.5-flash\",\n",
    "        temperature: float = 0.1,\n",
    "        max_output_tokens: int = 500,\n",
    "        top_p: float = 0.95,\n",
    "        top_k: int = 40\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Generation config optimized for factual Q&A\n",
    "        self.generation_config = {\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\": top_k,\n",
    "            \"max_output_tokens\": max_output_tokens,\n",
    "        }\n",
    "        \n",
    "        # Safety settings (adjust as needed)\n",
    "        self.safety_settings = [\n",
    "            {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "        ]\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = genai.GenerativeModel(\n",
    "            model_name=self.model_name,\n",
    "            generation_config=self.generation_config,\n",
    "            safety_settings=self.safety_settings\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ GeminiLLM initialized with {self.model_name}\")\n",
    "        print(f\"   Temperature: {temperature}, Max tokens: {max_output_tokens}\")\n",
    "    \n",
    "    def generate(self, prompt: str, max_retries: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Generate response with retry logic\n",
    "        \n",
    "        Args:\n",
    "            prompt: The input prompt\n",
    "            max_retries: Number of retry attempts on failure\n",
    "            \n",
    "        Returns:\n",
    "            Generated text response\n",
    "        \"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.model.generate_content(prompt)\n",
    "                return response.text.strip()\n",
    "            \n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = 2 ** attempt  # Exponential backoff\n",
    "                    print(f\"⚠️  Attempt {attempt + 1} failed: {e}\")\n",
    "                    print(f\"   Retrying in {wait_time}s...\")\n",
    "                    import time\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"❌ All {max_retries} attempts failed\")\n",
    "                    raise\n",
    "\n",
    "# Initialize Gemini LLM\n",
    "gemini_llm = GeminiLLM(\n",
    "    temperature=0.1,      # Low temperature for factual responses\n",
    "    max_output_tokens=500,\n",
    "    top_p=0.95,\n",
    "    top_k=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "uszk6qjde0h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: models/gemini-2.5-pro-preview-03-25\n",
      "  Display name: Gemini 2.5 Pro Preview 03-25\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-flash-preview-05-20\n",
      "  Display name: Gemini 2.5 Flash Preview 05-20\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-flash\n",
      "  Display name: Gemini 2.5 Flash\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-flash-lite-preview-06-17\n",
      "  Display name: Gemini 2.5 Flash-Lite Preview 06-17\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-pro-preview-05-06\n",
      "  Display name: Gemini 2.5 Pro Preview 05-06\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-pro-preview-06-05\n",
      "  Display name: Gemini 2.5 Pro Preview\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-pro\n",
      "  Display name: Gemini 2.5 Pro\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-exp\n",
      "  Display name: Gemini 2.0 Flash Experimental\n",
      "  Supported methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash\n",
      "  Display name: Gemini 2.0 Flash\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-001\n",
      "  Display name: Gemini 2.0 Flash 001\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-exp-image-generation\n",
      "  Display name: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "  Supported methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-lite-001\n",
      "  Display name: Gemini 2.0 Flash-Lite 001\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-lite\n",
      "  Display name: Gemini 2.0 Flash-Lite\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-preview-image-generation\n",
      "  Display name: Gemini 2.0 Flash Preview Image Generation\n",
      "  Supported methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-lite-preview-02-05\n",
      "  Display name: Gemini 2.0 Flash-Lite Preview 02-05\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-lite-preview\n",
      "  Display name: Gemini 2.0 Flash-Lite Preview\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-pro-exp\n",
      "  Display name: Gemini 2.0 Pro Experimental\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-pro-exp-02-05\n",
      "  Display name: Gemini 2.0 Pro Experimental 02-05\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-exp-1206\n",
      "  Display name: Gemini Experimental 1206\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-thinking-exp-01-21\n",
      "  Display name: Gemini 2.5 Flash Preview 05-20\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-thinking-exp\n",
      "  Display name: Gemini 2.5 Flash Preview 05-20\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.0-flash-thinking-exp-1219\n",
      "  Display name: Gemini 2.5 Flash Preview 05-20\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-flash-preview-tts\n",
      "  Display name: Gemini 2.5 Flash Preview TTS\n",
      "  Supported methods: ['countTokens', 'generateContent']\n",
      "\n",
      "Model: models/gemini-2.5-pro-preview-tts\n",
      "  Display name: Gemini 2.5 Pro Preview TTS\n",
      "  Supported methods: ['countTokens', 'generateContent']\n",
      "\n",
      "Model: models/learnlm-2.0-flash-experimental\n",
      "  Display name: LearnLM 2.0 Flash Experimental\n",
      "  Supported methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model: models/gemma-3-1b-it\n",
      "  Display name: Gemma 3 1B\n",
      "  Supported methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model: models/gemma-3-4b-it\n",
      "  Display name: Gemma 3 4B\n",
      "  Supported methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model: models/gemma-3-12b-it\n",
      "  Display name: Gemma 3 12B\n",
      "  Supported methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model: models/gemma-3-27b-it\n",
      "  Display name: Gemma 3 27B\n",
      "  Supported methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model: models/gemma-3n-e4b-it\n",
      "  Display name: Gemma 3n E4B\n",
      "  Supported methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model: models/gemma-3n-e2b-it\n",
      "  Display name: Gemma 3n E2B\n",
      "  Supported methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model: models/gemini-flash-latest\n",
      "  Display name: Gemini Flash Latest\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-flash-lite-latest\n",
      "  Display name: Gemini Flash-Lite Latest\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-pro-latest\n",
      "  Display name: Gemini Pro Latest\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-flash-lite\n",
      "  Display name: Gemini 2.5 Flash-Lite\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-flash-image-preview\n",
      "  Display name: Nano Banana\n",
      "  Supported methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-flash-image\n",
      "  Display name: Nano Banana\n",
      "  Supported methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-flash-preview-09-2025\n",
      "  Display name: Gemini 2.5 Flash Preview Sep 2025\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-2.5-flash-lite-preview-09-2025\n",
      "  Display name: Gemini 2.5 Flash-Lite Preview Sep 2025\n",
      "  Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "Model: models/gemini-robotics-er-1.5-preview\n",
      "  Display name: Gemini Robotics-ER 1.5 Preview\n",
      "  Supported methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model: models/gemini-2.5-computer-use-preview-10-2025\n",
      "  Display name: Gemini 2.5 Computer Use Preview 10-2025\n",
      "  Supported methods: ['generateContent', 'countTokens']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List available models to find the correct one\n",
    "for model in genai.list_models():\n",
    "    if 'generateContent' in model.supported_generation_methods:\n",
    "        print(f\"Model: {model.name}\")\n",
    "        print(f\"  Display name: {model.display_name}\")\n",
    "        print(f\"  Supported methods: {model.supported_generation_methods}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bs8kyg706ih",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(query: str, top_k: int = 3) -> dict:\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline: Retrieve relevant context + Generate answer\n",
    "\n",
    "    Args:\n",
    "        query: User's question\n",
    "        top_k: Number of relevant chunks to retrieve\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with answer, sources, and metadata\n",
    "    \"\"\"\n",
    "    print(f\"📝 Query: {query}\")\n",
    "    print(f\"🔍 Retrieving top {top_k} relevant chunks...\\n\")\n",
    "\n",
    "    # Step 1: Retrieve relevant documents (returns list of dicts)\n",
    "    results = rag_retriever.retrieve(query, top_k=top_k)\n",
    "\n",
    "    if not results:\n",
    "        return {\n",
    "            \"answer\": \"I couldn't find relevant information to answer this question.\",\n",
    "            \"sources\": [],\n",
    "            \"context_used\": \"\"\n",
    "        }\n",
    "\n",
    "    # Step 2: Build context from retrieved chunks\n",
    "    context_parts = []\n",
    "    for i, doc_dict in enumerate(results, 1):\n",
    "        content = doc_dict['content']\n",
    "        metadata = doc_dict['metadata']\n",
    "        source = metadata.get('source', 'Unknown')\n",
    "        page = metadata.get('page', 'N/A')\n",
    "        similarity = doc_dict['similarity_score']\n",
    "\n",
    "        context_parts.append(f\"[Source {i}: {source}, Page {page}]\\n{content}\")\n",
    "        print(f\"📄 Source {i}: {source} (Page {page}) - Similarity: {similarity:.1%}\")\n",
    "\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    # Step 3: Build RAG prompt\n",
    "    prompt = f\"\"\"You are a helpful assistant that answers questions based on the provided context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Instructions:\n",
    "- Answer based ONLY on the information in the context above\n",
    "- If the context doesn't contain enough information, say so\n",
    "- Be concise but complete\n",
    "- Cite which source(s) you used\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Step 4: Generate answer\n",
    "    print(f\"\\n🤖 Generating answer with Gemini...\\n\")\n",
    "    answer = gemini_llm.generate(prompt)\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"sources\": [\n",
    "            {\n",
    "                \"source\": doc_dict['metadata'].get('source', 'Unknown'),\n",
    "                \"page\": doc_dict['metadata'].get('page', 'N/A'),\n",
    "                \"similarity\": doc_dict['similarity_score'],\n",
    "                \"content\": doc_dict['content'][:200] + \"...\"  # Preview\n",
    "            }\n",
    "            for doc_dict in results\n",
    "        ],\n",
    "        \"context_used\": context\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bmghk3rl7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Query: What are news values?\n",
      "🔍 Retrieving top 3 relevant chunks...\n",
      "\n",
      "Retrieving documents for query: 'What are news values?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 156.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n",
      "📄 Source 1: ..\\data\\pdf\\12037624.pdf (Page 6) - Similarity: 60.9%\n",
      "📄 Source 2: ..\\data\\pdf\\12037624.pdf (Page 6) - Similarity: 60.9%\n",
      "📄 Source 3: ..\\data\\pdf\\12037624.pdf (Page 6) - Similarity: 60.9%\n",
      "\n",
      "🤖 Generating answer with Gemini...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANSWER:\n",
      "================================================================================\n",
      "News values, also known as newsworthiness, is a term discussed by many linguists, sociologists, and researchers involved in media studies. (Source 1, Source 2, Source 3)\n",
      "\n",
      "================================================================================\n",
      "SOURCES USED:\n",
      "================================================================================\n",
      "\n",
      "1. ..\\data\\pdf\\12037624.pdf (Page 6) - Similarity: 60.9%\n",
      "   Preview: 7 \n",
      " \n",
      "What is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \n",
      "sociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \n",
      "stud...\n",
      "\n",
      "2. ..\\data\\pdf\\12037624.pdf (Page 6) - Similarity: 60.9%\n",
      "   Preview: 7 \n",
      " \n",
      "What is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \n",
      "sociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \n",
      "stud...\n",
      "\n",
      "3. ..\\data\\pdf\\12037624.pdf (Page 6) - Similarity: 60.9%\n",
      "   Preview: 7 \n",
      " \n",
      "What is News Values?  Newsworthiness  or news values  is a term discussed by many linguists, \n",
      "sociologists and, mainly,  researchers dealing, directly or indirectly, with the field of media \n",
      "stud...\n"
     ]
    }
   ],
   "source": [
    "# Test the complete RAG pipeline\n",
    "result = rag_answer(\"What are news values?\", top_k=3)\n",
    "\n",
    "# Display answer\n",
    "print(\"=\" * 80)\n",
    "print(\"ANSWER:\")\n",
    "print(\"=\" * 80)\n",
    "print(result['answer'])\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SOURCES USED:\")\n",
    "print(\"=\" * 80)\n",
    "for i, source in enumerate(result['sources'], 1):\n",
    "    print(f\"\\n{i}. {source['source']} (Page {source['page']}) - Similarity: {source['similarity']:.1%}\")\n",
    "    print(f\"   Preview: {source['content']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
